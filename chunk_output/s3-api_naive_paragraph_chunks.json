{
  "document_id": "4f161031-4dab-487a-8b04-cff65ef06c6a",
  "document_name": "s3-api.txt",
  "chunks": [
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_0",
      "text": "API Reference\nAmazon Simple Storage Service\nAPI Version 2006-03-01\nCopyright \u00a9 2024 Amazon Web Services, Inc. and/or its affiliates. All rights reserved.",
      "start_idx": 0,
      "end_idx": 153,
      "metadata": {
        "num_sentences": 2,
        "num_words": 22,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1",
      "text": "Amazon Simple Storage Service API Reference\nAmazon Simple Storage Service: API Reference\nCopyright \u00a9 2024 Amazon Web Services, Inc. and/or its affiliates. All rights reserved.\nAmazon's trademarks and trade dress may not be used in connection with any product or service\nthat is not Amazon's, in any manner that is likely to cause confusion among customers, or in any\nmanner that disparages or discredits Amazon. All other trademarks not owned by Amazon are\nthe property of their respective owners, who may or may not be affiliated with, connected to, or\nsponsored by Amazon.",
      "start_idx": 155,
      "end_idx": 729,
      "metadata": {
        "num_sentences": 4,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2",
      "text": "Amazon Simple Storage Service API Reference\nTable of Contents\nWelcome........................................................................................................................................... 1\nS3 API Reference ............................................................................................................................. 4\nActions............................................................................................................................................................ 4\nAmazon S3............................................................................................................................................. 11\nAmazon S3 Control ............................................................................................................................ 751\nAmazon S3 on Outposts ................................................................................................................. 1109\nData Types .............................................................................................................................................. 1128\nAmazon S3 ......................................................................................................................................... 1138\nAmazon S3 Control .......................................................................................................................... 1383\nAmazon S3 on Outposts ................................................................................................................. 1594\nDeveloping with Amazon S3 .................................................................................................... 1602\nMaking requests ..................................................................................................................................... 1602\nAbout access keys ............................................................................................................................ 1603\nRequest endpoints ........................................................................................................................... 1605\nMaking requests over IPv6 ............................................................................................................. 1605\nMaking requests using the AWS SDKs ......................................................................................... 1615\nMaking requests using the REST API ........................................................................................... 1655\nUsing the AWS CLI ................................................................................................................................ 1667\nLearn more about the AWS CLI .................................................................................................... 1667\nDeveloping with AWS SDKs ................................................................................................................ 1668\nSDK Programming interfaces ........................................................................................................ 1669\nSpecifying the Signature Version in Request Authentication ................................................. 1669\nGet Amazon S3 request IDs for AWS Support ................................................................................ 1678\nUsing HTTP to obtain request IDs ................................................................................................ 1679\nUsing a web browser to obtain request IDs ............................................................................... 1679\nUsing the AWS SDKs to obtain request IDs ................................................................................ 1680\nUsing the AWS CLI to obtain request IDs ................................................................................... 1682\nUsing Windows PowerShell to obtain request IDs .................................................................... 1682\nUsing AWS CloudTrail data events to obtain request IDs ........................................................ 1682\nUsing S3 server access logging to obtain request IDs .............................................................. 1682\nCode examples ........................................................................................................................... 1683\nAmazon S3 .............................................................................................................................................. 1687\nBasics................................................................................................................................................... 1705\nScenarios............................................................................................................................................ 2284\nAPI Version 2006-03-01 iii",
      "start_idx": 731,
      "end_idx": 5606,
      "metadata": {
        "num_sentences": 1,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3",
      "text": "Amazon Simple Storage Service API Reference\nServerless examples......................................................................................................................... 2572\nAmazon S3 Control ............................................................................................................................... 2584\nBasics................................................................................................................................................... 2588\nAuthenticating Requests (AWS Signature Version 4) .............................................................. 2638\nAuthentication Methods....................................................................................................................... 2639\nIntroduction to Signing Requests ...................................................................................................... 2640\nUsing an Authorization Header .......................................................................................................... 2641\nOverview............................................................................................................................................ 2642\nSignature Calculation: Transfer Payload in a Single Chunk ..................................................... 2646\nSignature Calculation: Transfer Payload in Multiple Chunks ................................................... 2663\nSignature Calculation: Including Trailing Headers ..................................................................... 2676\nUsing Query Parameters ...................................................................................................................... 2682\nCalculating a Signature ................................................................................................................... 2685\nAn Example ........................................................................................................................................ 2688\nExample 2.......................................................................................................................................... 2690\nExamples: Signature Calculations ...................................................................................................... 2691\nSignature Calculation Examples Using Java ............................................................................... 2691\nSignature Calculation Examples Using C# .................................................................................. 2693\nAuthenticating HTTP POST Requests ............................................................................................... 2694\nCalculating a Signature ................................................................................................................... 2696\nAmazon S3 Signature Version 4 Authentication Specific Policy Keys ......................................... 2697\nBucket Policy Examples Using Signature Version 4 Related Condition Keys ........................ 2700\nBrowser-Based Uploads Using POST ........................................................................................ 2703\nPOST Object........................................................................................................................................... 2704\nDescription......................................................................................................................................... 2704\nVersioning.......................................................................................................................................... 2705\nRequests............................................................................................................................................. 2705\nExamples............................................................................................................................................ 2723\nRelated Resources ............................................................................................................................ 2724\nPOST Object restore ............................................................................................................................. 2725\nDescription......................................................................................................................................... 2725\nQuerying Archives with Select Requests ..................................................................................... 2725\nRestoring Archives............................................................................................................................ 2727\nRequests............................................................................................................................................. 2728\nResponses........................................................................................................................................... 2743\nExamples............................................................................................................................................ 2744\nAPI Version 2006-03-01 iv",
      "start_idx": 5608,
      "end_idx": 10776,
      "metadata": {
        "num_sentences": 1,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_4",
      "text": "Amazon Simple Storage Service API Reference\nMore Info........................................................................................................................................... 2747\nBrowser-Based Uploads Using HTTP POST ..................................................................................... 2747\nCalculating a Signature ........................................................................................................................ 2749\nCreating HTML Forms ........................................................................................................................... 2750\nHTML Form Declaration .................................................................................................................. 2751\nHTML Form Fields ............................................................................................................................ 2752\nPOST Policy............................................................................................................................................ 2758\nExpiration........................................................................................................................................... 2759\nCondition Matching ......................................................................................................................... 2759\nConditions.......................................................................................................................................... 2761\nCharacter Escaping ........................................................................................................................... 2766\nPOST Upload Example ......................................................................................................................... 2767\nUploading a File to Amazon S3 Using HTTP POST ................................................................... 2767\nBrowser-Based Uploads Using AWS Amplify ................................................................................... 2770\nUsing the AWS Amplify JavaScript library to Upload Files to Amazon S3 ........................... 2770\nMore Info........................................................................................................................................... 2771\nCommon Request Headers ........................................................................................................ 2772\nCommon Response Headers ..................................................................................................... 2776\nError responses.......................................................................................................................... 2781\nREST error responses ............................................................................................................................ 2782\nList of error codes ................................................................................................................................. 2783\nList of SELECT Object Content Error Codes ..................................................................................... 2807\nList of Replication-related error codes ............................................................................................. 2820\nList of Tagging-related error codes ................................................................................................... 2822\nList of Amazon S3 on Outposts error codes .................................................................................... 2823\nList of Amazon S3 Storage Lens error codes .................................................................................. 2824\nList of Amazon S3 Object Lambda error codes .............................................................................. 2832\nList of Amazon S3 asynchronous error codes ................................................................................. 2836\nList of Amazon S3 Access Grants Error Codes ................................................................................. 2838\nAmazon S3 error best practices ......................................................................................................... 2840\nRetry InternalErrors ......................................................................................................................... 2841\nTune application for repeated SlowDown errors ....................................................................... 2841\nIsolate errors..................................................................................................................................... 2841\nAWS Glossary............................................................................................................................. 2843\nResources.................................................................................................................................... 2844\nDocument History ..................................................................................................................... 2846\nAPI Version 2006-03-01 v",
      "start_idx": 10778,
      "end_idx": 15903,
      "metadata": {
        "num_sentences": 1,
        "num_words": 222,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_5",
      "text": "Amazon Simple Storage Service API Reference\nAppendix .................................................................................................................................... 2874\nAppendix: SelectObjectContent Response ....................................................................................... 2875\nDescription......................................................................................................................................... 2875\nResponses........................................................................................................................................... 2875\nRelated Resources ............................................................................................................................ 2885\nAppendix: OPTIONS object .................................................................................................................. 2887\nDescription......................................................................................................................................... 2887\nRequests............................................................................................................................................. 2887\nResponses........................................................................................................................................... 2888\nExamples............................................................................................................................................ 2890\nRelated Resources ............................................................................................................................ 2890\nAppendix: SOAP API .............................................................................................................................. 2891\nOperations on the Service (SOAP API) ........................................................................................ 2891\nOperations on Buckets (SOAP API) .............................................................................................. 2893\nOperations on Objects (SOAP API) ............................................................................................... 2907\nAuthenticating SOAP requests ...................................................................................................... 2932\nSetting access policy with SOAP ................................................................................................... 2934\nCommon elements ........................................................................................................................... 2935\nSOAP Error Responses ..................................................................................................................... 2936\nAppendix: Authenticating requests (AWS signature version 2) .................................................... 2938\nAuthenticating requests using the REST API (AWS signature version 2) ............................... 2939\nSigning and authenticating REST requests (AWS signature version 2) ................................. 2942\nBrowser-based uploads using POST (AWS signature version 2) ............................................. 2957\nAppendix: Lifecycle Configuration APIs (Deprecated) .................................................................... 2980\nPUT Bucket lifecycle (Deprecated) ................................................................................................ 2981\nGET Bucket lifecycle (Deprecated) ................................................................................................ 2997\nAPI Version 2006-03-01 vi",
      "start_idx": 15905,
      "end_idx": 19569,
      "metadata": {
        "num_sentences": 1,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_6",
      "text": "Amazon Simple Storage Service API Reference\nWelcome\nWelcome to the Amazon Simple Storage Service API Reference. This guide explains the Amazon\nSimple Storage Service (Amazon S3) application programming interface (API).\nYou can use any toolkit that supports HTTP to use the REST API. You can even use a browser to\nfetch objects, as long as they are anonymously readable.\nThe REST API uses the standard HTTP headers and status codes, so that standard browsers and\ntoolkits work as expected. In some areas, we have added functionality to HTTP (for example, we\nadded headers to support access control). In these cases, we have done our best to add the new\nfunctionality in a way that matched the style of standard HTTP usage.\nVersion\nThe current version of the Amazon S3 API is 2006-03-01.\nType\nAmazon S3 supports the REST API.\nNote\nSupport for SOAP over HTTP is deprecated, but it is still available over HTTPS. However,\nnew Amazon S3 features will not be supported for SOAP. We recommend that you use\neither this REST API or the AWS SDKs at the following link:\nhttps://aws.amazon.com/developer/tools/\nThis REST API reference includes:\n\u2022 S3 API Reference \u2014 which contains Actions (operations) and Data Types\n\u2022 Headers \u2014 Common Request Headers and Common Response Headers\n\u2022 Error responses\n\u2022 Browser-Based Uploads Using POST (AWS Signature Version 4)\nAPI Version 2006-03-01 1",
      "start_idx": 19571,
      "end_idx": 20942,
      "metadata": {
        "num_sentences": 12,
        "num_words": 226,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_7",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nRead the following about authentication and access control before going to specific API\ntopics.\nRequests to Amazon S3 can be authenticated or anonymous. Authenticated access requires\ncredentials that AWS can use to authenticate your requests.\nAPI call recommendations\nMaking REST API calls directly from your code can be cumbersome. It requires you to write the\nnecessary code to calculate a valid signature to authenticate your requests. We recommend the\nfollowing alternatives instead:\n\u2022 Use the AWS SDKs to send your requests.\nAlso, see the Sample Code and Libraries.\nIf you use the SDKs, you don't need to write code to calculate a signature for request\nauthentication because the SDK clients authenticate your requests by using access keys that you\nprovide. Unless you have a good reason not to, you should always use the AWS SDKs.\n\u2022 Use the AWS CLI to make Amazon S3 API calls. For information about setting up the AWS CLI and\nexample Amazon S3 commands see the following topics:\nSet Up the AWS CLI in the Amazon Simple Storage Service User Guide.\nUsing Amazon S3 with the AWS Command Line Interface in the AWS Command Line Interface\nUser Guide.\nMaking direct REST API calls\nNote\nThe PUT request header is limited to 8 KB in size. Within the PUT request header, the\nsystem-defined metadata is limited to 2 KB in size. The size of system-defined metadata is\nmeasured by taking the sum of the number of bytes in the US-ASCII encoding of each key\nand value.\nAPI Version 2006-03-01 2",
      "start_idx": 20944,
      "end_idx": 22483,
      "metadata": {
        "num_sentences": 16,
        "num_words": 261,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_8",
      "text": "Amazon Simple Storage Service API Reference\nIf you'd like to make your own REST API calls instead of using one of the above alternatives, there\nare some things to keep in mind.\n\u2022 To make direct REST API calls from your code, create a signature using valid credentials and\ninclude the signature in your request. For information about various authentication methods and\nsignature calculations, see Authenticating Requests (AWS Signature Version 4).\n\u2022 The REST API uses standard HTTP headers and status codes, so standard browsers and toolkits\nwork as expected. In some areas, we have added functionality to HTTP (for example, we added\nheaders to support access control). In these cases, we have done our best to add the new\nfunctionality in a way that matches the style of standard HTTP usage. For more information\nabout making requests, see Making requests.\nPermissions\nYou can have valid credentials to authenticate your requests, but unless you have S3 permissions\nfrom the account owner or bucket owner you cannot create or access Amazon S3 resources. These\npermissions are typically granted through an AWS Identity and Access Management (IAM) policy,\nsuch as a bucket policy. For example, you must have permissions to create an S3 bucket or get an\nobject in a bucket. For a complete list of S3 permissions, see Actions, resources, and condition keys\nfor Amazon S3.\nFor more information about the permissions to S3 API operations by S3 resource types, see\nRequired permissions for Amazon S3 API operations in the Amazon Simple Storage Service User\nGuide.\nIf you use the root user credentials of your AWS account, you have all the permissions. However,\nusing root user credentials is not recommended. Instead, we recommend that you create AWS\nIdentity and Access Management (IAM) roles in your account and manage user permissions. For\nmore information, see Access Management in the Amazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 3",
      "start_idx": 22485,
      "end_idx": 24434,
      "metadata": {
        "num_sentences": 17,
        "num_words": 317,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_9",
      "text": "Amazon Simple Storage Service API Reference\nS3 API Reference\nThis section contains the Amazon S3 API Reference documentation, which includes actions\n(operations) and data types.\nThe S3 API reference groups each of its Actions and Data Types into three sets: Amazon S3, Amazon\nS3 Control, and Amazon S3 on Outposts. There is no functional distinction between the three sets.\nIf you don't find an API operation or data type that you're looking for in one set, check one of the\nother sets.\nActions\n\u2022 Amazon S3 \u2014 API operations that apply bucket-level and object-level actions.\n\u2022 Amazon S3 Control \u2014 API operations for managing all other S3 resources.\n\u2022 Amazon S3 on Outposts \u2014 API operations for use with Amazon S3 on Outposts. You\ncommunicate with your Outposts bucket using an access point and endpoint connection over a\nvirtual private cloud (VPC).\nData types\n\u2022 Amazon S3 \u2014 Data types of API operations that apply bucket-level and object-level actions.\n\u2022 Amazon S3 Control \u2014 Data types of API operations for managing all other S3 resources.\n\u2022 Amazon S3 on Outposts \u2014 Data types of API operations for use with Amazon S3 on Outposts.\nActions\nThe following actions are supported by Amazon S3:\n\u2022 AbortMultipartUpload\n\u2022 CompleteMultipartUpload\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 CreateMultipartUpload\n\u2022 CreateSession\n\u2022 DeleteBucket\nActions API Version 2006-03-01 4",
      "start_idx": 24436,
      "end_idx": 25790,
      "metadata": {
        "num_sentences": 12,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_20",
      "text": "Amazon Simple Storage Service API Reference\nAbortMultipartUpload\nService: Amazon S3\nThis operation aborts a multipart upload. After a multipart upload is aborted, no additional parts\ncan be uploaded using that upload ID. The storage consumed by any previously uploaded parts will\nbe freed. However, if any part uploads are currently in progress, those part uploads might or might\nnot succeed. As a result, it might be necessary to abort a given multipart upload multiple times in\norder to completely free all storage consumed by all parts.\nTo verify that all parts have been removed and prevent getting charged for the part storage, you\nshould call the ListParts API operation and ensure that the parts list is empty.\nNote\n\u2022 Directory buckets - If multipart uploads in a directory bucket are in progress, you can't\ndelete the bucket until all the in-progress multipart uploads are aborted or completed.\nTo delete these in-progress multipart uploads, use the ListMultipartUploads\noperation to list the in-progress multipart uploads in the bucket and use the\nAbortMultipartUpload operation to abort all the in-progress multipart uploads.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the\nformat https://bucket_name.s3express-az_id.region.amazonaws.com/key-\nname . Path-style requests are not supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - For information about permissions required to use the\nmultipart upload, see Multipart Upload and Permissions in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nAmazon S3 API Version 2006-03-01 15",
      "start_idx": 33966,
      "end_idx": 36397,
      "metadata": {
        "num_sentences": 19,
        "num_words": 372,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_21",
      "text": "Amazon Simple Storage Service API Reference\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to AbortMultipartUpload:\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\n\u2022 CompleteMultipartUpload\n\u2022 ListParts\n\u2022 ListMultipartUploads\nRequest Syntax\nDELETE /Key+?uploadId=UploadId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name to which the upload was taking place.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 16",
      "start_idx": 36399,
      "end_idx": 37690,
      "metadata": {
        "num_sentences": 11,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_22",
      "text": "Amazon Simple Storage Service API Reference\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nKey of the object for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nuploadId\nUpload ID that identifies the multipart upload.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 17",
      "start_idx": 37692,
      "end_idx": 39373,
      "metadata": {
        "num_sentences": 17,
        "num_words": 271,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_23",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 18",
      "start_idx": 39375,
      "end_idx": 40453,
      "metadata": {
        "num_sentences": 11,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_26",
      "text": "Amazon Simple Storage Service API Reference\nCompleteMultipartUpload\nService: Amazon S3\nCompletes a multipart upload by assembling previously uploaded parts.\nYou first initiate the multipart upload and then upload all parts using the UploadPart operation\nor the UploadPartCopy operation. After successfully uploading all relevant parts of an upload,\nyou call this CompleteMultipartUpload operation to complete the upload. Upon receiving this\nrequest, Amazon S3 concatenates all the parts in ascending order by part number to create a new\nobject. In the CompleteMultipartUpload request, you must provide the parts list and ensure that\nthe parts list is complete. The CompleteMultipartUpload API operation concatenates the parts that\nyou provide in the list. For each part in the list, you must provide the PartNumber value and the\nETag value that are returned after that part was uploaded.\nThe processing of a CompleteMultipartUpload request could take several minutes to finalize. After\nAmazon S3 begins processing the request, it sends an HTTP response header that specifies a 200\nOK response. While processing is in progress, Amazon S3 periodically sends white space characters\nto keep the connection from timing out. A request could fail after the initial 200 OK response has\nbeen sent. This means that a 200 OK response can contain either a success or an error. The error\nresponse might be embedded in the 200 OK response. If you call this API operation directly, make\nsure to design your application to parse the contents of the response and handle it appropriately.\nIf you use AWS SDKs, SDKs handle this condition. The SDKs detect the embedded error and apply\nerror handling per your configuration settings (including automatically retrying the request as\nappropriate). If the condition persists, the SDKs throw an exception (or, for the SDKs that don't use\nexceptions, they return an error).\nNote that if CompleteMultipartUpload fails, applications should be prepared to retry any\nfailed requests (including 500 error responses). For more information, see Amazon S3 Error Best\nPractices.\nImportant\nYou can't use Content-Type: application/x-www-form-urlencoded for the\nCompleteMultipartUpload requests. Also, if you don't provide a Content-Type header,\nCompleteMultipartUpload can still return a 200 OK response.\nFor more information about multipart uploads, see Uploading Objects Using Multipart Upload in\nthe Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 21",
      "start_idx": 41698,
      "end_idx": 44171,
      "metadata": {
        "num_sentences": 23,
        "num_words": 373,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_27",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - For information about permissions required to use the\nmultipart upload API, see Multipart Upload and Permissions in the Amazon S3 User Guide.\nIf you provide an additional checksum value in your MultipartUpload requests and the\nobject is encrypted with AWS Key Management Service, you must have permission to use the\nkms:Decrypt action for the CompleteMultipartUpload request to succeed.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key.\nSpecial errors\n\u2022 Error Code: EntityTooSmall\n\u2022 Description: Your proposed upload is smaller than the minimum allowed object size. Each\npart must be at least 5 MB in size, except the last part.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 Error Code: InvalidPart\nAmazon S3 API Version 2006-03-01 22",
      "start_idx": 44173,
      "end_idx": 46313,
      "metadata": {
        "num_sentences": 17,
        "num_words": 323,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_28",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Description: One or more of the specified parts could not be found. The part might not\nhave been uploaded, or the specified ETag might not have matched the uploaded part's\nETag.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 Error Code: InvalidPartOrder\n\u2022 Description: The list of parts was not in ascending order. The parts list must be specified in\norder by part number.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 Error Code: NoSuchUpload\n\u2022 Description: The specified multipart upload does not exist. The upload ID might be invalid,\nor the multipart upload might have been aborted or completed.\n\u2022 HTTP Status Code: 404 Not Found\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to CompleteMultipartUpload:\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\n\u2022 AbortMultipartUpload\n\u2022 ListParts\n\u2022 ListMultipartUploads\nRequest Syntax\nPOST /Key+?uploadId=UploadId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 23",
      "start_idx": 46315,
      "end_idx": 47610,
      "metadata": {
        "num_sentences": 8,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_29",
      "text": "Amazon Simple Storage Service API Reference\nIf-None-Match: IfNoneMatch\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CompleteMultipartUpload xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Part>\n<ChecksumCRC32>string</ChecksumCRC32>\n<ChecksumCRC32C>string</ChecksumCRC32C>\n<ChecksumSHA1>string</ChecksumSHA1>\n<ChecksumSHA256>string</ChecksumSHA256>\n<ETag>string</ETag>\n<PartNumber>integer</PartNumber>\n</Part>\n...\n</CompleteMultipartUpload>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nName of the bucket to which the multipart upload was initiated.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 24",
      "start_idx": 47612,
      "end_idx": 49529,
      "metadata": {
        "num_sentences": 13,
        "num_words": 219,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_30",
      "text": "Amazon Simple Storage Service API Reference\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nIf-None-Match\nUploads the object only if the object key name does not already exist in the bucket specified.\nOtherwise, Amazon S3 returns a 412 Precondition Failed error.\nIf a conflicting operation occurs during the upload S3 returns a 409\nConditionalRequestConflict response. On a 409 failure you should re-initiate the\nmultipart upload with CreateMultipartUpload and re-upload each part.\nExpects the '*' (asterisk) character.\nFor more information about conditional requests, see RFC 7232, or Conditional requests in the\nAmazon S3 User Guide.\nKey\nObject key for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nuploadId\nID for the initiated multipart upload.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 25",
      "start_idx": 49531,
      "end_idx": 50920,
      "metadata": {
        "num_sentences": 16,
        "num_words": 214,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_31",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nx-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32C\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nx-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 160-bit SHA-1 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nx-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 256-bit SHA-256 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 26",
      "start_idx": 50922,
      "end_idx": 52982,
      "metadata": {
        "num_sentences": 20,
        "num_words": 323,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_32",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nThe server-side encryption (SSE) algorithm used to encrypt the object. This parameter is\nrequired only when the object was created using a checksum algorithm or if your bucket policy\nrequires the use of SSE-C. For more information, see Protecting data using SSE-C keys in the\nAmazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nThe server-side encryption (SSE) customer managed key. This parameter is needed only when\nthe object was created using a checksum algorithm. For more information, see Protecting data\nusing SSE-C keys in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nThe MD5 server-side encryption (SSE) customer managed key. This parameter is needed only\nwhen the object was created using a checksum algorithm. For more information, see Protecting\ndata using SSE-C keys in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request accepts the following data in XML format.\nAmazon S3 API Version 2006-03-01 27",
      "start_idx": 52984,
      "end_idx": 54242,
      "metadata": {
        "num_sentences": 13,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_34",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the object expiration is configured, this will contain the expiration date (expiry-date) and\nrule ID (rule-id). The value of rule-id is URL-encoded.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when storing this object in Amazon S3 (for example,\nAES256, aws:kms).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the multipart upload uses an S3 Bucket Key for server-side encryption with\nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-version-id\nVersion ID of the newly created object, in case the bucket has versioning turned on.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 29",
      "start_idx": 55400,
      "end_idx": 56577,
      "metadata": {
        "num_sentences": 11,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_35",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nCompleteMultipartUploadResult\nRoot level tag for the CompleteMultipartUploadResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket that contains the newly created object. Does not return the access\npoint ARN or access point alias if used.\nNote\nAccess points are not supported by directory buckets.\nType: String\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nAmazon S3 API Version 2006-03-01 30",
      "start_idx": 56579,
      "end_idx": 58080,
      "metadata": {
        "num_sentences": 16,
        "num_words": 239,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_36",
      "text": "Amazon Simple Storage Service API Reference\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nType: String\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nETag\nEntity tag that identifies the newly created object's data. Objects with different object data will\nhave different entity tags. The entity tag is an opaque string. The entity tag may or may not be\nan MD5 digest of the object data. If the entity tag is not an MD5 digest of the object data, it\nwill contain one or more nonhexadecimal characters and/or will consist of less than 32 or more\nthan 32 hexadecimal digits. For more information about how the entity tag is calculated, see\nChecking object integrity in the Amazon S3 User Guide.\nType: String\nKey\nThe object key of the newly created object.\nType: String\nLength Constraints: Minimum length of 1.\nLocation\nThe URI that identifies the newly created object.\nAmazon S3 API Version 2006-03-01 31",
      "start_idx": 58082,
      "end_idx": 59915,
      "metadata": {
        "num_sentences": 20,
        "num_words": 306,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_39",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nConnection: close\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error>\n<Code>InternalError</Code>\n<Message>We encountered an internal error. Please try again.</Message>\n<RequestId>656c76696e6727732072657175657374</RequestId>\n<HostId>Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==</HostId>\n</Error>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 34",
      "start_idx": 62415,
      "end_idx": 63296,
      "metadata": {
        "num_sentences": 2,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_40",
      "text": "Amazon Simple Storage Service API Reference\nCopyObject\nService: Amazon S3\nCreates a copy of an object that is already stored in Amazon S3.\nNote\nYou can store individual objects of up to 5 TB in Amazon S3. You create a copy of your\nobject up to 5 GB in size in a single atomic action using this API. However, to copy\nan object greater than 5 GB, you must use the multipart upload Upload Part - Copy\n(UploadPartCopy) API. For more information, see Copy Object Using the REST Multipart\nUpload API.\nYou can copy individual objects between general purpose buckets, between directory buckets, and\nbetween general purpose buckets and directory buckets.\nNote\n\u2022 Amazon S3 supports copy operations using Multi-Region Access Points only as a\ndestination when using the Multi-Region Access Point ARN.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the\nformat https://bucket_name.s3express-az_id.region.amazonaws.com/key-\nname . Path-style requests are not supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\n\u2022 VPC endpoints don't support cross-Region requests (including copies). If you're using VPC\nendpoints, your source and destination buckets should be in the same AWS Region as\nyour VPC endpoint.\nBoth the Region that you want to copy the object from and the Region that you want to copy the\nobject to must be enabled for your account. For more information about how to enable a Region\nfor your account, see Enable or disable a Region for standalone accounts in the AWS Account\nManagement Guide.\nAmazon S3 API Version 2006-03-01 35",
      "start_idx": 63298,
      "end_idx": 64989,
      "metadata": {
        "num_sentences": 16,
        "num_words": 273,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_41",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nAmazon S3 transfer acceleration does not support cross-Region copies. If you request a\ncross-Region copy using a transfer acceleration endpoint, you get a 400 Bad Request\nerror. For more information, see Transfer Acceleration.\nAuthentication and authorization\nAll CopyObject requests must be authenticated and signed by using IAM credentials\n(access key ID and secret access key for the IAM identities). All headers with the x-amz-\nprefix, including x-amz-copy-source, must be signed. For more information, see REST\nAuthentication.\nDirectory buckets - You must use the IAM credentials to authenticate and authorize your access\nto the CopyObject API operation, instead of using the temporary security credentials through\nthe CreateSession API operation.\nAWS CLI or SDKs handles authentication and authorization on your behalf.\nPermissions\nYou must have read access to the source object and write access to the destination bucket.\n\u2022 General purpose bucket permissions - You must have permissions in an IAM policy based on\nthe source and destination bucket types in a CopyObject operation.\n\u2022 If the source object is in a general purpose bucket, you must have s3:GetObject\npermission to read the source object that is being copied.\n\u2022 If the destination bucket is a general purpose bucket, you must have s3:PutObject\npermission to write the object copy to the destination bucket.\n\u2022 Directory bucket permissions - You must have permissions in a bucket policy or an IAM\nidentity-based policy based on the source and destination bucket types in a CopyObject\noperation.\n\u2022 If the source object that you want to copy is in a directory bucket, you must have the\ns3express:CreateSession permission in the Action element of a policy to read the\nobject. By default, the session is in the ReadWrite mode. If you want to restrict the access,\nyou can explicitly set the s3express:SessionMode condition key to ReadOnly on the\ncopy source bucket.\nAmazon S3 API Version 2006-03-01 36",
      "start_idx": 64991,
      "end_idx": 67007,
      "metadata": {
        "num_sentences": 17,
        "num_words": 317,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_42",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 If the copy destination is a directory bucket, you must have the\ns3express:CreateSession permission in the Action element of a policy to write the\nobject to the destination. The s3express:SessionMode condition key can't be set to\nReadOnly on the copy destination bucket.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key.\nFor example policies, see Example bucket policies for S3 Express One Zone and AWS Identity\nand Access Management (IAM) identity-based policies for S3 Express One Zone in the Amazon\nS3 User Guide.\nResponse and special errors\nWhen the request is an HTTP 1.1 request, the response is chunk encoded. When the request is\nnot an HTTP 1.1 request, the response would not contain the Content-Length. You always\nneed to read the entire response body to check if the copy succeeds.\n\u2022 If the copy is successful, you receive a response with information about the copied object.\n\u2022 A copy request might return an error when Amazon S3 receives the copy request or while\nAmazon S3 is copying the files. A 200 OK response can contain either a success or an error.\n\u2022 If the error occurs before the copy action starts, you receive a standard Amazon S3 error.\n\u2022 If the error occurs during the copy operation, the error response is embedded in the 200\nOK response. For example, in a cross-region copy, you may encounter throttling and receive\na 200 OK response. For more information, see Resolve the Error 200 response when\ncopying objects to Amazon S3. The 200 OK status code means the copy was accepted,\nbut it doesn't mean the copy is complete. Another example is when you disconnect from\nAmazon S3 before the copy is complete, Amazon S3 might cancel the copy and you\nmay receive a 200 OK response. You must stay connected to Amazon S3 until the entire\nresponse is successfully received and processed.\nIf you call this API operation directly, make sure to design your application to parse the\ncontent of the response and handle it appropriately. If you use AWS SDKs, SDKs handle\nthis condition. The SDKs detect the embedded error and apply error handling per your\nconfiguration settings (including automatically retrying the request as appropriate). If the\ncondition persists, the SDKs throw an exception (or, for the SDKs that don't use exceptions,\nthey return an error).\nAmazon S3 API Version 2006-03-01 37",
      "start_idx": 67009,
      "end_idx": 69505,
      "metadata": {
        "num_sentences": 22,
        "num_words": 420,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_43",
      "text": "Amazon Simple Storage Service API Reference\nCharge\nThe copy request charge is based on the storage class and Region that you specify for the\ndestination object. The request can also result in a data retrieval charge for the source if the\nsource storage class bills for data retrieval. If the copy source is in a different region, the data\ntransfer is billed to the copy source account. For pricing information, see Amazon S3 pricing.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to CopyObject:\n\u2022 PutObject\n\u2022 GetObject\nRequest Syntax\nPUT /Key+ HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nCache-Control: CacheControl\nx-amz-checksum-algorithm: ChecksumAlgorithm\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Type: ContentType\nx-amz-copy-source: CopySource\nx-amz-copy-source-if-match: CopySourceIfMatch\nx-amz-copy-source-if-modified-since: CopySourceIfModifiedSince\nx-amz-copy-source-if-none-match: CopySourceIfNoneMatch\nx-amz-copy-source-if-unmodified-since: CopySourceIfUnmodifiedSince\nExpires: Expires\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-metadata-directive: MetadataDirective\nx-amz-tagging-directive: TaggingDirective\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-storage-class: StorageClass\nAmazon S3 API Version 2006-03-01 38",
      "start_idx": 69507,
      "end_idx": 71054,
      "metadata": {
        "num_sentences": 6,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_44",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-copy-source-server-side-encryption-customer-\nalgorithm: CopySourceSSECustomerAlgorithm\nx-amz-copy-source-server-side-encryption-customer-key: CopySourceSSECustomerKey\nx-amz-copy-source-server-side-encryption-customer-key-MD5: CopySourceSSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-tagging: Tagging\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-source-expected-bucket-owner: ExpectedSourceBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the destination bucket.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 39",
      "start_idx": 71056,
      "end_idx": 73380,
      "metadata": {
        "num_sentences": 13,
        "num_words": 226,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_45",
      "text": "Amazon Simple Storage Service API Reference\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nCache-Control\nSpecifies the caching behavior along the request/reply chain.\nContent-Disposition\nSpecifies presentational information for the object. Indicates whether an object should be\ndisplayed in a web browser or downloaded as a file. It allows specifying the desired filename for\nthe downloaded file.\nContent-Encoding\nSpecifies what content encodings have been applied to the object and thus what decoding\nmechanisms must be applied to obtain the media-type referenced by the Content-Type header\nfield.\nNote\nFor directory buckets, only the aws-chunked value is supported in this header field.\nContent-Language\nThe language the content is in.\nContent-Type\nA standard MIME type that describes the format of the object data.\nAmazon S3 API Version 2006-03-01 40",
      "start_idx": 73382,
      "end_idx": 74776,
      "metadata": {
        "num_sentences": 15,
        "num_words": 212,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_46",
      "text": "Amazon Simple Storage Service API Reference\nExpires\nThe date and time at which the object is no longer cacheable.\nKey\nThe key of the destination object.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-acl\nThe canned access control list (ACL) to apply to the object.\nWhen you copy an object, the ACL metadata is not preserved and is set to private by default.\nOnly the owner has full access control. To override the default ACL setting, specify a new ACL\nwhen you generate a copy request. For more information, see Using ACLs.\nIf the destination bucket that you're copying objects to uses the bucket owner enforced setting\nfor S3 Object Ownership, ACLs are disabled and no longer affect permissions. Buckets that use\nthis setting only accept PUT requests that don't specify an ACL or PUT requests that specify\nbucket owner full control ACLs, such as the bucket-owner-full-control canned ACL or an\nequivalent form of this ACL expressed in the XML format. For more information, see Controlling\nownership of objects and disabling ACLs in the Amazon S3 User Guide.\nNote\n\u2022 If your destination bucket uses the bucket owner enforced setting for Object\nOwnership, all objects written to the bucket by any account will be owned by the\nbucket owner.\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nValid Values: private | public-read | public-read-write | authenticated-read\n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-checksum-algorithm\nIndicates the algorithm that you want Amazon S3 to use to create the checksum for the object.\nFor more information, see Checking object integrity in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 41",
      "start_idx": 74778,
      "end_idx": 76532,
      "metadata": {
        "num_sentences": 17,
        "num_words": 282,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_47",
      "text": "Amazon Simple Storage Service API Reference\nWhen you copy an object, if the source object has a checksum, that checksum value will\nbe copied to the new object by default. If the CopyObject request does not include this\nx-amz-checksum-algorithm header, the checksum algorithm will be copied from the\nsource object to the destination object (if it's present on the source object). You can optionally\nspecify a different checksum algorithm to use with the x-amz-checksum-algorithm\nheader. Unrecognized or unsupported values will respond with the HTTP status code 400 Bad\nRequest.\nNote\nFor directory buckets, when you use AWS SDKs, CRC32 is the default checksum\nalgorithm that's used for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-copy-source\nSpecifies the source object for the copy operation. The source object can be up to 5 GB. If the\nsource object is an object that was uploaded by using a multipart upload, the object copy will\nbe a single part object after the source object is copied to the destination bucket.\nYou specify the value of the copy source in one of two formats, depending on whether you want\nto access the source object through an access point:\n\u2022 For objects not accessed through an access point, specify the name of the source bucket\nand the key of the source object, separated by a slash (/). For example, to copy the object\nreports/january.pdf from the general purpose bucket awsexamplebucket, use\nawsexamplebucket/reports/january.pdf. The value must be URL-encoded. To copy\nthe object reports/january.pdf from the directory bucket awsexamplebucket--use1-\naz5--x-s3, use awsexamplebucket--use1-az5--x-s3/reports/january.pdf. The\nvalue must be URL-encoded.\n\u2022 For objects accessed through access points, specify the Amazon Resource\nName (ARN) of the object as accessed through the access point, in the format\narn:aws:s3:<Region>:<account-id>:accesspoint/<access-point-name>/\nobject/<key>. For example, to copy the object reports/january.pdf through access\npoint my-access-point owned by account 123456789012 in Region us-west-2, use the\nURL encoding of arn:aws:s3:us-west-2:123456789012:accesspoint/my-access-\npoint/object/reports/january.pdf. The value must be URL encoded.\nAmazon S3 API Version 2006-03-01 42",
      "start_idx": 76534,
      "end_idx": 78783,
      "metadata": {
        "num_sentences": 17,
        "num_words": 326,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_48",
      "text": "Amazon Simple Storage Service API Reference\nNote\n\u2022 Amazon S3 supports copy operations using Access points only when the source and\ndestination buckets are in the same AWS Region.\n\u2022 Access points are not supported by directory buckets.\nAlternatively, for objects accessed through Amazon S3 on Outposts, specify the ARN of\nthe object as accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/object/<key>. For example, to copy the object\nreports/january.pdf through outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/object/reports/january.pdf. The\nvalue must be URL-encoded.\nIf your source bucket versioning is enabled, the x-amz-copy-source header by default\nidentifies the current version of an object to copy. If the current version is a delete\nmarker, Amazon S3 behaves as if the object was deleted. To copy a different version,\nuse the versionId query parameter. Specifically, append ?versionId=<version-\nid> to the value (for example, awsexamplebucket/reports/january.pdf?\nversionId=QUpfdndhfd8438MNFDN93jdnJFkdmqnh893). If you don't specify a version ID,\nAmazon S3 copies the latest version of the source object.\nIf you enable versioning on the destination bucket, Amazon S3 generates a unique version\nID for the copied object. This version ID is different from the version ID of the source object.\nAmazon S3 returns the version ID of the copied object in the x-amz-version-id response\nheader in the response.\nIf you do not enable versioning or suspend it on the destination bucket, the version ID that\nAmazon S3 generates in the x-amz-version-id response header is always null.\nNote\nDirectory buckets - S3 Versioning isn't enabled and supported for directory buckets.\nPattern: \\/.+\\/.+\nAmazon S3 API Version 2006-03-01 43",
      "start_idx": 78785,
      "end_idx": 80651,
      "metadata": {
        "num_sentences": 17,
        "num_words": 264,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_50",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 x-amz-copy-source-if-unmodified-since condition evaluates to false\nx-amz-copy-source-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when decrypting the source object (for example, AES256).\nIf the source object for the copy is stored in Amazon S3 using SSE-C, you must provide the\nnecessary encryption information in your request so that Amazon S3 can decrypt the object for\ncopying.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use to decrypt the source\nobject. The encryption key provided in this header must be the same one that was used when\nthe source object was created.\nIf the source object for the copy is stored in Amazon S3 using SSE-C, you must provide the\nnecessary encryption information in your request so that Amazon S3 can decrypt the object for\ncopying.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nIf the source object for the copy is stored in Amazon S3 using SSE-C, you must provide the\nnecessary encryption information in your request so that Amazon S3 can decrypt the object for\ncopying.\nAmazon S3 API Version 2006-03-01 45",
      "start_idx": 82400,
      "end_idx": 83982,
      "metadata": {
        "num_sentences": 11,
        "num_words": 235,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_51",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected destination bucket owner. If the account ID that you provide\ndoes not match the actual owner of the destination bucket, the request fails with the HTTP\nstatus code 403 Forbidden (access denied).\nx-amz-grant-full-control\nGives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nAllows grantee to read the object data and its metadata.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read-acp\nAllows grantee to read the object ACL.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nAmazon S3 API Version 2006-03-01 46",
      "start_idx": 83984,
      "end_idx": 85034,
      "metadata": {
        "num_sentences": 13,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_52",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable object.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-metadata-directive\nSpecifies whether the metadata is copied from the source object or replaced with metadata\nthat's provided in the request. When copying an object, you can preserve all metadata (the\ndefault) or specify new metadata. If this header isn\u2019t specified, COPY is the default behavior.\nGeneral purpose bucket - For general purpose buckets, when you grant permissions, you can\nuse the s3:x-amz-metadata-directive condition key to enforce certain metadata behavior\nwhen objects are uploaded. For more information, see Amazon S3 condition key examples in\nthe Amazon S3 User Guide.\nNote\nx-amz-website-redirect-location is unique to each object and is not copied\nwhen using the x-amz-metadata-directive header. To copy the value, you must\nspecify x-amz-website-redirect-location in the request header.\nValid Values: COPY | REPLACE\nx-amz-object-lock-legal-hold\nSpecifies whether you want to apply a legal hold to the object copy.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nAmazon S3 API Version 2006-03-01 47",
      "start_idx": 85036,
      "end_idx": 86354,
      "metadata": {
        "num_sentences": 13,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_53",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-object-lock-mode\nThe Object Lock mode that you want to apply to the object copy.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when you want the Object Lock of the object copy to expire.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when storing this object in Amazon S3.\nUnrecognized or unsupported values won\u2019t write a destination object and will receive a 400\nBad Request response.\nAmazon S3 API Version 2006-03-01 48",
      "start_idx": 86356,
      "end_idx": 87568,
      "metadata": {
        "num_sentences": 12,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_54",
      "text": "Amazon Simple Storage Service API Reference\nAmazon S3 automatically encrypts all new objects that are copied to an S3 bucket. When\ncopying an object, if you don't specify encryption information in your copy request, the\nencryption setting of the target object is set to the default encryption configuration of the\ndestination bucket. By default, all buckets have a base level of encryption configuration that\nuses server-side encryption with Amazon S3 managed keys (SSE-S3). If the destination bucket\nhas a different default encryption configuration, Amazon S3 uses the corresponding encryption\nkey to encrypt the target object copy.\nWith server-side encryption, Amazon S3 encrypts your data as it writes your data to disks in its\ndata centers and decrypts the data when you access it. For more information about server-side\nencryption, see Using Server-Side Encryption in the Amazon S3 User Guide.\nGeneral purpose buckets\n\u2022 For general purpose buckets, there are the following supported options for server-side\nencryption: server-side encryption with AWS Key Management Service (AWS KMS) keys\n(SSE-KMS), dual-layer server-side encryption with AWS KMS keys (DSSE-KMS), and server-\nside encryption with customer-provided encryption keys (SSE-C). Amazon S3 uses the\ncorresponding KMS key, or a customer-provided key to encrypt the target object copy.\n\u2022 When you perform a CopyObject operation, if you want to use a different type of\nencryption setting for the target object, you can specify appropriate encryption-related\nheaders to encrypt the target object with an Amazon S3 managed key, a KMS key, or a\ncustomer-provided key. If the encryption setting in your request is different from the default\nencryption configuration of the destination bucket, the encryption setting in your request\ntakes precedence.\nDirectory buckets\n\u2022 For directory buckets, there are only two supported options for server-side encryption:\nserver-side encryption with Amazon S3 managed keys (SSE-S3) (AES256) and server-side\nencryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that the bucket's\ndefault encryption uses the desired encryption configuration and you don't override the\nbucket default encryption in your CreateSession requests or PUT object requests. Then,\nnew objects are automatically encrypted with the desired encryption settings. For more\ninformation, see Protecting data with server-side encryption in the Amazon S3 User Guide.\nFor more information about the encryption overriding behaviors in directory buckets, see\nSpecifying server-side encryption with AWS KMS for new object uploads.\n\u2022 To encrypt new object copies to a directory bucket with SSE-KMS, we recommend you\nspecify SSE-KMS as the directory bucket's default encryption configuration with a KMS key\nAmazon S3 API Version 2006-03-01 49",
      "start_idx": 87570,
      "end_idx": 90373,
      "metadata": {
        "num_sentences": 16,
        "num_words": 416,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_55",
      "text": "Amazon Simple Storage Service API Reference\n(specifically, a customer managed key). The AWS managed key (aws/s3) isn't supported. Your\nSSE-KMS configuration can only support 1 customer managed key per directory bucket for\nthe lifetime of the bucket. After you specify a customer managed key for SSE-KMS, you can't\noverride the customer managed key for the bucket's SSE-KMS configuration. Then, when you\nperform a CopyObject operation and want to specify server-side encryption settings for\nnew object copies with SSE-KMS in the encryption-related request headers, you must ensure\nthe encryption key is the same customer managed key that you specified for the directory\nbucket's default encryption configuration.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nSpecifies the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. All\nGET and PUT requests for an object protected by AWS KMS will fail if they're not made via SSL\nor using SigV4. For information about configuring any of the officially supported AWS SDKs and\nAWS CLI, see Specifying the Signature Version in Request Authentication in the Amazon S3 User\nGuide.\nDirectory buckets - If you specify x-amz-server-side-encryption with aws:kms, the\nx-amz-server-side-encryption-aws-kms-key-id header is implicitly assigned the\nID of the AWS KMS symmetric encryption customer managed key that's configured for your\ndirectory bucket's default encryption setting. If you want to specify the x-amz-server-\nside-encryption-aws-kms-key-id header explicitly, you can only specify it with the ID\n(Key ID or Key ARN) of the AWS KMS customer managed key that's configured for your directory\nbucket's default encryption setting. Otherwise, you get an HTTP 400 Bad Request error. Only\nuse the key ID or key ARN. The key alias format of the KMS key isn't supported. Your SSE-KMS\nconfiguration can only support 1 customer managed key per directory bucket for the lifetime of\nthe bucket. The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpecifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS Key Management Service (AWS KMS) keys (SSE-KMS). If a target\nobject uses SSE-KMS, you can enable an S3 Bucket Key for the object.\nSetting this header to true causes Amazon S3 to use an S3 Bucket Key for object encryption\nwith SSE-KMS. Specifying this header with a COPY action doesn\u2019t affect bucket-level settings\nfor S3 Bucket Key.\nFor more information, see Amazon S3 Bucket Keys in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 50",
      "start_idx": 90375,
      "end_idx": 93024,
      "metadata": {
        "num_sentences": 21,
        "num_words": 406,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_56",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - S3 Bucket Keys aren't supported, when you copy SSE-KMS\nencrypted objects from general purpose buckets to directory buckets, from directory\nbuckets to general purpose buckets, or between directory buckets, through CopyObject.\nIn this case, Amazon S3 makes a call to AWS KMS every time a copy request is made for\na KMS-encrypted object.\nx-amz-server-side-encryption-context\nSpecifies the AWS KMS Encryption Context as an additional encryption context to use for\nthe destination object encryption. The value of this header is a base64-encoded UTF-8 string\nholding JSON with the encryption context key-value pairs.\nGeneral purpose buckets - This value must be explicitly added to specify encryption context for\nCopyObject requests if you want an additional encryption context for your destination object.\nThe additional encryption context of the source object won't be copied to the destination\nobject. For more information, see Encryption context in the Amazon S3 User Guide.\nDirectory buckets - You can optionally provide an explicit encryption context value. The value\nmust match the default encryption context - the bucket Amazon Resource Name (ARN). An\nadditional encryption context value is not supported.\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nWhen you perform a CopyObject operation, if you want to use a different type of encryption\nsetting for the target object, you can specify appropriate encryption-related headers to encrypt\nthe target object with an Amazon S3 managed key, a KMS key, or a customer-provided key. If\nthe encryption setting in your request is different from the default encryption configuration of\nthe destination bucket, the encryption setting in your request takes precedence.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nAmazon S3 API Version 2006-03-01 51",
      "start_idx": 93026,
      "end_idx": 95016,
      "metadata": {
        "num_sentences": 15,
        "num_words": 294,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_57",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded. Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-amz-\nserver-side-encryption-customer-algorithm header.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-source-expected-bucket-owner\nThe account ID of the expected source bucket owner. If the account ID that you provide does not\nmatch the actual owner of the source bucket, the request fails with the HTTP status code 403\nForbidden (access denied).\nx-amz-storage-class\nIf the x-amz-storage-class header is not used, the copied object will be stored in the\nSTANDARD Storage Class by default. The STANDARD storage class provides high durability and\nhigh availability. Depending on performance needs, you can specify a different Storage Class.\nNote\n\u2022 Directory buckets - For directory buckets, only the S3 Express One Zone storage\nclass is supported to store newly created objects. Unsupported storage class values\nwon't write a destination object and will respond with the HTTP status code 400 Bad\nRequest.\nAmazon S3 API Version 2006-03-01 52",
      "start_idx": 95018,
      "end_idx": 96703,
      "metadata": {
        "num_sentences": 16,
        "num_words": 249,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_58",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Amazon S3 on Outposts - S3 on Outposts only uses the OUTPOSTS Storage Class.\nYou can use the CopyObject action to change the storage class of an object that is already\nstored in Amazon S3 by using the x-amz-storage-class header. For more information, see\nStorage Classes in the Amazon S3 User Guide.\nBefore using an object as a source object for the copy operation, you must restore a copy of it if\nit meets any of the following conditions:\n\u2022 The storage class of the source object is GLACIER or DEEP_ARCHIVE.\n\u2022 The storage class of the source object is INTELLIGENT_TIERING and it's S3 Intelligent-\nTiering access tier is Archive Access or Deep Archive Access.\nFor more information, see RestoreObject and Copying Objects in the Amazon S3 User Guide.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nx-amz-tagging\nThe tag-set for the object copy in the destination bucket. This value must be used in\nconjunction with the x-amz-tagging-directive if you choose REPLACE for the x-amz-\ntagging-directive. If you choose COPY for the x-amz-tagging-directive, you don't\nneed to set the x-amz-tagging header, because the tag-set will be copied from the source\nobject directly. The tag-set must be encoded as URL Query parameters.\nThe default value is the empty value.\nNote\nDirectory buckets - For directory buckets in a CopyObject operation, only the empty\ntag-set is supported. Any requests that attempt to write non-empty tags into directory\nbuckets will receive a 501 Not Implemented status code. When the destination\nbucket is a directory bucket, you will receive a 501 Not Implemented response in any\nof the following situations:\n\u2022 When you attempt to COPY the tag-set from an S3 source object that has non-empty\ntags.\nAmazon S3 API Version 2006-03-01 53",
      "start_idx": 96705,
      "end_idx": 98619,
      "metadata": {
        "num_sentences": 15,
        "num_words": 311,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_59",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 When you attempt to REPLACE the tag-set of a source object and set a non-empty\nvalue to x-amz-tagging.\n\u2022 When you don't set the x-amz-tagging-directive header and the source\nobject has non-empty tags. This is because the default value of x-amz-tagging-\ndirective is COPY.\nBecause only the empty tag-set is supported for directory buckets in a CopyObject\noperation, the following situations are allowed:\n\u2022 When you attempt to COPY the tag-set from a directory bucket source object that\nhas no tags to a general purpose bucket. It copies an empty tag-set to the destination\nobject.\n\u2022 When you attempt to REPLACE the tag-set of a directory bucket source object and set\nthe x-amz-tagging value of the directory bucket destination object to empty.\n\u2022 When you attempt to REPLACE the tag-set of a general purpose bucket source object\nthat has non-empty tags and set the x-amz-tagging value of the directory bucket\ndestination object to empty.\n\u2022 When you attempt to REPLACE the tag-set of a directory bucket source object and\ndon't set the x-amz-tagging value of the directory bucket destination object. This is\nbecause the default value of x-amz-tagging is the empty value.\nx-amz-tagging-directive\nSpecifies whether the object tag-set is copied from the source object or replaced with the tag-\nset that's provided in the request.\nThe default value is COPY.\nNote\nDirectory buckets - For directory buckets in a CopyObject operation, only the empty\ntag-set is supported. Any requests that attempt to write non-empty tags into directory\nbuckets will receive a 501 Not Implemented status code. When the destination\nbucket is a directory bucket, you will receive a 501 Not Implemented response in any\nof the following situations:\n\u2022 When you attempt to COPY the tag-set from an S3 source object that has non-empty\ntags.\nAmazon S3 API Version 2006-03-01 54",
      "start_idx": 98621,
      "end_idx": 100508,
      "metadata": {
        "num_sentences": 15,
        "num_words": 308,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_60",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 When you attempt to REPLACE the tag-set of a source object and set a non-empty\nvalue to x-amz-tagging.\n\u2022 When you don't set the x-amz-tagging-directive header and the source\nobject has non-empty tags. This is because the default value of x-amz-tagging-\ndirective is COPY.\nBecause only the empty tag-set is supported for directory buckets in a CopyObject\noperation, the following situations are allowed:\n\u2022 When you attempt to COPY the tag-set from a directory bucket source object that\nhas no tags to a general purpose bucket. It copies an empty tag-set to the destination\nobject.\n\u2022 When you attempt to REPLACE the tag-set of a directory bucket source object and set\nthe x-amz-tagging value of the directory bucket destination object to empty.\n\u2022 When you attempt to REPLACE the tag-set of a general purpose bucket source object\nthat has non-empty tags and set the x-amz-tagging value of the directory bucket\ndestination object to empty.\n\u2022 When you attempt to REPLACE the tag-set of a directory bucket source object and\ndon't set the x-amz-tagging value of the directory bucket destination object. This is\nbecause the default value of x-amz-tagging is the empty value.\nValid Values: COPY | REPLACE\nx-amz-website-redirect-location\nIf the destination bucket is configured as a website, redirects requests for this object copy to\nanother object in the same bucket or to an external URL. Amazon S3 stores the value of this\nheader in the object metadata. This value is unique to each object and is not copied when using\nthe x-amz-metadata-directive header. Instead, you may opt to provide this header in\ncombination with the x-amz-metadata-directive header.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 55",
      "start_idx": 100510,
      "end_idx": 102306,
      "metadata": {
        "num_sentences": 15,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_62",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the object expiration is configured, the response includes this header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for\nexample, AES256, aws:kms, aws:kms:dsse).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the copied object uses an S3 Bucket Key for server-side encryption with AWS\nKey Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value\nof this header is a base64-encoded UTF-8 string holding JSON with the encryption context key-\nvalue pairs.\nAmazon S3 API Version 2006-03-01 57",
      "start_idx": 103589,
      "end_idx": 104773,
      "metadata": {
        "num_sentences": 10,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_64",
      "text": "Amazon Simple Storage Service API Reference\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nETag\nReturns the ETag of the new object. The ETag reflects only changes to the contents of an object,\nnot its metadata.\nType: String\nLastModified\nCreation date of the object.\nType: Timestamp\nAmazon S3 API Version 2006-03-01 59",
      "start_idx": 105726,
      "end_idx": 106908,
      "metadata": {
        "num_sentences": 16,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_67",
      "text": "Amazon Simple Storage Service API Reference\nSuccess Response for general purpose buckets: Copying a versioned object into a version-\nsuspended bucket\nThe following response shows that an object was copied into a target bucket where versioning is\nsuspended. The parameter VersionId does not appear.\nHTTP/1.1 200 OK\nx-amz-id-2:\neftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran\nx-amz-request-id: 318BC8BC148832E5\nx-amz-copy-source-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nConnection: close\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CopyObjectResult>\n<LastModified>2009-10-28T22:32:00</LastModified>\n<ETag>\"9b2cf535f27731c974343645a3985328\"</ETag>\n</CopyObjectResult>\nSample Request for general purpose buckets: Copy from unencrypted object to an object\nencrypted with server-side encryption with customer-provided encryption keys\nThe following example specifies the HTTP PUT header to copy an unencrypted object to an object\nencrypted with server-side encryption with customer-provided encryption keys (SSE-C).\nPUT /exampleDestinationObject HTTP/1.1\nHost: example-destination-bucket.s3.<Region>.amazonaws.com\nx-amz-server-side-encryption-customer-algorithm: AES256\nx-amz-server-side-encryption-customer-key: Base64(YourKey)\nx-amz-server-side-encryption-customer-key-MD5 : Base64(MD5(YourKey))\nx-amz-metadata-directive: metadata_directive\nx-amz-copy-source: /example_source_bucket/exampleSourceObject\nx-amz-copy-source-if-match: etag\nx-amz-copy-source-if-none-match: etag\nx-amz-copy-source-if-unmodified-since: time_stamp\nx-amz-copy-source-if-modified-since: time_stamp\nAmazon S3 API Version 2006-03-01 62",
      "start_idx": 109359,
      "end_idx": 111064,
      "metadata": {
        "num_sentences": 4,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_70",
      "text": "Amazon Simple Storage Service API Reference\nCreateBucket\nService: Amazon S3\nNote\nThis action creates an Amazon S3 bucket. To create an Amazon S3 on Outposts bucket, see\nCreateBucket.\nCreates a new S3 bucket. To create a bucket, you must set up Amazon S3 and have a valid AWS\nAccess Key ID to authenticate requests. Anonymous requests are never allowed to create buckets.\nBy creating the bucket, you become the bucket owner.\nThere are two types of buckets: general purpose buckets and directory buckets. For more\ninformation about these bucket types, see Creating, configuring, and working with Amazon S3\nbuckets in the Amazon S3 User Guide.\nNote\n\u2022 General purpose buckets - If you send your CreateBucket request to the\ns3.amazonaws.com global endpoint, the request goes to the us-east-1 Region. So\nthe signature calculations in Signature Version 4 must use us-east-1 as the Region,\neven if the location constraint in the request specifies another Region where the bucket\nis to be created. If you create a bucket in a Region other than US East (N. Virginia), your\napplication must be able to handle 307 redirect. For more information, see Virtual\nhosting of buckets in the Amazon S3 User Guide.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - In addition to the s3:CreateBucket permission, the\nfollowing permissions are required in a policy when your CreateBucket request includes\nspecific headers:\nAmazon S3 API Version 2006-03-01 65",
      "start_idx": 112916,
      "end_idx": 114725,
      "metadata": {
        "num_sentences": 17,
        "num_words": 279,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_71",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Access control lists (ACLs) - In your CreateBucket request, if you specify an access\ncontrol list (ACL) and set it to public-read, public-read-write, authenticated-\nread, or if you explicitly specify any other custom ACLs, both s3:CreateBucket and\ns3:PutBucketAcl permissions are required. In your CreateBucket request, if you\nset the ACL to private, or if you don't specify any ACLs, only the s3:CreateBucket\npermission is required.\n\u2022 Object Lock - In your CreateBucket request, if you set x-amz-bucket-object-\nlock-enabled to true, the s3:PutBucketObjectLockConfiguration and\ns3:PutBucketVersioning permissions are required.\n\u2022 S3 Object Ownership - If your CreateBucket request includes the x-amz-object-\nownership header, then the s3:PutBucketOwnershipControls permission is required.\nImportant\nTo set an ACL on a bucket as part of a CreateBucket request, you must explicitly\nset S3 Object Ownership for the bucket to a different value than the default,\nBucketOwnerEnforced. Additionally, if your desired bucket ACL grants public\naccess, you must first create the bucket (without the bucket ACL) and then explicitly\ndisable Block Public Access on the bucket before using PutBucketAcl to set the\nACL. If you try to create a bucket with a public ACL, the request will fail.\nFor the majority of modern use cases in S3, we recommend that you keep all Block\nPublic Access settings enabled and keep ACLs disabled. If you would like to share\ndata with users outside of your account, you can use bucket policies as needed. For\nmore information, see Controlling ownership of objects and disabling ACLs for your\nbucket and Blocking public access to your Amazon S3 storage in the Amazon S3\nUser Guide.\n\u2022 S3 Block Public Access - If your specific use case requires granting public access to your\nS3 resources, you can disable Block Public Access. Specifically, you can create a new bucket\nwith Block Public Access enabled, then separately call the DeletePublicAccessBlock\nAPI. To use this operation, you must have the s3:PutBucketPublicAccessBlock\npermission. For more information about S3 Block Public Access, see Blocking public access\nto your Amazon S3 storage in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - You must have the s3express:CreateBucket permission\nin an IAM identity-based policy instead of a bucket policy. Cross-account access to this API\noperation isn't supported. This operation can only be performed by the AWS account that\nAmazon S3 API Version 2006-03-01 66",
      "start_idx": 114727,
      "end_idx": 117258,
      "metadata": {
        "num_sentences": 17,
        "num_words": 392,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_72",
      "text": "Amazon Simple Storage Service API Reference\nowns the resource. For more information about directory bucket policies and permissions, see\nAWS Identity and Access Management (IAM) for S3 Express One Zone in the Amazon S3 User\nGuide.\nImportant\nThe permissions for ACLs, Object Lock, S3 Object Ownership, and S3 Block Public\nAccess are not supported for directory buckets. For directory buckets, all Block Public\nAccess settings are enabled at the bucket level and S3 Object Ownership is set to\nBucket owner enforced (ACLs disabled). These settings can't be modified.\nFor more information about permissions for creating and working with directory\nbuckets, see Directory buckets in the Amazon S3 User Guide. For more information\nabout supported S3 features for directory buckets, see Features of S3 Express One\nZone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to CreateBucket:\n\u2022 PutObject\n\u2022 DeleteBucket\nRequest Syntax\nPUT / HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-bucket-object-lock-enabled: ObjectLockEnabledForBucket\nx-amz-object-ownership: ObjectOwnership\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateBucketConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\nAmazon S3 API Version 2006-03-01 67",
      "start_idx": 117260,
      "end_idx": 118796,
      "metadata": {
        "num_sentences": 9,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_73",
      "text": "Amazon Simple Storage Service API Reference\n<LocationConstraint>string</LocationConstraint>\n<Location>\n<Name>string</Name>\n<Type>string</Type>\n</Location>\n<Bucket>\n<DataRedundancy>string</DataRedundancy>\n<Type>string</Type>\n</Bucket>\n</CreateBucketConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to create.\nGeneral purpose buckets - For information about bucket naming restrictions, see Bucket\nnaming rules in the Amazon S3 User Guide.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-acl\nThe canned ACL to apply to the bucket.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: private | public-read | public-read-write | authenticated-read\nAmazon S3 API Version 2006-03-01 68",
      "start_idx": 118798,
      "end_idx": 120080,
      "metadata": {
        "num_sentences": 10,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_75",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-object-ownership\nThe container element for object ownership for a bucket's ownership controls.\nBucketOwnerPreferred - Objects uploaded to the bucket change ownership to the bucket\nowner if the objects are uploaded with the bucket-owner-full-control canned ACL.\nObjectWriter - The uploading account will own the object if the object is uploaded with the\nbucket-owner-full-control canned ACL.\nBucketOwnerEnforced - Access control lists (ACLs) are disabled and no longer affect\npermissions. The bucket owner automatically owns and has full control over every object in\nthe bucket. The bucket only accepts PUT requests that don't specify an ACL or specify bucket\nowner full control ACLs (such as the predefined bucket-owner-full-control canned ACL or\na custom ACL in XML format that grants the same permissions).\nBy default, ObjectOwnership is set to BucketOwnerEnforced and ACLs are disabled. We\nrecommend keeping ACLs disabled, except in uncommon use cases where you must control\naccess for each object individually. For more information about S3 Object Ownership, see\nControlling ownership of objects and disabling ACLs for your bucket in the Amazon S3 User\nGuide.\nNote\nThis functionality is not supported for directory buckets. Directory buckets use the\nbucket owner enforced setting for S3 Object Ownership.\nAmazon S3 API Version 2006-03-01 70",
      "start_idx": 120942,
      "end_idx": 122545,
      "metadata": {
        "num_sentences": 15,
        "num_words": 235,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_76",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: BucketOwnerPreferred | ObjectWriter | BucketOwnerEnforced\nRequest Body\nThe request accepts the following data in XML format.\nCreateBucketConfiguration\nRoot level tag for the CreateBucketConfiguration parameters.\nRequired: Yes\nBucket\nSpecifies the information about the bucket that will be created.\nNote\nThis functionality is only supported by directory buckets.\nType: BucketInfo data type\nRequired: No\nLocation\nSpecifies the location where the bucket will be created.\nFor directory buckets, the location type is Availability Zone.\nNote\nThis functionality is only supported by directory buckets.\nType: LocationInfo data type\nRequired: No\nLocationConstraint\nSpecifies the Region where the bucket will be created. You might choose a Region to optimize\nlatency, minimize costs, or address regulatory requirements. For example, if you reside in\nAmazon S3 API Version 2006-03-01 71",
      "start_idx": 122547,
      "end_idx": 123480,
      "metadata": {
        "num_sentences": 10,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_77",
      "text": "Amazon Simple Storage Service API Reference\nEurope, you will probably find it advantageous to create buckets in the Europe (Ireland) Region.\nFor more information, see Accessing a bucket in the Amazon S3 User Guide.\nIf you don't specify a Region, the bucket is created in the US East (N. Virginia) Region (us-east-1)\nby default.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nValid Values: af-south-1 | ap-east-1 | ap-northeast-1 | ap-northeast-2 | ap-\nnortheast-3 | ap-south-1 | ap-south-2 | ap-southeast-1 | ap-southeast-2\n| ap-southeast-3 | ca-central-1 | cn-north-1 | cn-northwest-1 | EU | eu-\ncentral-1 | eu-north-1 | eu-south-1 | eu-south-2 | eu-west-1 | eu-west-2\n| eu-west-3 | me-south-1 | sa-east-1 | us-east-2 | us-gov-east-1 | us-\ngov-west-1 | us-west-1 | us-west-2\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nLocation: Location\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nLocation\nA forward slash followed by the name of the bucket.\nAmazon S3 API Version 2006-03-01 72",
      "start_idx": 123482,
      "end_idx": 124586,
      "metadata": {
        "num_sentences": 8,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_78",
      "text": "Amazon Simple Storage Service API Reference\nErrors\nBucketAlreadyExists\nThe requested bucket name is not available. The bucket namespace is shared by all users of the\nsystem. Select a different name and try again.\nHTTP Status Code: 409\nBucketAlreadyOwnedByYou\nThe bucket you tried to create already exists, and you own it. Amazon S3 returns this error in all\nAWS Regions except in the North Virginia Region. For legacy compatibility, if you re-create an\nexisting bucket that you already own in the North Virginia Region, Amazon S3 returns 200 OK\nand resets the bucket access control lists (ACLs).\nHTTP Status Code: 409\nExamples\nSample Request for general purpose buckets\nThis request creates a bucket named colorpictures.\nPUT / HTTP/1.1\nHost: colorpictures.s3.<Region>.amazonaws.com\nContent-Length: 0\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAuthorization: authorization string\nSample Response for general purpose buckets\nThis example illustrates one usage of CreateBucket.\nHTTP/1.1 200 OK\nx-amz-id-2:\nYgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAmazon S3 API Version 2006-03-01 73",
      "start_idx": 124588,
      "end_idx": 125755,
      "metadata": {
        "num_sentences": 9,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_83",
      "text": "Amazon Simple Storage Service API Reference\nCreateMultipartUpload\nService: Amazon S3\nThis action initiates a multipart upload and returns an upload ID. This upload ID is used to\nassociate all of the parts in the specific multipart upload. You specify this upload ID in each of\nyour subsequent upload part requests (see UploadPart). You also include this upload ID in the final\nrequest to either complete or abort the multipart upload request. For more information about\nmultipart uploads, see Multipart Upload Overview in the Amazon S3 User Guide.\nNote\nAfter you initiate a multipart upload and upload one or more parts, to stop being charged\nfor storing the uploaded parts, you must either complete or abort the multipart upload.\nAmazon S3 frees up the space used to store the parts and stops charging you for storing\nthem only after you either complete or abort a multipart upload.\nIf you have configured a lifecycle rule to abort incomplete multipart uploads, the created\nmultipart upload must be completed within the number of days specified in the bucket lifecycle\nconfiguration. Otherwise, the incomplete multipart upload becomes eligible for an abort action\nand Amazon S3 aborts the multipart upload. For more information, see Aborting Incomplete\nMultipart Uploads Using a Bucket Lifecycle Configuration.\nNote\n\u2022 Directory buckets - S3 Lifecycle is not supported by directory buckets.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the\nformat https://bucket_name.s3express-az_id.region.amazonaws.com/key-\nname . Path-style requests are not supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nRequest signing\nFor request signing, multipart upload is just a series of regular requests. You initiate a multipart\nupload, send one or more requests to upload parts, and then complete the multipart upload\nAmazon S3 API Version 2006-03-01 78",
      "start_idx": 128951,
      "end_idx": 130958,
      "metadata": {
        "num_sentences": 17,
        "num_words": 308,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_84",
      "text": "Amazon Simple Storage Service API Reference\nprocess. You sign each request individually. There is nothing special about signing multipart\nupload requests. For more information about signing, see Authenticating Requests (AWS\nSignature Version 4) in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - To perform a multipart upload with encryption using\nan AWS Key Management Service (AWS KMS) KMS key, the requester must have permission to\nthe kms:Decrypt and kms:GenerateDataKey actions on the key. The requester must also\nhave permissions for the kms:GenerateDataKey action for the CreateMultipartUpload\nAPI. Then, the requester needs permissions for the kms:Decrypt action on the UploadPart\nand UploadPartCopy APIs. These permissions are required because Amazon S3 must\ndecrypt and read data from the encrypted file parts before it completes the multipart upload.\nFor more information, see Multipart upload API and permissions and Protecting data using\nserver-side encryption with AWS KMS in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nEncryption\n\u2022 General purpose buckets - Server-side encryption is for data encryption at rest. Amazon S3\nencrypts your data as it writes it to disks in its data centers and decrypts it when you access it.\nAmazon S3 automatically encrypts all new objects that are uploaded to an S3 bucket. When\ndoing a multipart upload, if you don't specify encryption information in your request, the\nencryption setting of the uploaded parts is set to the default encryption configuration of\nthe destination bucket. By default, all buckets have a base level of encryption configuration\nthat uses server-side encryption with Amazon S3 managed keys (SSE-S3). If the destination\nbucket has a default encryption configuration that uses server-side encryption with an AWS\nKey Management Service (AWS KMS) key (SSE-KMS), or a customer-provided encryption key\n(SSE-C), Amazon S3 uses the corresponding KMS key, or a customer-provided key to encrypt\nthe uploaded parts. When you perform a CreateMultipartUpload operation, if you want to use\nAmazon S3 API Version 2006-03-01 79",
      "start_idx": 130960,
      "end_idx": 133860,
      "metadata": {
        "num_sentences": 23,
        "num_words": 442,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_85",
      "text": "Amazon Simple Storage Service API Reference\na different type of encryption setting for the uploaded parts, you can request that Amazon\nS3 encrypts the object with a different encryption key (such as an Amazon S3 managed\nkey, a KMS key, or a customer-provided key). When the encryption setting in your request is\ndifferent from the default encryption configuration of the destination bucket, the encryption\nsetting in your request takes precedence. If you choose to provide your own encryption key,\nthe request headers you provide in UploadPart and UploadPartCopy requests must match the\nheaders you used in the CreateMultipartUpload request.\n\u2022 Use KMS keys (SSE-KMS) that include the AWS managed key (aws/s3) and AWS KMS\ncustomer managed keys stored in AWS Key Management Service (AWS KMS) \u2013 If you want\nAWS to manage the keys used to encrypt data, specify the following headers in the request.\n\u2022 x-amz-server-side-encryption\n\u2022 x-amz-server-side-encryption-aws-kms-key-id\n\u2022 x-amz-server-side-encryption-context\nNote\n\u2022 If you specify x-amz-server-side-encryption:aws:kms, but don't provide\nx-amz-server-side-encryption-aws-kms-key-id, Amazon S3 uses the\nAWS managed key (aws/s3 key) in AWS KMS to protect the data.\n\u2022 To perform a multipart upload with encryption by using an AWS KMS\nkey, the requester must have permission to the kms:Decrypt and\nkms:GenerateDataKey* actions on the key. These permissions are required\nbecause Amazon S3 must decrypt and read data from the encrypted file parts\nbefore it completes the multipart upload. For more information, see Multipart\nupload API and permissions and Protecting data using server-side encryption\nwith AWS KMS in the Amazon S3 User Guide.\n\u2022 If your AWS Identity and Access Management (IAM) user or role is in the same\nAWS account as the KMS key, then you must have these permissions on the key\npolicy. If your IAM user or role is in a different account from the key, then you\nmust have the permissions on both the key policy and your IAM user or role.\n\u2022 All GET and PUT requests for an object protected by AWS KMS fail if you don't\nmake them by using Secure Sockets Layer (SSL), Transport Layer Security (TLS),\nor Signature Version 4. For information about configuring any of the officially\nsupported AWS SDKs and AWS CLI, see Specifying the Signature Version in\nRequest Authentication in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 80",
      "start_idx": 133862,
      "end_idx": 136261,
      "metadata": {
        "num_sentences": 13,
        "num_words": 382,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_86",
      "text": "Amazon Simple Storage Service API Reference\nFor more information about server-side encryption with AWS KMS keys (SSE-KMS), see\nProtecting Data Using Server-Side Encryption with KMS keys in the Amazon S3 User Guide.\n\u2022 Use customer-provided encryption keys (SSE-C) \u2013 If you want to manage your own\nencryption keys, provide all the following headers in the request.\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information about server-side encryption with customer-provided encryption\nkeys (SSE-C), see Protecting data using server-side encryption with customer-provided\nencryption keys (SSE-C) in the Amazon S3 User Guide.\n\u2022 Directory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256)\nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that\nthe bucket's default encryption uses the desired encryption configuration and you don't\noverride the bucket default encryption in your CreateSession requests or PUT object\nrequests. Then, new objects are automatically encrypted with the desired encryption settings.\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User\nGuide. For more information about the encryption overriding behaviors in directory buckets,\nsee Specifying server-side encryption with AWS KMS for new object uploads.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST API,\nthe encryption request headers must match the encryption settings that are specified in the\nCreateSession request. You can't override the values of the encryption settings (x-amz-\nserver-side-encryption, x-amz-server-side-encryption-aws-kms-key-id, x-\namz-server-side-encryption-context, and x-amz-server-side-encryption-\nbucket-key-enabled) that are specified in the CreateSession request. You don't need\nto explicitly specify these encryption settings values in Zonal endpoint API calls, and Amazon\nS3 will use the encryption settings values from the CreateSession request to protect new\nobjects in the directory bucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession, the session token\nrefreshes automatically to avoid service interruptions when a session expires. The\nAmazon S3 API Version 2006-03-01 81",
      "start_idx": 136263,
      "end_idx": 138692,
      "metadata": {
        "num_sentences": 13,
        "num_words": 323,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_87",
      "text": "Amazon Simple Storage Service API Reference\nCLI or the AWS SDKs use the bucket's default encryption configuration for the\nCreateSession request. It's not supported to override the encryption settings\nvalues in the CreateSession request. So in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), the encryption request headers must match the\ndefault encryption configuration of the directory bucket.\nNote\nFor directory buckets, when you perform a CreateMultipartUpload operation\nand an UploadPartCopy operation, the request headers you provide in the\nCreateMultipartUpload request must match the default encryption configuration\nof the destination bucket.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to CreateMultipartUpload:\n\u2022 UploadPart\n\u2022 CompleteMultipartUpload\n\u2022 AbortMultipartUpload\n\u2022 ListParts\n\u2022 ListMultipartUploads\nRequest Syntax\nPOST /{Key+}?uploads HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nCache-Control: CacheControl\nContent-Disposition: ContentDisposition\nContent-Encoding: ContentEncoding\nContent-Language: ContentLanguage\nContent-Type: ContentType\nAmazon S3 API Version 2006-03-01 82",
      "start_idx": 138694,
      "end_idx": 139938,
      "metadata": {
        "num_sentences": 6,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_88",
      "text": "Amazon Simple Storage Service API Reference\nExpires: Expires\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-storage-class: StorageClass\nx-amz-website-redirect-location: WebsiteRedirectLocation\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-payer: RequestPayer\nx-amz-tagging: Tagging\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-checksum-algorithm: ChecksumAlgorithm\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket where the multipart upload is initiated and where the object is\nuploaded.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\nAmazon S3 API Version 2006-03-01 83",
      "start_idx": 139940,
      "end_idx": 141987,
      "metadata": {
        "num_sentences": 10,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_89",
      "text": "Amazon Simple Storage Service API Reference\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nCache-Control\nSpecifies caching behavior along the request/reply chain.\nContent-Disposition\nSpecifies presentational information for the object.\nContent-Encoding\nSpecifies what content encodings have been applied to the object and thus what decoding\nmechanisms must be applied to obtain the media-type referenced by the Content-Type header\nfield.\nNote\nFor directory buckets, only the aws-chunked value is supported in this header field.\nContent-Language\nThe language that the content is in.\nAmazon S3 API Version 2006-03-01 84",
      "start_idx": 141989,
      "end_idx": 143452,
      "metadata": {
        "num_sentences": 15,
        "num_words": 218,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_90",
      "text": "Amazon Simple Storage Service API Reference\nContent-Type\nA standard MIME type describing the format of the object data.\nExpires\nThe date and time at which the object is no longer cacheable.\nKey\nObject key for which the multipart upload is to be initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-acl\nThe canned ACL to apply to the object. Amazon S3 supports a set of predefined ACLs, known\nas canned ACLs. Each canned ACL has a predefined set of grantees and permissions. For more\ninformation, see Canned ACL in the Amazon S3 User Guide.\nBy default, all objects are private. Only the owner has full access control. When uploading an\nobject, you can grant access permissions to individual AWS accounts or to predefined groups\ndefined by Amazon S3. These permissions are then added to the access control list (ACL) on the\nnew object. For more information, see Using ACLs. One way to grant the permissions using the\nrequest headers is to specify a canned ACL with the x-amz-acl request header.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nValid Values: private | public-read | public-read-write | authenticated-read\n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-checksum-algorithm\nIndicates the algorithm that you want Amazon S3 to use to create the checksum for the object.\nFor more information, see Checking object integrity in the Amazon S3 User Guide.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 85",
      "start_idx": 143454,
      "end_idx": 145018,
      "metadata": {
        "num_sentences": 19,
        "num_words": 253,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_91",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nSpecify access permissions explicitly to give the grantee READ, READ_ACP, and WRITE_ACP\npermissions on the object.\nBy default, all objects are private. Only the owner has full access control. When uploading an\nobject, you can use this header to explicitly grant access permissions to specific AWS accounts\nor groups. This header maps to specific permissions that Amazon S3 supports in an ACL. For\nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022 id \u2013 if the value specified is the canonical user ID of an AWS account\n\u2022 uri \u2013 if you are granting permissions to a predefined group\n\u2022 emailAddress \u2013 if the value specified is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nAmazon S3 API Version 2006-03-01 86",
      "start_idx": 145020,
      "end_idx": 146545,
      "metadata": {
        "num_sentences": 10,
        "num_words": 257,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_92",
      "text": "Amazon Simple Storage Service API Reference\nFor example, the following x-amz-grant-read header grants the AWS accounts identified by\naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nSpecify access permissions explicitly to allow grantee to read the object data and its metadata.\nBy default, all objects are private. Only the owner has full access control. When uploading an\nobject, you can use this header to explicitly grant access permissions to specific AWS accounts\nor groups. This header maps to specific permissions that Amazon S3 supports in an ACL. For\nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022 id \u2013 if the value specified is the canonical user ID of an AWS account\n\u2022 uri \u2013 if you are granting permissions to a predefined group\n\u2022 emailAddress \u2013 if the value specified is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\nAmazon S3 API Version 2006-03-01 87",
      "start_idx": 146547,
      "end_idx": 148003,
      "metadata": {
        "num_sentences": 9,
        "num_words": 239,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_93",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nFor example, the following x-amz-grant-read header grants the AWS accounts identified by\naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read-acp\nSpecify access permissions explicitly to allows grantee to read the object ACL.\nBy default, all objects are private. Only the owner has full access control. When uploading an\nobject, you can use this header to explicitly grant access permissions to specific AWS accounts\nor groups. This header maps to specific permissions that Amazon S3 supports in an ACL. For\nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022 id \u2013 if the value specified is the canonical user ID of an AWS account\n\u2022 uri \u2013 if you are granting permissions to a predefined group\n\u2022 emailAddress \u2013 if the value specified is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\nAmazon S3 API Version 2006-03-01 88",
      "start_idx": 148005,
      "end_idx": 149531,
      "metadata": {
        "num_sentences": 10,
        "num_words": 251,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_94",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nFor example, the following x-amz-grant-read header grants the AWS accounts identified by\naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-write-acp\nSpecify access permissions explicitly to allows grantee to allow grantee to write the ACL for the\napplicable object.\nBy default, all objects are private. Only the owner has full access control. When uploading an\nobject, you can use this header to explicitly grant access permissions to specific AWS accounts\nor groups. This header maps to specific permissions that Amazon S3 supports in an ACL. For\nmore information, see Access Control List (ACL) Overview in the Amazon S3 User Guide.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022 id \u2013 if the value specified is the canonical user ID of an AWS account\n\u2022 uri \u2013 if you are granting permissions to a predefined group\n\u2022 emailAddress \u2013 if the value specified is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\nAmazon S3 API Version 2006-03-01 89",
      "start_idx": 149533,
      "end_idx": 151067,
      "metadata": {
        "num_sentences": 10,
        "num_words": 250,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_95",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nFor example, the following x-amz-grant-read header grants the AWS accounts identified by\naccount IDs permissions to read object data and its metadata:\nx-amz-grant-read: id=\"11112222333\", id=\"444455556666\"\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-object-lock-legal-hold\nSpecifies whether you want to apply a legal hold to the uploaded object.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nx-amz-object-lock-mode\nSpecifies the Object Lock mode that you want to apply to the uploaded object.\nAmazon S3 API Version 2006-03-01 90",
      "start_idx": 151069,
      "end_idx": 152085,
      "metadata": {
        "num_sentences": 7,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_96",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nSpecifies the date and time when you want the Object Lock to expire.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for\nexample, AES256, aws:kms).\n\u2022 Directory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256)\nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that\nthe bucket's default encryption uses the desired encryption configuration and you don't\noverride the bucket default encryption in your CreateSession requests or PUT object\nAmazon S3 API Version 2006-03-01 91",
      "start_idx": 152087,
      "end_idx": 153559,
      "metadata": {
        "num_sentences": 11,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_97",
      "text": "Amazon Simple Storage Service API Reference\nrequests. Then, new objects are automatically encrypted with the desired encryption settings.\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User\nGuide. For more information about the encryption overriding behaviors in directory buckets,\nsee Specifying server-side encryption with AWS KMS for new object uploads.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST API,\nthe encryption request headers must match the encryption settings that are specified in the\nCreateSession request. You can't override the values of the encryption settings (x-amz-\nserver-side-encryption, x-amz-server-side-encryption-aws-kms-key-id, x-\namz-server-side-encryption-context, and x-amz-server-side-encryption-\nbucket-key-enabled) that are specified in the CreateSession request. You don't need\nto explicitly specify these encryption settings values in Zonal endpoint API calls, and Amazon\nS3 will use the encryption settings values from the CreateSession request to protect new\nobjects in the directory bucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession, the session token\nrefreshes automatically to avoid service interruptions when a session expires. The\nCLI or the AWS SDKs use the bucket's default encryption configuration for the\nCreateSession request. It's not supported to override the encryption settings\nvalues in the CreateSession request. So in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), the encryption request headers must match the\ndefault encryption configuration of the directory bucket.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nSpecifies the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the\nKMS key doesn't exist in the same account that's issuing the command, you must use the full\nKey ARN not the Key ID.\nGeneral purpose buckets - If you specify x-amz-server-side-encryption with aws:kms\nor aws:kms:dsse, this header specifies the ID (Key ID, Key ARN, or Key Alias) of the AWS KMS\nkey to use. If you specify x-amz-server-side-encryption:aws:kms or x-amz-server-\nside-encryption:aws:kms:dsse, but do not provide x-amz-server-side-encryption-\naws-kms-key-id, Amazon S3 uses the AWS managed key (aws/s3) to protect the data.\nAmazon S3 API Version 2006-03-01 92",
      "start_idx": 153561,
      "end_idx": 155963,
      "metadata": {
        "num_sentences": 16,
        "num_words": 337,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_98",
      "text": "Amazon Simple Storage Service API Reference\nDirectory buckets - If you specify x-amz-server-side-encryption with aws:kms, the\nx-amz-server-side-encryption-aws-kms-key-id header is implicitly assigned the\nID of the AWS KMS symmetric encryption customer managed key that's configured for your\ndirectory bucket's default encryption setting. If you want to specify the x-amz-server-\nside-encryption-aws-kms-key-id header explicitly, you can only specify it with the ID\n(Key ID or Key ARN) of the AWS KMS customer managed key that's configured for your directory\nbucket's default encryption setting. Otherwise, you get an HTTP 400 Bad Request error. Only\nuse the key ID or key ARN. The key alias format of the KMS key isn't supported. Your SSE-KMS\nconfiguration can only support 1 customer managed key per directory bucket for the lifetime of\nthe bucket. The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpecifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS Key Management Service (AWS KMS) keys (SSE-KMS).\nGeneral purpose buckets - Setting this header to true causes Amazon S3 to use an S3 Bucket\nKey for object encryption with SSE-KMS. Also, specifying this header with a PUT action doesn't\naffect bucket-level settings for S3 Bucket Key.\nDirectory buckets - S3 Bucket Keys are always enabled for GET and PUT operations in a\ndirectory bucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you copy SSE-\nKMS encrypted objects from general purpose buckets to directory buckets, from directory\nbuckets to general purpose buckets, or between directory buckets, through CopyObject,\nUploadPartCopy, the Copy operation in Batch Operations, or the import jobs. In this case,\nAmazon S3 makes a call to AWS KMS every time a copy request is made for a KMS-encrypted\nobject.\nx-amz-server-side-encryption-context\nSpecifies the AWS KMS Encryption Context to use for object encryption. The value of this\nheader is a Base64-encoded string of a UTF-8 encoded JSON, which contains the encryption\ncontext as key-value pairs.\nDirectory buckets - You can optionally provide an explicit encryption context value. The value\nmust match the default encryption context - the bucket Amazon Resource Name (ARN). An\nadditional encryption context value is not supported.\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nAmazon S3 API Version 2006-03-01 93",
      "start_idx": 155965,
      "end_idx": 158489,
      "metadata": {
        "num_sentences": 20,
        "num_words": 374,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_99",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded; Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-amz-\nserver-side-encryption-customer-algorithm header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the customer-provided encryption key according to RFC\n1321. Amazon S3 uses this header for a message integrity check to ensure that the encryption\nkey was transmitted without error.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-storage-class\nBy default, Amazon S3 uses the STANDARD Storage Class to store newly created objects.\nThe STANDARD storage class provides high durability and high availability. Depending on\nperformance needs, you can specify a different Storage Class. For more information, see\nStorage Classes in the Amazon S3 User Guide.\nNote\n\u2022 For directory buckets, only the S3 Express One Zone storage class is supported to\nstore newly created objects.\nAmazon S3 API Version 2006-03-01 94",
      "start_idx": 158491,
      "end_idx": 159840,
      "metadata": {
        "num_sentences": 14,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_100",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Amazon S3 on Outposts only uses the OUTPOSTS Storage Class.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nx-amz-tagging\nThe tag-set for the object. The tag-set must be encoded as URL Query parameters.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-website-redirect-location\nIf the bucket is configured as a website, redirects requests for this object to another object in\nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object\nmetadata.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-abort-date: AbortDate\nx-amz-abort-rule-id: AbortRuleId\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nAmazon S3 API Version 2006-03-01 95",
      "start_idx": 159842,
      "end_idx": 161058,
      "metadata": {
        "num_sentences": 9,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_101",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\nx-amz-checksum-algorithm: ChecksumAlgorithm\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InitiateMultipartUploadResult>\n<Bucket>string</Bucket>\n<Key>string</Key>\n<UploadId>string</UploadId>\n</InitiateMultipartUploadResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-abort-date\nIf the bucket has a lifecycle rule configured with an action to abort incomplete multipart\nuploads and the prefix in the lifecycle rule matches the object name in the request, the\nresponse includes this header. The header indicates when the initiated multipart upload\nbecomes eligible for an abort operation. For more information, see Aborting Incomplete\nMultipart Uploads Using a Bucket Lifecycle Configuration in the Amazon S3 User Guide.\nThe response also includes the x-amz-abort-rule-id header that provides the ID of the\nlifecycle configuration rule that defines the abort action.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-abort-rule-id\nThis header is returned along with the x-amz-abort-date header. It identifies the applicable\nlifecycle configuration rule that defines the action to abort incomplete multipart uploads.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 96",
      "start_idx": 161060,
      "end_idx": 162539,
      "metadata": {
        "num_sentences": 11,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_102",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-checksum-algorithm\nThe algorithm that was used to create a checksum of the object.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for\nexample, AES256, aws:kms).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the multipart upload uses an S3 Bucket Key for server-side encryption with\nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value\nof this header is a Base64-encoded string of a UTF-8 encoded JSON, which contains the\nencryption context as key-value pairs.\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response\nwill include this header to confirm the encryption algorithm that's used.\nAmazon S3 API Version 2006-03-01 97",
      "start_idx": 162541,
      "end_idx": 163926,
      "metadata": {
        "num_sentences": 10,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_103",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the\nresponse will include this header to provide the round-trip message integrity verification of the\ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nInitiateMultipartUploadResult\nRoot level tag for the InitiateMultipartUploadResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket to which the multipart upload was initiated. Does not return the access\npoint ARN or access point alias if used.\nNote\nAccess points are not supported by directory buckets.\nType: String\nKey\nObject key for which the multipart upload was initiated.\nType: String\nAmazon S3 API Version 2006-03-01 98",
      "start_idx": 163928,
      "end_idx": 164857,
      "metadata": {
        "num_sentences": 10,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_105",
      "text": "Amazon Simple Storage Service API Reference\nExample for general purpose buckets: Initiate a multipart upload using server-side encryption\nwith customer-provided encryption keys\nThis example, which initiates a multipart upload request, specifies server-side encryption with\ncustomer-provided encryption keys by adding relevant headers.\nPOST /example-object?uploads HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAuthorization:authorization string\nDate: Wed, 28 May 2014 19:34:57 +0000\nx-amz-server-side-encryption-customer-key:\ng0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEEXAMPLE\nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2example\nx-amz-server-side-encryption-customer-algorithm: AES256\nSample Response for general purpose buckets\nIn the response, Amazon S3 returns an UploadId. In addition, Amazon S3 returns the encryption\nalgorithm and the MD5 digest of the encryption key that you provided in the request.\nHTTP/1.1 200 OK\nx-amz-id-2:\n36HRCaIGp57F1FvWvVRrvd3hNn9WoBGfEaCVHTCt8QWf00qxdHazQUgfoXAbhFWD\nx-amz-request-id: 50FA1D691B62CA43\nDate: Wed, 28 May 2014 19:34:58 GMT\nx-amz-server-side-encryption-customer-algorithm: AES256\nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2m3tFg==\nTransfer-Encoding: chunked\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InitiateMultipartUploadResult\nxmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Bucket>example-bucket</Bucket>\n<Key>example-object</Key>\n<UploadId>EXAMPLEJZ6e0YupT2h66iePQCc9IEbYbDUy4RTpMeoSMLPRp8Z5o1u8feSRonpvnWsKKG35tI2LB9VDPiCgTy.Gq2VxQLYjrue4Nq.NBdqI-\n</UploadId>\n</InitiateMultipartUploadResult>\nAmazon S3 API Version 2006-03-01 100",
      "start_idx": 165957,
      "end_idx": 167585,
      "metadata": {
        "num_sentences": 4,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_107",
      "text": "Amazon Simple Storage Service API Reference\nCreateSession\nService: Amazon S3\nCreates a session that establishes temporary security credentials to support fast authentication and\nauthorization for the Zonal endpoint API operations on directory buckets. For more information\nabout Zonal endpoint API operations that include the Availability Zone in the request endpoint, see\nS3 Express One Zone APIs in the Amazon S3 User Guide.\nTo make Zonal endpoint API requests on a directory bucket, use the CreateSession API\noperation. Specifically, you grant s3express:CreateSession permission to a bucket in a bucket\npolicy or an IAM identity-based policy. Then, you use IAM credentials to make the CreateSession\nAPI request on the bucket, which returns temporary security credentials that include the access key\nID, secret access key, session token, and expiration. These credentials have associated permissions\nto access the Zonal endpoint API operations. After the session is created, you don\u2019t need to use\nother policies to grant permissions to each Zonal endpoint API individually. Instead, in your Zonal\nendpoint API requests, you sign your requests by applying the temporary security credentials of the\nsession to the request headers and following the SigV4 protocol for authentication. You also apply\nthe session token to the x-amz-s3session-token request header for authorization. Temporary\nsecurity credentials are scoped to the bucket and expire after 5 minutes. After the expiration time,\nany calls that you make with those credentials will fail. You must use IAM credentials again to\nmake a CreateSession API request that generates a new set of temporary credentials for use.\nTemporary credentials cannot be extended or refreshed beyond the original specified interval.\nIf you use AWS SDKs, SDKs handle the session token refreshes automatically to avoid service\ninterruptions when a session expires. We recommend that you use the AWS SDKs to initiate and\nmanage requests to the CreateSession API. For more information, see Performance guidelines and\ndesign patterns in the Amazon S3 User Guide.\nNote\n\u2022 You must make requests for this API operation to the Zonal endpoint.\nThese endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com. Path-style\nrequests are not supported. For more information, see Regional and Zonal endpoints in\nthe Amazon S3 User Guide.\n\u2022 CopyObject API operation - Unlike other Zonal endpoint API operations, the\nCopyObject API operation doesn't use the temporary security credentials returned from\nAmazon S3 API Version 2006-03-01 102",
      "start_idx": 167981,
      "end_idx": 170602,
      "metadata": {
        "num_sentences": 21,
        "num_words": 387,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_108",
      "text": "Amazon Simple Storage Service API Reference\nthe CreateSession API operation for authentication and authorization. For information\nabout authentication and authorization of the CopyObject API operation on directory\nbuckets, see CopyObject.\n\u2022 HeadBucket API operation - Unlike other Zonal endpoint API operations, the\nHeadBucket API operation doesn't use the temporary security credentials returned from\nthe CreateSession API operation for authentication and authorization. For information\nabout authentication and authorization of the HeadBucket API operation on directory\nbuckets, see HeadBucket.\nPermissions\nTo obtain temporary security credentials, you must create a bucket policy or an IAM identity-\nbased policy that grants s3express:CreateSession permission to the bucket. In a policy,\nyou can have the s3express:SessionMode condition key to control who can create a\nReadWrite or ReadOnly session. For more information about ReadWrite or ReadOnly\nsessions, see x-amz-create-session-mode. For example policies, see Example bucket\npolicies for S3 Express One Zone and AWS Identity and Access Management (IAM) identity-\nbased policies for S3 Express One Zone in the Amazon S3 User Guide.\nTo grant cross-account access to Zonal endpoint API operations, the bucket policy should also\ngrant both accounts the s3express:CreateSession permission.\nIf you want to encrypt objects with SSE-KMS, you must also have the kms:GenerateDataKey\nand the kms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for\nthe target AWS KMS key.\nEncryption\nFor directory buckets, there are only two supported options for server-side encryption: server-\nside encryption with Amazon S3 managed keys (SSE-S3) (AES256) and server-side encryption\nwith AWS KMS keys (SSE-KMS) (aws:kms). We recommend that the bucket's default encryption\nuses the desired encryption configuration and you don't override the bucket default encryption\nin your CreateSession requests or PUT object requests. Then, new objects are automatically\nencrypted with the desired encryption settings. For more information, see Protecting data with\nserver-side encryption in the Amazon S3 User Guide. For more information about the encryption\noverriding behaviors in directory buckets, see Specifying server-side encryption with AWS KMS\nfor new object uploads.\nAmazon S3 API Version 2006-03-01 103",
      "start_idx": 170604,
      "end_idx": 172966,
      "metadata": {
        "num_sentences": 16,
        "num_words": 332,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_109",
      "text": "Amazon Simple Storage Service API Reference\nFor Zonal endpoint (object-level) API operations except CopyObject and UploadPartCopy, you\nauthenticate and authorize requests through CreateSession for low latency. To encrypt new\nobjects in a directory bucket with SSE-KMS, you must specify SSE-KMS as the directory bucket's\ndefault encryption configuration with a KMS key (specifically, a customer managed key). Then,\nwhen a session is created for Zonal endpoint API operations, new objects are automatically\nencrypted and decrypted with SSE-KMS and S3 Bucket Keys during the session.\nNote\nOnly 1 customer managed key is supported per directory bucket for the lifetime of the\nbucket. The AWS managed key (aws/s3) isn't supported. After you specify SSE-KMS as\nyour bucket's default encryption configuration with a customer managed key, you can't\nchange the customer managed key for the bucket's SSE-KMS configuration.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST\nAPI, you can't override the values of the encryption settings (x-amz-server-side-\nencryption, x-amz-server-side-encryption-aws-kms-key-id, x-amz-server-\nside-encryption-context, and x-amz-server-side-encryption-bucket-key-\nenabled) from the CreateSession request. You don't need to explicitly specify these\nencryption settings values in Zonal endpoint API calls, and Amazon S3 will use the encryption\nsettings values from the CreateSession request to protect new objects in the directory\nbucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession, the session token\nrefreshes automatically to avoid service interruptions when a session expires. The\nCLI or the AWS SDKs use the bucket's default encryption configuration for the\nCreateSession request. It's not supported to override the encryption settings\nvalues in the CreateSession request. Also, in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), it's not supported to override the values of the\nencryption settings from the CreateSession request.\nAmazon S3 API Version 2006-03-01 104",
      "start_idx": 172968,
      "end_idx": 175034,
      "metadata": {
        "num_sentences": 13,
        "num_words": 291,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_110",
      "text": "Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nRequest Syntax\nGET /?session HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-create-session-mode: SessionMode\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket that you create a session for.\nRequired: Yes\nx-amz-create-session-mode\nSpecifies the mode of the session that will be created, either ReadWrite or ReadOnly. By\ndefault, a ReadWrite session is created. A ReadWrite session is capable of executing all\nthe Zonal endpoint API operations on a directory bucket. A ReadOnly session is constrained\nto execute the following Zonal endpoint API operations: GetObject, HeadObject,\nListObjectsV2, GetObjectAttributes, ListParts, and ListMultipartUploads.\nValid Values: ReadOnly | ReadWrite\nx-amz-server-side-encryption\nThe server-side encryption algorithm to use when you store objects in the directory bucket.\nFor directory buckets, there are only two supported options for server-side encryption: server-\nside encryption with Amazon S3 managed keys (SSE-S3) (AES256) and server-side encryption\nAmazon S3 API Version 2006-03-01 105",
      "start_idx": 175036,
      "end_idx": 176517,
      "metadata": {
        "num_sentences": 9,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_111",
      "text": "Amazon Simple Storage Service API Reference\nwith AWS KMS keys (SSE-KMS) (aws:kms). By default, Amazon S3 encrypts data with SSE-S3.\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User\nGuide.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf you specify x-amz-server-side-encryption with aws:kms, you must specify the x-\namz-server-side-encryption-aws-kms-key-id header with the ID (Key ID or Key ARN)\nof the AWS KMS symmetric encryption customer managed key to use. Otherwise, you get an\nHTTP 400 Bad Request error. Only use the key ID or key ARN. The key alias format of the\nKMS key isn't supported. Also, if the KMS key doesn't exist in the same account that't issuing the\ncommand, you must use the full Key ARN not the Key ID.\nYour SSE-KMS configuration can only support 1 customer managed key per directory bucket for\nthe lifetime of the bucket. The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpecifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS KMS keys (SSE-KMS).\nS3 Bucket Keys are always enabled for GET and PUT operations in a directory bucket and can\u2019t\nbe disabled. S3 Bucket Keys aren't supported, when you copy SSE-KMS encrypted objects\nfrom general purpose buckets to directory buckets, from directory buckets to general purpose\nbuckets, or between directory buckets, through CopyObject, UploadPartCopy, the Copy\noperation in Batch Operations, or the import jobs. In this case, Amazon S3 makes a call to AWS\nKMS every time a copy request is made for a KMS-encrypted object.\nx-amz-server-side-encryption-context\nSpecifies the AWS KMS Encryption Context as an additional encryption context to use for\nobject encryption. The value of this header is a Base64-encoded string of a UTF-8 encoded\nJSON, which contains the encryption context as key-value pairs. This value is stored as object\nmetadata and automatically gets passed on to AWS KMS for future GetObject operations on\nthis object.\nGeneral purpose buckets - This value must be explicitly added during CopyObject operations\nif you want an additional encryption context for your object. For more information, see\nEncryption context in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 106",
      "start_idx": 176519,
      "end_idx": 178874,
      "metadata": {
        "num_sentences": 20,
        "num_words": 362,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_112",
      "text": "Amazon Simple Storage Service API Reference\nDirectory buckets - You can optionally provide an explicit encryption context value. The value\nmust match the default encryption context - the bucket Amazon Resource Name (ARN). An\nadditional encryption context value is not supported.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateSessionOutput>\n<Credentials>\n<AccessKeyId>string</AccessKeyId>\n<Expiration>timestamp</Expiration>\n<SecretAccessKey>string</SecretAccessKey>\n<SessionToken>string</SessionToken>\n</Credentials>\n</CreateSessionOutput>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store objects in the directory bucket.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf you specify x-amz-server-side-encryption with aws:kms, this header indicates the\nID of the AWS KMS symmetric encryption customer managed key that was used for object\nencryption.\nAmazon S3 API Version 2006-03-01 107",
      "start_idx": 178876,
      "end_idx": 180302,
      "metadata": {
        "num_sentences": 9,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_113",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether to use an S3 Bucket Key for server-side encryption with AWS KMS keys (SSE-\nKMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value\nof this header is a Base64-encoded string of a UTF-8 encoded JSON, which contains the\nencryption context as key-value pairs. This value is stored as object metadata and automatically\ngets passed on to AWS KMS for future GetObject operations on this object.\nThe following data is returned in XML format by the service.\nCreateSessionOutput\nRoot level tag for the CreateSessionOutput parameters.\nRequired: Yes\nCredentials\nThe established temporary security credentials for the created session.\nType: SessionCredentials data type\nErrors\nNoSuchBucket\nThe specified bucket does not exist.\nHTTP Status Code: 404\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\nAmazon S3 API Version 2006-03-01 108",
      "start_idx": 180304,
      "end_idx": 181426,
      "metadata": {
        "num_sentences": 9,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_115",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucket\nService: Amazon S3\nDeletes the S3 bucket. All objects (including all object versions and delete markers) in the bucket\nmust be deleted before the bucket itself can be deleted.\nNote\n\u2022 Directory buckets - If multipart uploads in a directory bucket are in progress, you can't\ndelete the bucket until all the in-progress multipart uploads are aborted or completed.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - You must have the s3:DeleteBucket permission on\nthe specified bucket in a policy.\n\u2022 Directory bucket permissions - You must have the s3express:DeleteBucket permission\nin an IAM identity-based policy instead of a bucket policy. Cross-account access to this API\noperation isn't supported. This operation can only be performed by the AWS account that\nowns the resource. For more information about directory bucket policies and permissions, see\nAWS Identity and Access Management (IAM) for S3 Express One Zone in the Amazon S3 User\nGuide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to DeleteBucket:\n\u2022 CreateBucket\n\u2022 DeleteObject\nAmazon S3 API Version 2006-03-01 110",
      "start_idx": 181662,
      "end_idx": 183275,
      "metadata": {
        "num_sentences": 14,
        "num_words": 235,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_116",
      "text": "Amazon Simple Storage Service API Reference\nRequest Syntax\nDELETE / HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpecifies the bucket being deleted.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 111",
      "start_idx": 183277,
      "end_idx": 184594,
      "metadata": {
        "num_sentences": 12,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_119",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketAnalyticsConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes an analytics configuration for the bucket (specified by the analytics configuration ID).\nTo use this operation, you must have permissions to perform the\ns3:PutAnalyticsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about the Amazon S3 analytics feature, see Amazon S3 Analytics \u2013 Storage Class\nAnalysis.\nThe following operations are related to DeleteBucketAnalyticsConfiguration:\n\u2022 GetBucketAnalyticsConfiguration\n\u2022 ListBucketAnalyticsConfigurations\n\u2022 PutBucketAnalyticsConfiguration\nRequest Syntax\nDELETE /?analytics&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which an analytics configuration is deleted.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 114",
      "start_idx": 185695,
      "end_idx": 186924,
      "metadata": {
        "num_sentences": 10,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_120",
      "text": "Amazon Simple Storage Service API Reference\nid\nThe ID that identifies the analytics configuration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the analytics configuration with the ID list1.\nDELETE ?/analytics&id=list1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 14 May 2014 02:11:22 GMT\nAuthorization: signatureValue\nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. The\nanalytics configuration with the ID list1 for the bucket has been removed.\nAmazon S3 API Version 2006-03-01 115",
      "start_idx": 186926,
      "end_idx": 187944,
      "metadata": {
        "num_sentences": 9,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_122",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketCors\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the cors configuration information set for the bucket.\nTo use this operation, you must have permission to perform the s3:PutBucketCORS action. The\nbucket owner has this permission by default and can grant this permission to others.\nFor information about cors, see Enabling Cross-Origin Resource Sharing in the Amazon S3 User\nGuide.\nRelated Resources\n\u2022 PutBucketCors\n\u2022 RESTOPTIONSobject\nRequest Syntax\nDELETE /?cors HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpecifies the bucket whose cors configuration is being deleted.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 117",
      "start_idx": 188530,
      "end_idx": 189601,
      "metadata": {
        "num_sentences": 10,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_123",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nRetrieve cors subresource\nThe following DELETE request deletes the cors subresource from the specified bucket. This action\nremoves cors configuration that is stored in the subresource.\nSample Request\nThis example illustrates one usage of DeleteBucketCors.\nDELETE /?cors HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 13 Dec 2011 19:14:42 GMT\nAuthorization: signatureValue\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\nAmazon S3 API Version 2006-03-01 118",
      "start_idx": 189603,
      "end_idx": 190481,
      "metadata": {
        "num_sentences": 6,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_125",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketEncryption\nService: Amazon S3\nThis implementation of the DELETE action resets the default encryption for the bucket as server-\nside encryption with Amazon S3 managed keys (SSE-S3).\nNote\n\u2022 General purpose buckets - For information about the bucket default encryption feature,\nsee Amazon S3 Bucket Default Encryption in the Amazon S3 User Guide.\n\u2022 Directory buckets - For directory buckets, there are only two supported options\nfor server-side encryption: SSE-S3 and SSE-KMS. For information about the default\nencryption configuration in directory buckets, see Setting default server-side encryption\nbehavior for directory buckets.\nPermissions\n\u2022 General purpose bucket permissions - The s3:PutEncryptionConfiguration\npermission is required in a policy. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions,\nsee Permissions Related to Bucket Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\n\u2022 Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:PutEncryptionConfiguration permission in an IAM identity-based policy\ninstead of a bucket policy. Cross-account access to this API operation isn't supported. This\noperation can only be performed by the AWS account that owns the resource. For more\ninformation about directory bucket policies and permissions, see AWS Identity and Access\nManagement (IAM) for S3 Express One Zone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to DeleteBucketEncryption:\n\u2022 PutBucketEncryption\nAmazon S3 API Version 2006-03-01 120",
      "start_idx": 190679,
      "end_idx": 192479,
      "metadata": {
        "num_sentences": 14,
        "num_words": 256,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_126",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 GetBucketEncryption\nRequest Syntax\nDELETE /?encryption HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the server-side encryption configuration to delete.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 121",
      "start_idx": 192481,
      "end_idx": 193881,
      "metadata": {
        "num_sentences": 12,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_129",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketIntelligentTieringConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the S3 Intelligent-Tiering configuration from the specified bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically\nmoving data to the most cost-effective storage access tier, without performance impact or\noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency\nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in\nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing,\nor unpredictable access patterns, independent of object size or retention period. If the size of an\nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering. Smaller objects can\nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering\nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently\naccessed objects.\nOperations related to DeleteBucketIntelligentTieringConfiguration include:\n\u2022 GetBucketIntelligentTieringConfiguration\n\u2022 PutBucketIntelligentTieringConfiguration\n\u2022 ListBucketIntelligentTieringConfigurations\nRequest Syntax\nDELETE /?intelligent-tiering&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 124",
      "start_idx": 195285,
      "end_idx": 196926,
      "metadata": {
        "num_sentences": 11,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_131",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketInventoryConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes an inventory configuration (identified by the inventory ID) from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:PutInventoryConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about the Amazon S3 inventory feature, see Amazon S3 Inventory.\nOperations related to DeleteBucketInventoryConfiguration include:\n\u2022 GetBucketInventoryConfiguration\n\u2022 PutBucketInventoryConfiguration\n\u2022 ListBucketInventoryConfigurations\nRequest Syntax\nDELETE /?inventory&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the inventory configuration to delete.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 126",
      "start_idx": 197711,
      "end_idx": 198893,
      "metadata": {
        "num_sentences": 10,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_132",
      "text": "Amazon Simple Storage Service API Reference\nid\nThe ID used to identify the inventory configuration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the inventory configuration with the ID list1.\nDELETE ?/inventory&id=list1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 14 May 2014 02:11:22 GMT\nAuthorization: signatureValue\nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. The\ninventory configuration with the ID list1 for the bucket has been removed.\nAmazon S3 API Version 2006-03-01 127",
      "start_idx": 198895,
      "end_idx": 199914,
      "metadata": {
        "num_sentences": 9,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_134",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketLifecycle\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the lifecycle configuration from the specified bucket. Amazon S3 removes all the lifecycle\nconfiguration rules in the lifecycle subresource associated with the bucket. Your objects never\nexpire, and Amazon S3 no longer automatically deletes any objects on the basis of rules contained\nin the deleted lifecycle configuration.\nTo use this operation, you must have permission to perform the\ns3:PutLifecycleConfiguration action. By default, the bucket owner has this permission and\nthe bucket owner can grant this permission to others.\nThere is usually some time lag before lifecycle configuration deletion is fully propagated to all the\nAmazon S3 systems.\nFor more information about the object expiration, see Elements to Describe Lifecycle Actions.\nRelated actions include:\n\u2022 PutBucketLifecycleConfiguration\n\u2022 GetBucketLifecycleConfiguration\nRequest Syntax\nDELETE /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name of the lifecycle to delete.\nAmazon S3 API Version 2006-03-01 129",
      "start_idx": 200499,
      "end_idx": 201770,
      "metadata": {
        "num_sentences": 11,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_135",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the lifecycle subresource from the specified bucket. This\nremoves lifecycle configuration stored in the subresource.\nDELETE /?lifecycle HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 14 Dec 2011 05:37:16 GMT\nAuthorization: signatureValue\nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. Objects\nin your bucket no longer expire.\nHTTP/1.1 204 No Content\nx-amz-id-2: Uuag1LuByRx9e6j5OnimrSAMPLEtRPfTaOAa==\nAmazon S3 API Version 2006-03-01 130",
      "start_idx": 201772,
      "end_idx": 202833,
      "metadata": {
        "num_sentences": 9,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_137",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketMetricsConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes a metrics configuration for the Amazon CloudWatch request metrics (specified by the\nmetrics configuration ID) from the bucket. Note that this doesn't include the daily storage metrics.\nTo use this operation, you must have permissions to perform the\ns3:PutMetricsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with\nAmazon CloudWatch.\nThe following operations are related to DeleteBucketMetricsConfiguration:\n\u2022 GetBucketMetricsConfiguration\n\u2022 PutBucketMetricsConfiguration\n\u2022 ListBucketMetricsConfigurations\n\u2022 Monitoring Metrics with Amazon CloudWatch\nRequest Syntax\nDELETE /?metrics&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the metrics configuration to delete.\nAmazon S3 API Version 2006-03-01 132",
      "start_idx": 203350,
      "end_idx": 204695,
      "metadata": {
        "num_sentences": 11,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_138",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nid\nThe ID used to identify the metrics configuration. The ID has a 64 character limit and can only\ncontain letters, numbers, periods, dashes, and underscores.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nDelete the metric configuration with a specified ID, which disables the CloudWatch metrics with the\nExampleMetrics value for the FilterId dimension.\nDELETE /?metrics&id=ExampleMetrics HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 15 Nov 2016 00:17:21 GMT\nAuthorization: signatureValue\nAmazon S3 API Version 2006-03-01 133",
      "start_idx": 204697,
      "end_idx": 205729,
      "metadata": {
        "num_sentences": 8,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_140",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketOwnershipControls\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRemoves OwnershipControls for an Amazon S3 bucket. To use this operation, you must have\nthe s3:PutBucketOwnershipControls permission. For more information about Amazon S3\npermissions, see Specifying Permissions in a Policy.\nFor information about Amazon S3 Object Ownership, see Using Object Ownership.\nThe following operations are related to DeleteBucketOwnershipControls:\n\u2022 GetBucketOwnershipControls\n\u2022 PutBucketOwnershipControls\nRequest Syntax\nDELETE /?ownershipControls HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe Amazon S3 bucket whose OwnershipControls you want to delete.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 135",
      "start_idx": 206479,
      "end_idx": 207614,
      "metadata": {
        "num_sentences": 10,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_143",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketPolicy\nService: Amazon S3\nDeletes the policy of a specified bucket.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\nIf you are using an identity other than the root user of the AWS account that owns the bucket,\nthe calling identity must both have the DeleteBucketPolicy permissions on the specified\nbucket and belong to the bucket owner's account in order to use this operation.\nIf you don't have DeleteBucketPolicy permissions, Amazon S3 returns a 403 Access\nDenied error. If you have the correct permissions, but you're not using an identity that belongs\nto the bucket owner's account, Amazon S3 returns a 405 Method Not Allowed error.\nImportant\nTo ensure that bucket owners don't inadvertently lock themselves out of their\nown buckets, the root principal in a bucket owner's AWS account can perform the\nGetBucketPolicy, PutBucketPolicy, and DeleteBucketPolicy API actions,\neven if their bucket policy explicitly denies the root principal's access. Bucket owner\nroot principals can only be blocked from performing these API actions by VPC endpoint\npolicies and AWS Organizations policies.\n\u2022 General purpose bucket permissions - The s3:DeleteBucketPolicy permission is\nrequired in a policy. For more information about general purpose buckets bucket policies, see\nUsing Bucket Policies and User Policies in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:DeleteBucketPolicy permission in an IAM identity-based policy instead of a\nAmazon S3 API Version 2006-03-01 138",
      "start_idx": 208896,
      "end_idx": 210836,
      "metadata": {
        "num_sentences": 13,
        "num_words": 285,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_144",
      "text": "Amazon Simple Storage Service API Reference\nbucket policy. Cross-account access to this API operation isn't supported. This operation can\nonly be performed by the AWS account that owns the resource. For more information about\ndirectory bucket policies and permissions, see AWS Identity and Access Management (IAM) for\nS3 Express One Zone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to DeleteBucketPolicy\n\u2022 CreateBucket\n\u2022 DeleteObject\nRequest Syntax\nDELETE /?policy HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nAmazon S3 API Version 2006-03-01 139",
      "start_idx": 210838,
      "end_idx": 212213,
      "metadata": {
        "num_sentences": 12,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_145",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request for general purpose buckets\nThis request deletes the bucket named BucketName.\nDELETE /?policy HTTP/1.1\nHost: BucketName.s3.<Region>.amazonaws.com\nDate: Tue, 04 Apr 2010 20:34:56 GMT\nAuthorization: signatureValue\nSample Response for general purpose buckets\nThis example illustrates one usage of DeleteBucketPolicy.\nAmazon S3 API Version 2006-03-01 140",
      "start_idx": 212215,
      "end_idx": 213236,
      "metadata": {
        "num_sentences": 9,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_147",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketReplication\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the replication configuration from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:PutReplicationConfiguration action. The bucket owner has these permissions by default\nand can grant it to others. For more information about permissions, see Permissions Related to\nBucket Subresource Operations and Managing Access Permissions to Your Amazon S3 Resources.\nNote\nIt can take a while for the deletion of a replication configuration to fully propagate.\nFor information about replication configuration, see Replication in the Amazon S3 User Guide.\nThe following operations are related to DeleteBucketReplication:\n\u2022 PutBucketReplication\n\u2022 GetBucketReplication\nRequest Syntax\nDELETE /?replication HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nAmazon S3 API Version 2006-03-01 142",
      "start_idx": 213828,
      "end_idx": 214920,
      "metadata": {
        "num_sentences": 10,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_148",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the replication subresource from the specified bucket.\nThis removes the replication configuration that is set for the bucket.\nDELETE /?replication HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 11 Feb 2015 05:37:16 GMT\n20150211T171320Z\nAuthorization: authorization string\nSample Response\nWhen the replication subresource has been deleted, Amazon S3 returns a 204 No Content\nresponse. It will not replicate new objects that are stored in the examplebucket bucket.\nAmazon S3 API Version 2006-03-01 143",
      "start_idx": 214922,
      "end_idx": 215989,
      "metadata": {
        "num_sentences": 9,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_150",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nDeletes the tags from the bucket.\nTo use this operation, you must have permission to perform the s3:PutBucketTagging action.\nBy default, the bucket owner has this permission and can grant this permission to others.\nThe following operations are related to DeleteBucketTagging:\n\u2022 GetBucketTagging\n\u2022 PutBucketTagging\nRequest Syntax\nDELETE /?tagging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket that has the tag set to be removed.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 145",
      "start_idx": 216575,
      "end_idx": 217555,
      "metadata": {
        "num_sentences": 9,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_151",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the tag set from the specified bucket.\nDELETE /?tagging HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 14 Dec 2011 05:37:16 GMT\nAuthorization: signatureValue\nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. The\ntag set for the bucket has been removed.\nHTTP/1.1 204 No Content\nDate: Wed, 25 Nov 2009 12:00:00 GMT\nConnection: close\nServer: AmazonS3\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 146",
      "start_idx": 217557,
      "end_idx": 218430,
      "metadata": {
        "num_sentences": 6,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_153",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketWebsite\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis action removes the website configuration for a bucket. Amazon S3 returns a 200 OK response\nupon successfully deleting a website configuration on the specified bucket. You will get a 200 OK\nresponse if the website configuration you are trying to delete does not exist on the bucket. Amazon\nS3 returns a 404 response if the bucket specified in the request does not exist.\nThis DELETE action requires the S3:DeleteBucketWebsite permission. By default, only the\nbucket owner can delete the website configuration attached to a bucket. However, bucket owners\ncan grant other users permission to delete the website configuration by writing a bucket policy\ngranting them the S3:DeleteBucketWebsite permission.\nFor more information about hosting websites, see Hosting Websites on Amazon S3.\nThe following operations are related to DeleteBucketWebsite:\n\u2022 GetBucketWebsite\n\u2022 PutBucketWebsite\nRequest Syntax\nDELETE /?website HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which you want to remove the website configuration.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 148",
      "start_idx": 218714,
      "end_idx": 220061,
      "metadata": {
        "num_sentences": 12,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_154",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample Request\nThis request deletes the website configuration on the specified bucket.\nDELETE ?website HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\nSample Response\nThis example illustrates one usage of DeleteBucketWebsite.\nHTTP/1.1 204 No Content\nx-amz-id-2: aws-s3integ-s3ws-31008.sea31.amazon.com\nx-amz-request-id: AF1DD829D3B49707\nDate: Thu, 03 Feb 2011 22:10:26 GMT\nServer: AmazonS3\nAmazon S3 API Version 2006-03-01 149",
      "start_idx": 220063,
      "end_idx": 221046,
      "metadata": {
        "num_sentences": 7,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_156",
      "text": "Amazon Simple Storage Service API Reference\nDeleteObject\nService: Amazon S3\nRemoves an object from a bucket. The behavior depends on the bucket's versioning state. For more\ninformation, see Best practices to consider before deleting an object.\nTo remove a specific version, you must use the versionId query parameter. Using this query\nparameter permanently deletes the version. If the object deleted is a delete marker, Amazon S3\nsets the response header x-amz-delete-marker to true. If the object you want to delete is in a\nbucket where the bucket versioning configuration is MFA delete enabled, you must include the x-\namz-mfa request header in the DELETE versionId request. Requests that include x-amz-mfa\nmust use HTTPS. For more information about MFA delete and to see example requests, see Using\nMFA delete and Sample request in the Amazon S3 User Guide.\nNote\n\u2022 S3 Versioning isn't enabled and supported for directory buckets. For this API operation,\nonly the null value of the version ID is supported by directory buckets. You can only\nspecify null to the versionId query parameter in the request.\n\u2022 For directory buckets, you must make requests for this API operation to the Zonal\nendpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\n\u2022 MFA delete is not supported by directory buckets.\nPermissions\n\u2022 General purpose bucket permissions - The following permissions are required in your\npolicies when your DeleteObjects request includes specific headers.\n\u2022 s3:DeleteObject - To delete an object from a bucket, you must always have the\ns3:DeleteObject permission.\nNote\nYou can also use PutBucketLifecycle to delete objects in Amazon S3.\nAmazon S3 API Version 2006-03-01 151",
      "start_idx": 221442,
      "end_idx": 223335,
      "metadata": {
        "num_sentences": 21,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_157",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 s3:DeleteObjectVersion - To delete a specific version of an object from a versioning-\nenabled bucket, you must have the s3:DeleteObjectVersion permission.\n\u2022 If you want to block users or accounts from removing or deleting objects from your\nbucket, you must deny them the s3:DeleteObject, s3:DeleteObjectVersion, and\ns3:PutLifeCycleConfiguration permissions.\n\u2022 Directory buckets permissions - To grant access to this API operation on a directory bucket,\nwe recommend that you use the CreateSession API operation for session-based authorization.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following action is related to DeleteObject:\n\u2022 PutObject\nRequest Syntax\nDELETE /Key+?versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-mfa: MFA\nx-amz-request-payer: RequestPayer\nx-amz-bypass-governance-retention: BypassGovernanceRetention\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name of the bucket containing the object.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nAmazon S3 API Version 2006-03-01 152",
      "start_idx": 223337,
      "end_idx": 224900,
      "metadata": {
        "num_sentences": 10,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_158",
      "text": "Amazon Simple Storage Service API Reference\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nKey name of the object to delete.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nVersion ID used to reference a specific version of the object.\nNote\nFor directory buckets in this API operation, only the null value of the version ID is\nsupported.\nAmazon S3 API Version 2006-03-01 153",
      "start_idx": 224902,
      "end_idx": 226574,
      "metadata": {
        "num_sentences": 18,
        "num_words": 268,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_159",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-bypass-governance-retention\nIndicates whether S3 Object Lock should bypass Governance-mode restrictions to process\nthis operation. To use this header, you must have the s3:BypassGovernanceRetention\npermission.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is\ndisplayed on your authentication device. Required to permanently delete a versioned object if\nversioning is configured with MFA delete enabled.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 154",
      "start_idx": 226576,
      "end_idx": 227998,
      "metadata": {
        "num_sentences": 14,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_160",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nx-amz-delete-marker: DeleteMarker\nx-amz-version-id: VersionId\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response.\nThe response returns the following HTTP headers.\nx-amz-delete-marker\nIndicates whether the specified object version that was permanently deleted was (true) or was\nnot (false) a delete marker before deletion. In a simple DELETE, this header indicates whether\n(true) or not (false) the current version of the object is a delete marker.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 155",
      "start_idx": 228000,
      "end_idx": 228971,
      "metadata": {
        "num_sentences": 9,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_165",
      "text": "Amazon Simple Storage Service API Reference\nDeleteObjects\nService: Amazon S3\nThis operation enables you to delete multiple objects from a bucket using a single HTTP request.\nIf you know the object keys that you want to delete, then this operation provides a suitable\nalternative to sending individual delete requests, reducing per-request overhead.\nThe request can contain a list of up to 1000 keys that you want to delete. In the XML, you provide\nthe object key names, and optionally, version IDs if you want to delete a specific version of the\nobject from a versioning-enabled bucket. For each key, Amazon S3 performs a delete operation\nand returns the result of that delete, success or failure, in the response. Note that if the object\nspecified in the request is not found, Amazon S3 returns the result as deleted.\nNote\n\u2022 Directory buckets - S3 Versioning isn't enabled and supported for directory buckets.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the\nformat https://bucket_name.s3express-az_id.region.amazonaws.com/key-\nname . Path-style requests are not supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nThe operation supports two modes for the response: verbose and quiet. By default, the operation\nuses verbose mode in which the response includes the result of deletion of each key in your\nrequest. In quiet mode the response includes only keys where the delete operation encountered\nan error. For a successful deletion in a quiet mode, the operation does not return any information\nabout the delete in the response body.\nWhen performing this action on an MFA Delete enabled bucket, that attempts to delete any\nversioned objects, you must include an MFA token. If you do not provide one, the entire request will\nfail, even if there are non-versioned objects you are trying to delete. If you provide an invalid token,\nwhether there are versioned keys in the request or not, the entire Multi-Object Delete request will\nfail. For information about MFA Delete, see MFA Delete in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 160",
      "start_idx": 232536,
      "end_idx": 234756,
      "metadata": {
        "num_sentences": 20,
        "num_words": 358,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_166",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - MFA delete is not supported by directory buckets.\nPermissions\n\u2022 General purpose bucket permissions - The following permissions are required in your\npolicies when your DeleteObjects request includes specific headers.\n\u2022 s3:DeleteObject - To delete an object from a bucket, you must always specify the\ns3:DeleteObject permission.\n\u2022 s3:DeleteObjectVersion - To delete a specific version of an object from a versioning-\nenabled bucket, you must specify the s3:DeleteObjectVersion permission.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nContent-MD5 request header\n\u2022 General purpose bucket - The Content-MD5 request header is required for all Multi-Object\nDelete requests. Amazon S3 uses the header value to ensure that your request body has not\nbeen altered in transit.\n\u2022 Directory bucket - The Content-MD5 request header or a additional checksum request\nheader (including x-amz-checksum-crc32, x-amz-checksum-crc32c, x-amz-\nchecksum-sha1, or x-amz-checksum-sha256) is required for all Multi-Object Delete\nrequests.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nAmazon S3 API Version 2006-03-01 161",
      "start_idx": 234758,
      "end_idx": 236758,
      "metadata": {
        "num_sentences": 16,
        "num_words": 288,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_167",
      "text": "Amazon Simple Storage Service API Reference\nThe following operations are related to DeleteObjects:\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\n\u2022 CompleteMultipartUpload\n\u2022 ListParts\n\u2022 AbortMultipartUpload\nRequest Syntax\nPOST /?delete HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-mfa: MFA\nx-amz-request-payer: RequestPayer\nx-amz-bypass-governance-retention: BypassGovernanceRetention\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Delete xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Object>\n<Key>string</Key>\n<VersionId>string</VersionId>\n</Object>\n...\n<Quiet>boolean</Quiet>\n</Delete>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the objects to delete.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nAmazon S3 API Version 2006-03-01 162",
      "start_idx": 236760,
      "end_idx": 237970,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_168",
      "text": "Amazon Simple Storage Service API Reference\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nx-amz-bypass-governance-retention\nSpecifies whether you want to delete this object even if it has a Governance-type Object Lock in\nplace. To use this header, you must have the s3:BypassGovernanceRetention permission.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 163",
      "start_idx": 237972,
      "end_idx": 239887,
      "metadata": {
        "num_sentences": 19,
        "num_words": 297,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_169",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is\ndisplayed on your authentication device. Required to permanently delete a versioned object if\nversioning is configured with MFA delete enabled.\nWhen performing the DeleteObjects operation on an MFA delete enabled bucket, which\nattempts to delete the specified versioned objects, you must include an MFA token. If you don't\nprovide an MFA token, the entire request will fail, even if there are non-versioned objects that\nyou are trying to delete. If you provide an invalid token, whether there are versioned object keys\nin the request or not, the entire Multi-Object Delete request will fail. For information about MFA\nDelete, see MFA Delete in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.\nThis header will not provide any additional functionality if you don't use the SDK. When you\nsend this header, there must be a corresponding x-amz-checksum-algorithm or x-amz-\ntrailer header sent. Otherwise, Amazon S3 fails the request with the HTTP status code 400\nBad Request.\nAmazon S3 API Version 2006-03-01 164",
      "start_idx": 239889,
      "end_idx": 241748,
      "metadata": {
        "num_sentences": 17,
        "num_words": 286,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_170",
      "text": "Amazon Simple Storage Service API Reference\nFor the x-amz-checksum-algorithm header, replace algorithm with the supported\nalgorithm from the following list:\n\u2022 CRC32\n\u2022 CRC32C\n\u2022 SHA1\n\u2022 SHA256\nFor more information, see Checking object integrity in the Amazon S3 User Guide.\nIf the individual checksum value you provide through x-amz-checksum-algorithm doesn't\nmatch the checksum algorithm you set through x-amz-sdk-checksum-algorithm, Amazon\nS3 ignores any provided ChecksumAlgorithm parameter and uses the checksum algorithm\nthat matches the provided value in x-amz-checksum-algorithm .\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nDelete\nRoot level tag for the Delete parameters.\nRequired: Yes\nObject\nThe object to delete.\nNote\nDirectory buckets - For directory buckets, an object that's composed entirely of\nwhitespace characters is not supported by the DeleteObjects API operation. The\nrequest will receive a 400 Bad Request error and none of the objects in the request\nwill be deleted.\nAmazon S3 API Version 2006-03-01 165",
      "start_idx": 241750,
      "end_idx": 242940,
      "metadata": {
        "num_sentences": 9,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_171",
      "text": "Amazon Simple Storage Service API Reference\nType: Array of ObjectIdentifier data types\nRequired: Yes\nQuiet\nElement to enable quiet mode for the request. When you add this element, you must set its\nvalue to true.\nType: Boolean\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteResult>\n<Deleted>\n<DeleteMarker>boolean</DeleteMarker>\n<DeleteMarkerVersionId>string</DeleteMarkerVersionId>\n<Key>string</Key>\n<VersionId>string</VersionId>\n</Deleted>\n...\n<Error>\n<Code>string</Code>\n<Key>string</Key>\n<Message>string</Message>\n<VersionId>string</VersionId>\n</Error>\n...\n</DeleteResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nAmazon S3 API Version 2006-03-01 166",
      "start_idx": 242942,
      "end_idx": 243879,
      "metadata": {
        "num_sentences": 6,
        "num_words": 105,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_172",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nDeleteResult\nRoot level tag for the DeleteResult parameters.\nRequired: Yes\nDeleted\nContainer element for a successful delete. It identifies the object that was successfully deleted.\nType: Array of DeletedObject data types\nError\nContainer for a failed delete action that describes the object that Amazon S3 attempted to\ndelete and the error it encountered.\nType: Array of Error data types\nExamples\nSample Request for general purpose buckets: Multi-object delete resulting in mixed success/\nerror response\nThis example illustrates a Multi-Object Delete request to delete objects that result in mixed success\nand errors response. The following request deletes two objects from a bucket (bucketname). In\nthis example, the requester does not have permission to delete the sample2.txt object.\nPOST /?delete HTTP/1.1\nHost: bucketname.s3.<Region>.amazonaws.com\nAccept: */*\nAmazon S3 API Version 2006-03-01 167",
      "start_idx": 243881,
      "end_idx": 244975,
      "metadata": {
        "num_sentences": 10,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_174",
      "text": "Amazon Simple Storage Service API Reference\nSample Request for general purpose buckets: Deleting an object from a versioned bucket\nIf you delete an item from a versioning enabled bucket, all versions of that object remain in the\nbucket; however, Amazon S3 inserts a delete marker. For more information, see Object Versioning.\nThe following scenarios describe the behavior of a multi-object Delete request when versioning is\nenabled for your bucket.\nCase 1 - Simple Delete: In the following sample request, the multi-object delete request specifies\nonly one key.\nPOST /?delete HTTP/1.1\nHost: bucketname.s3.<Region>.amazonaws.com\nAccept: */*\nx-amz-date: Wed, 30 Nov 2011 03:39:05 GMT\nContent-MD5: p5/WA/oEr30qrEEl21PAqw==\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIee=\nContent-Length: 79\nConnection: Keep-Alive\n<Delete>\n<Object>\n<Key>SampleDocument.txt</Key>\n</Object>\n</Delete>\nSample Response for general purpose buckets\nBecause versioning is enabled on the bucket, Amazon S3 does not delete the object. Instead, it\nadds a delete marker for this object. The following response indicates that a delete marker was\nadded (the DeleteMarker element in the response as a value of true) and the version number of\nthe delete marker it added.\nHTTP/1.1 200 OK\nx-amz-id-2: P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/FB7oiQaScI9Yaxd8olYXc7d1111ab\n+\nx-amz-request-id: 264A17BF16E9E80A\nAmazon S3 API Version 2006-03-01 169",
      "start_idx": 246125,
      "end_idx": 247546,
      "metadata": {
        "num_sentences": 8,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_175",
      "text": "Amazon Simple Storage Service API Reference\nDate: Wed, 30 Nov 2011 03:39:32 GMT\nContent-Type: application/xml\nServer: AmazonS3\nContent-Length: 276\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Deleted>\n<Key>SampleDocument.txt</Key>\n<DeleteMarker>true</DeleteMarker>\n<DeleteMarkerVersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</\nDeleteMarkerVersionId>\n</Deleted>\n</DeleteResult>\nCase 2 for general purpose buckets - Versioned Delete\nThe following request attempts to delete a specific version of an object.\nPOST /?delete HTTP/1.1\nHost: bucketname.s3.<Region>.amazonaws.com\nAccept: */*\nx-amz-date: Wed, 30 Nov 2011 03:39:05 GMT\nContent-MD5: p5/WA/oEr30qrEEl21PAqw==\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIxx=\nContent-Length: 140\nConnection: Keep-Alive\n<Delete>\n<Object>\n<Key>SampleDocument.txt</Key>\n<VersionId>OYcLXagmS.WaD..oyH4KRguB95_YhLs7</VersionId>\n</Object>\n</Delete>\nSample Response for general purpose buckets\nIn this case, Amazon S3 deletes the specific object version from the bucket and returns the\nfollowing response. In the response, Amazon S3 returns the key and version ID of the object\ndeleted.\nAmazon S3 API Version 2006-03-01 170",
      "start_idx": 247548,
      "end_idx": 248774,
      "metadata": {
        "num_sentences": 4,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_176",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 400 Bad Request\nx-amz-id-2: P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/\nFB7oiQaScI9Yaxd8olYXc7d1111xx+\nx-amz-request-id: 264A17BF16E9E80A\nDate: Wed, 30 Nov 2011 03:39:32 GMT\nContent-Type: application/xml\nServer: AmazonS3\nContent-Length: 219\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Deleted>\n<Key>SampleDocument.txt</Key>\n<VersionId>OYcLXagmS.WaD..oyH4KRguB95_YhLs7</VersionId>\n</Deleted>\n</DeleteResult>\nCase 3 for general purpose buckets - Versioned delete of a delete marker\nIn the preceding example, the request refers to a delete marker (instead of an object), then Amazon\nS3 deletes the delete marker. The effect of this action is to make your object reappear in your\nbucket. Amazon S3 returns a response that indicates the delete marker it deleted (DeleteMarker\nelement with value true) and the version ID of the delete marker.\nHTTP/1.1 200 OK\nx-amz-id-2:\nIIPUZrtolxDEmWsKOae9JlSZe6yWfTye3HQ3T2iAe0ZE4XHa6NKvAJcPp51zZaBr\nx-amz-request-id: D6B284CEC9B05E4E\nDate: Wed, 30 Nov 2011 03:43:25 GMT\nContent-Type: application/xml\nServer: AmazonS3\nContent-Length: 331\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Deleted>\n<Key>SampleDocument.txt</Key>\n<VersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</VersionId>\n<DeleteMarker>true</DeleteMarker>\nAmazon S3 API Version 2006-03-01 171",
      "start_idx": 248776,
      "end_idx": 250215,
      "metadata": {
        "num_sentences": 4,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_177",
      "text": "Amazon Simple Storage Service API Reference\n<DeleteMarkerVersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</\nDeleteMarkerVersionId>\n</Deleted>\n</DeleteResult>\nSample Response for general purpose buckets\nIn general, when a multi-object Delete request results in Amazon S3 either adding a delete marker\nor removing a delete marker, the response returns the following elements.\n<DeleteMarker>true</DeleteMarker>\n<DeleteMarkerVersionId>NeQt5xeFTfgPJD8B4CGWnkSLtluMr11s</\nDeleteMarkerVersionId>\nSample Request for general purpose buckets: Malformed XML in the request\nThis example shows how Amazon S3 responds to a request that includes a malformed XML\ndocument. The following request sends a malformed XML document (missing the Delete end\nelement).\nPOST /?delete HTTP/1.1\nHost: bucketname.s3.<Region>.amazonaws.com\nAccept: */*\nx-amz-date: Wed, 30 Nov 2011 03:39:05 GMT\nContent-MD5: p5/WA/oEr30qrEEl21PAqw==\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:W0qPYCLe6JwkZAD1ei6hp9XZIee=\nContent-Length: 104\nConnection: Keep-Alive\n<Delete>\n<Object>\n<Key>404.txt</Key>\n</Object>\n<Object>\n<Key>a.txt</Key>\n</Object>\nAmazon S3 API Version 2006-03-01 172",
      "start_idx": 250217,
      "end_idx": 251344,
      "metadata": {
        "num_sentences": 4,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_178",
      "text": "Amazon Simple Storage Service API Reference\nSample Response for general purpose buckets\nThe response returns the error messages that describe the error.\nHTTP/1.1 200 OK\nx-amz-id-2: P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/\nFB7oiQaScI9Yaxd8olYXc7d1111ab+\nx-amz-request-id: 264A17BF16E9E80A\nDate: Wed, 30 Nov 2011 03:39:32 GMT\nContent-Type: application/xml\nServer: AmazonS3\nContent-Length: 207\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error>\n<Code>MalformedXML</Code>\n<Message>The XML you provided was not well-formed or did not\nvalidate against our published schema</Message>\n<RequestId>264A17BF16E9E80A</RequestId>\n<HostId>P3xqrhuhYxlrefdw3rEzmJh8z5KDtGzb+/FB7oiQaScI9Yaxd8olYXc7d1111ab\n+</HostId>\n</Error>\nSample Request for general purpose buckets: DeleteObjects containing a carriage return\nThe following example illustrates the use of an XML entity code as a substitution for a carriage\nreturn. This DeleteObjects request deletes an object with the key parameter: /some/prefix/\nobjectwith\\rcarriagereturn (where the \\r is the carriage return).\n<Delete xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Object>\n<Key>/some/prefix/objectwith&#13;carriagereturn</Key>\n</Object>\n</Delete>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 173",
      "start_idx": 251346,
      "end_idx": 252674,
      "metadata": {
        "num_sentences": 4,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_180",
      "text": "Amazon Simple Storage Service API Reference\nDeleteObjectTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRemoves the entire tag set from the specified object. For more information about managing object\ntags, see Object Tagging.\nTo use this operation, you must have permission to perform the s3:DeleteObjectTagging\naction.\nTo delete tags of a specific object version, add the versionId query parameter in the request. You\nwill need permission for the s3:DeleteObjectVersionTagging action.\nThe following operations are related to DeleteObjectTagging:\n\u2022 PutObjectTagging\n\u2022 GetObjectTagging\nRequest Syntax\nDELETE /{Key+}?tagging&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the objects from which to remove the tags.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nAmazon S3 API Version 2006-03-01 175",
      "start_idx": 252958,
      "end_idx": 254285,
      "metadata": {
        "num_sentences": 12,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_181",
      "text": "Amazon Simple Storage Service API Reference\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nThe key that identifies the object in the bucket from which to remove all tags.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe versionId of the object that the tag-set will be removed from.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nx-amz-version-id: VersionId\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response.\nAmazon S3 API Version 2006-03-01 176",
      "start_idx": 254287,
      "end_idx": 255730,
      "metadata": {
        "num_sentences": 15,
        "num_words": 237,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_182",
      "text": "Amazon Simple Storage Service API Reference\nThe response returns the following HTTP headers.\nx-amz-version-id\nThe versionId of the object the tag-set was removed from.\nExamples\nSample Request\nThe following DELETE request deletes the tag set from the specified object.\nDELETE /exampleobject?tagging HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 25 Nov 2016 12:00:00 GMT\nAuthorization: signatureValue\nSample Response\nThe following successful response shows Amazon S3 returning a 204 No Content response. The tag\nset for the object has been removed.\nHTTP/1.1 204 No Content\nx-amz-version-id: VersionId\nDate: Wed, 25 Nov 2016 12:00:00 GMT\nConnection: close\nServer: AmazonS3\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\nAmazon S3 API Version 2006-03-01 177",
      "start_idx": 255732,
      "end_idx": 256636,
      "metadata": {
        "num_sentences": 6,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_184",
      "text": "Amazon Simple Storage Service API Reference\nDeletePublicAccessBlock\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRemoves the PublicAccessBlock configuration for an Amazon S3 bucket. To use this operation,\nyou must have the s3:PutBucketPublicAccessBlock permission. For more information about\npermissions, see Permissions Related to Bucket Subresource Operations and Managing Access\nPermissions to Your Amazon S3 Resources.\nThe following operations are related to DeletePublicAccessBlock:\n\u2022 Using Amazon S3 Block Public Access\n\u2022 GetPublicAccessBlock\n\u2022 PutPublicAccessBlock\n\u2022 GetBucketPolicyStatus\nRequest Syntax\nDELETE /?publicAccessBlock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe Amazon S3 bucket whose PublicAccessBlock configuration you want to delete.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 179",
      "start_idx": 256854,
      "end_idx": 257819,
      "metadata": {
        "num_sentences": 7,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_185",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 180",
      "start_idx": 257821,
      "end_idx": 258643,
      "metadata": {
        "num_sentences": 5,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_186",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketAccelerateConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the GET action uses the accelerate subresource to return the Transfer\nAcceleration state of a bucket, which is either Enabled or Suspended. Amazon S3 Transfer\nAcceleration is a bucket-level feature that enables you to perform faster data transfers to and from\nAmazon S3.\nTo use this operation, you must have permission to perform the\ns3:GetAccelerateConfiguration action. The bucket owner has this permission by default.\nThe bucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to your\nAmazon S3 Resources in the Amazon S3 User Guide.\nYou set the Transfer Acceleration state of an existing bucket to Enabled or Suspended by using\nthe PutBucketAccelerateConfiguration operation.\nA GET accelerate request does not return a state value for a bucket that has no transfer\nacceleration state. A bucket has no Transfer Acceleration state if a state has never been set on the\nbucket.\nFor more information about transfer acceleration, see Transfer Acceleration in the Amazon S3 User\nGuide.\nThe following operations are related to GetBucketAccelerateConfiguration:\n\u2022 PutBucketAccelerateConfiguration\nRequest Syntax\nGET /?accelerate HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nAmazon S3 API Version 2006-03-01 181",
      "start_idx": 258645,
      "end_idx": 260229,
      "metadata": {
        "num_sentences": 12,
        "num_words": 218,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_187",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which the accelerate configuration is retrieved.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccelerateConfiguration>\n<Status>string</Status>\nAmazon S3 API Version 2006-03-01 182",
      "start_idx": 260231,
      "end_idx": 261462,
      "metadata": {
        "num_sentences": 11,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_191",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the GET action uses the acl subresource to return the access control list\n(ACL) of a bucket. To use GET to return the ACL of the bucket, you must have the READ_ACP access\nto the bucket. If READ_ACP permission is granted to the anonymous user, you can return the ACL of\nthe bucket without using an authorization header.\nWhen you use this API operation with an access point, provide the alias of the access point in place\nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias\nin a request is not valid, the error code InvalidAccessPointAliasError is returned. For more\ninformation about InvalidAccessPointAliasError, see List of Error Codes.\nNote\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, requests to\nread ACLs are still supported and return the bucket-owner-full-control ACL with the\nowner being the account that created the bucket. For more information, see Controlling\nobject ownership and disabling ACLs in the Amazon S3 User Guide.\nThe following operations are related to GetBucketAcl:\n\u2022 ListObjects\nRequest Syntax\nGET /?acl HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 186",
      "start_idx": 263987,
      "end_idx": 265489,
      "metadata": {
        "num_sentences": 11,
        "num_words": 235,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_192",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpecifies the S3 bucket whose ACL is being requested.\nWhen you use this API operation with an access point, provide the alias of the access point in\nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point\nalias in a request is not valid, the error code InvalidAccessPointAliasError is returned.\nFor more information about InvalidAccessPointAliasError, see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n<AccessControlList>\n<Grant>\n<Grantee>\n<DisplayName>string</DisplayName>\n<EmailAddress>string</EmailAddress>\nAmazon S3 API Version 2006-03-01 187",
      "start_idx": 265491,
      "end_idx": 266742,
      "metadata": {
        "num_sentences": 10,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_196",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketAnalyticsConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the GET action returns an analytics configuration (identified by the\nanalytics configuration ID) from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:GetAnalyticsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources in the Amazon S3 User Guide.\nFor information about Amazon S3 analytics feature, see Amazon S3 Analytics \u2013 Storage Class\nAnalysis in the Amazon S3 User Guide.\nThe following operations are related to GetBucketAnalyticsConfiguration:\n\u2022 DeleteBucketAnalyticsConfiguration\n\u2022 ListBucketAnalyticsConfigurations\n\u2022 PutBucketAnalyticsConfiguration\nRequest Syntax\nGET /?analytics&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which an analytics configuration is retrieved.\nAmazon S3 API Version 2006-03-01 191",
      "start_idx": 268871,
      "end_idx": 270174,
      "metadata": {
        "num_sentences": 10,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_197",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nid\nThe ID that identifies the analytics configuration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AnalyticsConfiguration>\n<Id>string</Id>\n<Filter>\n<And>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n...\n</And>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Filter>\n<StorageClassAnalysis>\n<DataExport>\n<Destination>\n<S3BucketDestination>\nAmazon S3 API Version 2006-03-01 192",
      "start_idx": 270176,
      "end_idx": 270995,
      "metadata": {
        "num_sentences": 5,
        "num_words": 99,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_198",
      "text": "Amazon Simple Storage Service API Reference\n<Bucket>string</Bucket>\n<BucketAccountId>string</BucketAccountId>\n<Format>string</Format>\n<Prefix>string</Prefix>\n</S3BucketDestination>\n</Destination>\n<OutputSchemaVersion>string</OutputSchemaVersion>\n</DataExport>\n</StorageClassAnalysis>\n</AnalyticsConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAnalyticsConfiguration\nRoot level tag for the AnalyticsConfiguration parameters.\nRequired: Yes\nFilter\nThe filter used to describe a set of objects for analyses. A filter must have exactly one prefix,\none tag, or one conjunction (AnalyticsAndOperator). If no filter is provided, all objects will be\nconsidered in any analysis.\nType: AnalyticsFilter data type\nId\nThe ID that identifies the analytics configuration.\nType: String\nStorageClassAnalysis\nContains data related to access patterns to be collected and made available to analyze the\ntradeoffs between different storage classes.\nType: StorageClassAnalysis data type\nAmazon S3 API Version 2006-03-01 193",
      "start_idx": 270997,
      "end_idx": 272116,
      "metadata": {
        "num_sentences": 9,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_201",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketCors\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the Cross-Origin Resource Sharing (CORS) configuration information set for the bucket.\nTo use this operation, you must have permission to perform the s3:GetBucketCORS action. By\ndefault, the bucket owner has this permission and can grant it to others.\nWhen you use this API operation with an access point, provide the alias of the access point in place\nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias\nin a request is not valid, the error code InvalidAccessPointAliasError is returned. For more\ninformation about InvalidAccessPointAliasError, see List of Error Codes.\nFor more information about CORS, see Enabling Cross-Origin Resource Sharing.\nThe following operations are related to GetBucketCors:\n\u2022 PutBucketCors\n\u2022 DeleteBucketCors\nRequest Syntax\nGET /?cors HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which to get the cors configuration.\nAmazon S3 API Version 2006-03-01 196",
      "start_idx": 273756,
      "end_idx": 275079,
      "metadata": {
        "num_sentences": 12,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_202",
      "text": "Amazon Simple Storage Service API Reference\nWhen you use this API operation with an access point, provide the alias of the access point in\nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point\nalias in a request is not valid, the error code InvalidAccessPointAliasError is returned.\nFor more information about InvalidAccessPointAliasError, see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CORSConfiguration>\n<CORSRule>\n<AllowedHeader>string</AllowedHeader>\n...\n<AllowedMethod>string</AllowedMethod>\n...\n<AllowedOrigin>string</AllowedOrigin>\n...\n<ExposeHeader>string</ExposeHeader>\n...\n<ID>string</ID>\n<MaxAgeSeconds>integer</MaxAgeSeconds>\n</CORSRule>\n...\n</CORSConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 API Version 2006-03-01 197",
      "start_idx": 275081,
      "end_idx": 276385,
      "metadata": {
        "num_sentences": 9,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_203",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nCORSConfiguration\nRoot level tag for the CORSConfiguration parameters.\nRequired: Yes\nCORSRule\nA set of origins and methods (cross-origin access that you want to allow). You can add up to 100\nrules to the configuration.\nType: Array of CORSRule data types\nExamples\nConfigure CORS Sample Request\nThe following PUT request adds the cors subresource to a bucket (examplebucket).\nPUT /?cors HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Tue, 21 Aug 2012 17:54:50 GMT\nContent-MD5: 8dYiLewFWZyGgV2Q5FNI4W==\nAuthorization: authorization string\nContent-Length: 216\n<CORSConfiguration>\n<CORSRule>\n<AllowedOrigin>http://www.example.com</AllowedOrigin>\n<AllowedMethod>PUT</AllowedMethod>\n<AllowedMethod>POST</AllowedMethod>\n<AllowedMethod>DELETE</AllowedMethod>\n<AllowedHeader>*</AllowedHeader>\n<MaxAgeSeconds>3000</MaxAgeSec>\n<ExposeHeader>x-amz-server-side-encryption</ExposeHeader>\n</CORSRule>\n<CORSRule>\n<AllowedOrigin>*</AllowedOrigin>\n<AllowedMethod>GET</AllowedMethod>\n<AllowedHeader>*</AllowedHeader>\nAmazon S3 API Version 2006-03-01 198",
      "start_idx": 276387,
      "end_idx": 277545,
      "metadata": {
        "num_sentences": 6,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_206",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketEncryption\nService: Amazon S3\nReturns the default encryption configuration for an Amazon S3 bucket. By default, all buckets have\na default encryption configuration that uses server-side encryption with Amazon S3 managed keys\n(SSE-S3).\nNote\n\u2022 General purpose buckets - For information about the bucket default encryption feature,\nsee Amazon S3 Bucket Default Encryption in the Amazon S3 User Guide.\n\u2022 Directory buckets - For directory buckets, there are only two supported options\nfor server-side encryption: SSE-S3 and SSE-KMS. For information about the default\nencryption configuration in directory buckets, see Setting default server-side encryption\nbehavior for directory buckets.\nPermissions\n\u2022 General purpose bucket permissions - The s3:GetEncryptionConfiguration\npermission is required in a policy. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions,\nsee Permissions Related to Bucket Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\n\u2022 Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:GetEncryptionConfiguration permission in an IAM identity-based policy\ninstead of a bucket policy. Cross-account access to this API operation isn't supported. This\noperation can only be performed by the AWS account that owns the resource. For more\ninformation about directory bucket policies and permissions, see AWS Identity and Access\nManagement (IAM) for S3 Express One Zone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to GetBucketEncryption:\n\u2022 PutBucketEncryption\nAmazon S3 API Version 2006-03-01 201",
      "start_idx": 279038,
      "end_idx": 280886,
      "metadata": {
        "num_sentences": 15,
        "num_words": 262,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_207",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 DeleteBucketEncryption\nRequest Syntax\nGET /?encryption HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which the server-side encryption configuration is retrieved.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 202",
      "start_idx": 280888,
      "end_idx": 282291,
      "metadata": {
        "num_sentences": 12,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_211",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketIntelligentTieringConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets the S3 Intelligent-Tiering configuration from the specified bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically\nmoving data to the most cost-effective storage access tier, without performance impact or\noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency\nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in\nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing,\nor unpredictable access patterns, independent of object size or retention period. If the size of an\nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering. Smaller objects can\nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering\nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently\naccessed objects.\nOperations related to GetBucketIntelligentTieringConfiguration include:\n\u2022 DeleteBucketIntelligentTieringConfiguration\n\u2022 PutBucketIntelligentTieringConfiguration\n\u2022 ListBucketIntelligentTieringConfigurations\nRequest Syntax\nGET /?intelligent-tiering&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 206",
      "start_idx": 284574,
      "end_idx": 286206,
      "metadata": {
        "num_sentences": 11,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_213",
      "text": "Amazon Simple Storage Service API Reference\n</IntelligentTieringConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nIntelligentTieringConfiguration\nRoot level tag for the IntelligentTieringConfiguration parameters.\nRequired: Yes\nFilter\nSpecifies a bucket filter. The configuration only includes objects that meet the filter's criteria.\nType: IntelligentTieringFilter data type\nId\nThe ID used to identify the S3 Intelligent-Tiering configuration.\nType: String\nStatus\nSpecifies the status of the configuration.\nType: String\nValid Values: Enabled | Disabled\nTiering\nSpecifies the S3 Intelligent-Tiering storage class tier of the configuration.\nType: Array of Tiering data types\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 208",
      "start_idx": 286944,
      "end_idx": 287883,
      "metadata": {
        "num_sentences": 9,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_215",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketInventoryConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns an inventory configuration (identified by the inventory configuration ID) from the bucket.\nTo use this operation, you must have permissions to perform the\ns3:GetInventoryConfiguration action. The bucket owner has this permission by default\nand can grant this permission to others. For more information about permissions, see Permissions\nRelated to Bucket Subresource Operations and Managing Access Permissions to Your Amazon S3\nResources.\nFor information about the Amazon S3 inventory feature, see Amazon S3 Inventory.\nThe following operations are related to GetBucketInventoryConfiguration:\n\u2022 DeleteBucketInventoryConfiguration\n\u2022 ListBucketInventoryConfigurations\n\u2022 PutBucketInventoryConfiguration\nRequest Syntax\nGET /?inventory&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the inventory configuration to retrieve.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 210",
      "start_idx": 288167,
      "end_idx": 289355,
      "metadata": {
        "num_sentences": 9,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_216",
      "text": "Amazon Simple Storage Service API Reference\nid\nThe ID used to identify the inventory configuration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InventoryConfiguration>\n<Destination>\n<S3BucketDestination>\n<AccountId>string</AccountId>\n<Bucket>string</Bucket>\n<Encryption>\n<SSE-KMS>\n<KeyId>string</KeyId>\n</SSE-KMS>\n<SSE-S3>\n</SSE-S3>\n</Encryption>\n<Format>string</Format>\n<Prefix>string</Prefix>\n</S3BucketDestination>\n</Destination>\n<IsEnabled>boolean</IsEnabled>\n<Filter>\n<Prefix>string</Prefix>\n</Filter>\n<Id>string</Id>\n<IncludedObjectVersions>string</IncludedObjectVersions>\n<OptionalFields>\nAmazon S3 API Version 2006-03-01 211",
      "start_idx": 289357,
      "end_idx": 290313,
      "metadata": {
        "num_sentences": 5,
        "num_words": 100,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_217",
      "text": "Amazon Simple Storage Service API Reference\n<Field>string</Field>\n</OptionalFields>\n<Schedule>\n<Frequency>string</Frequency>\n</Schedule>\n</InventoryConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nInventoryConfiguration\nRoot level tag for the InventoryConfiguration parameters.\nRequired: Yes\nDestination\nContains information about where to publish the inventory results.\nType: InventoryDestination data type\nFilter\nSpecifies an inventory filter. The inventory only includes objects that meet the filter's criteria.\nType: InventoryFilter data type\nId\nThe ID used to identify the inventory configuration.\nType: String\nIncludedObjectVersions\nObject versions to include in the inventory list. If set to All, the list includes all the object\nversions, which adds the version-related fields VersionId, IsLatest, and DeleteMarker to\nthe list. If set to Current, the list does not contain these version-related fields.\nType: String\nValid Values: All | Current\nAmazon S3 API Version 2006-03-01 212",
      "start_idx": 290315,
      "end_idx": 291422,
      "metadata": {
        "num_sentences": 11,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_218",
      "text": "Amazon Simple Storage Service API Reference\nIsEnabled\nSpecifies whether the inventory is enabled or disabled. If set to True, an inventory list is\ngenerated. If set to False, no inventory list is generated.\nType: Boolean\nOptionalFields\nContains the optional fields that are included in the inventory results.\nType: Array of strings\nValid Values: Size | LastModifiedDate | StorageClass | ETag |\nIsMultipartUploaded | ReplicationStatus | EncryptionStatus |\nObjectLockRetainUntilDate | ObjectLockMode | ObjectLockLegalHoldStatus\n| IntelligentTieringAccessTier | BucketKeyStatus | ChecksumAlgorithm |\nObjectAccessControlList | ObjectOwner\nSchedule\nSpecifies the schedule for generating inventory results.\nType: InventorySchedule data type\nExamples\nSample Request: Configure an inventory report\nThe following GET request for the bucket examplebucket returns the inventory configuration\nwith the ID list1.\nGET /?inventory&id=list1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nAuthorization: authorization string\nSample Response\nThis example illustrates one usage of GetBucketInventoryConfiguration.\nAmazon S3 API Version 2006-03-01 213",
      "start_idx": 291424,
      "end_idx": 292599,
      "metadata": {
        "num_sentences": 8,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_221",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketLifecycle\nService: Amazon S3\nImportant\nFor an updated version of this API, see GetBucketLifecycleConfiguration. If you configured\na bucket lifecycle using the filter element, you should see the updated version of this\ntopic. This topic is provided for backward compatibility.\nNote\nThis operation is not supported by directory buckets.\nReturns the lifecycle configuration information set on the bucket. For information about lifecycle\nconfiguration, see Object Lifecycle Management.\nTo use this operation, you must have permission to perform the\ns3:GetLifecycleConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nGetBucketLifecycle has the following special error:\n\u2022 Error code: NoSuchLifecycleConfiguration\n\u2022 Description: The lifecycle configuration does not exist.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\nThe following operations are related to GetBucketLifecycle:\n\u2022 GetBucketLifecycleConfiguration\n\u2022 PutBucketLifecycle\n\u2022 DeleteBucketLifecycle\nAmazon S3 API Version 2006-03-01 216",
      "start_idx": 294121,
      "end_idx": 295413,
      "metadata": {
        "num_sentences": 12,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_222",
      "text": "Amazon Simple Storage Service API Reference\nRequest Syntax\nGET /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the lifecycle information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration>\n<Rule>\n<AbortIncompleteMultipartUpload>\n<DaysAfterInitiation>integer</DaysAfterInitiation>\n</AbortIncompleteMultipartUpload>\n<Expiration>\n<Date>timestamp</Date>\n<Days>integer</Days>\n<ExpiredObjectDeleteMarker>boolean</ExpiredObjectDeleteMarker>\n</Expiration>\n<ID>string</ID>\n<NoncurrentVersionExpiration>\nAmazon S3 API Version 2006-03-01 217",
      "start_idx": 295415,
      "end_idx": 296455,
      "metadata": {
        "num_sentences": 6,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_226",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketLifecycleConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNote\nBucket lifecycle configuration now supports specifying a lifecycle rule using an object key\nname prefix, one or more object tags, object size, or any combination of these. Accordingly,\nthis section describes the latest API. The previous version of the API supported filtering\nbased only on an object key name prefix, which is supported for backward compatibility.\nFor the related API description, see GetBucketLifecycle. Accordingly, this section describes\nthe latest API. The response describes the new filter element that you can use to specify\na filter to select a subset of objects to which the rule applies. If you are using a previous\nversion of the lifecycle configuration, it still works. For the earlier action,\nReturns the lifecycle configuration information set on the bucket. For information about lifecycle\nconfiguration, see Object Lifecycle Management.\nTo use this operation, you must have permission to perform the\ns3:GetLifecycleConfiguration action. The bucket owner has this permission, by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nGetBucketLifecycleConfiguration has the following special error:\n\u2022 Error code: NoSuchLifecycleConfiguration\n\u2022 Description: The lifecycle configuration does not exist.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\nThe following operations are related to GetBucketLifecycleConfiguration:\nAmazon S3 API Version 2006-03-01 221",
      "start_idx": 298946,
      "end_idx": 300678,
      "metadata": {
        "num_sentences": 16,
        "num_words": 247,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_227",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 GetBucketLifecycle\n\u2022 PutBucketLifecycle\n\u2022 DeleteBucketLifecycle\nRequest Syntax\nGET /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the lifecycle information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-transition-default-minimum-object-size: TransitionDefaultMinimumObjectSize\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration>\n<Rule>\n<AbortIncompleteMultipartUpload>\n<DaysAfterInitiation>integer</DaysAfterInitiation>\n</AbortIncompleteMultipartUpload>\n<Expiration>\n<Date>timestamp</Date>\nAmazon S3 API Version 2006-03-01 222",
      "start_idx": 300680,
      "end_idx": 301723,
      "metadata": {
        "num_sentences": 6,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_229",
      "text": "Amazon Simple Storage Service API Reference\n</LifecycleConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-transition-default-minimum-object-size\nIndicates which default minimum object size behavior is applied to the lifecycle configuration.\n\u2022 all_storage_classes_128K - Objects smaller than 128 KB will not transition to any\nstorage class by default.\n\u2022 varies_by_storage_class - Objects smaller than 128 KB will transition to Glacier Flexible\nRetrieval or Glacier Deep Archive storage classes. By default, all other storage classes will\nprevent transitions smaller than 128 KB.\nTo customize the minimum object size for any transition you can add a filter that specifies a\ncustom ObjectSizeGreaterThan or ObjectSizeLessThan in the body of your transition\nrule. Custom filters always take precedence over the default transition behavior.\nValid Values: varies_by_storage_class | all_storage_classes_128K\nThe following data is returned in XML format by the service.\nLifecycleConfiguration\nRoot level tag for the LifecycleConfiguration parameters.\nRequired: Yes\nRule\nContainer for a lifecycle rule.\nType: Array of LifecycleRule data types\nExamples\nSample Request\nThis example illustrates one usage of GetBucketLifecycleConfiguration.\nAmazon S3 API Version 2006-03-01 224",
      "start_idx": 302840,
      "end_idx": 304216,
      "metadata": {
        "num_sentences": 13,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_232",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketLocation\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the Region the bucket resides in. You set the bucket's Region using the\nLocationConstraint request parameter in a CreateBucket request. For more information, see\nCreateBucket.\nWhen you use this API operation with an access point, provide the alias of the access point in place\nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias\nin a request is not valid, the error code InvalidAccessPointAliasError is returned. For more\ninformation about InvalidAccessPointAliasError, see List of Error Codes.\nNote\nWe recommend that you use HeadBucket to return the Region that a bucket resides in. For\nbackward compatibility, Amazon S3 continues to support GetBucketLocation.\nThe following operations are related to GetBucketLocation:\n\u2022 GetObject\n\u2022 CreateBucket\nRequest Syntax\nGET /?location HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 227",
      "start_idx": 305581,
      "end_idx": 306788,
      "metadata": {
        "num_sentences": 11,
        "num_words": 175,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_233",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the location.\nWhen you use this API operation with an access point, provide the alias of the access point in\nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point\nalias in a request is not valid, the error code InvalidAccessPointAliasError is returned.\nFor more information about InvalidAccessPointAliasError, see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LocationConstraint>\n<LocationConstraint>string</LocationConstraint>\n</LocationConstraint>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 API Version 2006-03-01 228",
      "start_idx": 306790,
      "end_idx": 308088,
      "metadata": {
        "num_sentences": 12,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_234",
      "text": "Amazon Simple Storage Service API Reference\nLocationConstraint\nRoot level tag for the LocationConstraint parameters.\nRequired: Yes\nLocationConstraint\nSpecifies the Region where the bucket resides. For a list of all the Amazon S3 supported\nlocation constraints by Region, see Regions and Endpoints. Buckets in Region us-east-1 have\na LocationConstraint of null.\nType: String\nValid Values: af-south-1 | ap-east-1 | ap-northeast-1 | ap-northeast-2 | ap-\nnortheast-3 | ap-south-1 | ap-south-2 | ap-southeast-1 | ap-southeast-2\n| ap-southeast-3 | ca-central-1 | cn-north-1 | cn-northwest-1 | EU | eu-\ncentral-1 | eu-north-1 | eu-south-1 | eu-south-2 | eu-west-1 | eu-west-2\n| eu-west-3 | me-south-1 | sa-east-1 | us-east-2 | us-gov-east-1 | us-\ngov-west-1 | us-west-1 | us-west-2\nExamples\nSample Request\nThe following request returns the Region of the specified bucket.\nGET /?location HTTP/1.1\nHost: myBucket.s3.amazonaws.com\nDate: Tue, 09 Oct 2007 20:26:04 +0000\nAuthorization: signatureValue\nSample Response\nThis example illustrates one usage of GetBucketLocation.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LocationConstraint xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">us-\nwest-2</LocationConstraint>\nAmazon S3 API Version 2006-03-01 229",
      "start_idx": 308090,
      "end_idx": 309327,
      "metadata": {
        "num_sentences": 7,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_236",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketLogging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the logging status of a bucket and the permissions users have to view and modify that\nstatus.\nThe following operations are related to GetBucketLogging:\n\u2022 CreateBucket\n\u2022 PutBucketLogging\nRequest Syntax\nGET /?logging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which to get the logging information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 231",
      "start_idx": 309723,
      "end_idx": 310643,
      "metadata": {
        "num_sentences": 8,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_238",
      "text": "Amazon Simple Storage Service API Reference\nLoggingEnabled\nDescribes where logs are stored and the prefix that Amazon S3 assigns to all log object keys for\na bucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nType: LoggingEnabled data type\nExamples\nSample Request\nThe following request returns the logging status for mybucket.\nGET ?logging HTTP/1.1\nHost: mybucket.s3.<Region>.amazonaws.com\nDate: Wed, 25 Nov 2009 12:00:00 GMT\nAuthorization: authorization string\nSample Response: Showing an enabled logging status\nThis example illustrates one usage of GetBucketLogging.\nHTTP/1.1 200 OK\nDate: Wed, 25 Nov 2009 12:00:00 GMT\nConnection: close\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<LoggingEnabled>\n<TargetBucket>mybucketlogs</TargetBucket>\n<TargetPrefix>mybucket-access_log-/</TargetPrefix>\n<TargetGrants>\n<Grant>\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"AmazonCustomerByEmail\">\n<EmailAddress>user@company.com</EmailAddress>\n</Grantee>\n<Permission>READ</Permission>\nAmazon S3 API Version 2006-03-01 233",
      "start_idx": 311593,
      "end_idx": 312744,
      "metadata": {
        "num_sentences": 5,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_240",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketMetricsConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets a metrics configuration (specified by the metrics configuration ID) from the bucket. Note that\nthis doesn't include the daily storage metrics.\nTo use this operation, you must have permissions to perform the\ns3:GetMetricsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with\nAmazon CloudWatch.\nThe following operations are related to GetBucketMetricsConfiguration:\n\u2022 PutBucketMetricsConfiguration\n\u2022 DeleteBucketMetricsConfiguration\n\u2022 ListBucketMetricsConfigurations\n\u2022 Monitoring Metrics with Amazon CloudWatch\nRequest Syntax\nGET /?metrics&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the metrics configuration to retrieve.\nAmazon S3 API Version 2006-03-01 235",
      "start_idx": 313510,
      "end_idx": 314806,
      "metadata": {
        "num_sentences": 11,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_241",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nid\nThe ID used to identify the metrics configuration. The ID has a 64 character limit and can only\ncontain letters, numbers, periods, dashes, and underscores.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration>\n<Id>string</Id>\n<Filter>\n<AccessPointArn>string</AccessPointArn>\n<And>\n<AccessPointArn>string</AccessPointArn>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n...\n</And>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Filter>\n</MetricsConfiguration>\nAmazon S3 API Version 2006-03-01 236",
      "start_idx": 314808,
      "end_idx": 315761,
      "metadata": {
        "num_sentences": 6,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_242",
      "text": "Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nMetricsConfiguration\nRoot level tag for the MetricsConfiguration parameters.\nRequired: Yes\nFilter\nSpecifies a metrics configuration filter. The metrics configuration will only include objects\nthat meet the filter's criteria. A filter must be a prefix, an object tag, an access point ARN, or a\nconjunction (MetricsAndOperator).\nType: MetricsFilter data type\nId\nThe ID used to identify the metrics configuration. The ID has a 64 character limit and can only\ncontain letters, numbers, periods, dashes, and underscores.\nType: String\nExamples\nFirst Sample Request\nRetrieve a metrics configuration that filters metrics based on a specified prefix.\nGET /?metrics&id=Documents HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 15 Nov 2016 00:17:21 GMT\nAuthorization: signatureValue\nFirst Sample Response\nThis example illustrates one usage of GetBucketMetricsConfiguration.\nAmazon S3 API Version 2006-03-01 237",
      "start_idx": 315763,
      "end_idx": 316883,
      "metadata": {
        "num_sentences": 11,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_246",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketNotification\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNo longer used, see GetBucketNotificationConfiguration.\nRequest Syntax\nGET /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the notification configuration.\nWhen you use this API operation with an access point, provide the alias of the access point in\nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point\nalias in a request is not valid, the error code InvalidAccessPointAliasError is returned.\nFor more information about InvalidAccessPointAliasError, see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 241",
      "start_idx": 319636,
      "end_idx": 320863,
      "metadata": {
        "num_sentences": 11,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_248",
      "text": "Amazon Simple Storage Service API Reference\nCloudFunctionConfiguration\nContainer for specifying the AWS Lambda notification configuration.\nType: CloudFunctionConfiguration data type\nQueueConfiguration\nThis data type is deprecated. This data type specifies the configuration for publishing messages\nto an Amazon Simple Queue Service (Amazon SQS) queue when Amazon S3 detects specified\nevents.\nType: QueueConfigurationDeprecated data type\nTopicConfiguration\nThis data type is deprecated. A container for specifying the configuration for publication of\nmessages to an Amazon Simple Notification Service (Amazon SNS) topic when Amazon S3\ndetects specified events.\nType: TopicConfigurationDeprecated data type\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 243",
      "start_idx": 321840,
      "end_idx": 322893,
      "metadata": {
        "num_sentences": 6,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_249",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketNotificationConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the notification configuration of a bucket.\nIf notifications are not enabled on the bucket, the action returns an empty\nNotificationConfiguration element.\nBy default, you must be the bucket owner to read the notification configuration of a bucket.\nHowever, the bucket owner can use a bucket policy to grant permission to other users to read this\nconfiguration with the s3:GetBucketNotification permission.\nWhen you use this API operation with an access point, provide the alias of the access point in place\nof the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point alias\nin a request is not valid, the error code InvalidAccessPointAliasError is returned. For more\ninformation about InvalidAccessPointAliasError, see List of Error Codes.\nFor more information about setting and reading the notification configuration on a bucket, see\nSetting Up Notification of Bucket Events. For more information about bucket policies, see Using\nBucket Policies.\nThe following action is related to GetBucketNotification:\n\u2022 PutBucketNotification\nRequest Syntax\nGET /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 244",
      "start_idx": 322895,
      "end_idx": 324390,
      "metadata": {
        "num_sentences": 12,
        "num_words": 213,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_250",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the notification configuration.\nWhen you use this API operation with an access point, provide the alias of the access point in\nplace of the bucket name.\nWhen you use this API operation with an Object Lambda access point, provide the alias of the\nObject Lambda access point in place of the bucket name. If the Object Lambda access point\nalias in a request is not valid, the error code InvalidAccessPointAliasError is returned.\nFor more information about InvalidAccessPointAliasError, see List of Error Codes.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<NotificationConfiguration>\n<TopicConfiguration>\n<Event>string</Event>\n...\n<Filter>\n<S3Key>\n<FilterRule>\n<Name>string</Name>\n<Value>string</Value>\n</FilterRule>\n...\nAmazon S3 API Version 2006-03-01 245",
      "start_idx": 324392,
      "end_idx": 325629,
      "metadata": {
        "num_sentences": 10,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_255",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketOwnershipControls\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves OwnershipControls for an Amazon S3 bucket. To use this operation, you must have\nthe s3:GetBucketOwnershipControls permission. For more information about Amazon S3\npermissions, see Specifying permissions in a policy.\nFor information about Amazon S3 Object Ownership, see Using Object Ownership.\nThe following operations are related to GetBucketOwnershipControls:\n\u2022 PutBucketOwnershipControls\n\u2022 DeleteBucketOwnershipControls\nRequest Syntax\nGET /?ownershipControls HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose OwnershipControls you want to retrieve.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 250",
      "start_idx": 328692,
      "end_idx": 329837,
      "metadata": {
        "num_sentences": 10,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_259",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketPolicy\nService: Amazon S3\nReturns the policy of a specified bucket.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\nIf you are using an identity other than the root user of the AWS account that owns the bucket,\nthe calling identity must both have the GetBucketPolicy permissions on the specified bucket\nand belong to the bucket owner's account in order to use this operation.\nIf you don't have GetBucketPolicy permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the\nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed error.\nImportant\nTo ensure that bucket owners don't inadvertently lock themselves out of their\nown buckets, the root principal in a bucket owner's AWS account can perform the\nGetBucketPolicy, PutBucketPolicy, and DeleteBucketPolicy API actions,\neven if their bucket policy explicitly denies the root principal's access. Bucket owner\nroot principals can only be blocked from performing these API actions by VPC endpoint\npolicies and AWS Organizations policies.\n\u2022 General purpose bucket permissions - The s3:GetBucketPolicy permission is required\nin a policy. For more information about general purpose buckets bucket policies, see Using\nBucket Policies and User Policies in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:GetBucketPolicy permission in an IAM identity-based policy instead of a\nAmazon S3 API Version 2006-03-01 254",
      "start_idx": 332549,
      "end_idx": 334474,
      "metadata": {
        "num_sentences": 13,
        "num_words": 285,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_260",
      "text": "Amazon Simple Storage Service API Reference\nbucket policy. Cross-account access to this API operation isn't supported. This operation can\nonly be performed by the AWS account that owns the resource. For more information about\ndirectory bucket policies and permissions, see AWS Identity and Access Management (IAM) for\nS3 Express One Zone in the Amazon S3 User Guide.\nExample bucket policies\nGeneral purpose buckets example bucket policies - See Bucket policy examples in the Amazon\nS3 User Guide.\nDirectory bucket example bucket policies - See Example bucket policies for S3 Express One\nZone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following action is related to GetBucketPolicy:\n\u2022 GetObject\nRequest Syntax\nGET /?policy HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name to get the bucket policy for.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nAmazon S3 API Version 2006-03-01 255",
      "start_idx": 334476,
      "end_idx": 335934,
      "metadata": {
        "num_sentences": 13,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_261",
      "text": "Amazon Simple Storage Service API Reference\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nAccess points - When you use this API operation with an access point, provide the alias of the\naccess point in place of the bucket name.\nObject Lambda access points - When you use this API operation with an Object\nLambda access point, provide the alias of the Object Lambda access point in place of\nthe bucket name. If the Object Lambda access point alias in a request is not valid, the\nerror code InvalidAccessPointAliasError is returned. For more information about\nInvalidAccessPointAliasError, see List of Error Codes.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n{ Policy in JSON format }\nAmazon S3 API Version 2006-03-01 256",
      "start_idx": 335936,
      "end_idx": 337314,
      "metadata": {
        "num_sentences": 12,
        "num_words": 220,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_264",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketPolicyStatus\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves the policy status for an Amazon S3 bucket, indicating whether the bucket is public. In\norder to use this operation, you must have the s3:GetBucketPolicyStatus permission. For\nmore information about Amazon S3 permissions, see Specifying Permissions in a Policy.\nFor more information about when Amazon S3 considers a bucket public, see The Meaning of\n\"Public\".\nThe following operations are related to GetBucketPolicyStatus:\n\u2022 Using Amazon S3 Block Public Access\n\u2022 GetPublicAccessBlock\n\u2022 PutPublicAccessBlock\n\u2022 DeletePublicAccessBlock\nRequest Syntax\nGET /?policyStatus HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose policy status you want to retrieve.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 259",
      "start_idx": 338730,
      "end_idx": 339740,
      "metadata": {
        "num_sentences": 8,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_265",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PolicyStatus>\n<IsPublic>boolean</IsPublic>\n</PolicyStatus>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPolicyStatus\nRoot level tag for the PolicyStatus parameters.\nRequired: Yes\nIsPublic\nThe policy status for this bucket. TRUE indicates that this bucket is public. FALSE indicates that\nthe bucket is not public.\nType: Boolean\nExamples\nSample Request\nThe following request gets a bucket policy status.\nAmazon S3 API Version 2006-03-01 260",
      "start_idx": 339742,
      "end_idx": 340686,
      "metadata": {
        "num_sentences": 11,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_268",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketReplication\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the replication configuration of a bucket.\nNote\nIt can take a while to propagate the put or delete a replication configuration to all Amazon\nS3 systems. Therefore, a get request soon after put or delete can return a wrong result.\nFor information about replication configuration, see Replication in the Amazon S3 User Guide.\nThis action requires permissions for the s3:GetReplicationConfiguration action. For more\ninformation about permissions, see Using Bucket Policies and User Policies.\nIf you include the Filter element in a replication configuration, you must also include the\nDeleteMarkerReplication and Priority elements. The response also returns those elements.\nFor information about GetBucketReplication errors, see List of replication-related error codes\nThe following operations are related to GetBucketReplication:\n\u2022 PutBucketReplication\n\u2022 DeleteBucketReplication\nRequest Syntax\nGET /?replication HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 263",
      "start_idx": 341660,
      "end_idx": 342914,
      "metadata": {
        "num_sentences": 11,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_269",
      "text": "Amazon Simple Storage Service API Reference\nBucket\nThe bucket name for which to get the replication information.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ReplicationConfiguration>\n<Role>string</Role>\n<Rule>\n<DeleteMarkerReplication>\n<Status>string</Status>\n</DeleteMarkerReplication>\n<Destination>\n<AccessControlTranslation>\n<Owner>string</Owner>\n</AccessControlTranslation>\n<Account>string</Account>\n<Bucket>string</Bucket>\n<EncryptionConfiguration>\n<ReplicaKmsKeyID>string</ReplicaKmsKeyID>\n</EncryptionConfiguration>\n<Metrics>\n<EventThreshold>\n<Minutes>integer</Minutes>\n</EventThreshold>\n<Status>string</Status>\n</Metrics>\n<ReplicationTime>\n<Status>string</Status>\n<Time>\nAmazon S3 API Version 2006-03-01 264",
      "start_idx": 342916,
      "end_idx": 343955,
      "metadata": {
        "num_sentences": 5,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_271",
      "text": "Amazon Simple Storage Service API Reference\nReplicationConfiguration\nRoot level tag for the ReplicationConfiguration parameters.\nRequired: Yes\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role\nthat Amazon S3 assumes when replicating objects. For more information, see How to Set Up\nReplication in the Amazon S3 User Guide.\nType: String\nRule\nA container for one or more replication rules. A replication configuration must have at least one\nrule and can contain a maximum of 1,000 rules.\nType: Array of ReplicationRule data types\nExamples\nSample Request: Retrieve replication configuration information\nThe following GET request retrieves information about the replication configuration set for the\nexamplebucket bucket:\nGET /?replication HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 10 Feb 2015 00:17:21 GMT\nAuthorization: authorization string\nSample Response\nThe following response shows that replication is enabled on the bucket. The empty prefix indicates\nthat Amazon S3 will replicate all objects that are created in the examplebucket bucket. The\nDestination element identifies the target bucket where Amazon S3 creates the object replicas,\nand the storage class (STANDARD_IA) that Amazon S3 uses when creating replicas.\nAmazon S3 API Version 2006-03-01 266",
      "start_idx": 344900,
      "end_idx": 346219,
      "metadata": {
        "num_sentences": 9,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_274",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketRequestPayment\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the request payment configuration of a bucket. To use this version of the operation, you\nmust be the bucket owner. For more information, see Requester Pays Buckets.\nThe following operations are related to GetBucketRequestPayment:\n\u2022 ListObjects\nRequest Syntax\nGET /?requestPayment HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the payment request configuration\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 269",
      "start_idx": 347617,
      "end_idx": 348625,
      "metadata": {
        "num_sentences": 9,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_278",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging>\n<TagSet>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</TagSet>\n</Tagging>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nContains the tag set.\nType: Array of Tag data types\nAmazon S3 API Version 2006-03-01 273",
      "start_idx": 351357,
      "end_idx": 352160,
      "metadata": {
        "num_sentences": 8,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_281",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketVersioning\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the versioning state of a bucket.\nTo retrieve the versioning state of a bucket, you must be the bucket owner.\nThis implementation also returns the MFA Delete status of the versioning state. If the MFA Delete\nstatus is enabled, the bucket owner must use an authentication device to change the versioning\nstate of the bucket.\nThe following operations are related to GetBucketVersioning:\n\u2022 GetObject\n\u2022 PutObject\n\u2022 DeleteObject\nRequest Syntax\nGET /?versioning HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to get the versioning information.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 276",
      "start_idx": 353264,
      "end_idx": 354153,
      "metadata": {
        "num_sentences": 8,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_282",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<VersioningConfiguration>\n<Status>string</Status>\n<MfaDelete>string</MfaDelete>\n</VersioningConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nVersioningConfiguration\nRoot level tag for the VersioningConfiguration parameters.\nRequired: Yes\nMFADelete\nSpecifies whether MFA delete is enabled in the bucket versioning configuration. This element is\nonly returned if the bucket has been configured with MFA delete. If the bucket has never been\nso configured, this element is not returned.\nType: String\nValid Values: Enabled | Disabled\nStatus\nThe versioning state of the bucket.\nAmazon S3 API Version 2006-03-01 277",
      "start_idx": 354155,
      "end_idx": 355279,
      "metadata": {
        "num_sentences": 11,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_285",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketWebsite\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the website configuration for a bucket. To host website on Amazon S3, you can configure a\nbucket as website by adding a website configuration. For more information about hosting websites,\nsee Hosting Websites on Amazon S3.\nThis GET action requires the S3:GetBucketWebsite permission. By default, only the\nbucket owner can read the bucket website configuration. However, bucket owners can allow\nother users to read the website configuration by writing a bucket policy granting them the\nS3:GetBucketWebsite permission.\nThe following operations are related to GetBucketWebsite:\n\u2022 DeleteBucketWebsite\n\u2022 PutBucketWebsite\nRequest Syntax\nGET /?website HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name for which to get the website configuration.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 280",
      "start_idx": 356619,
      "end_idx": 357686,
      "metadata": {
        "num_sentences": 10,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_286",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<WebsiteConfiguration>\n<RedirectAllRequestsTo>\n<HostName>string</HostName>\n<Protocol>string</Protocol>\n</RedirectAllRequestsTo>\n<IndexDocument>\n<Suffix>string</Suffix>\n</IndexDocument>\n<ErrorDocument>\n<Key>string</Key>\n</ErrorDocument>\n<RoutingRules>\n<RoutingRule>\n<Condition>\n<HttpErrorCodeReturnedEquals>string</HttpErrorCodeReturnedEquals>\n<KeyPrefixEquals>string</KeyPrefixEquals>\n</Condition>\n<Redirect>\n<HostName>string</HostName>\n<HttpRedirectCode>string</HttpRedirectCode>\n<Protocol>string</Protocol>\n<ReplaceKeyPrefixWith>string</ReplaceKeyPrefixWith>\n<ReplaceKeyWith>string</ReplaceKeyWith>\n</Redirect>\n</RoutingRule>\n</RoutingRules>\n</WebsiteConfiguration>\nAmazon S3 API Version 2006-03-01 281",
      "start_idx": 357688,
      "end_idx": 358789,
      "metadata": {
        "num_sentences": 4,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_290",
      "text": "Amazon Simple Storage Service API Reference\nGetObject\nService: Amazon S3\nRetrieves an object from Amazon S3.\nIn the GetObject request, specify the full key name for the object.\nGeneral purpose buckets - Both the virtual-hosted-style requests and the path-style requests\nare supported. For a virtual hosted-style request example, if you have the object photos/2006/\nFebruary/sample.jpg, specify the object key name as /photos/2006/February/\nsample.jpg. For a path-style request example, if you have the object photos/2006/\nFebruary/sample.jpg in the bucket named examplebucket, specify the object key name as /\nexamplebucket/photos/2006/February/sample.jpg. For more information about request\ntypes, see HTTP Host Header Bucket Specification in the Amazon S3 User Guide.\nDirectory buckets - Only virtual-hosted-style requests are supported. For a virtual hosted-style\nrequest example, if you have the object photos/2006/February/sample.jpg in the bucket\nnamed examplebucket--use1-az5--x-s3, specify the object key name as /photos/2006/\nFebruary/sample.jpg. Also, when you make requests to this API operation, your requests are\nsent to the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name . Path-\nstyle requests are not supported. For more information, see Regional and Zonal endpoints in the\nAmazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - You must have the required permissions in a policy. To\nuse GetObject, you must have the READ access to the object (or version). If you grant READ\naccess to the anonymous user, the GetObject operation returns the object without using\nan authorization header. For more information, see Specifying permissions in a policy in the\nAmazon S3 User Guide.\nIf you include a versionId in your request header, you must have the\ns3:GetObjectVersion permission to access a specific version of an object. The\ns3:GetObject permission is not required in this scenario.\nIf you request the current version of an object without a specific versionId in the request\nheader, only the s3:GetObject permission is required. The s3:GetObjectVersion\npermission is not required in this scenario.\nAmazon S3 API Version 2006-03-01 285",
      "start_idx": 360932,
      "end_idx": 363201,
      "metadata": {
        "num_sentences": 21,
        "num_words": 321,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_291",
      "text": "Amazon Simple Storage Service API Reference\nIf the object that you request doesn\u2019t exist, the error that Amazon S3 returns depends on\nwhether you also have the s3:ListBucket permission.\n\u2022 If you have the s3:ListBucket permission on the bucket, Amazon S3 returns an HTTP\nstatus code 404 Not Found error.\n\u2022 If you don\u2019t have the s3:ListBucket permission, Amazon S3 returns an HTTP status code\n403 Access Denied error.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nIf the object is encrypted using SSE-KMS, you must also have the kms:GenerateDataKey\nand kms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for\nthe AWS KMS key.\nStorage classes\nIf the object you are retrieving is stored in the S3 Glacier Flexible Retrieval storage class,\nthe S3 Glacier Deep Archive storage class, the S3 Intelligent-Tiering Archive Access tier,\nor the S3 Intelligent-Tiering Deep Archive Access tier, before you can retrieve the object\nyou must first restore a copy using RestoreObject. Otherwise, this operation returns an\nInvalidObjectState error. For information about restoring archived objects, see Restoring\nArchived Objects in the Amazon S3 User Guide.\nDirectory buckets - For directory buckets, only the S3 Express One Zone storage class is\nsupported to store newly created objects. Unsupported storage class values won't write a\ndestination object and will respond with the HTTP status code 400 Bad Request.\nEncryption\nEncryption request headers, like x-amz-server-side-encryption, should not be sent for\nthe GetObject requests, if your object uses server-side encryption with Amazon S3 managed\nAmazon S3 API Version 2006-03-01 286",
      "start_idx": 363203,
      "end_idx": 365610,
      "metadata": {
        "num_sentences": 17,
        "num_words": 370,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_292",
      "text": "Amazon Simple Storage Service API Reference\nencryption keys (SSE-S3), server-side encryption with AWS Key Management Service (AWS KMS)\nkeys (SSE-KMS), or dual-layer server-side encryption with AWS KMS keys (DSSE-KMS). If you\ninclude the header in your GetObject requests for the object that uses these types of keys,\nyou\u2019ll get an HTTP 400 Bad Request error.\nDirectory buckets - For directory buckets, there are only two supported options for server-side\nencryption: SSE-S3 and SSE-KMS. SSE-C isn't supported. For more information, see Protecting\ndata with server-side encryption in the Amazon S3 User Guide.\nOverriding response header values through the request\nThere are times when you want to override certain response header values of a GetObject\nresponse. For example, you might override the Content-Disposition response header value\nthrough your GetObject request.\nYou can override values for a set of response headers. These modified response header values\nare included only in a successful response, that is, when the HTTP status code 200 OK is\nreturned. The headers you can override using the following query parameters in the request are\na subset of the headers that Amazon S3 accepts when you create an object.\nThe response headers that you can override for the GetObject response are Cache-Control,\nContent-Disposition, Content-Encoding, Content-Language, Content-Type, and\nExpires.\nTo override values for a set of response headers in the GetObject response, you can use the\nfollowing query parameters in the request.\n\u2022 response-cache-control\n\u2022 response-content-disposition\n\u2022 response-content-encoding\n\u2022 response-content-language\n\u2022 response-content-type\n\u2022 response-expires\nNote\nWhen you use these parameters, you must sign the request by using either an\nAuthorization header or a presigned URL. These parameters cannot be used with an\nunsigned (anonymous) request.\nAmazon S3 API Version 2006-03-01 287",
      "start_idx": 365612,
      "end_idx": 367525,
      "metadata": {
        "num_sentences": 15,
        "num_words": 280,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_293",
      "text": "Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to GetObject:\n\u2022 ListBuckets\n\u2022 GetObjectAcl\nRequest Syntax\nGET /Key+?partNumber=PartNumber&response-cache-control=ResponseCacheControl&response-\ncontent-disposition=ResponseContentDisposition&response-\ncontent-encoding=ResponseContentEncoding&response-content-\nlanguage=ResponseContentLanguage&response-content-type=ResponseContentType&response-\nexpires=ResponseExpires&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nIf-Match: IfMatch\nIf-Modified-Since: IfModifiedSince\nIf-None-Match: IfNoneMatch\nIf-Unmodified-Since: IfUnmodifiedSince\nRange: Range\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-checksum-mode: ChecksumMode\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nAmazon S3 API Version 2006-03-01 288",
      "start_idx": 367527,
      "end_idx": 368963,
      "metadata": {
        "num_sentences": 5,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_294",
      "text": "Amazon Simple Storage Service API Reference\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nObject Lambda access points - When you use this action with an Object Lambda access\npoint, you must direct requests to the Object Lambda access point hostname. The Object\nLambda access point hostname takes the form AccessPointName-AccountId.s3-object-\nlambda.Region.amazonaws.com.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nIf-Match\nReturn the object only if its entity tag (ETag) is the same as the one specified in this header;\notherwise, return a 412 Precondition Failed error.\nIf both of the If-Match and If-Unmodified-Since headers are present in the request\nas follows: If-Match condition evaluates to true, and; If-Unmodified-Since condition\nevaluates to false; then, S3 returns 200 OK and the data requested.\nAmazon S3 API Version 2006-03-01 289",
      "start_idx": 368965,
      "end_idx": 371210,
      "metadata": {
        "num_sentences": 20,
        "num_words": 344,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_296",
      "text": "Amazon Simple Storage Service API Reference\npartNumber\nPart number of the object being read. This is a positive integer between 1 and 10,000.\nEffectively performs a 'ranged' GET request for the part specified. Useful for downloading just a\npart of an object.\nRange\nDownloads the specified byte range of an object. For more information about the HTTP Range\nheader, see https://www.rfc-editor.org/rfc/rfc9110.html#name-range.\nNote\nAmazon S3 doesn't support retrieving multiple ranges of data per GET request.\nresponse-cache-control\nSets the Cache-Control header of the response.\nresponse-content-disposition\nSets the Content-Disposition header of the response.\nresponse-content-encoding\nSets the Content-Encoding header of the response.\nresponse-content-language\nSets the Content-Language header of the response.\nresponse-content-type\nSets the Content-Type header of the response.\nresponse-expires\nSets the Expires header of the response.\nversionId\nVersion ID used to reference a specific version of the object.\nBy default, the GetObject operation returns the current version of an object. To return a\ndifferent version, use the versionId subresource.\nAmazon S3 API Version 2006-03-01 291",
      "start_idx": 372795,
      "end_idx": 373981,
      "metadata": {
        "num_sentences": 17,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_297",
      "text": "Amazon Simple Storage Service API Reference\nNote\n\u2022 If you include a versionId in your request header, you must have the\ns3:GetObjectVersion permission to access a specific version of an object. The\ns3:GetObject permission is not required in this scenario.\n\u2022 If you request the current version of an object without a specific versionId\nin the request header, only the s3:GetObject permission is required. The\ns3:GetObjectVersion permission is not required in this scenario.\n\u2022 Directory buckets - S3 Versioning isn't enabled and supported for directory buckets.\nFor this API operation, only the null value of the version ID is supported by directory\nbuckets. You can only specify null to the versionId query parameter in the\nrequest.\nFor more information about versioning, see PutBucketVersioning.\nx-amz-checksum-mode\nTo retrieve the checksum, this mode must be enabled.\nGeneral purpose buckets - In addition, if you enable checksum mode and the object is\nuploaded with a checksum and encrypted with an AWS Key Management Service (AWS KMS)\nkey, you must have permission to use the kms:Decrypt action to retrieve the checksum.\nValid Values: ENABLED\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 292",
      "start_idx": 373983,
      "end_idx": 375850,
      "metadata": {
        "num_sentences": 17,
        "num_words": 291,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_298",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when decrypting the object (for example, AES256).\nIf you encrypt an object by using server-side encryption with customer-provided encryption\nkeys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must\nuse the following headers:\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided\nEncryption Keys) in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key that you originally provided for Amazon S3 to\nencrypt the data before storing it. This value is used to decrypt the object when recovering it\nand must match the one used when storing the data. The key must be appropriate for use with\nthe algorithm specified in the x-amz-server-side-encryption-customer-algorithm\nheader.\nIf you encrypt an object by using server-side encryption with customer-provided encryption\nkeys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must\nuse the following headers:\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\nAmazon S3 API Version 2006-03-01 293",
      "start_idx": 375852,
      "end_idx": 377411,
      "metadata": {
        "num_sentences": 8,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_299",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided\nEncryption Keys) in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the customer-provided encryption key according to RFC\n1321. Amazon S3 uses this header for a message integrity check to ensure that the encryption\nkey was transmitted without error.\nIf you encrypt an object by using server-side encryption with customer-provided encryption\nkeys (SSE-C) when you store the object in Amazon S3, then when you GET the object, you must\nuse the following headers:\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided\nEncryption Keys) in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-delete-marker: DeleteMarker\naccept-ranges: AcceptRanges\nAmazon S3 API Version 2006-03-01 294",
      "start_idx": 377413,
      "end_idx": 378695,
      "metadata": {
        "num_sentences": 8,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_302",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nx-amz-delete-marker\nIndicates whether the object retrieved was (true) or was not (false) a Delete Marker. If false, this\nresponse header does not appear in the response.\nNote\n\u2022 If the current version of the object is a delete marker, Amazon S3 behaves as if the\nobject was deleted and includes x-amz-delete-marker: true in the response.\n\u2022 If the specified version in the request is a delete marker, the response returns a 405\nMethod Not Allowed error and the Last-Modified: timestamp response\nheader.\nx-amz-expiration\nIf the object expiration is configured (see PutBucketLifecycleConfiguration), the\nresponse includes this header. It includes the expiry-date and rule-id key-value pairs\nproviding object expiration information. The value of the rule-id is URL-encoded.\nAmazon S3 API Version 2006-03-01 297",
      "start_idx": 381408,
      "end_idx": 383145,
      "metadata": {
        "num_sentences": 20,
        "num_words": 263,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_303",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-missing-meta\nThis is set to the number of metadata entries not returned in the headers that are prefixed with\nx-amz-meta-. This can happen if you create metadata using an API like SOAP that supports\nmore flexible metadata than the REST API. For example, using SOAP, you can create metadata\nwhose values are not legal HTTP headers.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-mp-parts-count\nThe count of parts this object has. This value is only returned if you specify partNumber in your\nrequest and the object was uploaded as a multipart upload.\nx-amz-object-lock-legal-hold\nIndicates whether this object has an active legal hold. This field is only returned if you have\npermission to view an object's legal hold status.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nx-amz-object-lock-mode\nThe Object Lock mode that's currently in place for this object.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 298",
      "start_idx": 383147,
      "end_idx": 384283,
      "metadata": {
        "num_sentences": 13,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_305",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone\nstorage class is supported by directory buckets to store objects.\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the object uses an S3 Bucket Key for server-side encryption with AWS Key\nManagement Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response\nwill include this header to confirm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the\nresponse will include this header to provide the round-trip message integrity verification of the\ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 300",
      "start_idx": 385151,
      "end_idx": 386464,
      "metadata": {
        "num_sentences": 10,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_306",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-storage-class\nProvides storage class information of the object. Amazon S3 returns this header for all objects\nexcept for S3 Standard storage class objects.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by\ndirectory buckets to store objects.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nx-amz-tagging-count\nThe number of tags, if any, on the object, when you have the relevant permission to read object\ntags.\nYou can use GetObjectTagging to retrieve the tag set associated with an object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-version-id\nVersion ID of the object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-website-redirect-location\nIf the bucket is configured as a website, redirects requests for this object to another object in\nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object\nmetadata.\nAmazon S3 API Version 2006-03-01 301",
      "start_idx": 386466,
      "end_idx": 387603,
      "metadata": {
        "num_sentences": 11,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_307",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in binary format by the service.\n<varlistentry> Body </varlistentry>\nErrors\nInvalidObjectState\nObject is archived and inaccessible until restored.\nIf the object you are retrieving is stored in the S3 Glacier Flexible Retrieval storage class,\nthe S3 Glacier Deep Archive storage class, the S3 Intelligent-Tiering Archive Access tier,\nor the S3 Intelligent-Tiering Deep Archive Access tier, before you can retrieve the object\nyou must first restore a copy using RestoreObject. Otherwise, this operation returns an\nInvalidObjectState error. For information about restoring archived objects, see Restoring\nArchived Objects in the Amazon S3 User Guide.\nHTTP Status Code: 403\nNoSuchKey\nThe specified key does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThe following request returns the object my-image.jpg.\nGET /my-image.jpg HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Mon, 3 Oct 2016 22:32:00 GMT\nAuthorization: authorization string\nAmazon S3 API Version 2006-03-01 302",
      "start_idx": 387605,
      "end_idx": 388760,
      "metadata": {
        "num_sentences": 9,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_309",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2:\neftixk72aD6Ap51TnqcoF8eFidJG9Z/2mkiDFu8yU9AS1ed4OpIszj7UDNEHGran\nx-amz-request-id: 318BC8BC148832E5\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nLast-Modified: Wed, 12 Oct 2009 17:50:00 GMT\nx-amz-expiration: expiry-date=\"Fri, 23 Dec 2012 00:00:00 GMT\", rule-\nid=\"picture-deletion-rule\"\nETag: \"fba9dede5f27731c9771645a39863328\"\nContent-Length: 434234\nContent-Type: text/plain\n[434234 bytes of object data]\nSample Response for general purpose buckets: If an object is archived in the S3 Glacier Flexible\nRetrieval or S3 Glacier Deep Archive storage classes\nIf the object you are retrieving is stored in the S3 Glacier Flexible Retrieval or S3 Glacier Deep\nArchive storage classes, you must first restore a copy using RestoreObject. Otherwise, this action\nreturns an InvalidObjectState error.\nHTTP/1.1 403 Forbidden\nx-amz-request-id: CD4BD8A1310A11B3\nx-amz-id-2: m9RDbQU0+RRBTjOUN1ChQ1eqMUnr9dv8b\n+KP6I2gHfRJZSTSrMCoRP8RtPRzX9mb\nContent-Type: application/xml\nDate: Mon, 12 Nov 2012 23:53:21 GMT\nServer: Amazon S3\nContent-Length: 231\n<Error>\n<Code>InvalidObjectState</Code>\n<Message>The action is not valid for the object's storage class</Message>\n<RequestId>9FEFFF118E15B86F</RequestId>\n<HostId>WVQ5kzhiT+oiUfDCOiOYv8W4Tk9eNcxWi/MK+hTS/av34Xy4rBU3zsavf0aaaaa</\nHostId>\n</Error>\nAmazon S3 API Version 2006-03-01 304",
      "start_idx": 389945,
      "end_idx": 391319,
      "metadata": {
        "num_sentences": 3,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_310",
      "text": "Amazon Simple Storage Service API Reference\nSample Response for general purpose buckets: If an object is archived with the S3 Intelligent-\nTiering Archive or S3 Intelligent-Tiering Deep Archive tiers\nIf the object you are retrieving is stored in the S3 Intelligent-Tiering Archive or S3 Intelligent-\nTiering Deep Archive tiers, you must first restore a copy using RestoreObject. Otherwise, this action\nreturns an InvalidObjectState error. When restoring from Archive Access or Deep Archive\nAccess tiers, the response will include StorageClass and AccessTier elements. Access tier valid\nvalues are ARCHIVE_ACCESS and DEEP_ARCHIVE_ACCESS. There is no syntax change if there is an\nongoing restore.\nHTTP/1.1 403 Forbidden\nx-amz-request-id: CB6AW8C4332B23B7\nx-amz-id-2: n3RRfT90+PJDUhut3nhGW2ehfhfNU5f55c\n+a2ceCC36ab7c7fe3a71Q273b9Q45b1R5\nContent-Type: application/xml\nDate: Mon, 12 Nov 2012 23:53:21 GMT\nServer: Amazon S3\nContent-Length: 231\n<Error>\n<Code>InvalidObjectState</Code>\n<Message>The action is not valid for the object's access tier</Message>\n<StorageClass>INTELLIGENT_TIERING</StorageClass>\n<AccessTier>ARCHIVE_ACCESS</AccessTier>\n<RequestId>9FEFFF118E15B86F</RequestId>\n<HostId>WVQ5kzhiT+oiUfDCOiOYv8W4Tk9eNcxWi/MK+hTS/av34Xy4rBU3zsavf0aaaaa</\nHostId>\n</Error>\nSample Response for general purpose buckets: If the Latest Object Is a Delete Marker\nNotice that the delete marker returns a 404 Not Found error.\nHTTP/1.1 404 Not Found\nx-amz-request-id: 318BC8BC148832E5\nx-amz-id-2: eftixk72aD6Ap51Tnqzj7UDNEHGran\nx-amz-version-id: 3GL4kqtJlcpXroDTDm3vjVBH40Nr8X8g\nx-amz-delete-marker: true\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAmazon S3 API Version 2006-03-01 305",
      "start_idx": 391321,
      "end_idx": 392987,
      "metadata": {
        "num_sentences": 7,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_312",
      "text": "Amazon Simple Storage Service API Reference\nGET /Junk3.txt?response-cache-control=No-cache&response-content-\ndisposition=attachment%3B%20filename%3Dtesting.txt&response-content-encoding=x-\ngzip&response-content-language=mi%2C%20en&response-expires=Thu%2C%2001%20Dec\n%201994%2016:00:00%20GMT HTTP/1.1\nx-amz-date: Sun, 19 Dec 2010 01:53:44 GMT\nAccept: */*\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:aaStE6nKnw8ihhiIdReoXYlMamW=\nSample Response for general purpose buckets: With overridden response header values\nThe following request specifies all the query string parameters in a GET request overriding the\nresponse header values.\nHTTP/1.1 200 OK\nx-amz-id-2: SIidWAK3hK+Il3/\nQqiu1ZKEuegzLAAspwsgwnwygb9GgFseeFHL5CII8NXSrfWW2\nx-amz-request-id: 881B1CBD9DF17WA1\nDate: Sun, 19 Dec 2010 01:54:01 GMT\nx-amz-meta-param1: value 1\nx-amz-meta-param2: value 2\nCache-Control: No-cache\nContent-Language: mi, en\nExpires: Thu, 01 Dec 1994 16:00:00 GMT\nContent-Disposition: attachment; filename=testing.txt\nContent-Encoding: x-gzip\nLast-Modified: Fri, 17 Dec 2010 18:10:41 GMT\nETag: \"0332bee1a7bf845f176c5c0d1ae7cf07\"\nAccept-Ranges: bytes\nContent-Type: text/plain\nContent-Length: 22\nServer: AmazonS3\n[object data not shown]\nSample Request for general purpose buckets: Range header\nThe following request specifies the HTTP Range header to retrieve the first 10 bytes of an\nobject. For more information about the HTTP Range header, see https://www.rfc-editor.org/rfc/\nrfc9110.html#name-range.\nAmazon S3 API Version 2006-03-01 307",
      "start_idx": 394158,
      "end_idx": 395666,
      "metadata": {
        "num_sentences": 4,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_314",
      "text": "Amazon Simple Storage Service API Reference\nSample Request for general purpose buckets: Get an object stored using server-side encryption\nwith customer-provided encryption keys\nIf an object is stored in Amazon S3 using server-side encryption with customer-provided\nencryption keys, Amazon S3 needs encryption information so that it can decrypt the object before\nsending it to you in response to a GET request. You provide the encryption information in your GET\nrequest using the relevant headers, as shown in the following example request.\nGET /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAccept: */*\nAuthorization:authorization string\nDate: Wed, 28 May 2014 19:24:44 +0000\nx-amz-server-side-encryption-customer-\nkey:g0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEKEXAMPLE\nx-amz-server-side-encryption-customer-key-MD5:ZjQrne1X/iTcskbY2m3example\nx-amz-server-side-encryption-customer-algorithm:AES256\nSample Response for general purpose buckets\nThe following sample response shows some of the response headers Amazon S3 returns. Note that\nit includes the encryption information in the response.\nHTTP/1.1 200 OK\nx-amz-id-2: ka5jRm8X3N12ZiY29Z989zg2tNSJPMcK+to7jNjxImXBbyChqc6tLAv\n+sau7Vjzh\nx-amz-request-id: 195157E3E073D3F9\nDate: Wed, 28 May 2014 19:24:45 GMT\nLast-Modified: Wed, 28 May 2014 19:21:01 GMT\nETag: \"c12022c9a3c6d3a28d29d90933a2b096\"\nx-amz-server-side-encryption-customer-algorithm: AES256\nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2m3example\nAmazon S3 API Version 2006-03-01 309",
      "start_idx": 396682,
      "end_idx": 398211,
      "metadata": {
        "num_sentences": 5,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_316",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the access control list (ACL) of an object. To use this operation, you must have\ns3:GetObjectAcl permissions or READ_ACP access to the object. For more information, see\nMapping of ACL permissions and access policy permissions in the Amazon S3 User Guide\nThis functionality is not supported for Amazon S3 on Outposts.\nBy default, GET returns ACL information about the current version of an object. To return ACL\ninformation about a different version, use the versionId subresource.\nNote\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, requests to\nread ACLs are still supported and return the bucket-owner-full-control ACL with the\nowner being the account that created the bucket. For more information, see Controlling\nobject ownership and disabling ACLs in the Amazon S3 User Guide.\nThe following operations are related to GetObjectAcl:\n\u2022 GetObject\n\u2022 GetObjectAttributes\n\u2022 DeleteObject\n\u2022 PutObject\nRequest Syntax\nGET /{Key+}?acl&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nAmazon S3 API Version 2006-03-01 311",
      "start_idx": 398607,
      "end_idx": 399838,
      "metadata": {
        "num_sentences": 9,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_317",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the object for which to get the ACL information.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nRequired: Yes\nKey\nThe key of the object for which to get the ACL information.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nVersion ID used to reference a specific version of the object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 312",
      "start_idx": 399840,
      "end_idx": 401215,
      "metadata": {
        "num_sentences": 14,
        "num_words": 217,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_318",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n<AccessControlList>\n<Grant>\n<Grantee>\n<DisplayName>string</DisplayName>\n<EmailAddress>string</EmailAddress>\n<ID>string</ID>\n<xsi:type>string</xsi:type>\n<URI>string</URI>\n</Grantee>\n<Permission>string</Permission>\n</Grant>\n</AccessControlList>\nAmazon S3 API Version 2006-03-01 313",
      "start_idx": 401217,
      "end_idx": 402333,
      "metadata": {
        "num_sentences": 7,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_323",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectAttributes\nService: Amazon S3\nRetrieves all the metadata from an object without returning the object itself. This operation is\nuseful if you're interested only in an object's metadata.\nGetObjectAttributes combines the functionality of HeadObject and ListParts. All\nof the data returned with each of those individual calls can be returned with a single call to\nGetObjectAttributes.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - To use GetObjectAttributes, you must\nhave READ access to the object. The permissions that you need to use this operation\ndepend on whether the bucket is versioned. If the bucket is versioned, you need both\nthe s3:GetObjectVersion and s3:GetObjectVersionAttributes permissions\nfor this operation. If the bucket is not versioned, you need the s3:GetObject and\ns3:GetObjectAttributes permissions. For more information, see Specifying Permissions\nin a Policy in the Amazon S3 User Guide. If the object that you request does not exist, the\nerror Amazon S3 returns depends on whether you also have the s3:ListBucket permission.\n\u2022 If you have the s3:ListBucket permission on the bucket, Amazon S3 returns an HTTP\nstatus code 404 Not Found (\"no such key\") error.\n\u2022 If you don't have the s3:ListBucket permission, Amazon S3 returns an HTTP status code\n403 Forbidden (\"access denied\") error.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nAmazon S3 API Version 2006-03-01 318",
      "start_idx": 406222,
      "end_idx": 408434,
      "metadata": {
        "num_sentences": 20,
        "num_words": 328,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_324",
      "text": "Amazon Simple Storage Service API Reference\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key.\nEncryption\nNote\nEncryption request headers, like x-amz-server-side-encryption, should not\nbe sent for HEAD requests if your object uses server-side encryption with AWS Key\nManagement Service (AWS KMS) keys (SSE-KMS), dual-layer server-side encryption\nwith AWS KMS keys (DSSE-KMS), or server-side encryption with Amazon S3 managed\nencryption keys (SSE-S3). The x-amz-server-side-encryption header is used when\nyou PUT an object to S3 and want to specify the encryption method. If you include this\nheader in a GET request for an object that uses these types of keys, you\u2019ll get an HTTP\n400 Bad Request error. It's because the encryption method can't be changed when\nyou retrieve the object.\nIf you encrypt an object by using server-side encryption with customer-provided encryption\nkeys (SSE-C) when you store the object in Amazon S3, then when you retrieve the metadata\nfrom the object, you must use the following headers to provide the encryption key for the\nserver to be able to retrieve the object's metadata. The headers are:\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided\nEncryption Keys) in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 319",
      "start_idx": 408436,
      "end_idx": 410379,
      "metadata": {
        "num_sentences": 12,
        "num_words": 284,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_325",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory bucket permissions - For directory buckets, there are only two supported\noptions for server-side encryption: server-side encryption with Amazon S3 managed\nkeys (SSE-S3) (AES256) and server-side encryption with AWS KMS keys (SSE-KMS)\n(aws:kms). We recommend that the bucket's default encryption uses the desired\nencryption configuration and you don't override the bucket default encryption in your\nCreateSession requests or PUT object requests. Then, new objects are automatically\nencrypted with the desired encryption settings. For more information, see Protecting\ndata with server-side encryption in the Amazon S3 User Guide. For more information\nabout the encryption overriding behaviors in directory buckets, see Specifying server-\nside encryption with AWS KMS for new object uploads.\nVersioning\nDirectory buckets - S3 Versioning isn't enabled and supported for directory buckets. For this\nAPI operation, only the null value of the version ID is supported by directory buckets. You can\nonly specify null to the versionId query parameter in the request.\nConditional request headers\nConsider the following when using request headers:\n\u2022 If both of the If-Match and If-Unmodified-Since headers are present in the request as\nfollows, then Amazon S3 returns the HTTP status code 200 OK and the data requested:\n\u2022 If-Match condition evaluates to true.\n\u2022 If-Unmodified-Since condition evaluates to false.\nFor more information about conditional requests, see RFC 7232.\n\u2022 If both of the If-None-Match and If-Modified-Since headers are present in the request\nas follows, then Amazon S3 returns the HTTP status code 304 Not Modified:\n\u2022 If-None-Match condition evaluates to false.\n\u2022 If-Modified-Since condition evaluates to true.\nFor more information about conditional requests, see RFC 7232.\nAmazon S3 API Version 2006-03-01 320",
      "start_idx": 410381,
      "end_idx": 412258,
      "metadata": {
        "num_sentences": 15,
        "num_words": 276,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_327",
      "text": "Amazon Simple Storage Service API Reference\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nThe object key.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID used to reference a specific version of the object.\nAmazon S3 API Version 2006-03-01 322",
      "start_idx": 413407,
      "end_idx": 415208,
      "metadata": {
        "num_sentences": 20,
        "num_words": 274,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_328",
      "text": "Amazon Simple Storage Service API Reference\nNote\nS3 Versioning isn't enabled and supported for directory buckets. For this API operation,\nonly the null value of the version ID is supported by directory buckets. You can only\nspecify null to the versionId query parameter in the request.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-max-parts\nSets the maximum number of parts to return.\nx-amz-object-attributes\nSpecifies the fields at the root level that you want returned in the response. Fields that you do\nnot specify are not returned.\nValid Values: ETag | Checksum | ObjectParts | StorageClass | ObjectSize\nRequired: Yes\nx-amz-part-number-marker\nSpecifies the part after which listing should begin. Only parts with higher part numbers will be\nlisted.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 323",
      "start_idx": 415210,
      "end_idx": 416709,
      "metadata": {
        "num_sentences": 16,
        "num_words": 231,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_329",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded; Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-amz-\nserver-side-encryption-customer-algorithm header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 324",
      "start_idx": 416711,
      "end_idx": 417835,
      "metadata": {
        "num_sentences": 11,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_331",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-delete-marker\nSpecifies whether the object retrieved was (true) or was not (false) a delete marker. If false,\nthis response header does not appear in the response.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-version-id\nThe version ID of the object.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nGetObjectAttributesOutput\nRoot level tag for the GetObjectAttributesOutput parameters.\nRequired: Yes\nChecksum\nThe checksum or digest of the object.\nType: Checksum data type\nAmazon S3 API Version 2006-03-01 326",
      "start_idx": 419042,
      "end_idx": 419894,
      "metadata": {
        "num_sentences": 11,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_332",
      "text": "Amazon Simple Storage Service API Reference\nETag\nAn ETag is an opaque identifier assigned by a web server to a specific version of a resource\nfound at a URL.\nType: String\nObjectParts\nA collection of parts associated with a multipart upload.\nType: GetObjectAttributesParts data type\nObjectSize\nThe size of the object in bytes.\nType: Long\nStorageClass\nProvides the storage class information of the object. Amazon S3 returns this header for all\nobjects except for S3 Standard storage class objects.\nFor more information, see Storage Classes.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by\ndirectory buckets to store objects.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nErrors\nNoSuchKey\nThe specified key does not exist.\nAmazon S3 API Version 2006-03-01 327",
      "start_idx": 419896,
      "end_idx": 420822,
      "metadata": {
        "num_sentences": 9,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_334",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectLegalHold\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets an object's current legal hold status. For more information, see Locking Objects.\nThis functionality is not supported for Amazon S3 on Outposts.\nThe following action is related to GetObjectLegalHold:\n\u2022 GetObjectAttributes\nRequest Syntax\nGET /{Key+}?legal-hold&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object whose legal hold status you want to retrieve.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 329",
      "start_idx": 421240,
      "end_idx": 422589,
      "metadata": {
        "num_sentences": 12,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_335",
      "text": "Amazon Simple Storage Service API Reference\nKey\nThe key name for the object whose legal hold status you want to retrieve.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID of the object whose legal hold status you want to retrieve.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LegalHold>\n<Status>string</Status>\nAmazon S3 API Version 2006-03-01 330",
      "start_idx": 422591,
      "end_idx": 423821,
      "metadata": {
        "num_sentences": 12,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_337",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectLockConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nGets the Object Lock configuration for a bucket. The rule specified in the Object Lock configuration\nwill be applied by default to every new object placed in the specified bucket. For more information,\nsee Locking Objects.\nThe following action is related to GetObjectLockConfiguration:\n\u2022 GetObjectAttributes\nRequest Syntax\nGET /?object-lock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket whose Object Lock configuration you want to retrieve.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 332",
      "start_idx": 424561,
      "end_idx": 425921,
      "metadata": {
        "num_sentences": 12,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_338",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ObjectLockConfiguration>\n<ObjectLockEnabled>string</ObjectLockEnabled>\n<Rule>\n<DefaultRetention>\n<Days>integer</Days>\n<Mode>string</Mode>\n<Years>integer</Years>\n</DefaultRetention>\n</Rule>\n</ObjectLockConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nObjectLockConfiguration\nRoot level tag for the ObjectLockConfiguration parameters.\nRequired: Yes\nObjectLockEnabled\nIndicates whether this bucket has an Object Lock configuration enabled. Enable\nObjectLockEnabled when you apply ObjectLockConfiguration to a bucket.\nType: String\nAmazon S3 API Version 2006-03-01 333",
      "start_idx": 425923,
      "end_idx": 427003,
      "metadata": {
        "num_sentences": 9,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_339",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: Enabled\nRule\nSpecifies the Object Lock rule for the specified object. Enable the this rule when you apply\nObjectLockConfiguration to a bucket. Bucket settings require both a mode and a period.\nThe period can be either Days or Years but you must select one. You cannot specify Days and\nYears at the same time.\nType: ObjectLockRule data type\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 334",
      "start_idx": 427005,
      "end_idx": 427751,
      "metadata": {
        "num_sentences": 6,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_340",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectRetention\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves an object's retention settings. For more information, see Locking Objects.\nThis functionality is not supported for Amazon S3 on Outposts.\nThe following action is related to GetObjectRetention:\n\u2022 GetObjectAttributes\nRequest Syntax\nGET /{Key+}?retention&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object whose retention settings you want to retrieve.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 335",
      "start_idx": 427753,
      "end_idx": 429100,
      "metadata": {
        "num_sentences": 12,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_341",
      "text": "Amazon Simple Storage Service API Reference\nKey\nThe key name for the object whose retention settings you want to retrieve.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID for the object whose retention settings you want to retrieve.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Retention>\n<Mode>string</Mode>\nAmazon S3 API Version 2006-03-01 336",
      "start_idx": 429102,
      "end_idx": 430331,
      "metadata": {
        "num_sentences": 12,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_344",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns the tag-set of an object. You send the GET request against the tagging subresource\nassociated with the object.\nTo use this operation, you must have permission to perform the s3:GetObjectTagging\naction. By default, the GET action returns information about current version of an object. For\na versioned bucket, you can have multiple versions of an object in your bucket. To retrieve\ntags of any other version, use the versionId query parameter. You also need permission for the\ns3:GetObjectVersionTagging action.\nBy default, the bucket owner has this permission and can grant this permission to others.\nFor information about the Amazon S3 object tagging feature, see Object Tagging.\nThe following actions are related to GetObjectTagging:\n\u2022 DeleteObjectTagging\n\u2022 GetObjectAttributes\n\u2022 PutObjectTagging\nRequest Syntax\nGET /{Key+}?tagging&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 339",
      "start_idx": 431290,
      "end_idx": 432519,
      "metadata": {
        "num_sentences": 12,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_345",
      "text": "Amazon Simple Storage Service API Reference\nBucket\nThe bucket name containing the object for which to get the tagging information.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nObject key for which to get the tagging information.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe versionId of the object for which to get the tagging information.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nAmazon S3 API Version 2006-03-01 340",
      "start_idx": 432521,
      "end_idx": 434398,
      "metadata": {
        "num_sentences": 19,
        "num_words": 303,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_346",
      "text": "Amazon Simple Storage Service API Reference\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-version-id: VersionId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging>\n<TagSet>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</TagSet>\n</Tagging>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-version-id\nThe versionId of the object for which you got the tagging information.\nThe following data is returned in XML format by the service.\nAmazon S3 API Version 2006-03-01 341",
      "start_idx": 434400,
      "end_idx": 435356,
      "metadata": {
        "num_sentences": 9,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_349",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectTorrent\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns torrent files from a bucket. BitTorrent can save you bandwidth when you're distributing\nlarge files.\nNote\nYou can get torrent only for objects that are less than 5 GB in size, and that are not\nencrypted using server-side encryption with a customer-provided encryption key.\nTo use GET, you must have READ access to the object.\nThis functionality is not supported for Amazon S3 on Outposts.\nThe following action is related to GetObjectTorrent:\n\u2022 GetObject\nRequest Syntax\nGET /{Key+}?torrent HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the object for which to get the torrent files.\nAmazon S3 API Version 2006-03-01 344",
      "start_idx": 436588,
      "end_idx": 437540,
      "metadata": {
        "num_sentences": 9,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_350",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nKey\nThe object key for which to get the information.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nBody\nAmazon S3 API Version 2006-03-01 345",
      "start_idx": 437542,
      "end_idx": 438644,
      "metadata": {
        "num_sentences": 11,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_353",
      "text": "Amazon Simple Storage Service API Reference\nGetPublicAccessBlock\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRetrieves the PublicAccessBlock configuration for an Amazon S3 bucket. To use this operation,\nyou must have the s3:GetBucketPublicAccessBlock permission. For more information about\nAmazon S3 permissions, see Specifying Permissions in a Policy.\nImportant\nWhen Amazon S3 evaluates the PublicAccessBlock configuration for a bucket or an\nobject, it checks the PublicAccessBlock configuration for both the bucket (or the bucket\nthat contains the object) and the bucket owner's account. If the PublicAccessBlock\nsettings are different between the bucket and the account, Amazon S3 uses the most\nrestrictive combination of the bucket-level and account-level settings.\nFor more information about when Amazon S3 considers a bucket or an object public, see The\nMeaning of \"Public\".\nThe following operations are related to GetPublicAccessBlock:\n\u2022 Using Amazon S3 Block Public Access\n\u2022 PutPublicAccessBlock\n\u2022 GetPublicAccessBlock\n\u2022 DeletePublicAccessBlock\nRequest Syntax\nGET /?publicAccessBlock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 348",
      "start_idx": 440196,
      "end_idx": 441446,
      "metadata": {
        "num_sentences": 8,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_354",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose PublicAccessBlock configuration you want to\nretrieve.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration>\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPublicAccessBlockConfiguration\nRoot level tag for the PublicAccessBlockConfiguration parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 349",
      "start_idx": 441448,
      "end_idx": 442586,
      "metadata": {
        "num_sentences": 9,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_355",
      "text": "Amazon Simple Storage Service API Reference\nBlockPublicAcls\nSpecifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and\nobjects in this bucket. Setting this element to TRUE causes the following behavior:\n\u2022 PUT Bucket ACL and PUT Object ACL calls fail if the specified ACL is public.\n\u2022 PUT Object calls fail if the request includes a public ACL.\n\u2022 PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't affect existing policies or ACLs.\nType: Boolean\nBlockPublicPolicy\nSpecifies whether Amazon S3 should block public bucket policies for this bucket. Setting this\nelement to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket\npolicy allows public access.\nEnabling this setting doesn't affect existing bucket policies.\nType: Boolean\nIgnorePublicAcls\nSpecifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this\nbucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket\nand objects in this bucket.\nEnabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent\nnew public ACLs from being set.\nType: Boolean\nRestrictPublicBuckets\nSpecifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this\nelement to TRUE restricts access to this bucket to only AWS service principals and authorized\nusers within this account if the bucket has a public policy.\nEnabling this setting doesn't affect previously stored bucket policies, except that public and\ncross-account access within any public bucket policy, including non-public delegation to specific\naccounts, is blocked.\nAmazon S3 API Version 2006-03-01 350",
      "start_idx": 442588,
      "end_idx": 444316,
      "metadata": {
        "num_sentences": 15,
        "num_words": 267,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_358",
      "text": "Amazon Simple Storage Service API Reference\nHeadBucket\nService: Amazon S3\nYou can use this operation to determine if a bucket exists and if you have permission to access it.\nThe action returns a 200 OK if the bucket exists and you have permission to access it.\nNote\nIf the bucket does not exist or you do not have permission to access it, the HEAD request\nreturns a generic 400 Bad Request, 403 Forbidden or 404 Not Found code. A\nmessage body is not included, so you cannot determine the exception beyond these HTTP\nresponse codes.\nAuthentication and authorization\nGeneral purpose buckets - Request to public buckets that grant the s3:ListBucket permission\npublicly do not need to be signed. All other HeadBucket requests must be authenticated and\nsigned by using IAM credentials (access key ID and secret access key for the IAM identities). All\nheaders with the x-amz- prefix, including x-amz-copy-source, must be signed. For more\ninformation, see REST Authentication.\nDirectory buckets - You must use IAM credentials to authenticate and authorize your access to\nthe HeadBucket API operation, instead of using the temporary security credentials through the\nCreateSession API operation.\nAWS CLI or SDKs handles authentication and authorization on your behalf.\nPermissions\n\u2022 General purpose bucket permissions - To use this operation, you must have permissions to\nperform the s3:ListBucket action. The bucket owner has this permission by default and\ncan grant this permission to others. For more information about permissions, see Managing\naccess permissions to your Amazon S3 resources in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - You must have the s3express:CreateSession\npermission in the Action element of a policy. By default, the session is in the ReadWrite\nmode. If you want to restrict the access, you can explicitly set the s3express:SessionMode\ncondition key to ReadOnly on the bucket.\nAmazon S3 API Version 2006-03-01 353",
      "start_idx": 445592,
      "end_idx": 447540,
      "metadata": {
        "num_sentences": 17,
        "num_words": 309,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_359",
      "text": "Amazon Simple Storage Service API Reference\nFor more information about example bucket policies, see Example bucket policies for S3\nExpress One Zone and AWS Identity and Access Management (IAM) identity-based policies for\nS3 Express One Zone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nNote\nYou must make requests for this API operation to the Zonal endpoint.\nThese endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com. Path-style\nrequests are not supported. For more information, see Regional and Zonal endpoints in\nthe Amazon S3 User Guide.\nRequest Syntax\nHEAD / HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 354",
      "start_idx": 447542,
      "end_idx": 449021,
      "metadata": {
        "num_sentences": 14,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_360",
      "text": "Amazon Simple Storage Service API Reference\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nObject Lambda access points - When you use this API operation with an Object\nLambda access point, provide the alias of the Object Lambda access point in place of\nthe bucket name. If the Object Lambda access point alias in a request is not valid, the\nerror code InvalidAccessPointAliasError is returned. For more information about\nInvalidAccessPointAliasError, see List of Error Codes.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nAmazon S3 API Version 2006-03-01 355",
      "start_idx": 449023,
      "end_idx": 450951,
      "metadata": {
        "num_sentences": 18,
        "num_words": 312,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_361",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\nx-amz-bucket-location-type: BucketLocationType\nx-amz-bucket-location-name: BucketLocationName\nx-amz-bucket-region: BucketRegion\nx-amz-access-point-alias: AccessPointAlias\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-access-point-alias\nIndicates whether the bucket name used in the request is an access point alias.\nNote\nFor directory buckets, the value of this field is false.\nx-amz-bucket-location-name\nThe name of the location where the bucket will be created.\nFor directory buckets, the AZ ID of the Availability Zone where the bucket is created. An\nexample AZ ID value is usw2-az1.\nNote\nThis functionality is only supported by directory buckets.\nx-amz-bucket-location-type\nThe type of location where the bucket is created.\nNote\nThis functionality is only supported by directory buckets.\nAmazon S3 API Version 2006-03-01 356",
      "start_idx": 450953,
      "end_idx": 451955,
      "metadata": {
        "num_sentences": 11,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_362",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: AvailabilityZone\nx-amz-bucket-region\nThe Region that the bucket is located.\nLength Constraints: Minimum length of 0. Maximum length of 20.\nErrors\nNoSuchBucket\nThe specified bucket does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThis example illustrates one usage of HeadBucket.\nHEAD / HTTP/1.1\nDate: Fri, 10 Feb 2012 21:34:55 GMT\nAuthorization: authorization string\nHost: myawsbucket.s3.amazonaws.com\nConnection: Keep-Alive\nSample Response for general purpose buckets\nThis example illustrates one usage of HeadBucket.\nHTTP/1.1 200 OK\nx-amz-id-2: JuKZqmXuiwFeDQxhD7M8KtsKobSzWA1QEjLbTMTagkKdBX2z7Il/\njGhDeJ3j6s80\nx-amz-request-id: 32FE2CEB32F5EE25\nx-amz-bucket-region: us-west-2\nx-amz-access-point-alias: false\nDate: Fri, 10 2012 21:34:56 GMT\nAmazon S3 API Version 2006-03-01 357",
      "start_idx": 451957,
      "end_idx": 452835,
      "metadata": {
        "num_sentences": 7,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_364",
      "text": "Amazon Simple Storage Service API Reference\nHeadObject\nService: Amazon S3\nThe HEAD operation retrieves metadata from an object without returning the object itself. This\noperation is useful if you're interested only in an object's metadata.\nNote\nA HEAD request has the same options as a GET operation on an object. The response is\nidentical to the GET response except that there is no response body. Because of this, if the\nHEAD request generates an error, it returns a generic code, such as 400 Bad Request,\n403 Forbidden, 404 Not Found, 405 Method Not Allowed, 412 Precondition\nFailed, or 304 Not Modified. It's not possible to retrieve the exact exception of these\nerror codes.\nRequest headers are limited to 8 KB in size. For more information, see Common Request Headers.\nPermissions\n\u2022 General purpose bucket permissions - To use HEAD, you must have the s3:GetObject\npermission. You need the relevant read object (or version) permission for this operation. For\nmore information, see Actions, resources, and condition keys for Amazon S3 in the Amazon S3\nUser Guide. For more information about the permissions to S3 API operations by S3 resource\ntypes, see Required permissions for Amazon S3 API operations in the Amazon S3 User Guide.\nIf the object you request doesn't exist, the error that Amazon S3 returns depends on whether\nyou also have the s3:ListBucket permission.\n\u2022 If you have the s3:ListBucket permission on the bucket, Amazon S3 returns an HTTP\nstatus code 404 Not Found error.\n\u2022 If you don\u2019t have the s3:ListBucket permission, Amazon S3 returns an HTTP status code\n403 Forbidden error.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nAmazon S3 API Version 2006-03-01 359",
      "start_idx": 453248,
      "end_idx": 455317,
      "metadata": {
        "num_sentences": 19,
        "num_words": 337,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_365",
      "text": "Amazon Simple Storage Service API Reference\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nIf you enable x-amz-checksum-mode in the request and the object is encrypted with AWS\nKey Management Service (AWS KMS), you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key to retrieve the checksum of the object.\nEncryption\nNote\nEncryption request headers, like x-amz-server-side-encryption, should not\nbe sent for HEAD requests if your object uses server-side encryption with AWS Key\nManagement Service (AWS KMS) keys (SSE-KMS), dual-layer server-side encryption\nwith AWS KMS keys (DSSE-KMS), or server-side encryption with Amazon S3 managed\nencryption keys (SSE-S3). The x-amz-server-side-encryption header is used when\nyou PUT an object to S3 and want to specify the encryption method. If you include this\nheader in a HEAD request for an object that uses these types of keys, you\u2019ll get an HTTP\n400 Bad Request error. It's because the encryption method can't be changed when\nyou retrieve the object.\nIf you encrypt an object by using server-side encryption with customer-provided encryption\nkeys (SSE-C) when you store the object in Amazon S3, then when you retrieve the metadata\nfrom the object, you must use the following headers to provide the encryption key for the\nserver to be able to retrieve the object's metadata. The headers are:\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information about SSE-C, see Server-Side Encryption (Using Customer-Provided\nEncryption Keys) in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 360",
      "start_idx": 455319,
      "end_idx": 457381,
      "metadata": {
        "num_sentences": 12,
        "num_words": 303,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_366",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory bucket - For directory buckets, there are only two supported options\nfor server-side encryption: SSE-S3 and SSE-KMS. SSE-C isn't supported. For more\ninformation, see Protecting data with server-side encryption in the Amazon S3 User\nGuide.\nVersioning\n\u2022 If the current version of the object is a delete marker, Amazon S3 behaves as if the object was\ndeleted and includes x-amz-delete-marker: true in the response.\n\u2022 If the specified version is a delete marker, the response returns a 405 Method Not\nAllowed error and the Last-Modified: timestamp response header.\nNote\n\u2022 Directory buckets - Delete marker is not supported by directory buckets.\n\u2022 Directory buckets - S3 Versioning isn't enabled and supported for directory buckets.\nFor this API operation, only the null value of the version ID is supported by directory\nbuckets. You can only specify null to the versionId query parameter in the\nrequest.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nNote\nFor directory buckets, you must make requests for this API operation to the Zonal\nendpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 361",
      "start_idx": 457383,
      "end_idx": 458859,
      "metadata": {
        "num_sentences": 15,
        "num_words": 217,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_367",
      "text": "Amazon Simple Storage Service API Reference\nThe following actions are related to HeadObject:\n\u2022 GetObject\n\u2022 GetObjectAttributes\nRequest Syntax\nHEAD /Key+?partNumber=PartNumber&response-cache-control=ResponseCacheControl&response-\ncontent-disposition=ResponseContentDisposition&response-\ncontent-encoding=ResponseContentEncoding&response-content-\nlanguage=ResponseContentLanguage&response-content-type=ResponseContentType&response-\nexpires=ResponseExpires&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nIf-Match: IfMatch\nIf-Modified-Since: IfModifiedSince\nIf-None-Match: IfNoneMatch\nIf-Unmodified-Since: IfUnmodifiedSince\nRange: Range\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-checksum-mode: ChecksumMode\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket that contains the object.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 362",
      "start_idx": 458861,
      "end_idx": 460499,
      "metadata": {
        "num_sentences": 8,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_368",
      "text": "Amazon Simple Storage Service API Reference\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nIf-Match\nReturn the object only if its entity tag (ETag) is the same as the one specified; otherwise, return\na 412 (precondition failed) error.\nIf both of the If-Match and If-Unmodified-Since headers are present in the request as\nfollows:\n\u2022 If-Match condition evaluates to true, and;\n\u2022 If-Unmodified-Since condition evaluates to false;\nThen Amazon S3 returns 200 OK and the data requested.\nFor more information about conditional requests, see RFC 7232.\nIf-Modified-Since\nReturn the object only if it has been modified since the specified time; otherwise, return a 304\n(not modified) error.\nAmazon S3 API Version 2006-03-01 363",
      "start_idx": 460501,
      "end_idx": 462349,
      "metadata": {
        "num_sentences": 16,
        "num_words": 296,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_370",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\npartNumber\nPart number of the object being read. This is a positive integer between 1 and 10,000.\nEffectively performs a 'ranged' HEAD request for the part specified. Useful querying about the\nsize of the part and the number of parts in this object.\nRange\nHeadObject returns only the metadata for an object. If the Range is satisfiable, only the\nContentLength is affected in the response. If the Range is not satisfiable, S3 returns a 416 -\nRequested Range Not Satisfiable error.\nresponse-cache-control\nSets the Cache-Control header of the response.\nresponse-content-disposition\nSets the Content-Disposition header of the response.\nresponse-content-encoding\nSets the Content-Encoding header of the response.\nresponse-content-language\nSets the Content-Language header of the response.\nresponse-content-type\nSets the Content-Type header of the response.\nresponse-expires\nSets the Expires header of the response.\nversionId\nVersion ID used to reference a specific version of the object.\nNote\nFor directory buckets in this API operation, only the null value of the version ID is\nsupported.\nAmazon S3 API Version 2006-03-01 365",
      "start_idx": 463738,
      "end_idx": 464917,
      "metadata": {
        "num_sentences": 16,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_371",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-checksum-mode\nTo retrieve the checksum, this parameter must be enabled.\nGeneral purpose buckets - If you enable checksum mode and the object is uploaded with a\nchecksum and encrypted with an AWS Key Management Service (AWS KMS) key, you must have\npermission to use the kms:Decrypt action to retrieve the checksum.\nDirectory buckets - If you enable ChecksumMode and the object is encrypted with AWS\nKey Management Service (AWS KMS), you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key to retrieve the checksum of the object.\nValid Values: ENABLED\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nAmazon S3 API Version 2006-03-01 366",
      "start_idx": 464919,
      "end_idx": 466548,
      "metadata": {
        "num_sentences": 12,
        "num_words": 246,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_372",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded; Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-amz-\nserver-side-encryption-customer-algorithm header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-delete-marker: DeleteMarker\naccept-ranges: AcceptRanges\nx-amz-expiration: Expiration\nx-amz-restore: Restore\nx-amz-archive-status: ArchiveStatus\nLast-Modified: LastModified\nAmazon S3 API Version 2006-03-01 367",
      "start_idx": 466550,
      "end_idx": 467699,
      "metadata": {
        "num_sentences": 10,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_374",
      "text": "Amazon Simple Storage Service API Reference\nContent-Encoding\nIndicates what content encodings have been applied to the object and thus what decoding\nmechanisms must be applied to obtain the media-type referenced by the Content-Type header\nfield.\nContent-Language\nThe language the content is in.\nContent-Length\nSize of the body in bytes.\nContent-Type\nA standard MIME type describing the format of the object data.\nETag\nAn entity tag (ETag) is an opaque identifier assigned by a web server to a specific version of a\nresource found at a URL.\nExpires\nThe date and time at which the object is no longer cacheable.\nLast-Modified\nDate and time when the object was last modified.\nx-amz-archive-status\nThe archive state of the head object.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ARCHIVE_ACCESS | DEEP_ARCHIVE_ACCESS\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nAmazon S3 API Version 2006-03-01 369",
      "start_idx": 469229,
      "end_idx": 470320,
      "metadata": {
        "num_sentences": 12,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_375",
      "text": "Amazon Simple Storage Service API Reference\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-delete-marker\nSpecifies whether the object retrieved was (true) or was not (false) a Delete Marker. If false, this\nresponse header does not appear in the response.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 370",
      "start_idx": 470322,
      "end_idx": 472485,
      "metadata": {
        "num_sentences": 22,
        "num_words": 345,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_376",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the object expiration is configured (see PutBucketLifecycleConfiguration), the\nresponse includes this header. It includes the expiry-date and rule-id key-value pairs\nproviding object expiration information. The value of the rule-id is URL-encoded.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-missing-meta\nThis is set to the number of metadata entries not returned in x-amz-meta headers. This can\nhappen if you create metadata using an API like SOAP that supports more flexible metadata\nthan the REST API. For example, using SOAP, you can create metadata whose values are not\nlegal HTTP headers.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-mp-parts-count\nThe count of parts this object has. This value is only returned if you specify partNumber in your\nrequest and the object was uploaded as a multipart upload.\nx-amz-object-lock-legal-hold\nSpecifies whether a legal hold is in effect for this object. This header is only returned if the\nrequester has the s3:GetObjectLegalHold permission. This header is not returned if the\nspecified version of this object has never had a legal hold applied. For more information about\nS3 Object Lock, see Object Lock.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nAmazon S3 API Version 2006-03-01 371",
      "start_idx": 472487,
      "end_idx": 473879,
      "metadata": {
        "num_sentences": 16,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_377",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-object-lock-mode\nThe Object Lock mode, if any, that's in effect for this object. This header is only returned if\nthe requester has the s3:GetObjectRetention permission. For more information about S3\nObject Lock, see Object Lock.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when the Object Lock retention period expires. This header is only returned if\nthe requester has the s3:GetObjectRetention permission.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-replication-status\nAmazon S3 can return this header if your request involves a bucket that is either a source or a\ndestination in a replication rule.\nIn replication, you have a source bucket on which you configure replication and destination\nbucket or buckets where Amazon S3 stores object replicas. When you request an object\n(GetObject) or object metadata (HeadObject) from these buckets, Amazon S3 will return the\nx-amz-replication-status header in the response as follows:\n\u2022 If requesting an object from the source bucket, Amazon S3 will return the x-amz-\nreplication-status header if the object in your request is eligible for replication.\nFor example, suppose that in your replication configuration, you specify object prefix\nTaxDocs requesting Amazon S3 to replicate objects with key prefix TaxDocs. Any objects\nyou upload with this key name prefix, for example TaxDocs/document1.pdf, are eligible\nfor replication. For any object request with this key name prefix, Amazon S3 will return the x-\nAmazon S3 API Version 2006-03-01 372",
      "start_idx": 473881,
      "end_idx": 475558,
      "metadata": {
        "num_sentences": 13,
        "num_words": 248,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_378",
      "text": "Amazon Simple Storage Service API Reference\namz-replication-status header with value PENDING, COMPLETED or FAILED indicating\nobject replication status.\n\u2022 If requesting an object from a destination bucket, Amazon S3 will return the x-amz-\nreplication-status header with value REPLICA if the object in your request is a replica\nthat Amazon S3 created and there is no replica modification replication in progress.\n\u2022 When replicating objects to multiple destination buckets, the x-amz-replication-\nstatus header acts differently. The header of the source object will only return a value of\nCOMPLETED when replication is successful to all destinations. The header will remain at value\nPENDING until replication has completed for all destinations. If one or more destinations fails\nreplication the header will return FAILED.\nFor more information, see Replication.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: COMPLETE | PENDING | FAILED | REPLICA | COMPLETED\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-restore\nIf the object is an archived object (an object whose storage class is GLACIER), the response\nincludes this header if either the archive restoration is in progress (see RestoreObject or an\narchive copy is already restored.\nIf an archive copy is already restored, the header value indicates when Amazon S3 is scheduled\nto delete the object copy. For example:\nAmazon S3 API Version 2006-03-01 373",
      "start_idx": 475560,
      "end_idx": 477146,
      "metadata": {
        "num_sentences": 13,
        "num_words": 236,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_379",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-restore: ongoing-request=\"false\", expiry-date=\"Fri, 21 Dec 2012\n00:00:00 GMT\"\nIf the object restoration is in progress, the header returns the value ongoing-\nrequest=\"true\".\nFor more information about archiving objects, see Transitioning Objects: General\nConsiderations.\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone\nstorage class is supported by directory buckets to store objects.\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3 (for\nexample, AES256, aws:kms, aws:kms:dsse).\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the object uses an S3 Bucket Key for server-side encryption with AWS Key\nManagement Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response\nwill include this header to confirm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 374",
      "start_idx": 477148,
      "end_idx": 478456,
      "metadata": {
        "num_sentences": 10,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_380",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the\nresponse will include this header to provide the round-trip message integrity verification of the\ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-storage-class\nProvides storage class information of the object. Amazon S3 returns this header for all objects\nexcept for S3 Standard storage class objects.\nFor more information, see Storage Classes.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by\ndirectory buckets to store objects.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nx-amz-version-id\nVersion ID of the object.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 375",
      "start_idx": 478458,
      "end_idx": 479464,
      "metadata": {
        "num_sentences": 9,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_381",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-website-redirect-location\nIf the bucket is configured as a website, redirects requests for this object to another object in\nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object\nmetadata.\nNote\nThis functionality is not supported for directory buckets.\nErrors\nNoSuchKey\nThe specified key does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets\nThe following request returns the metadata of an object.\nHEAD /my-image.jpg HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0RonhpaBX5sCYVf1bNRuU=\nSample Response for general purpose buckets\nThis example illustrates one usage of HeadObject.\nHTTP/1.1 200 OK\nx-amz-id-2: ef8yU9AS1ed4OpIszj7UDNEHGran\nx-amz-request-id: 318BC8BC143432E5\nx-amz-version-id: 3HL4kqtJlcpXroDTDmjVBH40Nrjfkd\nAmazon S3 API Version 2006-03-01 376",
      "start_idx": 479466,
      "end_idx": 480436,
      "metadata": {
        "num_sentences": 7,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_382",
      "text": "Amazon Simple Storage Service API Reference\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nLast-Modified: Sun, 1 Jan 2006 12:00:00 GMT\nETag: \"fba9dede5f27731c9771645a39863328\"\nContent-Length: 434234\nContent-Type: text/plain\nConnection: close\nServer: AmazonS3\nSample Response for general purpose buckets: With an expiration tag\nIf the object is scheduled to expire according to a lifecycle configuration set on the bucket, the\nresponse returns the x-amz-expiration tag with information about when Amazon S3 will delete\nthe object. For more information, see Transitioning Objects: General Considerations.\nHTTP/1.1 200 OK\nx-amz-id-2: azQRZtQJ2m1P8R+TIsG9h0VuC/DmiSJmjXUMq7snk\n+LKSJeurtmfzSlGhR46GzSJ\nx-amz-request-id: 0EFF61CCE3F24A26\nDate: Mon, 17 Dec 2012 02:26:39 GMT\nLast-Modified: Mon, 17 Dec 2012 02:14:10 GMT\nx-amz-expiration: expiry-date=\"Fri, 21 Dec 2012 00:00:00 GMT\", rule-\nid=\"Rule for testfile.txt\"\nETag: \"54b0c58c7ce9f2a8b551351102ee0938\"\nAccept-Ranges: bytes\nContent-Type: text/plain\nContent-Length: 14\nServer: AmazonS3\nSample Request for general purpose buckets: Getting metadata from a specified version of an\nobject\nThe following request returns the metadata of the specified version of an object.\nHEAD /my-image.jpg?versionId=3HL4kqCxf3vjVBH40Nrjfkd HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0WpaBX5sCYVf1bNRuU=\nAmazon S3 API Version 2006-03-01 377",
      "start_idx": 480438,
      "end_idx": 481881,
      "metadata": {
        "num_sentences": 4,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_383",
      "text": "Amazon Simple Storage Service API Reference\nSample Response for general purpose buckets: To a versioned HEAD request\nThis example illustrates one usage of HeadObject.\nHTTP/1.1 200 OK\nx-amz-id-2: eftixk72aD6Ap51TnqcoF8epIszj7UDNEHGran\nx-amz-request-id: 318BC8BC143432E5\nx-amz-version-id: 3HL4kqtJlcpXrof3vjVBH40Nrjfkd\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nLast-Modified: Sun, 1 Jan 2006 12:00:00 GMT\nETag: \"fba9dede5f27731c9771645a39863328\"\nContent-Length: 434234\nContent-Type: text/plain\nConnection: close\nServer: AmazonS3\nSample Request for general purpose buckets: For an S3 Glacier object\nFor an archived object, the x-amz-restore header provides the date when the restored copy\nexpires, as shown in the following response. Even if the object is stored in S3 Glacier, all object\nmetadata is still available.\nHEAD /my-image.jpg HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: 13 Nov 2012 00:28:38 GMT\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:02236Q3V0RonhpaBX5sCYVf1bNRuU=\nSample Response for general purpose buckets: S3 Glacier object\nIf the object is already restored, the x-amz-restore header provides the date when the restored\ncopy will expire, as shown in the following response.\nHTTP/1.1 200 OK\nx-amz-id-2: FSVaTMjrmBp3Izs1NnwBZeu7M19iI8UbxMbi0A8AirHANJBo\n+hEftBuiESACOMJp\nx-amz-request-id: E5CEFCB143EB505A\nDate: Tue, 13 Nov 2012 00:28:38 GMT\nAmazon S3 API Version 2006-03-01 378",
      "start_idx": 481883,
      "end_idx": 483275,
      "metadata": {
        "num_sentences": 5,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_387",
      "text": "Amazon Simple Storage Service API Reference\nListBucketAnalyticsConfigurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nLists the analytics configurations for the bucket. You can have up to 1,000 analytics configurations\nper bucket.\nThis action supports list pagination and does not return more than 100 configurations at a\ntime. You should always check the IsTruncated element in the response. If there are no more\nconfigurations to list, IsTruncated is set to false. If there are more configurations to list,\nIsTruncated is set to true, and there will be a value in NextContinuationToken. You use the\nNextContinuationToken value to continue the pagination of the list by passing the value in\ncontinuation-token in the request to GET the next page.\nTo use this operation, you must have permissions to perform the\ns3:GetAnalyticsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about Amazon S3 analytics feature, see Amazon S3 Analytics \u2013 Storage Class\nAnalysis.\nThe following operations are related to ListBucketAnalyticsConfigurations:\n\u2022 GetBucketAnalyticsConfiguration\n\u2022 DeleteBucketAnalyticsConfiguration\n\u2022 PutBucketAnalyticsConfiguration\nRequest Syntax\nGET /?analytics&continuation-token=ContinuationToken HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 382",
      "start_idx": 486281,
      "end_idx": 487902,
      "metadata": {
        "num_sentences": 14,
        "num_words": 215,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_388",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket from which analytics configurations are retrieved.\nRequired: Yes\ncontinuation-token\nThe ContinuationToken that represents a placeholder from where this request should begin.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketAnalyticsConfigurationResult>\n<IsTruncated>boolean</IsTruncated>\n<ContinuationToken>string</ContinuationToken>\n<NextContinuationToken>string</NextContinuationToken>\n<AnalyticsConfiguration>\n<Filter>\n<And>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n...\n</And>\n<Prefix>string</Prefix>\n<Tag>\nAmazon S3 API Version 2006-03-01 383",
      "start_idx": 487904,
      "end_idx": 488945,
      "metadata": {
        "num_sentences": 7,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_389",
      "text": "Amazon Simple Storage Service API Reference\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Filter>\n<Id>string</Id>\n<StorageClassAnalysis>\n<DataExport>\n<Destination>\n<S3BucketDestination>\n<Bucket>string</Bucket>\n<BucketAccountId>string</BucketAccountId>\n<Format>string</Format>\n<Prefix>string</Prefix>\n</S3BucketDestination>\n</Destination>\n<OutputSchemaVersion>string</OutputSchemaVersion>\n</DataExport>\n</StorageClassAnalysis>\n</AnalyticsConfiguration>\n...\n</ListBucketAnalyticsConfigurationResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListBucketAnalyticsConfigurationResult\nRoot level tag for the ListBucketAnalyticsConfigurationResult parameters.\nRequired: Yes\nAnalyticsConfiguration\nThe list of analytics configurations for a bucket.\nType: Array of AnalyticsConfiguration data types\nContinuationToken\nThe marker that is used as a starting point for this analytics configuration list response. This\nvalue is present if it was sent in the request.\nType: String\nAmazon S3 API Version 2006-03-01 384",
      "start_idx": 488947,
      "end_idx": 490063,
      "metadata": {
        "num_sentences": 7,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_390",
      "text": "Amazon Simple Storage Service API Reference\nIsTruncated\nIndicates whether the returned list of analytics configurations is complete. A value of true\nindicates that the list is not complete and the NextContinuationToken will be provided for a\nsubsequent request.\nType: Boolean\nNextContinuationToken\nNextContinuationToken is sent when isTruncated is true, which indicates that\nthere are more analytics configurations to list. The next request must include this\nNextContinuationToken. The token is obfuscated and is not a usable value.\nType: String\nExamples\nSample Request\nDelete the metric configuration with a specified ID, which disables the CloudWatch metrics with the\nExampleMetrics value for the FilterId dimension.\nGET /?analytics HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nx-amz-date: 20160430T233541Z\nAuthorization: authorization string\nSample Response\nThis example illustrates one usage of ListBucketAnalyticsConfigurations.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Length: length\nServer: AmazonS3\nAmazon S3 API Version 2006-03-01 385",
      "start_idx": 490065,
      "end_idx": 491250,
      "metadata": {
        "num_sentences": 8,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_392",
      "text": "Amazon Simple Storage Service API Reference\n<Format>CSV</Format>\n<BucketAccountId>123456789012</BucketAccountId>\n<Bucket>arn:aws:s3:::destination-bucket</Bucket>\n<Prefix>destination-prefix</Prefix>\n</S3BucketDestination>\n</Destination>\n</DataExport>\n</StorageClassAnalysis>\n</AnalyticsConfiguration>\n...\n<IsTruncated>false</IsTruncated>\n<!-- If ContinuationToken was provided in the request. -->\n<ContinuationToken>...</ContinuationToken>\n<!-- if IsTruncated == true -->\n<IsTruncated>true</IsTruncated>\n<NextContinuationToken>...</NextContinuationToken>\n</ListBucketAnalyticsConfigurationResult>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 387",
      "start_idx": 492214,
      "end_idx": 493158,
      "metadata": {
        "num_sentences": 2,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_393",
      "text": "Amazon Simple Storage Service API Reference\nListBucketIntelligentTieringConfigurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nLists the S3 Intelligent-Tiering configuration from the specified bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically\nmoving data to the most cost-effective storage access tier, without performance impact or\noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency\nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in\nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing,\nor unpredictable access patterns, independent of object size or retention period. If the size of an\nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering. Smaller objects can\nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering\nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently\naccessed objects.\nOperations related to ListBucketIntelligentTieringConfigurations include:\n\u2022 DeleteBucketIntelligentTieringConfiguration\n\u2022 PutBucketIntelligentTieringConfiguration\n\u2022 GetBucketIntelligentTieringConfiguration\nRequest Syntax\nGET /?intelligent-tiering&continuation-token=ContinuationToken HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 388",
      "start_idx": 493160,
      "end_idx": 494826,
      "metadata": {
        "num_sentences": 11,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_395",
      "text": "Amazon Simple Storage Service API Reference\n...\n</IntelligentTieringConfiguration>\n...\n</ListBucketIntelligentTieringConfigurationsOutput>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListBucketIntelligentTieringConfigurationsOutput\nRoot level tag for the ListBucketIntelligentTieringConfigurationsOutput parameters.\nRequired: Yes\nContinuationToken\nThe ContinuationToken that represents a placeholder from where this request should begin.\nType: String\nIntelligentTieringConfiguration\nThe list of S3 Intelligent-Tiering configurations for a bucket.\nType: Array of IntelligentTieringConfiguration data types\nIsTruncated\nIndicates whether the returned list of analytics configurations is complete. A value of true\nindicates that the list is not complete and the NextContinuationToken will be provided for a\nsubsequent request.\nType: Boolean\nNextContinuationToken\nThe marker used to continue this inventory configuration listing. Use the\nNextContinuationToken from this response to continue the listing in a subsequent request.\nThe continuation token is an opaque value that Amazon S3 understands.\nType: String\nAmazon S3 API Version 2006-03-01 390",
      "start_idx": 495772,
      "end_idx": 497023,
      "metadata": {
        "num_sentences": 11,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_397",
      "text": "Amazon Simple Storage Service API Reference\nListBucketInventoryConfigurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns a list of inventory configurations for the bucket. You can have up to 1,000 analytics\nconfigurations per bucket.\nThis action supports list pagination and does not return more than 100 configurations at a time.\nAlways check the IsTruncated element in the response. If there are no more configurations to\nlist, IsTruncated is set to false. If there are more configurations to list, IsTruncated is set to\ntrue, and there is a value in NextContinuationToken. You use the NextContinuationToken\nvalue to continue the pagination of the list by passing the value in continuation-token in the\nrequest to GET the next page.\nTo use this operation, you must have permissions to perform the\ns3:GetInventoryConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about the Amazon S3 inventory feature, see Amazon S3 Inventory\nThe following operations are related to ListBucketInventoryConfigurations:\n\u2022 GetBucketInventoryConfiguration\n\u2022 DeleteBucketInventoryConfiguration\n\u2022 PutBucketInventoryConfiguration\nRequest Syntax\nGET /?inventory&continuation-token=ContinuationToken HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 392",
      "start_idx": 497419,
      "end_idx": 499010,
      "metadata": {
        "num_sentences": 13,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_398",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the inventory configurations to retrieve.\nRequired: Yes\ncontinuation-token\nThe marker used to continue an inventory configuration listing that has been truncated. Use the\nNextContinuationToken from a previously truncated list response to continue the listing.\nThe continuation token is an opaque value that Amazon S3 understands.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListInventoryConfigurationsResult>\n<ContinuationToken>string</ContinuationToken>\n<InventoryConfiguration>\n<Destination>\n<S3BucketDestination>\n<AccountId>string</AccountId>\n<Bucket>string</Bucket>\n<Encryption>\n<SSE-KMS>\n<KeyId>string</KeyId>\n</SSE-KMS>\n<SSE-S3>\n</SSE-S3>\n</Encryption>\nAmazon S3 API Version 2006-03-01 393",
      "start_idx": 499012,
      "end_idx": 500172,
      "metadata": {
        "num_sentences": 9,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_400",
      "text": "Amazon Simple Storage Service API Reference\nIsTruncated\nTells whether the returned list of inventory configurations is complete. A value of true indicates\nthat the list is not complete and the NextContinuationToken is provided for a subsequent\nrequest.\nType: Boolean\nNextContinuationToken\nThe marker used to continue this inventory configuration listing. Use the\nNextContinuationToken from this response to continue the listing in a subsequent request.\nThe continuation token is an opaque value that Amazon S3 understands.\nType: String\nExamples\nSample Request\nThe following request returns the inventory configurations in example-bucket.\nGET /?inventory HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nx-amz-date: 20160430T233541Z\nAuthorization: authorization string\nContent-Type: text/plain\nSample Response\nDelete the metric configuration with a specified ID, which disables the CloudWatch metrics with the\nExampleMetrics value for the FilterId dimension.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Type: application/xml\nContent-Length: length\nConnection: close\nAmazon S3 API Version 2006-03-01 395",
      "start_idx": 501294,
      "end_idx": 502530,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_403",
      "text": "Amazon Simple Storage Service API Reference\n...\n<IsTruncated>false</IsTruncated>\n<!-- If ContinuationToken was provided in the request. -->\n<ContinuationToken>...</ContinuationToken>\n<!-- if IsTruncated == true -->\n<IsTruncated>true</IsTruncated>\n<NextContinuationToken>...</NextContinuationToken>\n</ListInventoryConfigurationsResult>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 398",
      "start_idx": 504896,
      "end_idx": 505579,
      "metadata": {
        "num_sentences": 2,
        "num_words": 102,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_404",
      "text": "Amazon Simple Storage Service API Reference\nListBucketMetricsConfigurations\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nLists the metrics configurations for the bucket. The metrics configurations are only for the request\nmetrics of the bucket and do not provide information on daily storage metrics. You can have up to\n1,000 configurations per bucket.\nThis action supports list pagination and does not return more than 100 configurations at a time.\nAlways check the IsTruncated element in the response. If there are no more configurations to\nlist, IsTruncated is set to false. If there are more configurations to list, IsTruncated is set to\ntrue, and there is a value in NextContinuationToken. You use the NextContinuationToken\nvalue to continue the pagination of the list by passing the value in continuation-token in the\nrequest to GET the next page.\nTo use this operation, you must have permissions to perform the\ns3:GetMetricsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor more information about metrics configurations and CloudWatch request metrics, see\nMonitoring Metrics with Amazon CloudWatch.\nThe following operations are related to ListBucketMetricsConfigurations:\n\u2022 PutBucketMetricsConfiguration\n\u2022 GetBucketMetricsConfiguration\n\u2022 DeleteBucketMetricsConfiguration\nRequest Syntax\nGET /?metrics&continuation-token=ContinuationToken HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nAmazon S3 API Version 2006-03-01 399",
      "start_idx": 505581,
      "end_idx": 507270,
      "metadata": {
        "num_sentences": 15,
        "num_words": 231,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_405",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the metrics configurations to retrieve.\nRequired: Yes\ncontinuation-token\nThe marker that is used to continue a metrics configuration listing that has been truncated.\nUse the NextContinuationToken from a previously truncated list response to continue the\nlisting. The continuation token is an opaque value that Amazon S3 understands.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMetricsConfigurationsResult>\n<IsTruncated>boolean</IsTruncated>\n<ContinuationToken>string</ContinuationToken>\n<NextContinuationToken>string</NextContinuationToken>\n<MetricsConfiguration>\n<Filter>\n<AccessPointArn>string</AccessPointArn>\n<And>\n<AccessPointArn>string</AccessPointArn>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\nAmazon S3 API Version 2006-03-01 400",
      "start_idx": 507272,
      "end_idx": 508533,
      "metadata": {
        "num_sentences": 9,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_406",
      "text": "Amazon Simple Storage Service API Reference\n<Value>string</Value>\n</Tag>\n...\n</And>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Filter>\n<Id>string</Id>\n</MetricsConfiguration>\n...\n</ListMetricsConfigurationsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListMetricsConfigurationsResult\nRoot level tag for the ListMetricsConfigurationsResult parameters.\nRequired: Yes\nContinuationToken\nThe marker that is used as a starting point for this metrics configuration list response. This\nvalue is present if it was sent in the request.\nType: String\nIsTruncated\nIndicates whether the returned list of metrics configurations is complete. A value of true\nindicates that the list is not complete and the NextContinuationToken will be provided for a\nsubsequent request.\nType: Boolean\nMetricsConfiguration\nThe list of metrics configurations for a bucket.\nAmazon S3 API Version 2006-03-01 401",
      "start_idx": 508535,
      "end_idx": 509561,
      "metadata": {
        "num_sentences": 9,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_407",
      "text": "Amazon Simple Storage Service API Reference\nType: Array of MetricsConfiguration data types\nNextContinuationToken\nThe marker used to continue a metrics configuration listing that has been truncated. Use the\nNextContinuationToken from a previously truncated list response to continue the listing.\nThe continuation token is an opaque value that Amazon S3 understands.\nType: String\nExamples\nSample Request\nDelete the metric configuration with a specified ID, which disables the CloudWatch metrics with the\nExampleMetrics value for the FilterId dimension.\nGET /?metrics HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Thu, 15 Nov 2016 00:17:21 GMT\nAuthorization: signatureValue\nSample Response\nDelete the metric configuration with a specified ID, which disables the CloudWatch metrics with the\nExampleMetrics value for the FilterId dimension.\nHTTP/1.1 200 OK\nx-amz-id-2: ITnGT1y4REXAMPLEPi4hklTXouTf0hccUjo0iCPEXAMPLEutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991EXAMPLE5321\nDate: Thu, 15 Nov 2016 00:17:22 GMT\nServer: AmazonS3\nContent-Length: 758\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMetricsConfigurationsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<MetricsConfiguration>\n<Id>EntireBucket</Id>\n</MetricsConfiguration>\nAmazon S3 API Version 2006-03-01 402",
      "start_idx": 509563,
      "end_idx": 510847,
      "metadata": {
        "num_sentences": 6,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_409",
      "text": "Amazon Simple Storage Service API Reference\nListBuckets\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns a list of all buckets owned by the authenticated sender of the request. To use this\noperation, you must have the s3:ListAllMyBuckets permission.\nFor information about Amazon S3 buckets, see Creating, configuring, and working with Amazon S3\nbuckets.\nRequest Syntax\nGET /?bucket-region=BucketRegion&continuation-token=ContinuationToken&max-\nbuckets=MaxBuckets&prefix=Prefix HTTP/1.1\nHost: s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nbucket-region\nLimits the response to buckets that are located in the specified AWS Region. The AWS Region\nmust be expressed according to the AWS Region code, such as us-west-2 for the US West\n(Oregon) Region. For a list of the valid values for all of the AWS Regions, see Regions and\nEndpoints.\nNote\nRequests made to a Regional endpoint that is different from the bucket-region\nparameter are not supported. For example, if you want to limit the response to your\nbuckets in Region us-west-2, the request must be made to an endpoint in Region us-\nwest-2.\nAmazon S3 API Version 2006-03-01 404",
      "start_idx": 511604,
      "end_idx": 512809,
      "metadata": {
        "num_sentences": 11,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_410",
      "text": "Amazon Simple Storage Service API Reference\ncontinuation-token\nContinuationToken indicates to Amazon S3 that the list is being continued on this bucket\nwith a token. ContinuationToken is obfuscated and is not a real key. You can use this\nContinuationToken for pagination of the list results.\nLength Constraints: Minimum length of 0. Maximum length of 1024.\nRequired: No.\nmax-buckets\nMaximum number of buckets to be returned in response. When the number is more than the\ncount of buckets that are owned by an AWS account, return all the buckets in response.\nValid Range: Minimum value of 1. Maximum value of 1000.\nprefix\nLimits the response to bucket names that begin with the specified bucket name prefix.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAllMyBucketsResult>\n<Buckets>\n<Bucket>\n<BucketRegion>string</BucketRegion>\n<CreationDate>timestamp</CreationDate>\n<Name>string</Name>\n</Bucket>\n</Buckets>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n<ContinuationToken>string</ContinuationToken>\n<Prefix>string</Prefix>\n</ListAllMyBucketsResult>\nAmazon S3 API Version 2006-03-01 405",
      "start_idx": 512811,
      "end_idx": 513999,
      "metadata": {
        "num_sentences": 12,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_411",
      "text": "Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListAllMyBucketsResult\nRoot level tag for the ListAllMyBucketsResult parameters.\nRequired: Yes\nBuckets\nThe list of buckets owned by the requester.\nType: Array of Bucket data types\nContinuationToken\nContinuationToken is included in the response when there are more buckets that can be\nlisted with pagination. The next ListBuckets request to Amazon S3 can be continued with\nthis ContinuationToken. ContinuationToken is obfuscated and is not a real bucket.\nType: String\nOwner\nThe owner of the buckets listed.\nType: Owner data type\nPrefix\nIf Prefix was sent with the request, it is included in the response.\nAll bucket names in the response begin with the specified bucket name prefix.\nType: String\nExamples\nSample Request\nThe following request returns a list of all buckets of the sender.\nAmazon S3 API Version 2006-03-01 406",
      "start_idx": 514001,
      "end_idx": 515020,
      "metadata": {
        "num_sentences": 12,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_413",
      "text": "Amazon Simple Storage Service API Reference\nListDirectoryBuckets\nService: Amazon S3\nReturns a list of all Amazon S3 directory buckets owned by the authenticated sender of the\nrequest. For more information about directory buckets, see Directory buckets in the Amazon S3\nUser Guide.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\nYou must have the s3express:ListAllMyDirectoryBuckets permission in an IAM\nidentity-based policy instead of a bucket policy. Cross-account access to this API operation isn't\nsupported. This operation can only be performed by the AWS account that owns the resource.\nFor more information about directory bucket policies and permissions, see AWS Identity and\nAccess Management (IAM) for S3 Express One Zone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nRequest Syntax\nGET /?continuation-token=ContinuationToken&max-directory-buckets=MaxDirectoryBuckets\nHTTP/1.1\nHost: s3.amazonaws.com\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 408",
      "start_idx": 515805,
      "end_idx": 517261,
      "metadata": {
        "num_sentences": 13,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_414",
      "text": "Amazon Simple Storage Service API Reference\ncontinuation-token\nContinuationToken indicates to Amazon S3 that the list is being continued on buckets in this\naccount with a token. ContinuationToken is obfuscated and is not a real bucket name. You\ncan use this ContinuationToken for the pagination of the list results.\nLength Constraints: Minimum length of 0. Maximum length of 1024.\nmax-directory-buckets\nMaximum number of buckets to be returned in response. When the number is more than the\ncount of buckets that are owned by an AWS account, return all the buckets in response.\nValid Range: Minimum value of 0. Maximum value of 1000.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListDirectoryBucketsOutput>\n<Buckets>\n<Bucket>\n<BucketRegion>string</BucketRegion>\n<CreationDate>timestamp</CreationDate>\n<Name>string</Name>\n</Bucket>\n</Buckets>\n<ContinuationToken>string</ContinuationToken>\n</ListDirectoryBucketsOutput>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListDirectoryBucketsOutput\nRoot level tag for the ListDirectoryBucketsOutput parameters.\nAmazon S3 API Version 2006-03-01 409",
      "start_idx": 517263,
      "end_idx": 518537,
      "metadata": {
        "num_sentences": 13,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_415",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nBuckets\nThe list of buckets owned by the requester.\nType: Array of Bucket data types\nContinuationToken\nIf ContinuationToken was sent with the request, it is included in the response. You can use\nthe returned ContinuationToken for pagination of the list response.\nType: String\nLength Constraints: Minimum length of 0. Maximum length of 1024.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 410",
      "start_idx": 518539,
      "end_idx": 519286,
      "metadata": {
        "num_sentences": 6,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_416",
      "text": "Amazon Simple Storage Service API Reference\nListMultipartUploads\nService: Amazon S3\nThis operation lists in-progress multipart uploads in a bucket. An in-progress multipart upload is\na multipart upload that has been initiated by the CreateMultipartUpload request, but has not\nyet been completed or aborted.\nNote\nDirectory buckets - If multipart uploads in a directory bucket are in progress, you can't\ndelete the bucket until all the in-progress multipart uploads are aborted or completed. To\ndelete these in-progress multipart uploads, use the ListMultipartUploads operation to\nlist the in-progress multipart uploads in the bucket and use the AbortMultipartUpload\noperation to abort all the in-progress multipart uploads.\nThe ListMultipartUploads operation returns a maximum of 1,000 multipart uploads in the\nresponse. The limit of 1,000 multipart uploads is also the default value. You can further limit the\nnumber of uploads in a response by specifying the max-uploads request parameter. If there\nare more than 1,000 multipart uploads that satisfy your ListMultipartUploads request,\nthe response returns an IsTruncated element with the value of true, a NextKeyMarker\nelement, and a NextUploadIdMarker element. To list the remaining multipart uploads, you\nneed to make subsequent ListMultipartUploads requests. In these requests, include two\nquery parameters: key-marker and upload-id-marker. Set the value of key-marker to the\nNextKeyMarker value from the previous response. Similarly, set the value of upload-id-marker\nto the NextUploadIdMarker value from the previous response.\nNote\nDirectory buckets - The upload-id-marker element and the NextUploadIdMarker\nelement aren't supported by directory buckets. To list the additional multipart uploads, you\nonly need to set the value of key-marker to the NextKeyMarker value from the previous\nresponse.\nFor more information about multipart uploads, see Uploading Objects Using Multipart Upload in\nthe Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 411",
      "start_idx": 519288,
      "end_idx": 521297,
      "metadata": {
        "num_sentences": 16,
        "num_words": 288,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_417",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - For information about permissions required to use the\nmultipart upload API, see Multipart Upload and Permissions in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nSorting of multipart uploads in response\n\u2022 General purpose bucket - In the ListMultipartUploads response, the multipart uploads\nare sorted based on two criteria:\n\u2022 Key-based sorting - Multipart uploads are initially sorted in ascending order based on their\nobject keys.\n\u2022 Time-based sorting - For uploads that share the same object key, they are further sorted in\nascending order based on the upload initiation time. Among uploads with the same key, the\none that was initiated first will appear before the ones that were initiated later.\n\u2022 Directory bucket - In the ListMultipartUploads response, the multipart uploads aren't\nsorted lexicographically based on the object keys.\nAmazon S3 API Version 2006-03-01 412",
      "start_idx": 521299,
      "end_idx": 523429,
      "metadata": {
        "num_sentences": 17,
        "num_words": 319,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_418",
      "text": "Amazon Simple Storage Service API Reference\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to ListMultipartUploads:\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\n\u2022 CompleteMultipartUpload\n\u2022 ListParts\n\u2022 AbortMultipartUpload\nRequest Syntax\nGET /?uploads&delimiter=Delimiter&encoding-type=EncodingType&key-marker=KeyMarker&max-\nuploads=MaxUploads&prefix=Prefix&upload-id-marker=UploadIdMarker HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to which the multipart upload was initiated.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\nAmazon S3 API Version 2006-03-01 413",
      "start_idx": 523431,
      "end_idx": 524944,
      "metadata": {
        "num_sentences": 10,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_419",
      "text": "Amazon Simple Storage Service API Reference\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\ndelimiter\nCharacter you use to group keys.\nAll keys that contain the same string between the prefix, if specified, and the first occurrence\nof the delimiter after the prefix are grouped under a single result element, CommonPrefixes.\nIf you don't specify the prefix parameter, then the substring starts at the beginning of the key.\nThe keys that are grouped under CommonPrefixes result element are not returned elsewhere\nin the response.\nNote\nDirectory buckets - For directory buckets, / is the only supported delimiter.\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response. Responses are\nencoded only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0\nAmazon S3 API Version 2006-03-01 414",
      "start_idx": 524946,
      "end_idx": 526727,
      "metadata": {
        "num_sentences": 19,
        "num_words": 283,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_420",
      "text": "Amazon Simple Storage Service API Reference\nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10. For\ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon\nS3 encode the keys in the response. For more information about characters to avoid in object\nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's\nkey name will be percent-encoded according to UTF-8 code values. For example, the\nobject test_file(3).png will appear as test_file%283%29.png.\nValid Values: url\nkey-marker\nSpecifies the multipart upload after which listing should begin.\nNote\n\u2022 General purpose buckets - For general purpose buckets, key-marker is an object\nkey. Together with upload-id-marker, this parameter specifies the multipart\nupload after which listing should begin.\nIf upload-id-marker is not specified, only the keys lexicographically greater than\nthe specified key-marker will be included in the list.\nIf upload-id-marker is specified, any multipart uploads for a key equal to the key-\nmarker might also be included, provided those multipart uploads have upload IDs\nlexicographically greater than the specified upload-id-marker.\n\u2022 Directory buckets - For directory buckets, key-marker is obfuscated and isn't a\nreal object key. The upload-id-marker parameter isn't supported by directory\nbuckets. To list the additional multipart uploads, you only need to set the value of\nkey-marker to the NextKeyMarker value from the previous response.\nIn the ListMultipartUploads response, the multipart uploads aren't sorted\nlexicographically based on the object keys.\nAmazon S3 API Version 2006-03-01 415",
      "start_idx": 526729,
      "end_idx": 528460,
      "metadata": {
        "num_sentences": 15,
        "num_words": 258,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_421",
      "text": "Amazon Simple Storage Service API Reference\nmax-uploads\nSets the maximum number of multipart uploads, from 1 to 1,000, to return in the response\nbody. 1,000 is the maximum number of uploads that can be returned in a response.\nprefix\nLists in-progress uploads only for those keys that begin with the specified prefix. You can use\nprefixes to separate a bucket into different grouping of keys. (You can think of using prefix to\nmake groups in the same way that you'd use a folder in a file system.)\nNote\nDirectory buckets - For directory buckets, only prefixes that end in a delimiter (/) are\nsupported.\nupload-id-marker\nTogether with key-marker, specifies the multipart upload after which listing should begin.\nIf key-marker is not specified, the upload-id-marker parameter is ignored. Otherwise, any\nmultipart uploads for a key equal to the key-marker might be included in the list only if they\nhave an upload ID lexicographically greater than the specified upload-id-marker.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nAmazon S3 API Version 2006-03-01 416",
      "start_idx": 528462,
      "end_idx": 530061,
      "metadata": {
        "num_sentences": 15,
        "num_words": 254,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_422",
      "text": "Amazon Simple Storage Service API Reference\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultipartUploadsResult>\n<Bucket>string</Bucket>\n<KeyMarker>string</KeyMarker>\n<UploadIdMarker>string</UploadIdMarker>\n<NextKeyMarker>string</NextKeyMarker>\n<Prefix>string</Prefix>\n<Delimiter>string</Delimiter>\n<NextUploadIdMarker>string</NextUploadIdMarker>\n<MaxUploads>integer</MaxUploads>\n<IsTruncated>boolean</IsTruncated>\n<Upload>\n<ChecksumAlgorithm>string</ChecksumAlgorithm>\n<Initiated>timestamp</Initiated>\n<Initiator>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Initiator>\n<Key>string</Key>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n<StorageClass>string</StorageClass>\nAmazon S3 API Version 2006-03-01 417",
      "start_idx": 530063,
      "end_idx": 531169,
      "metadata": {
        "num_sentences": 5,
        "num_words": 90,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_423",
      "text": "Amazon Simple Storage Service API Reference\n<UploadId>string</UploadId>\n</Upload>\n...\n<CommonPrefixes>\n<Prefix>string</Prefix>\n</CommonPrefixes>\n...\n<EncodingType>string</EncodingType>\n</ListMultipartUploadsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nListMultipartUploadsResult\nRoot level tag for the ListMultipartUploadsResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket to which the multipart upload was initiated. Does not return the access\npoint ARN or access point alias if used.\nType: String\nAmazon S3 API Version 2006-03-01 418",
      "start_idx": 531171,
      "end_idx": 532076,
      "metadata": {
        "num_sentences": 9,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_424",
      "text": "Amazon Simple Storage Service API Reference\nCommonPrefixes\nIf you specify a delimiter in the request, then the result returns each distinct key prefix\ncontaining the delimiter in a CommonPrefixes element. The distinct key prefixes are returned\nin the Prefix child element.\nNote\nDirectory buckets - For directory buckets, only prefixes that end in a delimiter (/) are\nsupported.\nType: Array of CommonPrefix data types\nDelimiter\nContains the delimiter you specified in the request. If you don't specify a delimiter in your\nrequest, this element is absent from the response.\nNote\nDirectory buckets - For directory buckets, / is the only supported delimiter.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode object keys in the response.\nIf you specify the encoding-type request parameter, Amazon S3 includes this element in the\nresponse, and returns encoded key name values in the following response elements:\nDelimiter, KeyMarker, Prefix, NextKeyMarker, Key.\nType: String\nValid Values: url\nIsTruncated\nIndicates whether the returned list of multipart uploads is truncated. A value of true indicates\nthat the list was truncated. The list can be truncated if the number of multipart uploads exceeds\nthe limit allowed or specified by max uploads.\nAmazon S3 API Version 2006-03-01 419",
      "start_idx": 532078,
      "end_idx": 533374,
      "metadata": {
        "num_sentences": 12,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_425",
      "text": "Amazon Simple Storage Service API Reference\nType: Boolean\nKeyMarker\nThe key at or after which the listing began.\nType: String\nMaxUploads\nMaximum number of multipart uploads that could have been included in the response.\nType: Integer\nNextKeyMarker\nWhen a list is truncated, this element specifies the value that should be used for the key-marker\nrequest parameter in a subsequent request.\nType: String\nNextUploadIdMarker\nWhen a list is truncated, this element specifies the value that should be used for the upload-\nid-marker request parameter in a subsequent request.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nPrefix\nWhen a prefix is provided in the request, this field contains the specified prefix. The result\ncontains only keys starting with the specified prefix.\nNote\nDirectory buckets - For directory buckets, only prefixes that end in a delimiter (/) are\nsupported.\nType: String\nAmazon S3 API Version 2006-03-01 420",
      "start_idx": 533376,
      "end_idx": 534333,
      "metadata": {
        "num_sentences": 9,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_426",
      "text": "Amazon Simple Storage Service API Reference\nUpload\nContainer for elements related to a particular multipart upload. A response can contain zero or\nmore Upload elements.\nType: Array of MultipartUpload data types\nUploadIdMarker\nTogether with key-marker, specifies the multipart upload after which listing should begin.\nIf key-marker is not specified, the upload-id-marker parameter is ignored. Otherwise, any\nmultipart uploads for a key equal to the key-marker might be included in the list only if they\nhave an upload ID lexicographically greater than the specified upload-id-marker.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nExamples\nSample Request for general purpose buckets\nThe following request lists three multipart uploads. The request specifies the max-uploads\nrequest parameter to set the maximum number of multipart uploads to return in the response\nbody.\nGET /?uploads&max-uploads=3 HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string\nSample Response for general purpose buckets\nThe following sample response indicates that the multipart upload list was truncated and provides\nthe NextKeyMarker and the NextUploadIdMarker elements. You specify these values in\nyour subsequent requests to read the next set of multipart uploads. That is, send a subsequent\nAmazon S3 API Version 2006-03-01 421",
      "start_idx": 534335,
      "end_idx": 535746,
      "metadata": {
        "num_sentences": 11,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_427",
      "text": "Amazon Simple Storage Service API Reference\nrequest specifying key-marker=my-movie2.m2ts (value of the NextKeyMarker element) and\nupload-id-marker=YW55IGlkZWEgd2h5IGVsdmluZydzIHVwbG9hZCBmYWlsZWQ (value of the\nNextUploadIdMarker).\nThe sample response also shows a case of two multipart uploads in progress with the same key\n(my-movie.m2ts). That is, the response shows two uploads with the same key. This response\nshows the uploads sorted by key, and within each key the uploads are sorted in ascending order by\nthe time the multipart upload was initiated.\nHTTP/1.1 200 OK\nx-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nContent-Length: 1330\nConnection: keep-alive\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultipartUploadsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Bucket>bucket</Bucket>\n<KeyMarker></KeyMarker>\n<UploadIdMarker></UploadIdMarker>\n<NextKeyMarker>my-movie.m2ts</NextKeyMarker>\n<NextUploadIdMarker>YW55IGlkZWEgd2h5IGVsdmluZydzIHVwbG9hZCBmYWlsZWQ</\nNextUploadIdMarker>\n<MaxUploads>3</MaxUploads>\n<IsTruncated>true</IsTruncated>\n<Upload>\n<Key>my-divisor</Key>\n<UploadId>XMgbGlrZSBlbHZpbmcncyBub3QgaGF2aW5nIG11Y2ggbHVjaw</UploadId>\n<Initiator>\n<ID>arn:aws:iam::111122223333:user/user1-11111a31-17b5-4fb7-9df5-b111111f13de</\nID>\n<DisplayName>user1-11111a31-17b5-4fb7-9df5-b111111f13de</DisplayName>\n</Initiator>\n<Owner>\n<ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>\n<DisplayName>OwnerDisplayName</DisplayName>\n</Owner>\n<StorageClass>STANDARD</StorageClass>\n<Initiated>2010-11-10T20:48:33.000Z</Initiated>\n</Upload>\nAmazon S3 API Version 2006-03-01 422",
      "start_idx": 535748,
      "end_idx": 537476,
      "metadata": {
        "num_sentences": 5,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_429",
      "text": "Amazon Simple Storage Service API Reference\nThe following list multipart upload request specifies the delimiter parameter with value \"/\".\nGET /?uploads&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string\nSample Response for general purpose buckets\nThe following sample response lists multipart uploads on the specified bucket, example-bucket.\nThe response returns multipart upload for the sample.jpg key in an <Upload> element.\nHowever, because all the other keys contain the specified delimiter, a distinct substring, from\nthe beginning of the key to the first occurrence of the delimiter, from each of these keys is\nreturned in a <CommonPrefixes> element. The key substrings, photos/ and videos/ in the\n<CommonPrefixes> element, indicate that there are one or more in-progress multipart uploads\nwith these key prefixes.\nThis is a useful scenario if you use key prefixes for your objects to create a logical folder like\nstructure. In this case, you can interpret the result as the folders photos/ and videos/ have one\nor more multipart uploads in progress.\n<ListMultipartUploadsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Bucket>example-bucket</Bucket>\n<KeyMarker/>\n<UploadIdMarker/>\n<NextKeyMarker>sample.jpg</NextKeyMarker>\n<NextUploadIdMarker>Xgw4MJT6ZPAVxpY0SAuGN7q4uWJJM22ZYg1W99trdp4tpO88.PT6.MhO0w2E17eutfAvQfQWoajgE_W2gpcxQw--\n</NextUploadIdMarker>\n<Delimiter>/</Delimiter>\n<Prefix/>\n<MaxUploads>1000</MaxUploads>\n<IsTruncated>false</IsTruncated>\n<Upload>\n<Key>sample.jpg</Key>\nAmazon S3 API Version 2006-03-01 424",
      "start_idx": 538834,
      "end_idx": 540457,
      "metadata": {
        "num_sentences": 8,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_430",
      "text": "Amazon Simple Storage Service API Reference\n<UploadId>Agw4MJT6ZPAVxpY0SAuGN7q4uWJJM22ZYg1N99trdp4tpO88.PT6.MhO0w2E17eutfAvQfQWoajgE_W2gpcxQw--\n</UploadId>\n<Initiator>\n<ID>314133b66967d86f031c7249d1d9a80249109428335cd0ef1cdc487b4566cb1b</ID>\n<DisplayName>string</DisplayName>\n</Initiator>\n<Owner>\n<ID>314133b66967d86f031c7249d1d9a80249109428335cd0ef1cdc487b4566cb1b</ID>\n<DisplayName>string</DisplayName>\n</Owner>\n<StorageClass>STANDARD</StorageClass>\n<Initiated>2010-11-26T19:24:17.000Z</Initiated>\n</Upload>\n<CommonPrefixes>\n<Prefix>photos/</Prefix>\n</CommonPrefixes>\n<CommonPrefixes>\n<Prefix>videos/</Prefix>\n</CommonPrefixes>\n</ListMultipartUploadsResult>\nSample Request for general purpose buckets\nIn addition to the delimiter parameter, you can filter results by adding a prefix parameter as shown\nin the following request.\nGET /?uploads&delimiter=/&prefix=photos/2006/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string\nSample Response for general purpose buckets\nIn this case, the response will include only multipart uploads for keys that start with the specified\nprefix. The value returned in the <CommonPrefixes> element is a substring from the beginning of\nthe key to the first occurrence of the specified delimiter after the prefix.\nAmazon S3 API Version 2006-03-01 425",
      "start_idx": 540459,
      "end_idx": 541816,
      "metadata": {
        "num_sentences": 4,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_432",
      "text": "Amazon Simple Storage Service API Reference\nListObjects\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns some or all (up to 1,000) of the objects in a bucket. You can use the request parameters as\nselection criteria to return a subset of the objects in a bucket. A 200 OK response can contain valid\nor invalid XML. Be sure to design your application to parse the contents of the response and handle\nit appropriately.\nImportant\nThis action has been revised. We recommend that you use the newer version,\nListObjectsV2, when developing applications. For backward compatibility, Amazon S3\ncontinues to support ListObjects.\nThe following operations are related to ListObjects:\n\u2022 ListObjectsV2\n\u2022 GetObject\n\u2022 PutObject\n\u2022 CreateBucket\n\u2022 ListBuckets\nRequest Syntax\nGET /?delimiter=Delimiter&encoding-type=EncodingType&marker=Marker&max-\nkeys=MaxKeys&prefix=Prefix HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-optional-object-attributes: OptionalObjectAttributes\nAmazon S3 API Version 2006-03-01 427",
      "start_idx": 542796,
      "end_idx": 543905,
      "metadata": {
        "num_sentences": 9,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_433",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket containing the objects.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\ndelimiter\nA delimiter is a character that you use to group keys.\nAmazon S3 API Version 2006-03-01 428",
      "start_idx": 543907,
      "end_idx": 545875,
      "metadata": {
        "num_sentences": 20,
        "num_words": 300,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_434",
      "text": "Amazon Simple Storage Service API Reference\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response. Responses are\nencoded only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0\nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10. For\ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon\nS3 encode the keys in the response. For more information about characters to avoid in object\nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's\nkey name will be percent-encoded according to UTF-8 code values. For example, the\nobject test_file(3).png will appear as test_file%283%29.png.\nValid Values: url\nmarker\nMarker is where you want Amazon S3 to start listing from. Amazon S3 starts listing after this\nspecified key. Marker can be any key in the bucket.\nmax-keys\nSets the maximum number of keys returned in the response. By default, the action returns up to\n1,000 key names. The response might contain fewer keys but will never contain more.\nprefix\nLimits the response to keys that begin with the specified prefix.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-optional-object-attributes\nSpecifies the optional fields that you want returned in the response. Fields that you do not\nspecify are not returned.\nAmazon S3 API Version 2006-03-01 429",
      "start_idx": 545877,
      "end_idx": 547528,
      "metadata": {
        "num_sentences": 20,
        "num_words": 268,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_437",
      "text": "Amazon Simple Storage Service API Reference\nCommonPrefixes lists keys that act like subdirectories in the directory specified by Prefix.\nFor example, if the prefix is notes/ and the delimiter is a slash (/), as in notes/summer/july,\nthe common prefix is notes/summer/. All of the keys that roll up into a common prefix count\nas a single return when calculating the number of returns.\nType: Array of CommonPrefix data types\nContents\nMetadata about each object returned.\nType: Array of Object data types\nDelimiter\nCauses keys that contain the same string between the prefix and the first occurrence of the\ndelimiter to be rolled up into a single result element in the CommonPrefixes collection. These\nrolled-up keys are not returned elsewhere in the response. Each rolled-up result counts as only\none return against the MaxKeys value.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode the object keys in the response. Responses are\nencoded only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0\nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10. For\ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon\nS3 encode the keys in the response. For more information about characters to avoid in object\nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's\nkey name will be percent-encoded according to UTF-8 code values. For example, the\nobject test_file(3).png will appear as test_file%283%29.png.\nType: String\nValid Values: url\nAmazon S3 API Version 2006-03-01 432",
      "start_idx": 549646,
      "end_idx": 551315,
      "metadata": {
        "num_sentences": 16,
        "num_words": 270,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_438",
      "text": "Amazon Simple Storage Service API Reference\nIsTruncated\nA flag that indicates whether Amazon S3 returned all of the results that satisfied the search\ncriteria.\nType: Boolean\nMarker\nIndicates where in the bucket listing begins. Marker is included in the response if it was sent\nwith the request.\nType: String\nMaxKeys\nThe maximum number of keys returned in the response body.\nType: Integer\nName\nThe bucket name.\nType: String\nNextMarker\nWhen the response is truncated (the IsTruncated element value in the response is true), you\ncan use the key name in this field as the marker parameter in the subsequent request to get\nthe next set of objects. Amazon S3 lists objects in alphabetical order.\nNote\nThis element is returned only if you have the delimiter request parameter specified.\nIf the response does not include the NextMarker element and it is truncated, you can\nuse the value of the last Key element in the response as the marker parameter in the\nsubsequent request to get the next set of object keys.\nType: String\nPrefix\nKeys that begin with the indicated prefix.\nAmazon S3 API Version 2006-03-01 433",
      "start_idx": 551317,
      "end_idx": 552421,
      "metadata": {
        "num_sentences": 11,
        "num_words": 186,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_442",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 photos/2006/February/sample3.jpg\n\u2022 photos/2006/February/sample4.jpg\nThe following GET request specifies the delimiter parameter with a value of /.\nGET /?delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAuthorization: authorization string\nSample Response\nThe key sample.jpg does not contain the delimiter character, and Amazon S3 returns it in the\nContents element in the response. However, all of the other keys contain the delimiter character.\nAmazon S3 groups these keys and returns a single CommonPrefixes element with the Prefix\nvalue photos/, which is a substring from the beginning of these keys to the first occurrence of the\nspecified delimiter.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>example-bucket</Name>\n<Prefix></Prefix>\n<Marker></Marker>\n<MaxKeys>1000</MaxKeys>\n<Delimiter>/</Delimiter>\n<IsTruncated>false</IsTruncated>\n<Contents>\n<Key>sample.jpg</Key>\n<LastModified>2011-02-26T01:56:20.000Z</LastModified>\n<ETag>\"bf1d737a4d46a19f3bced6905cc8b902\"</ETag>\n<Size>142863</Size>\n<Owner>\n<ID>canonical-user-id</ID>\n<DisplayName>display-name</DisplayName>\n</Owner>\n<StorageClass>STANDARD</StorageClass>\n</Contents>\n<CommonPrefixes>\nAmazon S3 API Version 2006-03-01 437",
      "start_idx": 555597,
      "end_idx": 556907,
      "metadata": {
        "num_sentences": 5,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_443",
      "text": "Amazon Simple Storage Service API Reference\n<Prefix>photos/</Prefix>\n</CommonPrefixes>\n</ListBucketResult>\nSample Request\nThe following GET request specifies the delimiter parameter with the value /, and the prefix\nparameter with the value photos/2006/.\nGET /?prefix=photos/2006/&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAuthorization: authorization string\nSample Response\nIn response, Amazon S3 returns only the keys that start with the specified prefix. Amazon S3 uses\nthe delimiter character to group keys that contain the same substring until the first occurrence\nof the delimiter character after the specified prefix. For each such key group, Amazon S3 returns\none CommonPrefixes element in the response. The keys grouped under this CommonPrefixes\nelement are not returned elsewhere in the response. The value returned in the CommonPrefixes\nelement is a substring that starts at the beginning of the key and ends at the first occurrence of the\nspecified delimiter after the prefix.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>example-bucket</Name>\n<Prefix>photos/2006/</Prefix>\n<Marker></Marker>\n<MaxKeys>1000</MaxKeys>\n<Delimiter>/</Delimiter>\n<IsTruncated>false</IsTruncated>\n<CommonPrefixes>\n<Prefix>photos/2006/February/</Prefix>\n</CommonPrefixes>\nAmazon S3 API Version 2006-03-01 438",
      "start_idx": 556909,
      "end_idx": 558294,
      "metadata": {
        "num_sentences": 7,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_445",
      "text": "Amazon Simple Storage Service API Reference\nListObjectsV2\nService: Amazon S3\nReturns some or all (up to 1,000) of the objects in a bucket with each request. You can use the\nrequest parameters as selection criteria to return a subset of the objects in a bucket. A 200 OK\nresponse can contain valid or invalid XML. Make sure to design your application to parse the\ncontents of the response and handle it appropriately. For more information about listing objects,\nsee Listing object keys programmatically in the Amazon S3 User Guide. To get a list of your buckets,\nsee ListBuckets.\nNote\n\u2022 General purpose bucket - For general purpose buckets, ListObjectsV2 doesn't return\nprefixes that are related only to in-progress multipart uploads.\n\u2022 Directory buckets - For directory buckets, ListObjectsV2 response includes the\nprefixes that are related only to in-progress multipart uploads.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the\nformat https://bucket_name.s3express-az_id.region.amazonaws.com/key-\nname . Path-style requests are not supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - To use this operation, you must have READ access to\nthe bucket. You must have permission to perform the s3:ListBucket action. The bucket\nowner has this permission by default and can grant this permission to others. For more\ninformation about permissions, see Permissions Related to Bucket Subresource Operations\nand Managing Access Permissions to Your Amazon S3 Resources in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nAmazon S3 API Version 2006-03-01 440",
      "start_idx": 558783,
      "end_idx": 561133,
      "metadata": {
        "num_sentences": 21,
        "num_words": 361,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_446",
      "text": "Amazon Simple Storage Service API Reference\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nSorting order of returned objects\n\u2022 General purpose bucket - For general purpose buckets, ListObjectsV2 returns objects in\nlexicographical order based on their key names.\n\u2022 Directory bucket - For directory buckets, ListObjectsV2 does not return objects in\nlexicographical order.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nImportant\nThis section describes the latest revision of this action. We recommend that you use this\nrevised API operation for application development. For backward compatibility, Amazon S3\ncontinues to support the prior version of this API operation, ListObjects.\nThe following operations are related to ListObjectsV2:\n\u2022 GetObject\n\u2022 PutObject\n\u2022 CreateBucket\nRequest Syntax\nGET /?list-type=2&continuation-token=ContinuationToken&delimiter=Delimiter&encoding-\ntype=EncodingType&fetch-owner=FetchOwner&max-keys=MaxKeys&prefix=Prefix&start-\nafter=StartAfter HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-optional-object-attributes: OptionalObjectAttributes\nAmazon S3 API Version 2006-03-01 441",
      "start_idx": 561135,
      "end_idx": 562550,
      "metadata": {
        "num_sentences": 10,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_447",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 442",
      "start_idx": 562552,
      "end_idx": 564408,
      "metadata": {
        "num_sentences": 18,
        "num_words": 280,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_448",
      "text": "Amazon Simple Storage Service API Reference\ncontinuation-token\nContinuationToken indicates to Amazon S3 that the list is being continued on this bucket\nwith a token. ContinuationToken is obfuscated and is not a real key. You can use this\nContinuationToken for pagination of the list results.\ndelimiter\nA delimiter is a character that you use to group keys.\nNote\n\u2022 Directory buckets - For directory buckets, / is the only supported delimiter.\n\u2022 Directory buckets - When you query ListObjectsV2 with a delimiter during in-\nprogress multipart uploads, the CommonPrefixes response parameter contains\nthe prefixes that are associated with the in-progress multipart uploads. For more\ninformation about multipart uploads, see Multipart Upload Overview in the Amazon\nS3 User Guide.\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response. Responses are\nencoded only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0\nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10. For\ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon\nS3 encode the keys in the response. For more information about characters to avoid in object\nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's\nkey name will be percent-encoded according to UTF-8 code values. For example, the\nobject test_file(3).png will appear as test_file%283%29.png.\nValid Values: url\nAmazon S3 API Version 2006-03-01 443",
      "start_idx": 564410,
      "end_idx": 565995,
      "metadata": {
        "num_sentences": 16,
        "num_words": 249,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_449",
      "text": "Amazon Simple Storage Service API Reference\nfetch-owner\nThe owner field is not present in ListObjectsV2 by default. If you want to return the owner\nfield with each key in the result, then set the FetchOwner field to true.\nNote\nDirectory buckets - For directory buckets, the bucket owner is returned as the object\nowner for all objects.\nmax-keys\nSets the maximum number of keys returned in the response. By default, the action returns up to\n1,000 key names. The response might contain fewer keys but will never contain more.\nprefix\nLimits the response to keys that begin with the specified prefix.\nNote\nDirectory buckets - For directory buckets, only prefixes that end in a delimiter (/) are\nsupported.\nstart-after\nStartAfter is where you want Amazon S3 to start listing from. Amazon S3 starts listing after this\nspecified key. StartAfter can be any key in the bucket.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 444",
      "start_idx": 565997,
      "end_idx": 567195,
      "metadata": {
        "num_sentences": 15,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_450",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-optional-object-attributes\nSpecifies the optional fields that you want returned in the response. Fields that you do not\nspecify are not returned.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: RestoreStatus\nx-amz-request-payer\nConfirms that the requester knows that she or he will be charged for the list objects request in\nV2 style. Bucket owners need not specify this parameter in their requests.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult>\n<IsTruncated>boolean</IsTruncated>\n<Contents>\n<ChecksumAlgorithm>string</ChecksumAlgorithm>\n...\n<ETag>string</ETag>\n<Key>string</Key>\n<LastModified>timestamp</LastModified>\nAmazon S3 API Version 2006-03-01 445",
      "start_idx": 567197,
      "end_idx": 568154,
      "metadata": {
        "num_sentences": 8,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_452",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nListBucketResult\nRoot level tag for the ListBucketResult parameters.\nRequired: Yes\nCommonPrefixes\nAll of the keys (up to 1,000) that share the same prefix are grouped together. When counting\nthe total numbers of returns by this API operation, this group of keys is considered as one item.\nA response can contain CommonPrefixes only if you specify a delimiter.\nCommonPrefixes contains all (if there are any) keys between Prefix and the next occurrence\nof the string specified by a delimiter.\nCommonPrefixes lists keys that act like subdirectories in the directory specified by Prefix.\nFor example, if the prefix is notes/ and the delimiter is a slash (/) as in notes/summer/july,\nthe common prefix is notes/summer/. All of the keys that roll up into a common prefix count\nas a single return when calculating the number of returns.\nNote\n\u2022 Directory buckets - For directory buckets, only prefixes that end in a delimiter (/) are\nsupported.\n\u2022 Directory buckets - When you query ListObjectsV2 with a delimiter during in-\nprogress multipart uploads, the CommonPrefixes response parameter contains\nthe prefixes that are associated with the in-progress multipart uploads. For more\ninformation about multipart uploads, see Multipart Upload Overview in the Amazon\nS3 User Guide.\nType: Array of CommonPrefix data types\nContents\nMetadata about each object returned.\nType: Array of Object data types\nAmazon S3 API Version 2006-03-01 447",
      "start_idx": 569223,
      "end_idx": 570751,
      "metadata": {
        "num_sentences": 14,
        "num_words": 241,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_453",
      "text": "Amazon Simple Storage Service API Reference\nContinuationToken\nIf ContinuationToken was sent with the request, it is included in the response. You can\nuse the returned ContinuationToken for pagination of the list response. You can use this\nContinuationToken for pagination of the list results.\nType: String\nDelimiter\nCauses keys that contain the same string between the prefix and the first occurrence of the\ndelimiter to be rolled up into a single result element in the CommonPrefixes collection. These\nrolled-up keys are not returned elsewhere in the response. Each rolled-up result counts as only\none return against the MaxKeys value.\nNote\nDirectory buckets - For directory buckets, / is the only supported delimiter.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode object key names in the XML response.\nIf you specify the encoding-type request parameter, Amazon S3 includes this element in the\nresponse, and returns encoded key name values in the following response elements:\nDelimiter, Prefix, Key, and StartAfter.\nType: String\nValid Values: url\nIsTruncated\nSet to false if all of the results were returned. Set to true if more keys are available to return.\nIf the number of results exceeds that specified by MaxKeys, all of the results might not be\nreturned.\nType: Boolean\nAmazon S3 API Version 2006-03-01 448",
      "start_idx": 570753,
      "end_idx": 572087,
      "metadata": {
        "num_sentences": 13,
        "num_words": 212,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_454",
      "text": "Amazon Simple Storage Service API Reference\nKeyCount\nKeyCount is the number of keys returned with this request. KeyCount will always be less than\nor equal to the MaxKeys field. For example, if you ask for 50 keys, your result will include 50\nkeys or fewer.\nType: Integer\nMaxKeys\nSets the maximum number of keys returned in the response. By default, the action returns up to\n1,000 key names. The response might contain fewer keys but will never contain more.\nType: Integer\nName\nThe bucket name.\nType: String\nNextContinuationToken\nNextContinuationToken is sent when isTruncated is true, which means there are more\nkeys in the bucket that can be listed. The next list requests to Amazon S3 can be continued with\nthis NextContinuationToken. NextContinuationToken is obfuscated and is not a real key\nType: String\nPrefix\nKeys that begin with the indicated prefix.\nNote\nDirectory buckets - For directory buckets, only prefixes that end in a delimiter (/) are\nsupported.\nType: String\nStartAfter\nIf StartAfter was sent with the request, it is included in the response.\nAmazon S3 API Version 2006-03-01 449",
      "start_idx": 572089,
      "end_idx": 573185,
      "metadata": {
        "num_sentences": 13,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_455",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nType: String\nErrors\nNoSuchBucket\nThe specified bucket does not exist.\nHTTP Status Code: 404\nExamples\nSample Request for general purpose buckets: Listing keys\nThis request returns the objects in bucket. The request specifies the list-type parameter, which\nindicates version 2 of the API operation.\nGET /?list-type=2 HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nx-amz-date: 20160430T233541Z\nAuthorization: authorization string\nContent-Type: text/plain\nSample Response for general purpose buckets\nThis example illustrates one usage of ListObjectsV2.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>bucket</Name>\n<Prefix/>\nAmazon S3 API Version 2006-03-01 450",
      "start_idx": 573187,
      "end_idx": 574017,
      "metadata": {
        "num_sentences": 6,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_457",
      "text": "Amazon Simple Storage Service API Reference\nContent-Length: length\nConnection: close\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>quotes</Name>\n<Prefix>E</Prefix>\n<StartAfter>ExampleGuide.pdf</StartAfter>\n<KeyCount>1</KeyCount>\n<MaxKeys>3</MaxKeys>\n<IsTruncated>false</IsTruncated>\n<Contents>\n<Key>ExampleObject.txt</Key>\n<LastModified>2013-09-17T18:07:53.000Z</LastModified>\n<ETag>\"599bab3ed2c697f1d26842727561fd94\"</ETag>\n<Size>857</Size>\n<StorageClass>REDUCED_REDUNDANCY</StorageClass>\n</Contents>\n</ListBucketResult>\nSample Request for general purpose buckets: Listing keys by using the prefix and delimiter\nparameters\nThis example illustrates the use of the prefix and the delimiter parameters in the request. For\nthis example, we assume that you have the following keys in your bucket:\n\u2022 sample.jpg\n\u2022 photos/2006/January/sample.jpg\n\u2022 photos/2006/February/sample2.jpg\n\u2022 photos/2006/February/sample3.jpg\n\u2022 photos/2006/February/sample4.jpg\nThe following GET request specifies the delimiter parameter with a value of /.\nGET /?list-type=2&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 452",
      "start_idx": 575280,
      "end_idx": 576508,
      "metadata": {
        "num_sentences": 3,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_458",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-date: 20160430T235931Z\nAuthorization: authorization string\nSample Response for general purpose buckets\nThe key sample.jpg does not contain the delimiter character, and Amazon S3 returns it in the\nContents element in the response. However, all of the other keys contain the delimiter character.\nAmazon S3 groups these keys and returns a single CommonPrefixes element with the Prefix\nvalue photos/. The Prefix element is a substring that starts at the beginning of these keys and\nends at the first occurrence of the specified delimiter.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>example-bucket</Name>\n<Prefix></Prefix>\n<KeyCount>2</KeyCount>\n<MaxKeys>1000</MaxKeys>\n<Delimiter>/</Delimiter>\n<IsTruncated>false</IsTruncated>\n<Contents>\n<Key>sample.jpg</Key>\n<LastModified>2011-02-26T01:56:20.000Z</LastModified>\n<ETag>\"bf1d737a4d46a19f3bced6905cc8b902\"</ETag>\n<Size>142863</Size>\n<StorageClass>STANDARD</StorageClass>\n</Contents>\n<CommonPrefixes>\n<Prefix>photos/</Prefix>\n</CommonPrefixes>\n</ListBucketResult>\nSample Request for general purpose buckets\nThe following request specifies the delimiter parameter with the value /, and the prefix\nparameter with the value photos/2006/.\nGET /?list-type=2&prefix=photos/2006/&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 453",
      "start_idx": 576510,
      "end_idx": 577911,
      "metadata": {
        "num_sentences": 6,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_459",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-date: 20160501T000433Z\nAuthorization: authorization string\nSample Response for general purpose buckets\nIn response, Amazon S3 returns only the keys that start with the specified prefix. Further,\nAmazon S3 uses the delimiter character to group keys that contain the same substring until the\nfirst occurrence of the delimiter character after the specified prefix. For each such key group,\nAmazon S3 returns one CommonPrefixes element in the response. The keys grouped under\nthis CommonPrefixes element are not returned elsewhere in the response. The Prefix value\nreturned in the CommonPrefixes element is a substring that starts at the beginning of the key\nand ends at the first occurrence of the specified delimiter after the prefix.\nNote\nIf you created folders by using the Amazon S3 console, you will see an additional 0-byte\nobject with a key of photos/2006/. This object is created because of the way that the\nconsole supports folder structures. For more information, see Organizing objects in the\nAmazon S3 console using folders in the Amazon S3 User Guide.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>example-bucket</Name>\n<Prefix>photos/2006/</Prefix>\n<KeyCount>2</KeyCount>\n<MaxKeys>1000</MaxKeys>\n<Delimiter>/</Delimiter>\n<IsTruncated>false</IsTruncated>\n<CommonPrefixes>\n<Prefix>photos/2006/February/</Prefix>\n</CommonPrefixes>\n<CommonPrefixes>\n<Prefix>photos/2006/January/</Prefix>\n</CommonPrefixes>\n</ListBucketResult>\nAmazon S3 API Version 2006-03-01 454",
      "start_idx": 577913,
      "end_idx": 579458,
      "metadata": {
        "num_sentences": 9,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_460",
      "text": "Amazon Simple Storage Service API Reference\nSample Request for general purpose buckets: Using a continuation token\nIn this example, the initial request returns more than 1,000 keys. In response to this request,\nAmazon S3 returns the IsTruncated element with the value set to true and with a\nNextContinuationToken element.\nGET /?list-type=2 HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Mon, 02 May 2016 23:17:07 GMT\nAuthorization: authorization string\nSample Response for general purpose buckets: Using a continuation token\nThis example illustrates one usage of ListObjectsV2.\nHTTP/1.1 200 OK\nx-amz-id-2: gyB+3jRPnrkN98ZajxHXr3u7EFM67bNgSAxexeEHndCX/7GRnfTXxReKUQF28IfP\nx-amz-request-id: 3B3C7C725673C630\nDate: Sat, 30 Apr 2016 23:29:37 GMT\nContent-Type: application/xml\nContent-Length: length\nConnection: close\nServer: AmazonS3\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>bucket</Name>\n<Prefix></Prefix>\n<NextContinuationToken>1ueGcxLPRx1Tr/XYExHnhbYLgveDs2J/wm36Hy4vbOwM=</\nNextContinuationToken>\n<KeyCount>1000</KeyCount>\n<MaxKeys>1000</MaxKeys>\n<IsTruncated>true</IsTruncated>\n<Contents>\n<Key>happyface.jpg</Key>\n<LastModified>2014-11-21T19:40:05.000Z</LastModified>\n<ETag>\"70ee1738b6b21e2c8a43f3a5ab0eee71\"</ETag>\n<Size>11</Size>\n<StorageClass>STANDARD</StorageClass>\n</Contents>\nAmazon S3 API Version 2006-03-01 455",
      "start_idx": 579460,
      "end_idx": 580818,
      "metadata": {
        "num_sentences": 4,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_463",
      "text": "Amazon Simple Storage Service API Reference\nListObjectVersions\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nReturns metadata about all versions of the objects in a bucket. You can also use request\nparameters as selection criteria to return metadata about a subset of all the object versions.\nImportant\nTo use this operation, you must have permission to perform the\ns3:ListBucketVersions action. Be aware of the name difference.\nNote\nA 200 OK response can contain valid or invalid XML. Make sure to design your application\nto parse the contents of the response and handle it appropriately.\nTo use this operation, you must have READ access to the bucket.\nThe following operations are related to ListObjectVersions:\n\u2022 ListObjectsV2\n\u2022 GetObject\n\u2022 PutObject\n\u2022 DeleteObject\nRequest Syntax\nGET /?versions&delimiter=Delimiter&encoding-type=EncodingType&key-marker=KeyMarker&max-\nkeys=MaxKeys&prefix=Prefix&version-id-marker=VersionIdMarker HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nAmazon S3 API Version 2006-03-01 458",
      "start_idx": 582666,
      "end_idx": 583706,
      "metadata": {
        "num_sentences": 9,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_464",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\nx-amz-optional-object-attributes: OptionalObjectAttributes\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the objects.\nRequired: Yes\ndelimiter\nA delimiter is a character that you specify to group keys. All keys that contain the same string\nbetween the prefix and the first occurrence of the delimiter are grouped under a single result\nelement in CommonPrefixes. These groups are counted as one result against the max-keys\nlimitation. These keys are not returned elsewhere in the response.\nencoding-type\nEncoding type used by Amazon S3 to encode the object keys in the response. Responses are\nencoded only in UTF-8. An object key can contain any Unicode character. However, the XML 1.0\nparser can't parse certain characters, such as characters with an ASCII value from 0 to 10. For\ncharacters that aren't supported in XML 1.0, you can add this parameter to request that Amazon\nS3 encode the keys in the response. For more information about characters to avoid in object\nkey names, see Object key naming guidelines.\nNote\nWhen using the URL encoding type, non-ASCII characters that are used in an object's\nkey name will be percent-encoded according to UTF-8 code values. For example, the\nobject test_file(3).png will appear as test_file%283%29.png.\nValid Values: url\nkey-marker\nSpecifies the key to start with when listing objects in a bucket.\nAmazon S3 API Version 2006-03-01 459",
      "start_idx": 583708,
      "end_idx": 585272,
      "metadata": {
        "num_sentences": 16,
        "num_words": 235,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_465",
      "text": "Amazon Simple Storage Service API Reference\nmax-keys\nSets the maximum number of keys returned in the response. By default, the action returns\nup to 1,000 key names. The response might contain fewer keys but will never contain more.\nIf additional keys satisfy the search criteria, but were not returned because max-keys was\nexceeded, the response contains <isTruncated>true</isTruncated>. To return the\nadditional keys, see key-marker and version-id-marker.\nprefix\nUse this parameter to select only those keys that begin with the specified prefix. You can use\nprefixes to separate a bucket into different groupings of keys. (You can think of using prefix\nto make groups in the same way that you'd use a folder in a file system.) You can use prefix\nwith delimiter to roll up numerous objects into a single result under CommonPrefixes.\nversion-id-marker\nSpecifies the object version you want to start listing from.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-optional-object-attributes\nSpecifies the optional fields that you want returned in the response. Fields that you do not\nspecify are not returned.\nValid Values: RestoreStatus\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 460",
      "start_idx": 585274,
      "end_idx": 587151,
      "metadata": {
        "num_sentences": 20,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_468",
      "text": "Amazon Simple Storage Service API Reference\nCommonPrefixes\nAll of the keys rolled up into a common prefix count as a single return when calculating the\nnumber of returns.\nType: Array of CommonPrefix data types\nDeleteMarker\nContainer for an object that is a delete marker.\nType: Array of DeleteMarkerEntry data types\nDelimiter\nThe delimiter grouping the included keys. A delimiter is a character that you specify to group\nkeys. All keys that contain the same string between the prefix and the first occurrence of the\ndelimiter are grouped under a single result element in CommonPrefixes. These groups are\ncounted as one result against the max-keys limitation. These keys are not returned elsewhere\nin the response.\nType: String\nEncodingType\nEncoding type used by Amazon S3 to encode object key names in the XML response.\nIf you specify the encoding-type request parameter, Amazon S3 includes this element in the\nresponse, and returns encoded key name values in the following response elements:\nKeyMarker, NextKeyMarker, Prefix, Key, and Delimiter.\nType: String\nValid Values: url\nIsTruncated\nA flag that indicates whether Amazon S3 returned all of the results that satisfied the search\ncriteria. If your results were truncated, you can make a follow-up paginated request by using\nthe NextKeyMarker and NextVersionIdMarker response parameters as a starting place in\nanother request to return the rest of the results.\nType: Boolean\nAmazon S3 API Version 2006-03-01 463",
      "start_idx": 589105,
      "end_idx": 590569,
      "metadata": {
        "num_sentences": 12,
        "num_words": 229,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_469",
      "text": "Amazon Simple Storage Service API Reference\nKeyMarker\nMarks the last key returned in a truncated response.\nType: String\nMaxKeys\nSpecifies the maximum number of objects to return.\nType: Integer\nName\nThe bucket name.\nType: String\nNextKeyMarker\nWhen the number of responses exceeds the value of MaxKeys, NextKeyMarker specifies the\nfirst key not returned that satisfies the search criteria. Use this value for the key-marker request\nparameter in a subsequent request.\nType: String\nNextVersionIdMarker\nWhen the number of responses exceeds the value of MaxKeys, NextVersionIdMarker\nspecifies the first object version not returned that satisfies the search criteria. Use this value for\nthe version-id-marker request parameter in a subsequent request.\nType: String\nPrefix\nSelects objects that start with the value supplied by this parameter.\nType: String\nVersion\nContainer for version information.\nType: Array of ObjectVersion data types\nVersionIdMarker\nMarks the last version of the key returned in a truncated response.\nAmazon S3 API Version 2006-03-01 464",
      "start_idx": 590571,
      "end_idx": 591622,
      "metadata": {
        "num_sentences": 11,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_477",
      "text": "Amazon Simple Storage Service API Reference\n</Owner>\n<StorageClass>STANDARD</StorageClass>\n</Version>\n</ListVersionsResult>\nSample Request: Using the delimiter and prefix Parameters\nAssume you have the following keys in your bucket, example-bucket.\nphotos/2006/January/sample.jpg\nphotos/2006/February/sample.jpg\nphotos/2006/March/sample.jpg\nvideos/2006/March/sample.wmv\nsample.jpg\nThe following GET versions request specifies the delimiter parameter with the value /.\nGET /?versions&delimiter=/ HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Wed, 02 Feb 2011 20:34:56 GMT\nAuthorization: authorization string\nSample Response\nThe list of keys from the specified bucket is shown in the following response.\nThe response returns the sample.jpg key in a Version element. However, because all the other\nkeys contain the specified delimiter, a distinct substring, from the beginning of the key to the first\noccurrence of the delimiter, from each of these keys is returned in a CommonPrefixes element.\nThe key substrings, photos/ and videos/, in the CommonPrefixes element indicate that there\nare one or more keys with these key prefixes.\nThis is a useful scenario if you use key prefixes for your objects to create a logical folder-like\nstructure. In this case, you can interpret the result as the folders photos/ and videos/ have one\nor more objects.\nAmazon S3 API Version 2006-03-01 472",
      "start_idx": 600897,
      "end_idx": 602292,
      "metadata": {
        "num_sentences": 9,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_479",
      "text": "Amazon Simple Storage Service API Reference\nAuthorization: authorization string\nExample\nIn this case, the response will include only object keys that start with the specified prefix. The value\nreturned in the CommonPrefixes element is a substring from the beginning of the key to the first\noccurrence of the specified delimiter after the prefix.\nNote\nIf you created folders by using the Amazon S3 console, you will see an additional 0-byte\nobject with a key of photos/2006/. This object is created because of the way that the\nconsole supports folder structures. For more information, see Organizing objects in the\nAmazon S3 console using folders in the Amazon S3 User Guide.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListVersionsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>example-bucket</Name>\n<Prefix>photos/2006/</Prefix>\n<KeyMarker></KeyMarker>\n<VersionIdMarker></VersionIdMarker>\n<MaxKeys>1000</MaxKeys>\n<Delimiter>/</Delimiter>\n<IsTruncated>false</IsTruncated>\n<CommonPrefixes>\n<Prefix>photos/2006/February/</Prefix>\n</CommonPrefixes>\n<CommonPrefixes>\n<Prefix>photos/2006/January/</Prefix>\n</CommonPrefixes>\n<CommonPrefixes>\n<Prefix>photos/2006/March/</Prefix>\n</CommonPrefixes>\n</ListVersionsResult>\nAmazon S3 API Version 2006-03-01 474",
      "start_idx": 603471,
      "end_idx": 604730,
      "metadata": {
        "num_sentences": 6,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_481",
      "text": "Amazon Simple Storage Service API Reference\nListParts\nService: Amazon S3\nLists the parts that have been uploaded for a specific multipart upload.\nTo use this operation, you must provide the upload ID in the request. You obtain this uploadID by\nsending the initiate multipart upload request through CreateMultipartUpload.\nThe ListParts request returns a maximum of 1,000 uploaded parts. The limit of 1,000 parts is\nalso the default value. You can restrict the number of parts in a response by specifying the max-\nparts request parameter. If your multipart upload consists of more than 1,000 parts, the response\nreturns an IsTruncated field with the value of true, and a NextPartNumberMarker element.\nTo list remaining uploaded parts, in subsequent ListParts requests, include the part-number-\nmarker query string parameter and set its value to the NextPartNumberMarker field value from\nthe previous response.\nFor more information on multipart uploads, see Uploading Objects Using Multipart Upload in the\nAmazon S3 User Guide.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - For information about permissions required to use the\nmultipart upload API, see Multipart Upload and Permissions in the Amazon S3 User Guide.\nIf the upload was created using server-side encryption with AWS Key Management Service\n(AWS KMS) keys (SSE-KMS) or dual-layer server-side encryption with AWS KMS keys (DSSE-\nKMS), you must have permission to the kms:Decrypt action for the ListParts request to\nsucceed.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nAmazon S3 API Version 2006-03-01 476",
      "start_idx": 605126,
      "end_idx": 607195,
      "metadata": {
        "num_sentences": 16,
        "num_words": 308,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_482",
      "text": "Amazon Simple Storage Service API Reference\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to ListParts:\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\n\u2022 CompleteMultipartUpload\n\u2022 AbortMultipartUpload\n\u2022 GetObjectAttributes\n\u2022 ListMultipartUploads\nRequest Syntax\nGET /Key+?max-parts=MaxParts&part-number-marker=PartNumberMarker&uploadId=UploadId\nHTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 API Version 2006-03-01 477",
      "start_idx": 607197,
      "end_idx": 608701,
      "metadata": {
        "num_sentences": 10,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_483",
      "text": "Amazon Simple Storage Service API Reference\nBucket\nThe name of the bucket to which the parts are being uploaded.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nObject key for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nAmazon S3 API Version 2006-03-01 478",
      "start_idx": 608703,
      "end_idx": 610653,
      "metadata": {
        "num_sentences": 20,
        "num_words": 298,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_484",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nmax-parts\nSets the maximum number of parts to return.\npart-number-marker\nSpecifies the part after which listing should begin. Only parts with higher part numbers will be\nlisted.\nuploadId\nUpload ID identifying the multipart upload whose parts are being listed.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nThe server-side encryption (SSE) algorithm used to encrypt the object. This parameter is needed\nonly when the object was created using a checksum algorithm. For more information, see\nProtecting data using SSE-C keys in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 479",
      "start_idx": 610655,
      "end_idx": 612089,
      "metadata": {
        "num_sentences": 15,
        "num_words": 213,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_485",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nThe server-side encryption (SSE) customer managed key. This parameter is needed only when\nthe object was created using a checksum algorithm. For more information, see Protecting data\nusing SSE-C keys in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nThe MD5 server-side encryption (SSE) customer managed key. This parameter is needed only\nwhen the object was created using a checksum algorithm. For more information, see Protecting\ndata using SSE-C keys in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-abort-date: AbortDate\nx-amz-abort-rule-id: AbortRuleId\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListPartsResult>\nAmazon S3 API Version 2006-03-01 480",
      "start_idx": 612091,
      "end_idx": 613153,
      "metadata": {
        "num_sentences": 11,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_486",
      "text": "Amazon Simple Storage Service API Reference\n<Bucket>string</Bucket>\n<Key>string</Key>\n<UploadId>string</UploadId>\n<PartNumberMarker>integer</PartNumberMarker>\n<NextPartNumberMarker>integer</NextPartNumberMarker>\n<MaxParts>integer</MaxParts>\n<IsTruncated>boolean</IsTruncated>\n<Part>\n<ChecksumCRC32>string</ChecksumCRC32>\n<ChecksumCRC32C>string</ChecksumCRC32C>\n<ChecksumSHA1>string</ChecksumSHA1>\n<ChecksumSHA256>string</ChecksumSHA256>\n<ETag>string</ETag>\n<LastModified>timestamp</LastModified>\n<PartNumber>integer</PartNumber>\n<Size>long</Size>\n</Part>\n...\n<Initiator>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Initiator>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n<StorageClass>string</StorageClass>\n<ChecksumAlgorithm>string</ChecksumAlgorithm>\n</ListPartsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-abort-date\nIf the bucket has a lifecycle rule configured with an action to abort incomplete multipart\nuploads and the prefix in the lifecycle rule matches the object name in the request, then the\nresponse includes this header indicating when the initiated multipart upload will become\neligible for abort operation. For more information, see Aborting Incomplete Multipart Uploads\nUsing a Bucket Lifecycle Configuration.\nAmazon S3 API Version 2006-03-01 481",
      "start_idx": 613155,
      "end_idx": 614559,
      "metadata": {
        "num_sentences": 5,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_487",
      "text": "Amazon Simple Storage Service API Reference\nThe response will also include the x-amz-abort-rule-id header that will provide the ID of\nthe lifecycle configuration rule that defines this action.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-abort-rule-id\nThis header is returned along with the x-amz-abort-date header. It identifies applicable\nlifecycle configuration rule that defines the action to abort incomplete multipart uploads.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nThe following data is returned in XML format by the service.\nListPartsResult\nRoot level tag for the ListPartsResult parameters.\nRequired: Yes\nBucket\nThe name of the bucket to which the multipart upload was initiated. Does not return the access\npoint ARN or access point alias if used.\nAmazon S3 API Version 2006-03-01 482",
      "start_idx": 614561,
      "end_idx": 615597,
      "metadata": {
        "num_sentences": 12,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_488",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nChecksumAlgorithm\nThe algorithm that was used to create a checksum of the object.\nType: String\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nInitiator\nContainer element that identifies who initiated the multipart upload. If the initiator is an AWS\naccount, this element provides the same information as the Owner element. If the initiator is an\nIAM User, this element provides the user ARN and display name.\nType: Initiator data type\nIsTruncated\nIndicates whether the returned list of parts is truncated. A true value indicates that the list\nwas truncated. A list can be truncated if the number of parts exceeds the limit returned in the\nMaxParts element.\nType: Boolean\nKey\nObject key for which the multipart upload was initiated.\nType: String\nLength Constraints: Minimum length of 1.\nMaxParts\nMaximum number of parts that were allowed in the response.\nType: Integer\nNextPartNumberMarker\nWhen a list is truncated, this element specifies the last part in the list, as well as the value to\nuse for the part-number-marker request parameter in a subsequent request.\nType: Integer\nAmazon S3 API Version 2006-03-01 483",
      "start_idx": 615599,
      "end_idx": 616767,
      "metadata": {
        "num_sentences": 12,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_489",
      "text": "Amazon Simple Storage Service API Reference\nOwner\nContainer element that identifies the object owner, after the object is created. If multipart\nupload is initiated by an IAM user, this element provides the parent account ID and display\nname.\nNote\nDirectory buckets - The bucket owner is returned as the object owner for all the parts.\nType: Owner data type\nPart\nContainer for elements related to a particular part. A response can contain zero or more Part\nelements.\nType: Array of Part data types\nPartNumberMarker\nSpecifies the part after which listing should begin. Only parts with higher part numbers will be\nlisted.\nType: Integer\nStorageClass\nThe class of storage used to store the uploaded object.\nNote\nDirectory buckets - Only the S3 Express One Zone storage class is supported by\ndirectory buckets to store objects.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nAmazon S3 API Version 2006-03-01 484",
      "start_idx": 616769,
      "end_idx": 617807,
      "metadata": {
        "num_sentences": 10,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_490",
      "text": "Amazon Simple Storage Service API Reference\nUploadId\nUpload ID identifying the multipart upload whose parts are being listed.\nType: String\nExamples\nSample Request for general purpose buckets\nAssume you have uploaded parts with sequential part numbers starting with 1. The following\nList Parts request specifies max-parts and part-number-marker query parameters. The\nrequest lists the first two parts that follow part number 1, that is, you will get parts 2 and 3\nin the response. If more parts exist, the result is a truncated result and therefore the response\nwill return an IsTruncated element with the value true. The response will also return the\nNextPartNumberMarker element with the value 3, which should be used for the value of the\npart-number-marker request query string parameter in the next ListParts request.\nGET /example-object?\nuploadId=XXBsb2FkIElEIGZvciBlbHZpbmcncyVcdS1tb3ZpZS5tMnRzEEEwbG9hZA&max-parts=2&part-\nnumber-marker=1 HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nAuthorization: authorization string\nSample Response for general purpose buckets\nThis example illustrates one usage of ListParts.\nHTTP/1.1 200 OK\nx-amz-id-2: Uuag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nContent-Length: 985\nConnection: keep-alive\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 API Version 2006-03-01 485",
      "start_idx": 617809,
      "end_idx": 619279,
      "metadata": {
        "num_sentences": 9,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_493",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketAccelerateConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the accelerate configuration of an existing bucket. Amazon S3 Transfer Acceleration is a\nbucket-level feature that enables you to perform faster data transfers to Amazon S3.\nTo use this operation, you must have permission to perform the\ns3:PutAccelerateConfiguration action. The bucket owner has this permission by default.\nThe bucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nThe Transfer Acceleration state of a bucket can be set to one of the following two values:\n\u2022 Enabled \u2013 Enables accelerated data transfers to the bucket.\n\u2022 Suspended \u2013 Disables accelerated data transfers to the bucket.\nThe GetBucketAccelerateConfiguration action returns the transfer acceleration state of a bucket.\nAfter setting the Transfer Acceleration state of a bucket to Enabled, it might take up to thirty\nminutes before the data transfer rates to the bucket increase.\nThe name of the bucket used for Transfer Acceleration must be DNS-compliant and must not\ncontain periods (\".\").\nFor more information about transfer acceleration, see Transfer Acceleration.\nThe following operations are related to PutBucketAccelerateConfiguration:\n\u2022 GetBucketAccelerateConfiguration\n\u2022 CreateBucket\nRequest Syntax\nPUT /?accelerate HTTP/1.1\nAmazon S3 API Version 2006-03-01 488",
      "start_idx": 620805,
      "end_idx": 622366,
      "metadata": {
        "num_sentences": 14,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_494",
      "text": "Amazon Simple Storage Service API Reference\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccelerateConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Status>string</Status>\n</AccelerateConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which the accelerate configuration is set.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nAccelerateConfiguration\nRoot level tag for the AccelerateConfiguration parameters.\nAmazon S3 API Version 2006-03-01 489",
      "start_idx": 622368,
      "end_idx": 623891,
      "metadata": {
        "num_sentences": 13,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_497",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the permissions on an existing bucket using access control lists (ACL). For more information,\nsee Using ACLs. To set the ACL of a bucket, you must have the WRITE_ACP permission.\nYou can use one of the following two ways to set a bucket's permissions:\n\u2022 Specify the ACL in the request body\n\u2022 Specify permissions using request headers\nNote\nYou cannot specify access permission using both the body and the request headers.\nDepending on your application needs, you may choose to set the ACL on a bucket using either the\nrequest body or the headers. For example, if you have an existing application that updates a bucket\nACL using the request body, then you can continue to use that approach.\nImportant\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, ACLs\nare disabled and no longer affect permissions. You must use policies to grant access to\nyour bucket and the objects in it. Requests to set ACLs or update ACLs fail and return\nthe AccessControlListNotSupported error code. Requests to read ACLs are still\nsupported. For more information, see Controlling object ownership in the Amazon S3 User\nGuide.\nPermissions\nYou can set access permissions by using one of the following methods:\nAmazon S3 API Version 2006-03-01 492",
      "start_idx": 625479,
      "end_idx": 626867,
      "metadata": {
        "num_sentences": 13,
        "num_words": 230,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_498",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Specify a canned ACL with the x-amz-acl request header. Amazon S3 supports a set of\npredefined ACLs, known as canned ACLs. Each canned ACL has a predefined set of grantees\nand permissions. Specify the canned ACL name as the value of x-amz-acl. If you use this\nheader, you cannot use other access control-specific headers in your request. For more\ninformation, see Canned ACL.\n\u2022 Specify access permissions explicitly with the x-amz-grant-read, x-amz-grant-read-\nacp, x-amz-grant-write-acp, and x-amz-grant-full-control headers. When\nusing these headers, you specify explicit access permissions and grantees (AWS accounts or\nAmazon S3 groups) who will receive the permission. If you use these ACL-specific headers,\nyou cannot use the x-amz-acl header to set a canned ACL. These parameters map to the set\nof permissions that Amazon S3 supports in an ACL. For more information, see Access Control\nList (ACL) Overview.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022 id \u2013 if the value specified is the canonical user ID of an AWS account\n\u2022 uri \u2013 if you are granting permissions to a predefined group\n\u2022 emailAddress \u2013 if the value specified is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nAmazon S3 API Version 2006-03-01 493",
      "start_idx": 626869,
      "end_idx": 628573,
      "metadata": {
        "num_sentences": 13,
        "num_words": 283,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_499",
      "text": "Amazon Simple Storage Service API Reference\nFor example, the following x-amz-grant-write header grants create, overwrite, and delete\nobjects permission to LogDelivery group predefined by Amazon S3 and two AWS accounts\nidentified by their email addresses.\nx-amz-grant-write: uri=\"http://acs.amazonaws.com/groups/s3/\nLogDelivery\", id=\"111122223333\", id=\"555566667777\"\nYou can use either a canned ACL or specify access permissions explicitly. You cannot do both.\nGrantee Values\nYou can specify the person (grantee) to whom you're assigning access rights (using request\nelements) in the following ways:\n\u2022 By the person's ID:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-\ninstance\" xsi:type=\"CanonicalUser\"><ID><>ID<></\nID><DisplayName><>GranteesEmail<></DisplayName> </Grantee>\nDisplayName is optional and ignored in the request\n\u2022 By URI:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"Group\"><URI><>http://acs.amazonaws.com/groups/global/\nAuthenticatedUsers<></URI></Grantee>\n\u2022 By Email address:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"AmazonCustomerByEmail\"><EmailAddress><>Grantees@email.com<></\nEmailAddress>&</Grantee>\nThe grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request,\nappears as the CanonicalUser.\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\nAmazon S3 API Version 2006-03-01 494",
      "start_idx": 628575,
      "end_idx": 630041,
      "metadata": {
        "num_sentences": 5,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_500",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nThe following operations are related to PutBucketAcl:\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 GetObjectAcl\nRequest Syntax\nPUT /?acl HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<AccessControlList>\n<Grant>\n<Grantee>\n<DisplayName>string</DisplayName>\n<EmailAddress>string</EmailAddress>\n<ID>string</ID>\nAmazon S3 API Version 2006-03-01 495",
      "start_idx": 630043,
      "end_idx": 631115,
      "metadata": {
        "num_sentences": 2,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_501",
      "text": "Amazon Simple Storage Service API Reference\n<xsi:type>string</xsi:type>\n<URI>string</URI>\n</Grantee>\n<Permission>string</Permission>\n</Grant>\n</AccessControlList>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n</AccessControlPolicy>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket to which to apply the ACL.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. This header must be used as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, go to RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-acl\nThe canned ACL to apply to the bucket.\nValid Values: private | public-read | public-read-write | authenticated-read\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nAllows grantee the read, write, read ACP, and write ACP permissions on the bucket.\nAmazon S3 API Version 2006-03-01 496",
      "start_idx": 631117,
      "end_idx": 632330,
      "metadata": {
        "num_sentences": 11,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_502",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-grant-read\nAllows grantee to list the objects in the bucket.\nx-amz-grant-read-acp\nAllows grantee to read the bucket ACL.\nx-amz-grant-write\nAllows grantee to create new objects in the bucket.\nFor the bucket and object owners of existing objects, also allows deletions and overwrites of\nthose objects.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nAccessControlPolicy\nRoot level tag for the AccessControlPolicy parameters.\nRequired: Yes\nGrants\nA list of grants.\nAmazon S3 API Version 2006-03-01 497",
      "start_idx": 632332,
      "end_idx": 633591,
      "metadata": {
        "num_sentences": 15,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_503",
      "text": "Amazon Simple Storage Service API Reference\nType: Array of Grant data types\nRequired: No\nOwner\nContainer for the bucket owner's display name and ID.\nType: Owner data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Access permissions specified in the body\nThe following request grants access permission to the existing examplebucket bucket. The\nrequest specifies the ACL in the body. In addition to granting full control to the bucket owner, the\nXML specifies the following grants.\n\u2022 Grant the AllUsers group READ permission on the bucket.\n\u2022 Grant the LogDelivery group WRITE permission on the bucket.\n\u2022 Grant an AWS account, identified by email address, WRITE_ACP permission.\n\u2022 Grant an AWS account, identified by canonical user ID, READ_ACP permission.\nPUT ?acl HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nContent-Length: 1660\nx-amz-date: Thu, 12 Apr 2012 20:04:21 GMT\nAuthorization: authorization string\n<AccessControlPolicy xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\nAmazon S3 API Version 2006-03-01 498",
      "start_idx": 633593,
      "end_idx": 634756,
      "metadata": {
        "num_sentences": 10,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_507",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketAnalyticsConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets an analytics configuration for the bucket (specified by the analytics configuration ID). You can\nhave up to 1,000 analytics configurations per bucket.\nYou can choose to have storage class analysis export analysis reports sent to a comma-separated\nvalues (CSV) flat file. See the DataExport request element. Reports are updated daily and\nare based on the object filters that you configure. When selecting data export, you specify a\ndestination bucket and an optional destination prefix where the file is written. You can export the\ndata to a destination bucket in a different account. However, the destination bucket must be in\nthe same Region as the bucket that you are making the PUT analytics configuration to. For more\ninformation, see Amazon S3 Analytics \u2013 Storage Class Analysis.\nImportant\nYou must create a bucket policy on the destination bucket where the exported file is\nwritten to grant permissions to Amazon S3 to write objects to the bucket. For an example\npolicy, see Granting Permissions for Amazon S3 Inventory and Storage Class Analysis.\nTo use this operation, you must have permissions to perform the\ns3:PutAnalyticsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nPutBucketAnalyticsConfiguration has the following special errors:\n\u2022 \u2022 HTTP Error: HTTP 400 Bad Request\n\u2022 Code: InvalidArgument\n\u2022 Cause: Invalid argument.\n\u2022 \u2022 HTTP Error: HTTP 400 Bad Request\nAmazon S3 API Version 2006-03-01 502",
      "start_idx": 637865,
      "end_idx": 639667,
      "metadata": {
        "num_sentences": 18,
        "num_words": 275,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_509",
      "text": "Amazon Simple Storage Service API Reference\n<Destination>\n<S3BucketDestination>\n<Bucket>string</Bucket>\n<BucketAccountId>string</BucketAccountId>\n<Format>string</Format>\n<Prefix>string</Prefix>\n</S3BucketDestination>\n</Destination>\n<OutputSchemaVersion>string</OutputSchemaVersion>\n</DataExport>\n</StorageClassAnalysis>\n</AnalyticsConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to which an analytics configuration is stored.\nRequired: Yes\nid\nThe ID that identifies the analytics configuration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nAnalyticsConfiguration\nRoot level tag for the AnalyticsConfiguration parameters.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 504",
      "start_idx": 640777,
      "end_idx": 641781,
      "metadata": {
        "num_sentences": 8,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_510",
      "text": "Amazon Simple Storage Service API Reference\nFilter\nThe filter used to describe a set of objects for analyses. A filter must have exactly one prefix,\none tag, or one conjunction (AnalyticsAndOperator). If no filter is provided, all objects will be\nconsidered in any analysis.\nType: AnalyticsFilter data type\nRequired: No\nId\nThe ID that identifies the analytics configuration.\nType: String\nRequired: Yes\nStorageClassAnalysis\nContains data related to access patterns to be collected and made available to analyze the\ntradeoffs between different storage classes.\nType: StorageClassAnalysis data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample 1: Creating an analytics configuration\nThe following PUT request for the bucket examplebucket creates a new or replaces an existing\nanalytics configuration with the ID report1. The configuration is defined in the request body.\nAmazon S3 API Version 2006-03-01 505",
      "start_idx": 641783,
      "end_idx": 642818,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_513",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketCors\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the cors configuration for your bucket. If the configuration exists, Amazon S3 replaces it.\nTo use this operation, you must be allowed to perform the s3:PutBucketCORS action. By default,\nthe bucket owner has this permission and can grant it to others.\nYou set this configuration on a bucket so that the bucket can service cross-origin requests. For\nexample, you might want to enable a request whose origin is http://www.example.com\nto access your Amazon S3 bucket at my.example.bucket.com by using the browser's\nXMLHttpRequest capability.\nTo enable cross-origin resource sharing (CORS) on a bucket, you add the cors subresource to\nthe bucket. The cors subresource is an XML document in which you configure rules that identify\norigins and the HTTP methods that can be executed on your bucket. The document is limited to 64\nKB in size.\nWhen Amazon S3 receives a cross-origin request (or a pre-flight OPTIONS request) against a\nbucket, it evaluates the cors configuration on the bucket and uses the first CORSRule rule that\nmatches the incoming browser request to enable a cross-origin request. For a rule to match, the\nfollowing conditions must be met:\n\u2022 The request's Origin header must match AllowedOrigin elements.\n\u2022 The request method (for example, GET, PUT, HEAD, and so on) or the Access-Control-\nRequest-Method header in case of a pre-flight OPTIONS request must be one of the\nAllowedMethod elements.\n\u2022 Every header specified in the Access-Control-Request-Headers request header of a pre-\nflight request must match an AllowedHeader element.\nFor more information about CORS, go to Enabling Cross-Origin Resource Sharing in the Amazon S3\nUser Guide.\nAmazon S3 API Version 2006-03-01 508",
      "start_idx": 644369,
      "end_idx": 646199,
      "metadata": {
        "num_sentences": 16,
        "num_words": 288,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_515",
      "text": "Amazon Simple Storage Service API Reference\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. This header must be used as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, go to RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nCORSConfiguration\nRoot level tag for the CORSConfiguration parameters.\nRequired: Yes\nCORSRule\nA set of origins and methods (cross-origin access that you want to allow). You can add up to 100\nrules to the configuration.\nAmazon S3 API Version 2006-03-01 510",
      "start_idx": 647102,
      "end_idx": 648640,
      "metadata": {
        "num_sentences": 17,
        "num_words": 244,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_516",
      "text": "Amazon Simple Storage Service API Reference\nType: Array of CORSRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample: CORS configuration on a bucket with two rules\n\u2022 The first CORSRule allows cross-origin PUT, POST, and DELETE requests whose origin is\nhttp://www.example.com origins. The rule also allows all headers in a pre-flight OPTIONS\nrequest through the Access-Control-Request-Headers header. Therefore, in response to\nany pre-flight OPTIONS request, Amazon S3 will return any requested headers.\n\u2022 The second rule allows cross-origin GET requests from all the origins. The '*' wildcard character\nrefers to all origins.\n<CORSConfiguration>\n<CORSRule>\n<AllowedOrigin>http://www.example.com</AllowedOrigin>\n<AllowedMethod>PUT</AllowedMethod>\n<AllowedMethod>POST</AllowedMethod>\n<AllowedMethod>DELETE</AllowedMethod>\n<AllowedHeader>*</AllowedHeader>\n</CORSRule>\n<CORSRule>\n<AllowedOrigin>*</AllowedOrigin>\n<AllowedMethod>GET</AllowedMethod>\n</CORSRule>\n</CORSConfiguration>\nAmazon S3 API Version 2006-03-01 511",
      "start_idx": 648642,
      "end_idx": 649793,
      "metadata": {
        "num_sentences": 7,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_517",
      "text": "Amazon Simple Storage Service API Reference\nExample: CORS configuration allows cross-origin PUT and POST requests from http://\nwww.example.com\nThe cors configuration also allows additional optional configuration parameters as shown in the\nfollowing cors configuration on a bucket. For example,\nIn the preceding configuration, CORSRule includes the following additional optional parameters:\n\u2022 MaxAgeSeconds\u2014Specifies the time in seconds that the browser will cache an Amazon S3\nresponse to a pre-flight OPTIONS request for the specified resource. In this example, this\nparameter is 3000 seconds. Caching enables the browsers to avoid sending pre-flight OPTIONS\nrequest to Amazon S3 for repeated requests.\n\u2022 ExposeHeader\u2014Identifies the response header (in this case x-amz-server-side-\nencryption) that you want customers to be able to access from their applications (for example,\nfrom a JavaScript XMLHttpRequest object).\n<CORSConfiguration>\n<CORSRule>\n<AllowedOrigin>http://www.example.com</AllowedOrigin>\n<AllowedMethod>PUT</AllowedMethod>\n<AllowedMethod>POST</AllowedMethod>\n<AllowedMethod>DELETE</AllowedMethod>\n<AllowedHeader>*</AllowedHeader>\n<MaxAgeSeconds>3000</MaxAgeSeconds>\n<ExposeHeader>x-amz-server-side-encryption</ExposeHeader>\n</CORSRule>\n</CORSConfiguration>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\nAmazon S3 API Version 2006-03-01 512",
      "start_idx": 649795,
      "end_idx": 651325,
      "metadata": {
        "num_sentences": 6,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_519",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketEncryption\nService: Amazon S3\nThis operation configures default encryption and Amazon S3 Bucket Keys for an existing bucket.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nBy default, all buckets have a default encryption configuration that uses server-side encryption\nwith Amazon S3 managed keys (SSE-S3).\nNote\n\u2022 General purpose buckets\n\u2022 You can optionally configure default encryption for a bucket by using server-side\nencryption with AWS Key Management Service (AWS KMS) keys (SSE-KMS) or dual-\nlayer server-side encryption with AWS KMS keys (DSSE-KMS). If you specify default\nencryption by using SSE-KMS, you can also configure Amazon S3 Bucket Keys. For\ninformation about the bucket default encryption feature, see Amazon S3 Bucket\nDefault Encryption in the Amazon S3 User Guide.\n\u2022 If you use PutBucketEncryption to set your default bucket encryption to SSE-KMS, you\nshould verify that your KMS key ID is correct. Amazon S3 doesn't validate the KMS key\nID provided in PutBucketEncryption requests.\n\u2022 Directory buckets - You can optionally configure default encryption for a bucket by\nusing server-side encryption with AWS Key Management Service (AWS KMS) keys (SSE-\nKMS).\n\u2022 We recommend that the bucket's default encryption uses the desired encryption\nconfiguration and you don't override the bucket default encryption in your\nCreateSession requests or PUT object requests. Then, new objects are automatically\nencrypted with the desired encryption settings. For more information about the\nAmazon S3 API Version 2006-03-01 514",
      "start_idx": 651501,
      "end_idx": 653414,
      "metadata": {
        "num_sentences": 15,
        "num_words": 277,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_520",
      "text": "Amazon Simple Storage Service API Reference\nencryption overriding behaviors in directory buckets, see Specifying server-side\nencryption with AWS KMS for new object uploads.\n\u2022 Your SSE-KMS configuration can only support 1 customer managed key per directory\nbucket for the lifetime of the bucket. The AWS managed key (aws/s3) isn't supported.\n\u2022 S3 Bucket Keys are always enabled for GET and PUT operations in a directory\nbucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you copy SSE-\nKMS encrypted objects from general purpose buckets to directory buckets, from\ndirectory buckets to general purpose buckets, or between directory buckets, through\nCopyObject, UploadPartCopy, the Copy operation in Batch Operations, or the import\njobs. In this case, Amazon S3 makes a call to AWS KMS every time a copy request is\nmade for a KMS-encrypted object.\n\u2022 When you specify an AWS KMS customer managed key for encryption in your directory\nbucket, only use the key ID or key ARN. The key alias format of the KMS key isn't\nsupported.\n\u2022 For directory buckets, if you use PutBucketEncryption to set your default bucket\nencryption to SSE-KMS, Amazon S3 validates the KMS key ID provided in\nPutBucketEncryption requests.\nImportant\nIf you're specifying a customer managed KMS key, we recommend using a fully qualified\nKMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the\nrequester\u2019s account. This behavior can result in data that's encrypted with a KMS key that\nbelongs to the requester, and not the bucket owner.\nAlso, this action requires AWS Signature Version 4. For more information, see\nAuthenticating Requests (AWS Signature Version 4).\nPermissions\n\u2022 General purpose bucket permissions - The s3:PutEncryptionConfiguration\npermission is required in a policy. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions,\nsee Permissions Related to Bucket Operations and Managing Access Permissions to Your\nAmazon S3 Resources in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 515",
      "start_idx": 653416,
      "end_idx": 655529,
      "metadata": {
        "num_sentences": 19,
        "num_words": 336,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_521",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:PutEncryptionConfiguration permission in an IAM identity-based policy\ninstead of a bucket policy. Cross-account access to this API operation isn't supported. This\noperation can only be performed by the AWS account that owns the resource. For more\ninformation about directory bucket policies and permissions, see AWS Identity and Access\nManagement (IAM) for S3 Express One Zone in the Amazon S3 User Guide.\nTo set a directory bucket default encryption with SSE-KMS, you must also have the\nkms:GenerateDataKey and the kms:Decrypt permissions in IAM identity-based policies\nand AWS KMS key policies for the target AWS KMS key.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to PutBucketEncryption:\n\u2022 GetBucketEncryption\n\u2022 DeleteBucketEncryption\nRequest Syntax\nPUT /?encryption HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Rule>\n<ApplyServerSideEncryptionByDefault>\n<KMSMasterKeyID>string</KMSMasterKeyID>\n<SSEAlgorithm>string</SSEAlgorithm>\n</ApplyServerSideEncryptionByDefault>\n<BucketKeyEnabled>boolean</BucketKeyEnabled>\n</Rule>\n...\n</ServerSideEncryptionConfiguration>\nAmazon S3 API Version 2006-03-01 516",
      "start_idx": 655531,
      "end_idx": 657126,
      "metadata": {
        "num_sentences": 7,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_522",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nSpecifies default encryption for a bucket using server-side encryption with different key\noptions.\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the server-side encryption configuration.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nAmazon S3 API Version 2006-03-01 517",
      "start_idx": 657128,
      "end_idx": 658614,
      "metadata": {
        "num_sentences": 14,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_523",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nNote\nFor directory buckets, when you use AWS SDKs, CRC32 is the default checksum\nalgorithm that's used for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nServerSideEncryptionConfiguration\nRoot level tag for the ServerSideEncryptionConfiguration parameters.\nRequired: Yes\nRule\nContainer for information about a particular server-side encryption configuration rule.\nType: Array of ServerSideEncryptionRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 518",
      "start_idx": 658616,
      "end_idx": 659798,
      "metadata": {
        "num_sentences": 11,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_524",
      "text": "Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nIn the request, you specify the encryption configuration in the request body. The encryption\nconfiguration is specified as XML, as shown in the following examples that show setting encryption\nusing SSE-S3, SSE-KMS, or DSSE-KMS.\nRequest Body for Setting SSE-S3 for general purpose buckets\nThis example illustrates one usage of PutBucketEncryption.\n<ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\">\n<Rule>\n<ApplyServerSideEncryptionByDefault>\n<SSEAlgorithm>AES256</SSEAlgorithm>\n</ApplyServerSideEncryptionByDefault>\n</Rule>\n</ServerSideEncryptionConfiguration>\nRequest Body for Setting SSE-KMS for general purpose buckets\nThis example illustrates one usage of PutBucketEncryption.\n<ServerSideEncryptionConfiguration xmlns=\"http://s3.amazonaws.com/\ndoc/2006-03-01/\">\n<Rule>\n<ApplyServerSideEncryptionByDefault>\n<SSEAlgorithm>aws:kms:dsse</SSEAlgorithm>\n<KMSKeyID>arn:aws:kms:us-east-1:1234/5678example</KMSKeyID>\n</ApplyServerSideEncryptionByDefault>\n</Rule>\n</ServerSideEncryptionConfiguration>\nAmazon S3 API Version 2006-03-01 519",
      "start_idx": 659800,
      "end_idx": 661034,
      "metadata": {
        "num_sentences": 6,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_526",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketIntelligentTieringConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPuts a S3 Intelligent-Tiering configuration to the specified bucket. You can have up to 1,000 S3\nIntelligent-Tiering configurations per bucket.\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically\nmoving data to the most cost-effective storage access tier, without performance impact or\noperational overhead. S3 Intelligent-Tiering delivers automatic cost savings in three low latency\nand high throughput access tiers. To get the lowest storage cost on data that can be accessed in\nminutes to hours, you can choose to activate additional archiving capabilities.\nThe S3 Intelligent-Tiering storage class is the ideal storage class for data with unknown, changing,\nor unpredictable access patterns, independent of object size or retention period. If the size of an\nobject is less than 128 KB, it is not monitored and not eligible for auto-tiering. Smaller objects can\nbe stored, but they are always charged at the Frequent Access tier rates in the S3 Intelligent-Tiering\nstorage class.\nFor more information, see Storage class for automatically optimizing frequently and infrequently\naccessed objects.\nOperations related to PutBucketIntelligentTieringConfiguration include:\n\u2022 DeleteBucketIntelligentTieringConfiguration\n\u2022 GetBucketIntelligentTieringConfiguration\n\u2022 ListBucketIntelligentTieringConfigurations\nNote\nYou only need S3 Intelligent-Tiering enabled on a bucket if you want to automatically\nmove objects stored in the S3 Intelligent-Tiering storage class to the Archive Access or\nDeep Archive Access tier.\nAmazon S3 API Version 2006-03-01 521",
      "start_idx": 662072,
      "end_idx": 663825,
      "metadata": {
        "num_sentences": 12,
        "num_words": 238,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_528",
      "text": "Amazon Simple Storage Service API Reference\n<Tiering>\n<AccessTier>string</AccessTier>\n<Days>integer</Days>\n</Tiering>\n...\n</IntelligentTieringConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose configuration you want to modify or retrieve.\nRequired: Yes\nid\nThe ID used to identify the S3 Intelligent-Tiering configuration.\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nIntelligentTieringConfiguration\nRoot level tag for the IntelligentTieringConfiguration parameters.\nRequired: Yes\nFilter\nSpecifies a bucket filter. The configuration only includes objects that meet the filter's criteria.\nType: IntelligentTieringFilter data type\nRequired: No\nId\nThe ID used to identify the S3 Intelligent-Tiering configuration.\nAmazon S3 API Version 2006-03-01 523",
      "start_idx": 664860,
      "end_idx": 665722,
      "metadata": {
        "num_sentences": 9,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_531",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketInventoryConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis implementation of the PUT action adds an inventory configuration (identified by the inventory\nID) to the bucket. You can have up to 1,000 inventory configurations per bucket.\nAmazon S3 inventory generates inventories of the objects in the bucket on a daily or weekly\nbasis, and the results are published to a flat file. The bucket that is inventoried is called the source\nbucket, and the bucket where the inventory flat file is stored is called the destination bucket. The\ndestination bucket must be in the same AWS Region as the source bucket.\nWhen you configure an inventory for a source bucket, you specify the destination bucket where you\nwant the inventory to be stored, and whether to generate the inventory daily or weekly. You can\nalso configure what object metadata to include and whether to inventory all object versions or only\ncurrent versions. For more information, see Amazon S3 Inventory in the Amazon S3 User Guide.\nImportant\nYou must create a bucket policy on the destination bucket to grant permissions to Amazon\nS3 to write objects to the bucket in the defined location. For an example policy, see\nGranting Permissions for Amazon S3 Inventory and Storage Class Analysis.\nPermissions\nTo use this operation, you must have permission to perform the\ns3:PutInventoryConfiguration action. The bucket owner has this permission by default\nand can grant this permission to others.\nThe s3:PutInventoryConfiguration permission allows a user to create an S3 Inventory\nreport that includes all object metadata fields available and to specify the destination bucket to\nstore the inventory. A user with read access to objects in the destination bucket can also access\nall object metadata fields that are available in the inventory report.\nAmazon S3 API Version 2006-03-01 526",
      "start_idx": 666616,
      "end_idx": 668554,
      "metadata": {
        "num_sentences": 16,
        "num_words": 307,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_532",
      "text": "Amazon Simple Storage Service API Reference\nTo restrict access to an inventory report, see Restricting access to an Amazon S3 Inventory\nreport in the Amazon S3 User Guide. For more information about the metadata fields available\nin S3 Inventory, see Amazon S3 Inventory lists in the Amazon S3 User Guide. For more\ninformation about permissions, see Permissions related to bucket subresource operations and\nIdentity and access management in Amazon S3 in the Amazon S3 User Guide.\nPutBucketInventoryConfiguration has the following special errors:\nHTTP 400 Bad Request Error\nCode: InvalidArgument\nCause: Invalid Argument\nHTTP 400 Bad Request Error\nCode: TooManyConfigurations\nCause: You are attempting to create a new configuration but have already reached the 1,000-\nconfiguration limit.\nHTTP 403 Forbidden Error\nCause: You are not the owner of the specified bucket, or you do not have the\ns3:PutInventoryConfiguration bucket permission to set the configuration on the bucket.\nThe following operations are related to PutBucketInventoryConfiguration:\n\u2022 GetBucketInventoryConfiguration\n\u2022 DeleteBucketInventoryConfiguration\n\u2022 ListBucketInventoryConfigurations\nRequest Syntax\nPUT /?inventory&id=Id HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InventoryConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\nAmazon S3 API Version 2006-03-01 527",
      "start_idx": 668556,
      "end_idx": 669984,
      "metadata": {
        "num_sentences": 6,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_534",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nInventoryConfiguration\nRoot level tag for the InventoryConfiguration parameters.\nRequired: Yes\nDestination\nContains information about where to publish the inventory results.\nType: InventoryDestination data type\nRequired: Yes\nFilter\nSpecifies an inventory filter. The inventory only includes objects that meet the filter's criteria.\nType: InventoryFilter data type\nRequired: No\nId\nThe ID used to identify the inventory configuration.\nType: String\nRequired: Yes\nIncludedObjectVersions\nObject versions to include in the inventory list. If set to All, the list includes all the object\nversions, which adds the version-related fields VersionId, IsLatest, and DeleteMarker to\nthe list. If set to Current, the list does not contain these version-related fields.\nAmazon S3 API Version 2006-03-01 529",
      "start_idx": 670849,
      "end_idx": 671981,
      "metadata": {
        "num_sentences": 12,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_535",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nValid Values: All | Current\nRequired: Yes\nIsEnabled\nSpecifies whether the inventory is enabled or disabled. If set to True, an inventory list is\ngenerated. If set to False, no inventory list is generated.\nType: Boolean\nRequired: Yes\nOptionalFields\nContains the optional fields that are included in the inventory results.\nType: Array of strings\nValid Values: Size | LastModifiedDate | StorageClass | ETag |\nIsMultipartUploaded | ReplicationStatus | EncryptionStatus |\nObjectLockRetainUntilDate | ObjectLockMode | ObjectLockLegalHoldStatus\n| IntelligentTieringAccessTier | BucketKeyStatus | ChecksumAlgorithm |\nObjectAccessControlList | ObjectOwner\nRequired: No\nSchedule\nSpecifies the schedule for generating inventory results.\nType: InventorySchedule data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nAmazon S3 API Version 2006-03-01 530",
      "start_idx": 671983,
      "end_idx": 672995,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_536",
      "text": "Amazon Simple Storage Service API Reference\nExamples\nExample: Create an inventory configuration\nThe following PUT request and response for the bucket examplebucket creates a new or replaces\nan existing inventory configuration with the ID report1. The configuration is defined in the\nrequest body.\nPUT /?inventory&id=report1 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Mon, 31 Oct 2016 12:00:00 GMT\nAuthorization: authorization string\nContent-Length: length\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<InventoryConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Id>report1</Id>\n<IsEnabled>true</IsEnabled>\n<Filter>\n<Prefix>filterPrefix</Prefix>\n</Filter>\n<Destination>\n<S3BucketDestination>\n<Format>CSV</Format>\n<AccountId>123456789012</AccountId>\n<Bucket>arn:aws:s3:::destination-bucket</Bucket>\n<Prefix>prefix1</Prefix>\n<Encryption>\n<SSE-KMS>\n<KeyId>arn:aws:kms:us-\nwest-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab</KeyId>\n</SSE-KMS>\n</Encryption>\n</S3BucketDestination>\n</Destination>\n<Schedule>\n<Frequency>Daily</Frequency>\n</Schedule>\n<IncludedObjectVersions>All</IncludedObjectVersions>\n<OptionalFields>\n<Field>Size</Field>\n<Field>LastModifiedDate</Field>\n<Field>ETag</Field>\nAmazon S3 API Version 2006-03-01 531",
      "start_idx": 672997,
      "end_idx": 674252,
      "metadata": {
        "num_sentences": 3,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_538",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketLifecycle\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nImportant\nFor an updated version of this API, see PutBucketLifecycleConfiguration. This version\nhas been deprecated. Existing lifecycle configurations will work. For new lifecycle\nconfigurations, use the updated API.\nCreates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration.\nFor information about lifecycle configuration, see Object Lifecycle Management in the Amazon S3\nUser Guide.\nBy default, all Amazon S3 resources, including buckets, objects, and related subresources (for\nexample, lifecycle configuration and website configuration) are private. Only the resource owner,\nthe AWS account that created the resource, can access it. The resource owner can optionally grant\naccess permissions to others by writing an access policy. For this operation, users must get the\ns3:PutLifecycleConfiguration permission.\nYou can also explicitly deny permissions. Explicit denial also supersedes any other permissions. If\nyou want to prevent users or accounts from removing or deleting objects from your bucket, you\nmust deny them permissions for the following actions:\n\u2022 s3:DeleteObject\n\u2022 s3:DeleteObjectVersion\n\u2022 s3:PutLifecycleConfiguration\nFor more information about permissions, see Managing Access Permissions to your Amazon S3\nResources in the Amazon S3 User Guide.\nFor more examples of transitioning objects to storage classes such as STANDARD_IA or\nONEZONE_IA, see Examples of Lifecycle Configuration.\nAmazon S3 API Version 2006-03-01 533",
      "start_idx": 675131,
      "end_idx": 676753,
      "metadata": {
        "num_sentences": 16,
        "num_words": 224,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_539",
      "text": "Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketLifecycle:\n\u2022 GetBucketLifecycle(Deprecated)\n\u2022 GetBucketLifecycleConfiguration\n\u2022 RestoreObject\n\u2022 By default, a resource owner\u2014in this case, a bucket owner, which is the AWS account that\ncreated the bucket\u2014can perform any of the operations. A resource owner can also grant others\npermission to perform the operation. For more information, see the following topics in the\nAmazon S3 User Guide:\n\u2022 Specifying Permissions in a Policy\n\u2022 Managing Access Permissions to your Amazon S3 Resources\nRequest Syntax\nPUT /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Rule>\n<AbortIncompleteMultipartUpload>\n<DaysAfterInitiation>integer</DaysAfterInitiation>\n</AbortIncompleteMultipartUpload>\n<Expiration>\n<Date>timestamp</Date>\n<Days>integer</Days>\n<ExpiredObjectDeleteMarker>boolean</ExpiredObjectDeleteMarker>\n</Expiration>\n<ID>string</ID>\n<NoncurrentVersionExpiration>\n<NewerNoncurrentVersions>integer</NewerNoncurrentVersions>\n<NoncurrentDays>integer</NoncurrentDays>\n</NoncurrentVersionExpiration>\n<NoncurrentVersionTransition>\n<NewerNoncurrentVersions>integer</NewerNoncurrentVersions>\n<NoncurrentDays>integer</NoncurrentDays>\n<StorageClass>string</StorageClass>\n</NoncurrentVersionTransition>\nAmazon S3 API Version 2006-03-01 534",
      "start_idx": 676755,
      "end_idx": 678306,
      "metadata": {
        "num_sentences": 3,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_540",
      "text": "Amazon Simple Storage Service API Reference\n<Prefix>string</Prefix>\n<Status>string</Status>\n<Transition>\n<Date>timestamp</Date>\n<Days>integer</Days>\n<StorageClass>string</StorageClass>\n</Transition>\n</Rule>\n...\n</LifecycleConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nRequired: Yes\nContent-MD5\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 535",
      "start_idx": 678308,
      "end_idx": 679639,
      "metadata": {
        "num_sentences": 11,
        "num_words": 186,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_541",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nLifecycleConfiguration\nRoot level tag for the LifecycleConfiguration parameters.\nRequired: Yes\nRule\nSpecifies lifecycle configuration rules for an Amazon S3 bucket.\nType: Array of Rule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Body of a basic lifecycle configuration\nIn the request, you specify the lifecycle configuration in the request body. The lifecycle\nconfiguration is specified as XML. The following is an example of a basic lifecycle configuration.\nIt specifies one rule. The Prefix in the rule identifies objects to which the rule applies. The rule\nalso specifies two actions (Transition and Expiration). Each action specifies a time line\nwhen Amazon S3 should perform the action. The Status indicates whether the rule is enabled or\ndisabled.\n<LifecycleConfiguration>\n<Rule>\n<ID>sample-rule</ID>\n<Prefix>key-prefix</Prefix>\nAmazon S3 API Version 2006-03-01 536",
      "start_idx": 679641,
      "end_idx": 680774,
      "metadata": {
        "num_sentences": 13,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_542",
      "text": "Amazon Simple Storage Service API Reference\n<Status>rule-status</Status>\n<Transition>\n<Date>value</Date>\n<StorageClass>storage class</StorageClass>\n</Transition>\n<Expiration>\n<Days>value</Days>\n</Expiration>\n</Rule>\n</LifecycleConfiguration>\nSample Request: Body of a lifecycle configuration specifying noncurrent versions\nIf the state of your bucket is versioning-enabled or versioning-suspended, you can have many\nversions of the same object: one current version and zero or more noncurrent versions. The\nfollowing lifecycle configuration specifies the actions (NoncurrentVersionTransition,\nNoncurrentVersionExpiration) that are specific to noncurrent object versions.\n<LifecycleConfiguration>\n<Rule>\n<ID>sample-rule</ID>\n<Prefix>key-prefix</Prefix>\n<Status>rule-status</Status>\n<NoncurrentVersionTransition>\n<NoncurrentDays>value</NoncurrentDays>\n<StorageClass>storage class</StorageClass>\n</NoncurrentVersionTransition>\n<NoncurrentVersionExpiration>\n<NoncurrentDays>value</NoncurrentDays>\n</NoncurrentVersionExpiration>\n</Rule>\n</LifecycleConfiguration>\nSample Request: Body of a lifecycle configuration that specifies a rule with\nAbortIncompleteMultipartUpload\nYou can use the multipart upload to upload large objects in parts. For more information about\nmultipart uploads, see Multipart Upload Overview in the Amazon S3 User Guide. With lifecycle\nconfiguration, you can tell Amazon S3 to abort incomplete multipart uploads, which are identified\nAmazon S3 API Version 2006-03-01 537",
      "start_idx": 680776,
      "end_idx": 682263,
      "metadata": {
        "num_sentences": 5,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_543",
      "text": "Amazon Simple Storage Service API Reference\nby the key name prefix specified in the rule, if they don't complete within a specified number of\ndays. When Amazon S3 aborts a multipart upload, it deletes all parts associated with the upload.\nThis ensures that you don't have incomplete multipart uploads that have left parts stored in\nAmazon S3, so you don't have to pay storage costs for them. The following is an example lifecycle\nconfiguration that specifies a rule with the AbortIncompleteMultipartUpload action. This\naction tells Amazon S3 to abort incomplete multipart uploads seven days after initiation.\n<LifecycleConfiguration>\n<Rule>\n<ID>sample-rule</ID>\n<Prefix>SomeKeyPrefix</Prefix>\n<Status>rule-status</Status>\n<AbortIncompleteMultipartUpload>\n<DaysAfterInitiation>7</DaysAfterInitiation>\n</AbortIncompleteMultipartUpload>\n</Rule>\n</LifecycleConfiguration>\nAdd lifecycle configuration to a bucket that is not versioning-enabled\nThe following is a sample PUT /?lifecycle request that adds the lifecycle configuration to the\nexamplebucket bucket. The lifecycle configuration specifies two rules, each with one action:\n\u2022 The Transition action tells Amazon S3 to transition objects with the \"documents/\" prefix to\nthe GLACIER storage class 30 days after creation.\n\u2022 The Expiration action tells Amazon S3 to delete objects with the \"logs/\" prefix 365 days after\ncreation.\nThe sample response follows the sample request.\nPUT /?lifecycle HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nx-amz-date: Wed, 14 May 2014 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: 415\n<LifecycleConfiguration>\n<Rule>\nAmazon S3 API Version 2006-03-01 538",
      "start_idx": 682265,
      "end_idx": 683966,
      "metadata": {
        "num_sentences": 10,
        "num_words": 218,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_544",
      "text": "Amazon Simple Storage Service API Reference\n<ID>id1</ID>\n<Prefix>documents/</Prefix>\n<Status>Enabled</Status>\n<Transition>\n<Days>30</Days>\n<StorageClass>GLACIER</StorageClass>\n</Transition>\n</Rule>\n<Rule>\n<ID>id2</ID>\n<Prefix>logs/</Prefix>\n<Status>Enabled</Status>\n<Expiration>\n<Days>365</Days>\n</Expiration>\n</Rule>\n</LifecycleConfiguration>\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 14 May 2014 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3\nAdd lifecycle configuration to a bucket that is versioning-enabled\nThe following is a sample PUT /?lifecycle request that adds the lifecycle configuration to the\nexamplebucket bucket. The lifecycle configuration specifies two rules, each with one action. You\nspecify these actions when your bucket is versioning-enabled or versioning is suspended:\n\u2022 The NoncurrentVersionExpiration action tells Amazon S3 to expire noncurrent versions of\nobjects with the \"logs/\" prefix 100 days after the objects become noncurrent.\n\u2022 The NoncurrentVersionTransition action tells Amazon S3 to transition noncurrent versions\nof objects with the \"documents/\" prefix to the GLACIER storage class 30 days after they become\nnoncurrent.\nThe sample response follows the sample request.\nAmazon S3 API Version 2006-03-01 539",
      "start_idx": 683968,
      "end_idx": 685309,
      "metadata": {
        "num_sentences": 6,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_547",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketLifecycleConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration.\nKeep in mind that this will overwrite an existing lifecycle configuration, so if you want to retain any\nconfiguration details, they must be included in the new lifecycle configuration. For information\nabout lifecycle configuration, see Managing your storage lifecycle.\nImportant\nWhen making a request using the REST API, you must include the Content-MD5 header.\nRules\nYou specify the lifecycle configuration in your request body. The lifecycle configuration is\nspecified as XML consisting of one or more rules. An Amazon S3 Lifecycle configuration can\nhave up to 1,000 rules. This limit is not adjustable.\nBucket lifecycle configuration supports specifying a lifecycle rule using an object key name\nprefix, one or more object tags, object size, or any combination of these. Accordingly, this\nsection describes the latest API. The previous version of the API supported filtering based only\non an object key name prefix, which is supported for backward compatibility. For the related\nAPI description, see PutBucketLifecycle.\nA lifecycle rule consists of the following:\n\u2022 A filter identifying a subset of objects to which the rule applies. The filter can be based on a\nkey name prefix, object tags, object size, or any combination of these.\n\u2022 A status indicating whether the rule is in effect.\n\u2022 One or more lifecycle transition and expiration actions that you want Amazon S3 to perform\non the objects identified by the filter. If the state of your bucket is versioning-enabled or\nversioning-suspended, you can have many versions of the same object (one current version\nAmazon S3 API Version 2006-03-01 542",
      "start_idx": 686676,
      "end_idx": 688535,
      "metadata": {
        "num_sentences": 18,
        "num_words": 288,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_548",
      "text": "Amazon Simple Storage Service API Reference\nand zero or more noncurrent versions). Amazon S3 provides predefined actions that you can\nspecify for current and noncurrent object versions.\nFor more information, see Object Lifecycle Management and Lifecycle Configuration Elements.\nPermissions\nBy default, all Amazon S3 resources are private, including buckets, objects, and related\nsubresources (for example, lifecycle configuration and website configuration). Only the resource\nowner (that is, the AWS account that created it) can access the resource. The resource owner can\noptionally grant access permissions to others by writing an access policy. For this operation, a\nuser must get the s3:PutLifecycleConfiguration permission.\nYou can also explicitly deny permissions. An explicit deny also supersedes any other\npermissions. If you want to block users or accounts from removing or deleting objects from your\nbucket, you must deny them permissions for the following actions:\n\u2022 s3:DeleteObject\n\u2022 s3:DeleteObjectVersion\n\u2022 s3:PutLifecycleConfiguration\nFor more information about permissions, see Managing Access Permissions to Your Amazon S3\nResources.\nThe following operations are related to PutBucketLifecycleConfiguration:\n\u2022 Examples of Lifecycle Configuration\n\u2022 GetBucketLifecycleConfiguration\n\u2022 DeleteBucketLifecycle\nRequest Syntax\nPUT /?lifecycle HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-transition-default-minimum-object-size: TransitionDefaultMinimumObjectSize\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Rule>\nAmazon S3 API Version 2006-03-01 543",
      "start_idx": 688537,
      "end_idx": 690260,
      "metadata": {
        "num_sentences": 11,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_550",
      "text": "Amazon Simple Storage Service API Reference\n</Transition>\n...\n</Rule>\n...\n</LifecycleConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which to set the configuration.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-transition-default-minimum-object-size\nIndicates which default minimum object size behavior is applied to the lifecycle configuration.\n\u2022 all_storage_classes_128K - Objects smaller than 128 KB will not transition to any\nstorage class by default.\n\u2022 varies_by_storage_class - Objects smaller than 128 KB will transition to Glacier Flexible\nRetrieval or Glacier Deep Archive storage classes. By default, all other storage classes will\nprevent transitions smaller than 128 KB.\nAmazon S3 API Version 2006-03-01 545",
      "start_idx": 691501,
      "end_idx": 693106,
      "metadata": {
        "num_sentences": 15,
        "num_words": 237,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_551",
      "text": "Amazon Simple Storage Service API Reference\nTo customize the minimum object size for any transition you can add a filter that specifies a\ncustom ObjectSizeGreaterThan or ObjectSizeLessThan in the body of your transition\nrule. Custom filters always take precedence over the default transition behavior.\nValid Values: varies_by_storage_class | all_storage_classes_128K\nRequest Body\nThe request accepts the following data in XML format.\nLifecycleConfiguration\nRoot level tag for the LifecycleConfiguration parameters.\nRequired: Yes\nRule\nA lifecycle rule for individual objects in an Amazon S3 bucket.\nType: Array of LifecycleRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nx-amz-transition-default-minimum-object-size: TransitionDefaultMinimumObjectSize\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-transition-default-minimum-object-size\nIndicates which default minimum object size behavior is applied to the lifecycle configuration.\n\u2022 all_storage_classes_128K - Objects smaller than 128 KB will not transition to any\nstorage class by default.\nAmazon S3 API Version 2006-03-01 546",
      "start_idx": 693108,
      "end_idx": 694298,
      "metadata": {
        "num_sentences": 10,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_552",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 varies_by_storage_class - Objects smaller than 128 KB will transition to Glacier Flexible\nRetrieval or Glacier Deep Archive storage classes. By default, all other storage classes will\nprevent transitions smaller than 128 KB.\nTo customize the minimum object size for any transition you can add a filter that specifies a\ncustom ObjectSizeGreaterThan or ObjectSizeLessThan in the body of your transition\nrule. Custom filters always take precedence over the default transition behavior.\nValid Values: varies_by_storage_class | all_storage_classes_128K\nExamples\nExample 1: Add lifecycle configuration - bucket not versioning-enabled\nThe following lifecycle configuration specifies two rules, each with one action.\n\u2022 The Transition action requests Amazon S3 to transition objects with the \"documents/\" prefix\nto the GLACIER storage class 30 days after creation.\n\u2022 The Expiration action requests Amazon S3 to delete objects with the \"logs/\" prefix 365 days\nafter creation.\n<LifecycleConfiguration>\n<Rule>\n<ID>id1</ID>\n<Filter>\n<Prefix>documents/</Prefix>\n</Filter>\n<Status>Enabled</Status>\n<Transition>\n<Days>30</Days>\n<StorageClass>GLACIER</StorageClass>\n</Transition>\n</Rule>\n<Rule>\n<ID>id2</ID>\n<Filter>\n<Prefix>logs/</Prefix>\n</Filter>\nAmazon S3 API Version 2006-03-01 547",
      "start_idx": 694300,
      "end_idx": 695615,
      "metadata": {
        "num_sentences": 8,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_554",
      "text": "Amazon Simple Storage Service API Reference\n</LifecycleConfiguration>\nSample Response\nThis example illustrates one usage of PutBucketLifecycleConfiguration.\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 14 May 2014 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3\nExample 2: Add lifecycle configuration - bucket is versioning-enabled\nThe following lifecycle configuration specifies two rules, each with one action for Amazon S3\nto perform. You specify these actions when your bucket is versioning-enabled or versioning is\nsuspended:\n\u2022 The NoncurrentVersionExpiration action requests Amazon S3 to expire noncurrent\nversions of objects with the \"logs/\" prefix 100 days after the objects become noncurrent.\n\u2022 The NoncurrentVersionTransition action requests Amazon S3 to transition noncurrent\nversions of objects with the \"documents/\" prefix to the GLACIER storage class 30 days after they\nbecome noncurrent.\n<LifeCycleConfiguration>\n<Rule>\n<ID>DeleteAfterBecomingNonCurrent</ID>\n<Filter>\n<Prefix>logs/</Prefix>\n</Filter>\n<Status>Enabled</Status>\n<NoncurrentVersionExpiration>\n<NoncurrentDays>100</NoncurrentDays>\n</NoncurrentVersionExpiration>\n</Rule>\nAmazon S3 API Version 2006-03-01 549",
      "start_idx": 696488,
      "end_idx": 697765,
      "metadata": {
        "num_sentences": 5,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_557",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketLogging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSet the logging parameters for a bucket and to specify permissions for who can view and modify\nthe logging parameters. All logs are saved to buckets in the same AWS Region as the source bucket.\nTo set the logging status of a bucket, you must be the bucket owner.\nThe bucket owner is automatically granted FULL_CONTROL to all logs. You use the Grantee\nrequest element to grant access to other people. The Permissions request element specifies the\nkind of access the grantee has to the logs.\nImportant\nIf the target bucket for log delivery uses the bucket owner enforced setting for S3\nObject Ownership, you can't use the Grantee request element to grant access to others.\nPermissions can only be granted using policies. For more information, see Permissions for\nserver access log delivery in the Amazon S3 User Guide.\nGrantee Values\nYou can specify the person (grantee) to whom you're assigning access rights (by using request\nelements) in the following ways:\n\u2022 By the person's ID:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-\ninstance\" xsi:type=\"CanonicalUser\"><ID><>ID<></\nID><DisplayName><>GranteesEmail<></DisplayName> </Grantee>\nDisplayName is optional and ignored in the request.\n\u2022 By Email address:\nAmazon S3 API Version 2006-03-01 552",
      "start_idx": 699708,
      "end_idx": 701097,
      "metadata": {
        "num_sentences": 12,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_558",
      "text": "Amazon Simple Storage Service API Reference\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"AmazonCustomerByEmail\"><EmailAddress><>Grantees@email.com<></\nEmailAddress></Grantee>\nThe grantee is resolved to the CanonicalUser and, in a response to a GETObjectAcl\nrequest, appears as the CanonicalUser.\n\u2022 By URI:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"Group\"><URI><>http://acs.amazonaws.com/groups/global/\nAuthenticatedUsers<></URI></Grantee>\nTo enable logging, you use LoggingEnabled and its children request elements. To disable\nlogging, you use an empty BucketLoggingStatus request element:\n<BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\" />\nFor more information about server access logging, see Server Access Logging in the Amazon S3\nUser Guide.\nFor more information about creating a bucket, see CreateBucket. For more information about\nreturning the logging status of a bucket, see GetBucketLogging.\nThe following operations are related to PutBucketLogging:\n\u2022 PutObject\n\u2022 DeleteBucket\n\u2022 CreateBucket\n\u2022 GetBucketLogging\nRequest Syntax\nPUT /?logging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 API Version 2006-03-01 553",
      "start_idx": 701099,
      "end_idx": 702462,
      "metadata": {
        "num_sentences": 6,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_560",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nBucketLoggingStatus\nRoot level tag for the BucketLoggingStatus parameters.\nRequired: Yes\nLoggingEnabled\nDescribes where logs are stored and the prefix that Amazon S3 assigns to all log object keys for\na bucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nType: LoggingEnabled data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 555",
      "start_idx": 703482,
      "end_idx": 704831,
      "metadata": {
        "num_sentences": 13,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_561",
      "text": "Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request\nThis request enables logging and gives the grantee of the bucket READ access to the logs.\nBuckets that use the bucket owner enforced setting for Object Ownership to disable ACLs don't\nsupport target grants. For more information, see Permissions for server access log delivery in the\nAmazon S3 User Guide.\nPUT ?logging HTTP/1.1\nHost: quotes.s3.<Region>.amazonaws.com\nContent-Length: 214\nDate: Wed, 25 Nov 2009 12:00:00 GMT\nAuthorization: authorization string\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<BucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<LoggingEnabled>\n<TargetBucket>mybucketlogs</TargetBucket>\n<TargetPrefix>mybucket-access_log-/</TargetPrefix>\n<TargetGrants>\n<Grant>\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"AmazonCustomerByEmail\">\n<EmailAddress>user@company.com</EmailAddress>\n</Grantee>\n<Permission>READ</Permission>\n</Grant>\n</TargetGrants>\n</LoggingEnabled>\n</BucketLoggingStatus>\nSample Response\nThis example illustrates one usage of PutBucketLogging.\nAmazon S3 API Version 2006-03-01 556",
      "start_idx": 704833,
      "end_idx": 706074,
      "metadata": {
        "num_sentences": 6,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_564",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketMetricsConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets a metrics configuration (specified by the metrics configuration ID) for the bucket. You can have\nup to 1,000 metrics configurations per bucket. If you're updating an existing metrics configuration,\nnote that this is a full replacement of the existing metrics configuration. If you don't include the\nelements you want to keep, they are erased.\nTo use this operation, you must have permissions to perform the\ns3:PutMetricsConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nPermissions Related to Bucket Subresource Operations and Managing Access Permissions to Your\nAmazon S3 Resources.\nFor information about CloudWatch request metrics for Amazon S3, see Monitoring Metrics with\nAmazon CloudWatch.\nThe following operations are related to PutBucketMetricsConfiguration:\n\u2022 DeleteBucketMetricsConfiguration\n\u2022 GetBucketMetricsConfiguration\n\u2022 ListBucketMetricsConfigurations\nPutBucketMetricsConfiguration has the following special error:\n\u2022 Error code: TooManyConfigurations\n\u2022 Description: You are attempting to create a new configuration but have already reached the\n1,000-configuration limit.\n\u2022 HTTP Status Code: HTTP 400 Bad Request\nRequest Syntax\nPUT /?metrics&id=Id HTTP/1.1\nAmazon S3 API Version 2006-03-01 559",
      "start_idx": 707301,
      "end_idx": 708784,
      "metadata": {
        "num_sentences": 12,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_565",
      "text": "Amazon Simple Storage Service API Reference\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<MetricsConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Id>string</Id>\n<Filter>\n<AccessPointArn>string</AccessPointArn>\n<And>\n<AccessPointArn>string</AccessPointArn>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n...\n</And>\n<Prefix>string</Prefix>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Filter>\n</MetricsConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket for which the metrics configuration is set.\nRequired: Yes\nid\nThe ID used to identify the metrics configuration. The ID has a 64 character limit and can only\ncontain letters, numbers, periods, dashes, and underscores.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 560",
      "start_idx": 708786,
      "end_idx": 709696,
      "metadata": {
        "num_sentences": 5,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_566",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nMetricsConfiguration\nRoot level tag for the MetricsConfiguration parameters.\nRequired: Yes\nFilter\nSpecifies a metrics configuration filter. The metrics configuration will only include objects\nthat meet the filter's criteria. A filter must be a prefix, an object tag, an access point ARN, or a\nconjunction (MetricsAndOperator).\nType: MetricsFilter data type\nRequired: No\nId\nThe ID used to identify the metrics configuration. The ID has a 64 character limit and can only\ncontain letters, numbers, periods, dashes, and underscores.\nType: String\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nAmazon S3 API Version 2006-03-01 561",
      "start_idx": 709698,
      "end_idx": 710776,
      "metadata": {
        "num_sentences": 11,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_571",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket.\nRequired: Yes\nContent-MD5\nThe MD5 hash of the PutPublicAccessBlock request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nNotificationConfiguration\nRoot level tag for the NotificationConfiguration parameters.\nAmazon S3 API Version 2006-03-01 566",
      "start_idx": 714902,
      "end_idx": 716273,
      "metadata": {
        "num_sentences": 15,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_572",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nCloudFunctionConfiguration\nContainer for specifying the AWS Lambda notification configuration.\nType: CloudFunctionConfiguration data type\nRequired: No\nQueueConfiguration\nThis data type is deprecated. This data type specifies the configuration for publishing messages\nto an Amazon Simple Queue Service (Amazon SQS) queue when Amazon S3 detects specified\nevents.\nType: QueueConfigurationDeprecated data type\nRequired: No\nTopicConfiguration\nThis data type is deprecated. A container for specifying the configuration for publication of\nmessages to an Amazon Simple Notification Service (Amazon SNS) topic when Amazon S3\ndetects specified events.\nType: TopicConfigurationDeprecated data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\nAmazon S3 API Version 2006-03-01 567",
      "start_idx": 716275,
      "end_idx": 717355,
      "metadata": {
        "num_sentences": 7,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_574",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketNotificationConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nEnables notifications of specified events for a bucket. For more information about event\nnotifications, see Configuring Event Notifications.\nUsing this API, you can replace an existing notification configuration. The configuration is an XML\nfile that defines the event types that you want Amazon S3 to publish and the destination where\nyou want Amazon S3 to publish an event notification when it detects an event of the specified\ntype.\nBy default, your bucket has no event notifications configured. That is, the notification configuration\nwill be an empty NotificationConfiguration.\n<NotificationConfiguration>\n</NotificationConfiguration>\nThis action replaces the existing notification configuration with the configuration you include in the\nrequest body.\nAfter Amazon S3 receives this request, it first verifies that any Amazon Simple Notification Service\n(Amazon SNS) or Amazon Simple Queue Service (Amazon SQS) destination exists, and that the\nbucket owner has permission to publish to it by sending a test notification. In the case of AWS\nLambda destinations, Amazon S3 verifies that the Lambda function permissions grant Amazon\nS3 permission to invoke the function from the Amazon S3 bucket. For more information, see\nConfiguring Notifications for Amazon S3 Events.\nYou can disable notifications by adding the empty NotificationConfiguration element.\nFor more information about the number of event notification configurations that you can create\nper bucket, see Amazon S3 service quotas in AWS General Reference.\nBy default, only the bucket owner can configure notifications on a bucket. However, bucket owners\ncan use a bucket policy to grant permission to other users to set this configuration with the\nrequired s3:PutBucketNotification permission.\nAmazon S3 API Version 2006-03-01 569",
      "start_idx": 717610,
      "end_idx": 719560,
      "metadata": {
        "num_sentences": 16,
        "num_words": 280,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_575",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThe PUT notification is an atomic operation. For example, suppose your notification\nconfiguration includes SNS topic, SQS queue, and Lambda function configurations. When\nyou send a PUT request with this configuration, Amazon S3 sends test messages to your\nSNS topic. If the message fails, the entire PUT action will fail, and Amazon S3 will not add\nthe configuration to your bucket.\nIf the configuration in the request body includes only one TopicConfiguration specifying only\nthe s3:ReducedRedundancyLostObject event type, the response will also include the x-amz-\nsns-test-message-id header containing the message ID of the test notification sent to the\ntopic.\nThe following action is related to PutBucketNotificationConfiguration:\n\u2022 GetBucketNotificationConfiguration\nRequest Syntax\nPUT /?notification HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-skip-destination-validation: SkipDestinationValidation\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<NotificationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<TopicConfiguration>\n<Event>string</Event>\n...\n<Filter>\n<S3Key>\n<FilterRule>\n<Name>string</Name>\n<Value>string</Value>\n</FilterRule>\n...\n</S3Key>\n</Filter>\n<Id>string</Id>\n<Topic>string</Topic>\n</TopicConfiguration>\nAmazon S3 API Version 2006-03-01 570",
      "start_idx": 719562,
      "end_idx": 720932,
      "metadata": {
        "num_sentences": 6,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_577",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-skip-destination-validation\nSkips validation of Amazon SQS, Amazon SNS, and AWS Lambda destinations. True or false\nvalue.\nRequest Body\nThe request accepts the following data in XML format.\nNotificationConfiguration\nRoot level tag for the NotificationConfiguration parameters.\nRequired: Yes\nCloudFunctionConfiguration\nDescribes the AWS Lambda functions to invoke and the events for which to invoke them.\nType: Array of LambdaFunctionConfiguration data types\nRequired: No\nEventBridgeConfiguration\nEnables delivery of events to Amazon EventBridge.\nType: EventBridgeConfiguration data type\nRequired: No\nQueueConfiguration\nThe Amazon Simple Queue Service queues to publish messages to and the events for which to\npublish messages.\nType: Array of QueueConfiguration data types\nAmazon S3 API Version 2006-03-01 572",
      "start_idx": 721677,
      "end_idx": 722778,
      "metadata": {
        "num_sentences": 10,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_578",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nTopicConfiguration\nThe topic to which notifications are sent and the events for which notifications are generated.\nType: Array of TopicConfiguration data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample 1: Configure notification to invoke a cloud function in Lambda\nThe following notification configuration includes CloudFunctionConfiguration, which identifies the\nevent type for which Amazon S3 can invoke a cloud function and the name of the cloud function to\ninvoke.\n<NotificationConfiguration>\n<CloudFunctionConfiguration>\n<Id>ObjectCreatedEvents</Id>\n<CloudFunction>arn:aws:lambda:us-west-2:35667example:function:CreateThumbnail</\nCloudFunction>\n<Event>s3:ObjectCreated:*</Event>\n</CloudFunctionConfiguration>\n</NotificationConfiguration>\nExample\nThe following PUT uploads the notification configuration. The action replaces the existing\nnotification configuration.\nAmazon S3 API Version 2006-03-01 573",
      "start_idx": 722780,
      "end_idx": 723876,
      "metadata": {
        "num_sentences": 6,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_580",
      "text": "Amazon Simple Storage Service API Reference\n<Topic>arn:aws:sns:us-east-1:356671443308:s3notificationtopic2</Topic>\n<Event>s3:ReducedRedundancyLostObject</Event>\n</TopicConfiguration>\n<QueueConfiguration>\n<Queue>arn:aws:sqs:us-east-1:356671443308:s3notificationqueue</Queue>\n<Event>s3:ObjectCreated:*</Event>\n</QueueConfiguration>\n</NotificationConfiguration>\nExample\nThe following PUT request against the notification subresource of the examplebucket bucket\nsends the preceding notification configuration in the request body. The action replaces the existing\nnotification configuration on the bucket.\nPUT http://s3.<Region>.amazonaws.com/examplebucket?notification= HTTP/1.1\nUser-Agent: s3curl 2.0\nHost: s3.amazonaws.com\nPragma: no-cache\nAccept: */*\nProxy-Connection: Keep-Alive\nAuthorization: authorization string\nDate: Mon, 13 Oct 2014 22:58:43 +0000\nContent-Length: 391\nExpect: 100-continue\nExample 3: Configure a notification with object key name filtering\nThe following notification configuration contains a queue configuration identifying an Amazon\nSQS queue for Amazon S3 to publish events to of the s3:ObjectCreated:Put type. The events\nwill be published whenever an object that has a prefix of images/ and a .jpg suffix is PUT to a\nbucket. For more examples of notification configurations that use filtering, see Configuring Event\nNotifications.\n<NotificationConfiguration>\n<QueueConfiguration>\nAmazon S3 API Version 2006-03-01 575",
      "start_idx": 724975,
      "end_idx": 726415,
      "metadata": {
        "num_sentences": 6,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_581",
      "text": "Amazon Simple Storage Service API Reference\n<Id>1</Id>\n<Filter>\n<S3Key>\n<FilterRule>\n<Name>prefix</Name>\n<Value>images/</Value>\n</FilterRule>\n<FilterRule>\n<Name>suffix</Name>\n<Value>.jpg</Value>\n</FilterRule>\n</S3Key>\n</Filter>\n<Queue>arn:aws:sqs:us-west-2:444455556666:s3notificationqueue</Queue>\n<Event>s3:ObjectCreated:Put</Event>\n</QueueConfiguration>\n</NotificationConfiguration>\nExample\nThe following PUT request against the notification subresource of the examplebucket bucket\nsends the preceding notification configuration in the request body. The action replaces the existing\nnotification configuration on the bucket.\nPUT http://s3.<Region>.amazonaws.com/examplebucket?notification= HTTP/1.1\nUser-Agent: s3curl 2.0\nHost: s3.amazonaws.com\nPragma: no-cache\nAccept: */*\nProxy-Connection: Keep-Alive\nAuthorization: authorization string\nDate: Mon, 13 Oct 2014 22:58:43 +0000\nContent-Length: length\nExpect: 100-continue\nSample Response\nThis example illustrates one usage of PutBucketNotificationConfiguration.\nAmazon S3 API Version 2006-03-01 576",
      "start_idx": 726417,
      "end_idx": 727466,
      "metadata": {
        "num_sentences": 4,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_583",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketOwnershipControls\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates or modifies OwnershipControls for an Amazon S3 bucket. To use this operation, you\nmust have the s3:PutBucketOwnershipControls permission. For more information about\nAmazon S3 permissions, see Specifying permissions in a policy.\nFor information about Amazon S3 Object Ownership, see Using object ownership.\nThe following operations are related to PutBucketOwnershipControls:\n\u2022 GetBucketOwnershipControls\n\u2022 DeleteBucketOwnershipControls\nRequest Syntax\nPUT /?ownershipControls HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<OwnershipControls xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Rule>\n<ObjectOwnership>string</ObjectOwnership>\n</Rule>\n...\n</OwnershipControls>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose OwnershipControls you want to set.\nAmazon S3 API Version 2006-03-01 578",
      "start_idx": 728061,
      "end_idx": 729180,
      "metadata": {
        "num_sentences": 8,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_584",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nContent-MD5\nThe MD5 hash of the OwnershipControls request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nRequest Body\nThe request accepts the following data in XML format.\nOwnershipControls\nRoot level tag for the OwnershipControls parameters.\nRequired: Yes\nRule\nThe container element for an ownership control rule.\nType: Array of OwnershipControlsRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nAmazon S3 API Version 2006-03-01 579",
      "start_idx": 729182,
      "end_idx": 730101,
      "metadata": {
        "num_sentences": 9,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_588",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketPolicy\nService: Amazon S3\nApplies an Amazon S3 bucket policy to an Amazon S3 bucket.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Regional endpoint. These endpoints support path-style requests in the format\nhttps://s3express-control.region_code.amazonaws.com/bucket-name .\nVirtual-hosted-style requests aren't supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nPermissions\nIf you are using an identity other than the root user of the AWS account that owns the bucket,\nthe calling identity must both have the PutBucketPolicy permissions on the specified bucket\nand belong to the bucket owner's account in order to use this operation.\nIf you don't have PutBucketPolicy permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the\nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed error.\nImportant\nTo ensure that bucket owners don't inadvertently lock themselves out of their\nown buckets, the root principal in a bucket owner's AWS account can perform the\nGetBucketPolicy, PutBucketPolicy, and DeleteBucketPolicy API actions,\neven if their bucket policy explicitly denies the root principal's access. Bucket owner\nroot principals can only be blocked from performing these API actions by VPC endpoint\npolicies and AWS Organizations policies.\n\u2022 General purpose bucket permissions - The s3:PutBucketPolicy permission is required\nin a policy. For more information about general purpose buckets bucket policies, see Using\nBucket Policies and User Policies in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation, you must have the\ns3express:PutBucketPolicy permission in an IAM identity-based policy instead of a\nAmazon S3 API Version 2006-03-01 583",
      "start_idx": 733463,
      "end_idx": 735405,
      "metadata": {
        "num_sentences": 13,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_589",
      "text": "Amazon Simple Storage Service API Reference\nbucket policy. Cross-account access to this API operation isn't supported. This operation can\nonly be performed by the AWS account that owns the resource. For more information about\ndirectory bucket policies and permissions, see AWS Identity and Access Management (IAM) for\nS3 Express One Zone in the Amazon S3 User Guide.\nExample bucket policies\nGeneral purpose buckets example bucket policies - See Bucket policy examples in the Amazon\nS3 User Guide.\nDirectory bucket example bucket policies - See Example bucket policies for S3 Express One\nZone in the Amazon S3 User Guide.\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is s3express-\ncontrol.region.amazonaws.com.\nThe following operations are related to PutBucketPolicy:\n\u2022 CreateBucket\n\u2022 DeleteBucket\nRequest Syntax\nPUT /?policy HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-confirm-remove-self-bucket-access: ConfirmRemoveSelfBucketAccess\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n{ Policy in JSON format }\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket.\nAmazon S3 API Version 2006-03-01 584",
      "start_idx": 735407,
      "end_idx": 736653,
      "metadata": {
        "num_sentences": 10,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_590",
      "text": "Amazon Simple Storage Service API Reference\nDirectory buckets - When you use this operation with a directory bucket,\nyou must use path-style requests in the format https://s3express-\ncontrol.region_code.amazonaws.com/bucket-name . Virtual-hosted-style requests\naren't supported. Directory bucket names must be unique in the chosen Availability Zone.\nBucket names must also follow the format bucket_base_name--az_id--x-s3 (for\nexample, DOC-EXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming\nrestrictions, see Directory bucket naming rules in the Amazon S3 User Guide\nRequired: Yes\nContent-MD5\nThe MD5 hash of the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-confirm-remove-self-bucket-access\nSet this parameter to true to confirm that you want to remove your permissions to change this\nbucket policy in the future.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 585",
      "start_idx": 736655,
      "end_idx": 737970,
      "metadata": {
        "num_sentences": 12,
        "num_words": 184,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_591",
      "text": "Amazon Simple Storage Service API Reference\nNote\nFor directory buckets, this header is not supported in this API operation. If you specify\nthis header, the request fails with the HTTP status code 501 Not Implemented.\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.\nThis header will not provide any additional functionality if you don't use the SDK. When you\nsend this header, there must be a corresponding x-amz-checksum-algorithm or x-amz-\ntrailer header sent. Otherwise, Amazon S3 fails the request with the HTTP status code 400\nBad Request.\nFor the x-amz-checksum-algorithm header, replace algorithm with the supported\nalgorithm from the following list:\n\u2022 CRC32\n\u2022 CRC32C\n\u2022 SHA1\n\u2022 SHA256\nFor more information, see Checking object integrity in the Amazon S3 User Guide.\nIf the individual checksum value you provide through x-amz-checksum-algorithm doesn't\nmatch the checksum algorithm you set through x-amz-sdk-checksum-algorithm, Amazon\nS3 ignores any provided ChecksumAlgorithm parameter and uses the checksum algorithm\nthat matches the provided value in x-amz-checksum-algorithm .\nNote\nFor directory buckets, when you use AWS SDKs, CRC32 is the default checksum\nalgorithm that's used for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 586",
      "start_idx": 737972,
      "end_idx": 739328,
      "metadata": {
        "num_sentences": 10,
        "num_words": 203,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_594",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketReplication\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates a replication configuration or replaces an existing one. For more information, see\nReplication in the Amazon S3 User Guide.\nSpecify the replication configuration in the request body. In the replication configuration, you\nprovide the name of the destination bucket or buckets where you want Amazon S3 to replicate\nobjects, the IAM role that Amazon S3 can assume to replicate objects on your behalf, and\nother relevant information. You can invoke this request for a specific AWS Region by using the\naws:RequestedRegion condition key.\nA replication configuration must include at least one rule, and can contain a maximum of 1,000.\nEach rule identifies a subset of objects to replicate by filtering the objects in the source bucket. To\nchoose additional subsets of objects to replicate, add a rule for each subset.\nTo specify a subset of the objects in the source bucket to apply a replication rule to, add the Filter\nelement as a child of the Rule element. You can filter objects based on an object key prefix, one or\nmore object tags, or both. When you add the Filter element in the configuration, you must also add\nthe following elements: DeleteMarkerReplication, Status, and Priority.\nNote\nIf you are using an earlier version of the replication configuration, Amazon S3\nhandles replication of delete markers differently. For more information, see Backward\nCompatibility.\nFor information about enabling versioning on a bucket, see Using Versioning.\nHandling Replication of Encrypted Objects\nBy default, Amazon S3 doesn't replicate objects that are stored at rest using server-\nside encryption with KMS keys. To replicate AWS KMS-encrypted objects, add the\nfollowing: SourceSelectionCriteria, SseKmsEncryptedObjects, Status,\nAmazon S3 API Version 2006-03-01 589",
      "start_idx": 740801,
      "end_idx": 742711,
      "metadata": {
        "num_sentences": 17,
        "num_words": 293,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_595",
      "text": "Amazon Simple Storage Service API Reference\nEncryptionConfiguration, and ReplicaKmsKeyID. For information about replication\nconfiguration, see Replicating Objects Created with SSE Using KMS keys.\nFor information on PutBucketReplication errors, see List of replication-related error codes\nPermissions\nTo create a PutBucketReplication request, you must have\ns3:PutReplicationConfiguration permissions for the bucket.\nBy default, a resource owner, in this case the AWS account that created the bucket, can perform\nthis operation. The resource owner can also grant others permissions to perform the operation.\nFor more information about permissions, see Specifying Permissions in a Policy and Managing\nAccess Permissions to Your Amazon S3 Resources.\nNote\nTo perform this operation, the user or role performing the action must have the\niam:PassRole permission.\nThe following operations are related to PutBucketReplication:\n\u2022 GetBucketReplication\n\u2022 DeleteBucketReplication\nRequest Syntax\nPUT /?replication HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-bucket-object-lock-token: Token\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ReplicationConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Role>string</Role>\n<Rule>\n<DeleteMarkerReplication>\n<Status>string</Status>\n</DeleteMarkerReplication>\nAmazon S3 API Version 2006-03-01 590",
      "start_idx": 742713,
      "end_idx": 744165,
      "metadata": {
        "num_sentences": 8,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_597",
      "text": "Amazon Simple Storage Service API Reference\n<SourceSelectionCriteria>\n<ReplicaModifications>\n<Status>string</Status>\n</ReplicaModifications>\n<SseKmsEncryptedObjects>\n<Status>string</Status>\n</SseKmsEncryptedObjects>\n</SourceSelectionCriteria>\n<Status>string</Status>\n</Rule>\n...\n</ReplicationConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. You must use this header as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-bucket-object-lock-token\nA token to allow Object Lock to be enabled for an existing bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nAmazon S3 API Version 2006-03-01 592",
      "start_idx": 745086,
      "end_idx": 746416,
      "metadata": {
        "num_sentences": 11,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_598",
      "text": "Amazon Simple Storage Service API Reference\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nReplicationConfiguration\nRoot level tag for the ReplicationConfiguration parameters.\nRequired: Yes\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role\nthat Amazon S3 assumes when replicating objects. For more information, see How to Set Up\nReplication in the Amazon S3 User Guide.\nType: String\nRequired: Yes\nRule\nA container for one or more replication rules. A replication configuration must have at least one\nrule and can contain a maximum of 1,000 rules.\nType: Array of ReplicationRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 593",
      "start_idx": 746418,
      "end_idx": 747540,
      "metadata": {
        "num_sentences": 11,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_599",
      "text": "Amazon Simple Storage Service API Reference\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Add a replication configuration\nThe following is a sample PUT request that creates a replication subresource on the specified\nbucket and saves the replication configuration in it. The replication configuration specifies a rule to\nreplicate objects to the DOC-EXAMPLE-BUCKET bucket. The rule includes a filter to replicate only\nthe objects created with the key name prefix TaxDocs and that have two specific tags.\nAfter you add a replication configuration to your bucket, Amazon S3 assumes the AWS Identity and\nAccess Management (IAM) role specified in the configuration to replicate objects on behalf of the\nbucket owner. The bucket owner is the AWS account that created the bucket.\nFiltering using the <Filter> element is supported in the latest XML configuration. If you are using an\nearlier version of the XML configuration, you can filter only on key prefix. In that case, you add the\n<Prefix> element as a child of the <Rule>.\nFor more examples of replication configuration, see Replication Configuration Overview in the\nAmazon S3 User Guide.\nPUT /?replication HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Wed, 11 Feb 2015 02:11:21 GMT\nContent-MD5: q6yJDlIkcBaGGfb3QLY69A==\nAuthorization: authorization string\nContent-Length: length\n<ReplicationConfiguration>\n<Role>arn:aws:iam::35667example:role/CrossRegionReplicationRoleForS3</Role>\n<Rule>\n<ID>rule1</ID>\n<Status>Enabled</Status>\n<Priority>1</Priority>\n<DeleteMarkerReplication>\n<Status>Disabled</Status>\n</DeleteMarkerReplication>\n<Filter>\n<And>\nAmazon S3 API Version 2006-03-01 594",
      "start_idx": 747542,
      "end_idx": 749284,
      "metadata": {
        "num_sentences": 11,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_600",
      "text": "Amazon Simple Storage Service API Reference\n<Prefix>TaxDocs</Prefix>\n<Tag>\n<Key>key1</Key>\n<Value>value1</Value>\n</Tag>\n<Tag>\n<Key>key1</Key>\n<Value>value1</Value>\n</Tag>\n</And>\n</Filter>\n<Destination>\n<Bucket>arn:aws:s3:::DOC-EXAMPLE-BUCKET</Bucket>\n</Destination>\n</Rule>\n</ReplicationConfiguration>\nSample Response\nThis example illustrates one usage of PutBucketReplication.\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 11 Feb 2015 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3\nSample Request: Add a Replication Configuration with Amazon S3 Replication Time Control\nEnabled\nYou can use S3 Replication Time Control (S3 RTC) to replicate your data in the same AWS Region\nor across different AWS Regions in a predictable time frame. S3 RTC replicates 99.99 percent of\nnew objects stored in Amazon S3 within 15 minutes. For more information, see Replicating objects\nusing Replication Time Control.\nPUT /?replication HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 595",
      "start_idx": 749286,
      "end_idx": 750388,
      "metadata": {
        "num_sentences": 5,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_603",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketRequestPayment\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the request payment configuration for a bucket. By default, the bucket owner pays for\ndownloads from the bucket. This configuration parameter enables the bucket owner (only) to\nspecify that the person requesting the download will be charged for the download. For more\ninformation, see Requester Pays Buckets.\nThe following operations are related to PutBucketRequestPayment:\n\u2022 CreateBucket\n\u2022 GetBucketRequestPayment\nRequest Syntax\nPUT /?requestPayment HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<RequestPaymentConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Payer>string</Payer>\n</RequestPaymentConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 598",
      "start_idx": 751724,
      "end_idx": 752800,
      "metadata": {
        "num_sentences": 8,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_604",
      "text": "Amazon Simple Storage Service API Reference\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. You must use this header as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nRequestPaymentConfiguration\nRoot level tag for the RequestPaymentConfiguration parameters.\nRequired: Yes\nPayer\nSpecifies who pays for the download and request fees.\nType: String\nAmazon S3 API Version 2006-03-01 599",
      "start_idx": 752802,
      "end_idx": 754297,
      "metadata": {
        "num_sentences": 16,
        "num_words": 231,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_607",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the tags for a bucket.\nUse tags to organize your AWS bill to reflect your own cost structure. To do this, sign up to get\nyour AWS account bill with tag key values included. Then, to see the cost of combined resources,\norganize your billing information according to resources with the same tag key values. For example,\nyou can tag several resources with a specific application name, and then organize your billing\ninformation to see the total cost of that application across several services. For more information,\nsee Cost Allocation and Tagging and Using Cost Allocation in Amazon S3 Bucket Tags.\nNote\nWhen this operation sets the tags for a bucket, it will overwrite any current tags the bucket\nalready has. You cannot use this operation to add tags to an existing list of tags.\nTo use this operation, you must have permissions to perform the s3:PutBucketTagging action.\nThe bucket owner has this permission by default and can grant this permission to others. For more\ninformation about permissions, see Permissions Related to Bucket Subresource Operations and\nManaging Access Permissions to Your Amazon S3 Resources.\nPutBucketTagging has the following special errors. For more Amazon S3 errors see, Error\nResponses.\n\u2022 InvalidTag - The tag provided was not a valid tag. This error can occur if the tag did not pass\ninput validation. For more information, see Using Cost Allocation in Amazon S3 Bucket Tags.\n\u2022 MalformedXML - The XML provided does not match the schema.\n\u2022 OperationAborted - A conflicting conditional action is currently in progress against this\nresource. Please try again.\n\u2022 InternalError - The service was unable to apply the provided tag to the bucket.\nAmazon S3 API Version 2006-03-01 602",
      "start_idx": 755770,
      "end_idx": 757622,
      "metadata": {
        "num_sentences": 22,
        "num_words": 302,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_608",
      "text": "Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketTagging:\n\u2022 GetBucketTagging\n\u2022 DeleteBucketTagging\nRequest Syntax\nPUT /?tagging HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<TagSet>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</TagSet>\n</Tagging>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. You must use this header as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nAmazon S3 API Version 2006-03-01 603",
      "start_idx": 757624,
      "end_idx": 758609,
      "metadata": {
        "num_sentences": 7,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_609",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nA collection for a set of tags\nType: Array of Tag data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 API Version 2006-03-01 604",
      "start_idx": 758611,
      "end_idx": 759775,
      "metadata": {
        "num_sentences": 11,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_612",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketVersioning\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nNote\nWhen you enable versioning on a bucket for the first time, it might take a short amount of\ntime for the change to be fully propagated. We recommend that you wait for 15 minutes\nafter enabling versioning before issuing write operations (PUT or DELETE) on objects in the\nbucket.\nSets the versioning state of an existing bucket.\nYou can set the versioning state with one of the following values:\nEnabled\u2014Enables versioning for the objects in the bucket. All objects added to the bucket receive\na unique version ID.\nSuspended\u2014Disables versioning for the objects in the bucket. All objects added to the bucket\nreceive the version ID null.\nIf the versioning state has never been set on a bucket, it has no versioning state; a\nGetBucketVersioning request does not return a versioning state value.\nIn order to enable MFA Delete, you must be the bucket owner. If you are the bucket owner and\nwant to enable MFA Delete in the bucket versioning configuration, you must include the x-amz-\nmfa request header and the Status and the MfaDelete request elements in a request to set\nthe versioning state of the bucket.\nImportant\nIf you have an object expiration lifecycle configuration in your non-versioned bucket\nand you want to maintain the same permanent delete behavior when you enable\nversioning, you must add a noncurrent expiration policy. The noncurrent expiration\nAmazon S3 API Version 2006-03-01 607",
      "start_idx": 761030,
      "end_idx": 762570,
      "metadata": {
        "num_sentences": 13,
        "num_words": 252,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_613",
      "text": "Amazon Simple Storage Service API Reference\nlifecycle configuration will manage the deletes of the noncurrent object versions in the\nversion-enabled bucket. (A version-enabled bucket maintains one current and zero or more\nnoncurrent object versions.) For more information, see Lifecycle and Versioning.\nThe following operations are related to PutBucketVersioning:\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 GetBucketVersioning\nRequest Syntax\nPUT /?versioning HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-mfa: MFA\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<MfaDelete>string</MfaDelete>\n<Status>string</Status>\n</VersioningConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nContent-MD5\n>The base64-encoded 128-bit MD5 digest of the data. You must use this header as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, see RFC 1864.\nAmazon S3 API Version 2006-03-01 608",
      "start_idx": 762572,
      "end_idx": 763749,
      "metadata": {
        "num_sentences": 9,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_614",
      "text": "Amazon Simple Storage Service API Reference\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is\ndisplayed on your authentication device.\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nVersioningConfiguration\nRoot level tag for the VersioningConfiguration parameters.\nRequired: Yes\nMFADelete\nSpecifies whether MFA delete is enabled in the bucket versioning configuration. This element is\nonly returned if the bucket has been configured with MFA delete. If the bucket has never been\nso configured, this element is not returned.\nType: String\nAmazon S3 API Version 2006-03-01 609",
      "start_idx": 763751,
      "end_idx": 765354,
      "metadata": {
        "num_sentences": 16,
        "num_words": 245,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_616",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar 2006 12:00:00 GMT3\nSample Request\nThe following request suspends versioning for the specified bucket.\nPUT /?versioning HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: 124\n<VersioningConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Status>Suspended</Status>\n</VersioningConfiguration>\nSample Response\nThis example illustrates one usage of PutBucketVersioning.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMg95r/0zo3emzU4dzsD4rcKCHQUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 236A8905248E5A01\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nSample Request\nThe following request enables versioning and MFA Delete on a bucket. Note the space between\n[SerialNumber] and [TokenCode] and that you must include Status whenever you use\nMfaDelete.\nAmazon S3 API Version 2006-03-01 611",
      "start_idx": 766206,
      "end_idx": 767282,
      "metadata": {
        "num_sentences": 5,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_619",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketWebsite\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the configuration of the website that is specified in the website subresource. To configure\na bucket as a website, you can add this subresource on the bucket with website configuration\ninformation such as the file name of the index document and any redirect rules. For more\ninformation, see Hosting Websites on Amazon S3.\nThis PUT action requires the S3:PutBucketWebsite permission. By default, only the bucket\nowner can configure the website attached to a bucket; however, bucket owners can allow\nother users to set the website configuration by writing a bucket policy that grants them the\nS3:PutBucketWebsite permission.\nTo redirect all website requests sent to the bucket's website endpoint, you add a website\nconfiguration with the following elements. Because all requests are sent to another website, you\ndon't need to provide index document name for the bucket.\n\u2022 WebsiteConfiguration\n\u2022 RedirectAllRequestsTo\n\u2022 HostName\n\u2022 Protocol\nIf you want granular control over redirects, you can use the following elements to add routing rules\nthat describe conditions for redirecting requests and information about the redirect destination. In\nthis case, the website configuration must provide an index document for the bucket, because some\nrequests might not be redirected.\n\u2022 WebsiteConfiguration\n\u2022 IndexDocument\n\u2022 Suffix\n\u2022 ErrorDocument\nAmazon S3 API Version 2006-03-01 614",
      "start_idx": 768454,
      "end_idx": 769968,
      "metadata": {
        "num_sentences": 11,
        "num_words": 228,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_620",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Key\n\u2022 RoutingRules\n\u2022 RoutingRule\n\u2022 Condition\n\u2022 HttpErrorCodeReturnedEquals\n\u2022 KeyPrefixEquals\n\u2022 Redirect\n\u2022 Protocol\n\u2022 HostName\n\u2022 ReplaceKeyPrefixWith\n\u2022 ReplaceKeyWith\n\u2022 HttpRedirectCode\nAmazon S3 has a limitation of 50 routing rules per website configuration. If you require more than\n50 routing rules, you can use object redirect. For more information, see Configuring an Object\nRedirect in the Amazon S3 User Guide.\nThe maximum request length is limited to 128 KB.\nRequest Syntax\nPUT /?website HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<WebsiteConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<ErrorDocument>\n<Key>string</Key>\n</ErrorDocument>\n<IndexDocument>\n<Suffix>string</Suffix>\n</IndexDocument>\n<RedirectAllRequestsTo>\n<HostName>string</HostName>\nAmazon S3 API Version 2006-03-01 615",
      "start_idx": 769970,
      "end_idx": 770977,
      "metadata": {
        "num_sentences": 5,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_621",
      "text": "Amazon Simple Storage Service API Reference\n<Protocol>string</Protocol>\n</RedirectAllRequestsTo>\n<RoutingRules>\n<RoutingRule>\n<Condition>\n<HttpErrorCodeReturnedEquals>string</HttpErrorCodeReturnedEquals>\n<KeyPrefixEquals>string</KeyPrefixEquals>\n</Condition>\n<Redirect>\n<HostName>string</HostName>\n<HttpRedirectCode>string</HttpRedirectCode>\n<Protocol>string</Protocol>\n<ReplaceKeyPrefixWith>string</ReplaceKeyPrefixWith>\n<ReplaceKeyWith>string</ReplaceKeyWith>\n</Redirect>\n</RoutingRule>\n</RoutingRules>\n</WebsiteConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. You must use this header as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, see RFC 1864.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nAmazon S3 API Version 2006-03-01 616",
      "start_idx": 770979,
      "end_idx": 772211,
      "metadata": {
        "num_sentences": 9,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_622",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nWebsiteConfiguration\nRoot level tag for the WebsiteConfiguration parameters.\nRequired: Yes\nErrorDocument\nThe name of the error document for the website.\nType: ErrorDocument data type\nRequired: No\nIndexDocument\nThe name of the index document for the website.\nType: IndexDocument data type\nRequired: No\nRedirectAllRequestsTo\nThe redirect behavior for every request to this bucket's website endpoint.\nAmazon S3 API Version 2006-03-01 617",
      "start_idx": 772213,
      "end_idx": 773369,
      "metadata": {
        "num_sentences": 12,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_623",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nIf you specify this property, you can't specify any other property.\nType: RedirectAllRequestsTo data type\nRequired: No\nRoutingRules\nRules that define when a redirect is applied and the redirect behavior.\nType: Array of RoutingRule data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nExample 1: Configure bucket as a website (add website configuration)\nThe following request configures a bucket example.com as a website. The configuration in the\nrequest specifies index.html as the index document. It also specifies the optional error document,\nSomeErrorDocument.html.\nPUT ?website HTTP/1.1\nHost: example.com.s3.<Region>.amazonaws.com\nContent-Length: 256\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'>\nAmazon S3 API Version 2006-03-01 618",
      "start_idx": 773371,
      "end_idx": 774378,
      "metadata": {
        "num_sentences": 7,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_624",
      "text": "Amazon Simple Storage Service API Reference\n<IndexDocument>\n<Suffix>index.html</Suffix>\n</IndexDocument>\n<ErrorDocument>\n<Key>SomeErrorDocument.html</Key>\n</ErrorDocument>\n</WebsiteConfiguration>\nSample Response\nThis example illustrates one usage of PutBucketWebsite.\nHTTP/1.1 200 OK\nx-amz-id-2: YgIPIfBiKa2bj0KMgUAdQkf3ShJTOOpXUueF6QKo\nx-amz-request-id: 80CD4368BD211111\nDate: Thu, 27 Jan 2011 00:00:00 GMT\nContent-Length: 0\nServer: AmazonS3\nExample 2: Configure bucket as a website but redirect all requests\nThe following request configures a bucket www.example.com as a website. However, the\nconfiguration specifies that all GET requests for the www.example.com bucket's website endpoint\nwill be redirected to host example.com. This redirect can be useful when you want to serve\nrequests for both http://www.example.com and http://example.com, but you want to\nmaintain the website content in only one bucket, in this case, example.com.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: length-value\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'>\n<RedirectAllRequestsTo>\n<HostName>example.com</HostName>\n</RedirectAllRequestsTo>\n</WebsiteConfiguration>\nAmazon S3 API Version 2006-03-01 619",
      "start_idx": 774380,
      "end_idx": 775697,
      "metadata": {
        "num_sentences": 5,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_625",
      "text": "Amazon Simple Storage Service API Reference\nExample 3: Configure bucket as a website and specify optional redirection rules\nExample 1 is the simplest website configuration. It configures a bucket as a website by providing\nonly an index document and an error document. You can further customize the website\nconfiguration by adding routing rules that redirect requests for one or more objects. For example,\nsuppose that your bucket contained the following objects:\n\u2022 index.html\n\u2022 docs/article1.html\n\u2022 docs/article2.html\nIf you decided to rename the folder from docs/ to documents/, you would need to redirect\nrequests for prefix /docs to documents/. For example, a request for docs/article1.html will need\nto be redirected to documents/article1.html.\nIn this case, you update the website configuration and add a routing rule as shown in the following\nrequest.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: length-value\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'>\n<IndexDocument>\n<Suffix>index.html</Suffix>\n</IndexDocument>\n<ErrorDocument>\n<Key>Error.html</Key>\n</ErrorDocument>\n<RoutingRules>\n<RoutingRule>\n<Condition>\n<KeyPrefixEquals>docs/</KeyPrefixEquals>\n</Condition>\n<Redirect>\nAmazon S3 API Version 2006-03-01 620",
      "start_idx": 775699,
      "end_idx": 777051,
      "metadata": {
        "num_sentences": 7,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_626",
      "text": "Amazon Simple Storage Service API Reference\n<ReplaceKeyPrefixWith>documents/</ReplaceKeyPrefixWith>\n</Redirect>\n</RoutingRule>\n</RoutingRules>\n</WebsiteConfiguration>\nExample 4: Configure a bucket as a website and redirect errors\nYou can use a routing rule to specify a condition that checks for a specific HTTP error code. When\na page request results in this error, you can optionally reroute requests. For example, you might\nroute requests to another host and optionally process the error. The routing rule in the following\nrequests redirects requests to an EC2 instance in the event of an HTTP error 404. For illustration,\nthe redirect also inserts an object key prefix report-404/ in the redirect. For example, if you\nrequest a page ExamplePage.html and it results in an HTTP 404 error, the request is routed to a\npage report-404/testPage.html on the specified EC2 instance. If there is no routing rule and\nthe HTTP error 404 occurred, then Error.html would be returned.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: 580\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'>\n<IndexDocument>\n<Suffix>index.html</Suffix>\n</IndexDocument>\n<ErrorDocument>\n<Key>Error.html</Key>\n</ErrorDocument>\n<RoutingRules>\n<RoutingRule>\n<Condition>\n<HttpErrorCodeReturnedEquals>404</HttpErrorCodeReturnedEquals >\n</Condition>\n<Redirect>\n<HostName>ec2-11-22-333-44.compute-1.amazonaws.com</HostName>\n<ReplaceKeyPrefixWith>report-404/</ReplaceKeyPrefixWith>\n</Redirect>\nAmazon S3 API Version 2006-03-01 621",
      "start_idx": 777053,
      "end_idx": 778667,
      "metadata": {
        "num_sentences": 8,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_627",
      "text": "Amazon Simple Storage Service API Reference\n</RoutingRule>\n</RoutingRules>\n</WebsiteConfiguration>\nExample 5: Configure a bucket as a website and redirect folder requests to a page\nSuppose you have the following pages in your bucket:\n\u2022 images/photo1.jpg\n\u2022 images/photo2.jpg\n\u2022 images/photo3.jpg\nNow you want to route requests for all pages with the images/ prefix to go to a single page,\nerrorpage.html. You can add a website configuration to your bucket with the routing rule shown in\nthe following request.\nPUT ?website HTTP/1.1\nHost: www.example.com.s3.<Region>.amazonaws.com\nContent-Length: 481\nDate: Thu, 27 Jan 2011 12:00:00 GMT\nAuthorization: signatureValue\n<WebsiteConfiguration xmlns='http://s3.amazonaws.com/doc/2006-03-01/'>\n<IndexDocument>\n<Suffix>index.html</Suffix>\n</IndexDocument>\n<ErrorDocument>\n<Key>Error.html</Key>\n</ErrorDocument>\n<RoutingRules>\n<RoutingRule>\n<Condition>\n<KeyPrefixEquals>images/</KeyPrefixEquals>\n</Condition>\n<Redirect>\n<ReplaceKeyWith>errorpage.html</ReplaceKeyWith>\n</Redirect>\n</RoutingRule>\nAmazon S3 API Version 2006-03-01 622",
      "start_idx": 778669,
      "end_idx": 779739,
      "metadata": {
        "num_sentences": 3,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_629",
      "text": "Amazon Simple Storage Service API Reference\nPutObject\nService: Amazon S3\nAdds an object to a bucket.\nNote\n\u2022 Amazon S3 never adds partial objects; if you receive a success response, Amazon S3\nadded the entire object to the bucket. You cannot use PutObject to only update a\nsingle piece of metadata for an existing object. You must put the entire object with\nupdated metadata if you want to update some values.\n\u2022 If your bucket uses the bucket owner enforced setting for Object Ownership, ACLs are\ndisabled and no longer affect permissions. All objects written to the bucket by any\naccount will be owned by the bucket owner.\n\u2022 Directory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the\nformat https://bucket_name.s3express-az_id.region.amazonaws.com/key-\nname . Path-style requests are not supported. For more information, see Regional and\nZonal endpoints in the Amazon S3 User Guide.\nAmazon S3 is a distributed system. If it receives multiple write requests for the same object\nsimultaneously, it overwrites all but the last object written. However, Amazon S3 provides features\nthat can modify this behavior:\n\u2022 S3 Object Lock - To prevent objects from being deleted or overwritten, you can use Amazon S3\nObject Lock in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\n\u2022 S3 Versioning - When you enable versioning for a bucket, if Amazon S3 receives multiple write\nrequests for the same object simultaneously, it stores all versions of the objects. For each write\nrequest that is made to the same object, Amazon S3 automatically generates a unique version\nID of that object being stored in Amazon S3. You can retrieve, replace, or delete any version of\nthe object. For more information about versioning, see Adding Objects to Versioning-Enabled\nAmazon S3 API Version 2006-03-01 624",
      "start_idx": 780175,
      "end_idx": 782109,
      "metadata": {
        "num_sentences": 18,
        "num_words": 311,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_630",
      "text": "Amazon Simple Storage Service API Reference\nBuckets in the Amazon S3 User Guide. For information about returning the versioning state of a\nbucket, see GetBucketVersioning.\nNote\nThis functionality is not supported for directory buckets.\nPermissions\n\u2022 General purpose bucket permissions - The following permissions are required in your\npolicies when your PutObject request includes specific headers.\n\u2022 s3:PutObject - To successfully complete the PutObject request, you must always have\nthe s3:PutObject permission on a bucket to add an object to it.\n\u2022 s3:PutObjectAcl - To successfully change the objects ACL of your PutObject request,\nyou must have the s3:PutObjectAcl.\n\u2022 s3:PutObjectTagging - To successfully set the tag-set with your PutObject request,\nyou must have the s3:PutObjectTagging.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key.\nData integrity with Content-MD5\n\u2022 General purpose bucket - To ensure that data is not corrupted traversing the network, use\nthe Content-MD5 header. When you use this header, Amazon S3 checks the object against\nthe provided MD5 value and, if they do not match, Amazon S3 returns an error. Alternatively,\nAmazon S3 API Version 2006-03-01 625",
      "start_idx": 782111,
      "end_idx": 784236,
      "metadata": {
        "num_sentences": 18,
        "num_words": 326,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_632",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-context: SSEKMSEncryptionContext\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-payer: RequestPayer\nx-amz-tagging: Tagging\nx-amz-object-lock-mode: ObjectLockMode\nx-amz-object-lock-retain-until-date: ObjectLockRetainUntilDate\nx-amz-object-lock-legal-hold: ObjectLockLegalHoldStatus\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nBody\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name to which the PUT action was initiated.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nAmazon S3 API Version 2006-03-01 627",
      "start_idx": 785676,
      "end_idx": 787667,
      "metadata": {
        "num_sentences": 14,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_633",
      "text": "Amazon Simple Storage Service API Reference\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nCache-Control\nCan be used to specify caching behavior along the request/reply chain. For more information,\nsee http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.9.\nContent-Disposition\nSpecifies presentational information for the object. For more information, see https://www.rfc-\neditor.org/rfc/rfc6266#section-4.\nContent-Encoding\nSpecifies what content encodings have been applied to the object and thus what decoding\nmechanisms must be applied to obtain the media-type referenced by the Content-Type header\nfield. For more information, see https://www.rfc-editor.org/rfc/rfc9110.html#field.content-\nencoding.\nContent-Language\nThe language the content is in.\nContent-Length\nSize of the body in bytes. This parameter is useful when the size of the body cannot be\ndetermined automatically. For more information, see https://www.rfc-editor.org/rfc/\nrfc9110.html#name-content-length.\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the message (without the headers) according to\nRFC 1864. This header can be used as a message integrity check to verify that the data is the\nsame data that was originally sent. Although it is optional, we recommend using the Content-\nMD5 mechanism as an end-to-end integrity check. For more information about REST request\nauthentication, see REST Authentication.\nAmazon S3 API Version 2006-03-01 628",
      "start_idx": 787669,
      "end_idx": 789554,
      "metadata": {
        "num_sentences": 20,
        "num_words": 257,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_634",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThe Content-MD5 or x-amz-sdk-checksum-algorithm header is required for any\nrequest to upload an object with a retention period configured using Amazon S3 Object\nLock. For more information, see Uploading objects to an Object Lock enabled bucket in\nthe Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nContent-Type\nA standard MIME type describing the format of the contents. For more information, see https://\nwww.rfc-editor.org/rfc/rfc9110.html#name-content-type.\nExpires\nThe date and time at which the object is no longer cacheable. For more information, see\nhttps://www.rfc-editor.org/rfc/rfc7234#section-5.3.\nIf-None-Match\nUploads the object only if the object key name does not already exist in the bucket specified.\nOtherwise, Amazon S3 returns a 412 Precondition Failed error.\nIf a conflicting operation occurs during the upload S3 returns a 409\nConditionalRequestConflict response. On a 409 failure you should retry the upload.\nExpects the '*' (asterisk) character.\nFor more information about conditional requests, see RFC 7232, or Conditional requests in the\nAmazon S3 User Guide.\nKey\nObject key for which the PUT action was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 629",
      "start_idx": 789556,
      "end_idx": 790876,
      "metadata": {
        "num_sentences": 16,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_635",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-acl\nThe canned ACL to apply to the object. For more information, see Canned ACL in the Amazon S3\nUser Guide.\nWhen adding a new object, you can use headers to grant ACL-based permissions to individual\nAWS accounts or to predefined groups defined by Amazon S3. These permissions are then\nadded to the ACL on the object. By default, all objects are private. Only the owner has full\naccess control. For more information, see Access Control List (ACL) Overview and Managing\nACLs Using the REST API in the Amazon S3 User Guide.\nIf the bucket that you're uploading objects to uses the bucket owner enforced setting for\nS3 Object Ownership, ACLs are disabled and no longer affect permissions. Buckets that use\nthis setting only accept PUT requests that don't specify an ACL or PUT requests that specify\nbucket owner full control ACLs, such as the bucket-owner-full-control canned ACL or an\nequivalent form of this ACL expressed in the XML format. PUT requests that contain other ACLs\n(for example, custom grants to certain AWS accounts) fail and return a 400 error with the error\ncode AccessControlListNotSupported. For more information, see Controlling ownership\nof objects and disabling ACLs in the Amazon S3 User Guide.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nValid Values: private | public-read | public-read-write | authenticated-read\n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nx-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32C\nAmazon S3 API Version 2006-03-01 630",
      "start_idx": 790878,
      "end_idx": 792964,
      "metadata": {
        "num_sentences": 18,
        "num_words": 331,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_636",
      "text": "Amazon Simple Storage Service API Reference\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nx-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 160-bit SHA-1 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nx-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 256-bit SHA-256 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nGives the grantee READ, READ_ACP, and WRITE_ACP permissions on the object.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nAllows grantee to read the object data and its metadata.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nAmazon S3 API Version 2006-03-01 631",
      "start_idx": 792966,
      "end_idx": 794431,
      "metadata": {
        "num_sentences": 17,
        "num_words": 229,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_637",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-grant-read-acp\nAllows grantee to read the object ACL.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable object.\nNote\n\u2022 This functionality is not supported for directory buckets.\n\u2022 This functionality is not supported for Amazon S3 on Outposts.\nx-amz-object-lock-legal-hold\nSpecifies whether a legal hold will be applied to this object. For more information about S3\nObject Lock, see Object Lock in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: ON | OFF\nx-amz-object-lock-mode\nThe Object Lock mode that you want to apply to this object.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 632",
      "start_idx": 794433,
      "end_idx": 795330,
      "metadata": {
        "num_sentences": 12,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_638",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-object-lock-retain-until-date\nThe date and time when you want this object's Object Lock to expire. Must be formatted as a\ntimestamp parameter.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK.\nThis header will not provide any additional functionality if you don't use the SDK. When you\nsend this header, there must be a corresponding x-amz-checksum-algorithm or x-amz-\ntrailer header sent. Otherwise, Amazon S3 fails the request with the HTTP status code 400\nBad Request.\nFor the x-amz-checksum-algorithm header, replace algorithm with the supported\nalgorithm from the following list:\n\u2022 CRC32\n\u2022 CRC32C\n\u2022 SHA1\nAmazon S3 API Version 2006-03-01 633",
      "start_idx": 795332,
      "end_idx": 796740,
      "metadata": {
        "num_sentences": 13,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_639",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 SHA256\nFor more information, see Checking object integrity in the Amazon S3 User Guide.\nIf the individual checksum value you provide through x-amz-checksum-algorithm doesn't\nmatch the checksum algorithm you set through x-amz-sdk-checksum-algorithm, Amazon\nS3 ignores any provided ChecksumAlgorithm parameter and uses the checksum algorithm\nthat matches the provided value in x-amz-checksum-algorithm .\nNote\nThe Content-MD5 or x-amz-sdk-checksum-algorithm header is required for any\nrequest to upload an object with a retention period configured using Amazon S3 Object\nLock. For more information, see Uploading objects to an Object Lock enabled bucket in\nthe Amazon S3 User Guide.\nFor directory buckets, when you use AWS SDKs, CRC32 is the default checksum algorithm that's\nused for performance.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-server-side-encryption\nThe server-side encryption algorithm that was used when you store this object in Amazon S3\n(for example, AES256, aws:kms, aws:kms:dsse).\n\u2022 General purpose buckets - You have four mutually exclusive options to protect data\nusing server-side encryption in Amazon S3, depending on how you choose to manage the\nencryption keys. Specifically, the encryption key options are Amazon S3 managed keys (SSE-\nS3), AWS KMS keys (SSE-KMS or DSSE-KMS), and customer-provided keys (SSE-C). Amazon\nS3 encrypts data with server-side encryption by using Amazon S3 managed keys (SSE-S3)\nby default. You can optionally tell Amazon S3 to encrypt data at rest by using server-side\nencryption with other key options. For more information, see Using Server-Side Encryption in\nthe Amazon S3 User Guide.\n\u2022 Directory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256)\nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). We recommend that\nthe bucket's default encryption uses the desired encryption configuration and you don't\noverride the bucket default encryption in your CreateSession requests or PUT object\nAmazon S3 API Version 2006-03-01 634",
      "start_idx": 796742,
      "end_idx": 798907,
      "metadata": {
        "num_sentences": 13,
        "num_words": 318,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_640",
      "text": "Amazon Simple Storage Service API Reference\nrequests. Then, new objects are automatically encrypted with the desired encryption settings.\nFor more information, see Protecting data with server-side encryption in the Amazon S3 User\nGuide. For more information about the encryption overriding behaviors in directory buckets,\nsee Specifying server-side encryption with AWS KMS for new object uploads.\nIn the Zonal endpoint API calls (except CopyObject and UploadPartCopy) using the REST API,\nthe encryption request headers must match the encryption settings that are specified in the\nCreateSession request. You can't override the values of the encryption settings (x-amz-\nserver-side-encryption, x-amz-server-side-encryption-aws-kms-key-id, x-\namz-server-side-encryption-context, and x-amz-server-side-encryption-\nbucket-key-enabled) that are specified in the CreateSession request. You don't need\nto explicitly specify these encryption settings values in Zonal endpoint API calls, and Amazon\nS3 will use the encryption settings values from the CreateSession request to protect new\nobjects in the directory bucket.\nNote\nWhen you use the CLI or the AWS SDKs, for CreateSession, the session token\nrefreshes automatically to avoid service interruptions when a session expires. The\nCLI or the AWS SDKs use the bucket's default encryption configuration for the\nCreateSession request. It's not supported to override the encryption settings\nvalues in the CreateSession request. So in the Zonal endpoint API calls (except\nCopyObject and UploadPartCopy), the encryption request headers must match the\ndefault encryption configuration of the directory bucket.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nSpecifies the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the\nKMS key doesn't exist in the same account that's issuing the command, you must use the full\nKey ARN not the Key ID.\nGeneral purpose buckets - If you specify x-amz-server-side-encryption with aws:kms\nor aws:kms:dsse, this header specifies the ID (Key ID, Key ARN, or Key Alias) of the AWS KMS\nkey to use. If you specify x-amz-server-side-encryption:aws:kms or x-amz-server-\nside-encryption:aws:kms:dsse, but do not provide x-amz-server-side-encryption-\naws-kms-key-id, Amazon S3 uses the AWS managed key (aws/s3) to protect the data.\nAmazon S3 API Version 2006-03-01 635",
      "start_idx": 798909,
      "end_idx": 801312,
      "metadata": {
        "num_sentences": 16,
        "num_words": 337,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_641",
      "text": "Amazon Simple Storage Service API Reference\nDirectory buckets - If you specify x-amz-server-side-encryption with aws:kms, the\nx-amz-server-side-encryption-aws-kms-key-id header is implicitly assigned the\nID of the AWS KMS symmetric encryption customer managed key that's configured for your\ndirectory bucket's default encryption setting. If you want to specify the x-amz-server-\nside-encryption-aws-kms-key-id header explicitly, you can only specify it with the ID\n(Key ID or Key ARN) of the AWS KMS customer managed key that's configured for your directory\nbucket's default encryption setting. Otherwise, you get an HTTP 400 Bad Request error. Only\nuse the key ID or key ARN. The key alias format of the KMS key isn't supported. Your SSE-KMS\nconfiguration can only support 1 customer managed key per directory bucket for the lifetime of\nthe bucket. The AWS managed key (aws/s3) isn't supported.\nx-amz-server-side-encryption-bucket-key-enabled\nSpecifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS Key Management Service (AWS KMS) keys (SSE-KMS).\nGeneral purpose buckets - Setting this header to true causes Amazon S3 to use an S3 Bucket\nKey for object encryption with SSE-KMS. Also, specifying this header with a PUT action doesn't\naffect bucket-level settings for S3 Bucket Key.\nDirectory buckets - S3 Bucket Keys are always enabled for GET and PUT operations in a\ndirectory bucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you copy SSE-\nKMS encrypted objects from general purpose buckets to directory buckets, from directory\nbuckets to general purpose buckets, or between directory buckets, through CopyObject,\nUploadPartCopy, the Copy operation in Batch Operations, or the import jobs. In this case,\nAmazon S3 makes a call to AWS KMS every time a copy request is made for a KMS-encrypted\nobject.\nx-amz-server-side-encryption-context\nSpecifies the AWS KMS Encryption Context as an additional encryption context to use for\nobject encryption. The value of this header is a Base64-encoded string of a UTF-8 encoded\nJSON, which contains the encryption context as key-value pairs. This value is stored as object\nmetadata and automatically gets passed on to AWS KMS for future GetObject operations on\nthis object.\nGeneral purpose buckets - This value must be explicitly added during CopyObject operations\nif you want an additional encryption context for your object. For more information, see\nEncryption context in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 636",
      "start_idx": 801314,
      "end_idx": 803870,
      "metadata": {
        "num_sentences": 19,
        "num_words": 388,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_642",
      "text": "Amazon Simple Storage Service API Reference\nDirectory buckets - You can optionally provide an explicit encryption context value. The value\nmust match the default encryption context - the bucket Amazon Resource Name (ARN). An\nadditional encryption context value is not supported.\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded; Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-amz-\nserver-side-encryption-customer-algorithm header.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-storage-class\nBy default, Amazon S3 uses the STANDARD Storage Class to store newly created objects.\nThe STANDARD storage class provides high durability and high availability. Depending on\nAmazon S3 API Version 2006-03-01 637",
      "start_idx": 803872,
      "end_idx": 805317,
      "metadata": {
        "num_sentences": 15,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_643",
      "text": "Amazon Simple Storage Service API Reference\nperformance needs, you can specify a different Storage Class. For more information, see\nStorage Classes in the Amazon S3 User Guide.\nNote\n\u2022 For directory buckets, only the S3 Express One Zone storage class is supported to\nstore newly created objects.\n\u2022 Amazon S3 on Outposts only uses the OUTPOSTS Storage Class.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nx-amz-tagging\nThe tag-set for the object. The tag-set must be encoded as URL Query parameters. (For\nexample, \"Key1=Value1\")\nNote\nThis functionality is not supported for directory buckets.\nx-amz-website-redirect-location\nIf the bucket is configured as a website, redirects requests for this object to another object in\nthe same bucket or to an external URL. Amazon S3 stores the value of this header in the object\nmetadata. For information about object metadata, see Object Key and Metadata in the Amazon\nS3 User Guide.\nIn the following example, the request header sets the redirect to an object (anotherPage.html)\nin the same bucket:\nx-amz-website-redirect-location: /anotherPage.html\nIn the following example, the request header sets the object redirect to another website:\nx-amz-website-redirect-location: http://www.example.com/\nAmazon S3 API Version 2006-03-01 638",
      "start_idx": 805319,
      "end_idx": 806711,
      "metadata": {
        "num_sentences": 11,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_645",
      "text": "Amazon Simple Storage Service API Reference\nGeneral purpose buckets - To ensure that data is not corrupted traversing the network, for\nobjects where the ETag is the MD5 digest of the object, you can calculate the MD5 while putting\nan object to Amazon S3 and compare the returned ETag to the calculated MD5 value.\nDirectory buckets - The ETag for the object in a directory bucket isn't the MD5 digest of the\nobject.\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 640",
      "start_idx": 807922,
      "end_idx": 810430,
      "metadata": {
        "num_sentences": 23,
        "num_words": 411,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_646",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-expiration\nIf the expiration is configured for the object (see PutBucketLifecycleConfiguration) in the\nAmazon S3 User Guide, the response includes this header. It includes the expiry-date and\nrule-id key-value pairs that provide information about object expiration. The value of the\nrule-id is URL-encoded.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption\nThe server-side encryption algorithm used when you store this object in Amazon S3.\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-server-side-encryption-aws-kms-key-id\nIf present, indicates the ID of the KMS key that was used for object encryption.\nx-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the uploaded object uses an S3 Bucket Key for server-side encryption with\nAWS Key Management Service (AWS KMS) keys (SSE-KMS).\nx-amz-server-side-encryption-context\nIf present, indicates the AWS KMS Encryption Context to use for object encryption. The value\nof this header is a Base64-encoded string of a UTF-8 encoded JSON, which contains the\nAmazon S3 API Version 2006-03-01 641",
      "start_idx": 810432,
      "end_idx": 811774,
      "metadata": {
        "num_sentences": 11,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_647",
      "text": "Amazon Simple Storage Service API Reference\nencryption context as key-value pairs. This value is stored as object metadata and automatically\ngets passed on to AWS KMS for future GetObject operations on this object.\nx-amz-server-side-encryption-customer-algorithm\nIf server-side encryption with a customer-provided encryption key was requested, the response\nwill include this header to confirm the encryption algorithm that's used.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the\nresponse will include this header to provide the round-trip message integrity verification of the\ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-version-id\nVersion ID of the object.\nIf you enable versioning for a bucket, Amazon S3 automatically generates a unique version\nID for the object being stored. Amazon S3 returns this ID in the response. When you enable\nversioning for a bucket, if Amazon S3 receives multiple write requests for the same object\nsimultaneously, it stores all of the objects. For more information about versioning, see Adding\nObjects to Versioning-Enabled Buckets in the Amazon S3 User Guide. For information about\nreturning the versioning state of a bucket, see GetBucketVersioning.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 642",
      "start_idx": 811776,
      "end_idx": 813267,
      "metadata": {
        "num_sentences": 14,
        "num_words": 207,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_648",
      "text": "Amazon Simple Storage Service API Reference\nExamples\nExample 1 for general purpose buckets: Upload an object\nThe following request stores the my-image.jpg file in the myBucket bucket.\nPUT /my-image.jpg HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nContent-Length: 11434\nx-amz-meta-author: Janet\nExpect: 100-continue\n[11434 bytes of object data]\nSample Response for general purpose buckets: Versioning suspended\nThis example illustrates one usage of PutObject.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nSample Response for general purpose buckets: Expiration rule created using lifecycle\nconfiguration\nIf an expiration rule that was created on the bucket using lifecycle configuration applies to\nthe object, you get a response with an x-amz-expiration header, as shown in the following\nresponse. For more information, see Transitioning Objects: General Considerations.\nAmazon S3 API Version 2006-03-01 643",
      "start_idx": 813269,
      "end_idx": 814512,
      "metadata": {
        "num_sentences": 5,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_649",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nx-amz-expiration: expiry-date=\"Fri, 23 Dec 2012 00:00:00 GMT\", rule-id=\"1\"\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nSample Response for general purpose buckets: Versioning enabled\nIf the bucket has versioning enabled, the response includes the x-amz-version-id header.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nx-amz-version-id: 43jfkodU8493jnFJD9fjj3HHNVfdsQUIFDNsidf038jfdsjGFDSIRp\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"fbacf535f27731c9771645a39863328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nExample 2 for general purpose buckets: Specifying the Reduced Redundancy Storage Class\nThe following request stores the image, my-image.jpg, in the myBucket bucket. The request\nspecifies the x-amz-storage-class header to request that the object is stored using the\nREDUCED_REDUNDANCY storage class.\nPUT /my-image.jpg HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nAmazon S3 API Version 2006-03-01 644",
      "start_idx": 814514,
      "end_idx": 815821,
      "metadata": {
        "num_sentences": 4,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_650",
      "text": "Amazon Simple Storage Service API Reference\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nAuthorization: authorization string\nContent-Type: image/jpeg\nContent-Length: 11434\nExpect: 100-continue\nx-amz-storage-class: REDUCED_REDUNDANCY\nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nExample 3 for general purpose buckets: Uploading an object and specifying access permissions\nexplicitly\nThe following request stores the TestObject.txt file in the myBucket bucket. The request\nspecifies various ACL headers to grant permission to AWS accounts that are specified with a\ncanonical user ID and an email address.\nPUT TestObject.txt HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nx-amz-date: Fri, 13 Apr 2012 05:40:14 GMT\nAuthorization: authorization string\nx-amz-grant-write-acp: id=8a6925ce4adf588a4532142d3f74dd8c71fa124ExampleCanonicalUserID\nx-amz-grant-full-control: emailAddress=\"ExampleUser@amazon.com\"\nx-amz-grant-write: emailAddress=\"ExampleUser1@amazon.com\",\nemailAddress=\"ExampleUser2@amazon.com\"\nContent-Length: 300\nAmazon S3 API Version 2006-03-01 645",
      "start_idx": 815823,
      "end_idx": 817198,
      "metadata": {
        "num_sentences": 4,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_651",
      "text": "Amazon Simple Storage Service API Reference\nExpect: 100-continue\nConnection: Keep-Alive\n...Object data in the body...\nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 200 OK\nx-amz-id-2: RUxG2sZJUfS+ezeAS2i0Xj6w/ST6xqF/8pFNHjTjTrECW56SCAUWGg+7QLVoj1GH\nx-amz-request-id: 8D017A90827290BA\nDate: Fri, 13 Apr 2012 05:40:25 GMT\nETag: \"dd038b344cf9553547f8b395a814b274\"\nContent-Length: 0\nServer: AmazonS3\nExample 4 for general purpose buckets: Using a canned ACL to set access permissions\nThe following request stores the TestObject.txt file in the myBucket bucket. The request uses\nan x-amz-acl header to specify a canned ACL that grants READ permission to the public.\nPUT TestObject.txt HTTP/1.1\nHost: myBucket.s3.<Region>.amazonaws.com\nx-amz-date: Fri, 13 Apr 2012 05:54:57 GMT\nx-amz-acl: public-read\nAuthorization: authorization string\nContent-Length: 300\nExpect: 100-continue\nConnection: Keep-Alive\n...Object data in the body...\nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nAmazon S3 API Version 2006-03-01 646",
      "start_idx": 817200,
      "end_idx": 818309,
      "metadata": {
        "num_sentences": 7,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_652",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: Yd6PSJxJFQeTYJ/3dDO7miqJfVMXXW0S2Hijo3WFs4bz6oe2QCVXasxXLZdMfASd\nx-amz-request-id: 80DF413BB3D28A25\nDate: Fri, 13 Apr 2012 05:54:59 GMT\nETag: \"dd038b344cf9553547f8b395a814b274\"\nContent-Length: 0\nServer: AmazonS3\nExample 5 for general purpose buckets: Upload an object (Request server-side encryption using\na customer-provided encryption key)\nThis example of an upload object requests server-side encryption and provides an encryption key.\nPUT /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAccept: */*\nAuthorization:authorization string\nDate: Wed, 28 May 2014 19:31:11 +0000\nx-amz-server-side-encryption-customer-key:g0lCfA3Dv40jZz5SQJ1ZukLRFqtI5WorC/8SEEXAMPLE\nx-amz-server-side-encryption-customer-key-MD5:ZjQrne1X/iTcskbY2example\nx-amz-server-side-encryption-customer-algorithm:AES256\nSample Response for general purpose buckets\nIn the response, Amazon S3 returns the encryption algorithm and MD5 of the encryption key that\nyou specified when uploading the object. The ETag that is returned is not the MD5 of the object.\nHTTP/1.1 200 OK\nx-amz-id-2: 7qoYGN7uMuFuYS6m7a4lszH6in+hccE+4DXPmDZ7C9KqucjnZC1gI5mshai6fbMG\nx-amz-request-id: 06437EDD40C407C7\nDate: Wed, 28 May 2014 19:31:12 GMT\nx-amz-server-side-encryption-customer-algorithm: AES256\nx-amz-server-side-encryption-customer-key-MD5: ZjQrne1X/iTcskbY2example\nETag: \"ae89237c20e759c5f479ece02c642f59\"\nAmazon S3 API Version 2006-03-01 647",
      "start_idx": 818311,
      "end_idx": 819801,
      "metadata": {
        "num_sentences": 4,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_653",
      "text": "Amazon Simple Storage Service API Reference\nExample 6 for general purpose buckets: Upload an object and specify tags\nThis example of an upload object request specifies the optional x-amz-tagging header to add\ntags to the object.\nAfter the object is created, Amazon S3 stores the specified object tags in the tagging subresource\nthat is associated with the object. For more information about tagging, see Object Tagging and\nAccess Control Policies in the Amazon S3 User Guide.\nPUT /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nAccept: */*\nAuthorization:authorization string\nDate: Thu, 22 Sep 2016 21:58:13 GMT\nx-amz-tagging: tag1=value1&tag2=value2\n[... bytes of object data]\nSample Response for general purpose buckets\nThis example illustrates one usage of PutObject.\nHTTP/1.1 200 OK\nx-amz-id-2: 7qoYGN7uMuFuYS6m7a4lszH6in+hccE+4DXPmDZ7C9KqucjnZC1gI5mshai6fbMG\nx-amz-request-id: 06437EDD40C407C7\nDate: Thu, 22 Sep 2016 21:58:17 GMT\nExample 7 for general purpose buckets: Upload an object and specify the checksum algorithm\nThis example of an upload object request specifies the additional checksum algorithm to use to\nverify the content of the object. For more information about using additional checksums, see\nChecking object integrity in the Amazon S3 User Guide.\nPUT /example-object HTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nx-amz-date: Mon, 22 Mar 2021 23:00:00 GMT\nAmazon S3 API Version 2006-03-01 648",
      "start_idx": 819803,
      "end_idx": 821249,
      "metadata": {
        "num_sentences": 7,
        "num_words": 196,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_655",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectAcl\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nUses the acl subresource to set the access control list (ACL) permissions for a new or existing\nobject in an S3 bucket. You must have the WRITE_ACP permission to set the ACL of an object. For\nmore information, see What permissions can I grant? in the Amazon S3 User Guide.\nThis functionality is not supported for Amazon S3 on Outposts.\nDepending on your application needs, you can choose to set the ACL on an object using either the\nrequest body or the headers. For example, if you have an existing application that updates a bucket\nACL using the request body, you can continue to use that approach. For more information, see\nAccess Control List (ACL) Overview in the Amazon S3 User Guide.\nImportant\nIf your bucket uses the bucket owner enforced setting for S3 Object Ownership, ACLs\nare disabled and no longer affect permissions. You must use policies to grant access to\nyour bucket and the objects in it. Requests to set ACLs or update ACLs fail and return\nthe AccessControlListNotSupported error code. Requests to read ACLs are still\nsupported. For more information, see Controlling object ownership in the Amazon S3 User\nGuide.\nPermissions\nYou can set access permissions using one of the following methods:\n\u2022 Specify a canned ACL with the x-amz-acl request header. Amazon S3 supports a set of\npredefined ACLs, known as canned ACLs. Each canned ACL has a predefined set of grantees\nand permissions. Specify the canned ACL name as the value of x-amz-acl. If you use this\nheader, you cannot use other access control-specific headers in your request. For more\ninformation, see Canned ACL.\nAmazon S3 API Version 2006-03-01 650",
      "start_idx": 822097,
      "end_idx": 823857,
      "metadata": {
        "num_sentences": 21,
        "num_words": 294,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_656",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Specify access permissions explicitly with the x-amz-grant-read, x-amz-grant-read-\nacp, x-amz-grant-write-acp, and x-amz-grant-full-control headers. When using\nthese headers, you specify explicit access permissions and grantees (AWS accounts or Amazon\nS3 groups) who will receive the permission. If you use these ACL-specific headers, you cannot\nuse x-amz-acl header to set a canned ACL. These parameters map to the set of permissions\nthat Amazon S3 supports in an ACL. For more information, see Access Control List (ACL)\nOverview.\nYou specify each grantee as a type=value pair, where the type is one of the following:\n\u2022 id \u2013 if the value specified is the canonical user ID of an AWS account\n\u2022 uri \u2013 if you are granting permissions to a predefined group\n\u2022 emailAddress \u2013 if the value specified is the email address of an AWS account\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nFor example, the following x-amz-grant-read header grants list objects permission to the\ntwo AWS accounts identified by their email addresses.\nx-amz-grant-read: emailAddress=\"xyz@amazon.com\",\nemailAddress=\"abc@amazon.com\"\nYou can use either a canned ACL or specify access permissions explicitly. You cannot do both.\nAmazon S3 API Version 2006-03-01 651",
      "start_idx": 823859,
      "end_idx": 825497,
      "metadata": {
        "num_sentences": 10,
        "num_words": 257,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_657",
      "text": "Amazon Simple Storage Service API Reference\nGrantee Values\nYou can specify the person (grantee) to whom you're assigning access rights (using request\nelements) in the following ways:\n\u2022 By the person's ID:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-\ninstance\" xsi:type=\"CanonicalUser\"><ID><>ID<></\nID><DisplayName><>GranteesEmail<></DisplayName> </Grantee>\nDisplayName is optional and ignored in the request.\n\u2022 By URI:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"Group\"><URI><>http://acs.amazonaws.com/groups/global/\nAuthenticatedUsers<></URI></Grantee>\n\u2022 By Email address:\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"AmazonCustomerByEmail\"><EmailAddress><>Grantees@email.com<></\nEmailAddress>lt;/Grantee>\nThe grantee is resolved to the CanonicalUser and, in a response to a GET Object acl request,\nappears as the CanonicalUser.\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nAmazon S3 API Version 2006-03-01 652",
      "start_idx": 825499,
      "end_idx": 826717,
      "metadata": {
        "num_sentences": 3,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_658",
      "text": "Amazon Simple Storage Service API Reference\nFor a list of all the Amazon S3 supported Regions and endpoints, see Regions and\nEndpoints in the AWS General Reference.\nVersioning\nThe ACL of an object is set at the object version level. By default, PUT sets the ACL of the\ncurrent version of an object. To set the ACL of a different version, use the versionId\nsubresource.\nThe following operations are related to PutObjectAcl:\n\u2022 CopyObject\n\u2022 GetObject\nRequest Syntax\nPUT /{Key+}?acl&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-acl: ACL\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AccessControlPolicy xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<AccessControlList>\n<Grant>\n<Grantee>\n<DisplayName>string</DisplayName>\n<EmailAddress>string</EmailAddress>\n<ID>string</ID>\n<xsi:type>string</xsi:type>\n<URI>string</URI>\n</Grantee>\n<Permission>string</Permission>\n</Grant>\nAmazon S3 API Version 2006-03-01 653",
      "start_idx": 826719,
      "end_idx": 827967,
      "metadata": {
        "num_sentences": 5,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_659",
      "text": "Amazon Simple Storage Service API Reference\n</AccessControlList>\n<Owner>\n<DisplayName>string</DisplayName>\n<ID>string</ID>\n</Owner>\n</AccessControlPolicy>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the object to which you want to attach the ACL.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the data. This header must be used as a message\nintegrity check to verify that the request body was not corrupted in transit. For more\ninformation, go to RFC 1864.>\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nAmazon S3 API Version 2006-03-01 654",
      "start_idx": 827969,
      "end_idx": 829734,
      "metadata": {
        "num_sentences": 16,
        "num_words": 277,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_660",
      "text": "Amazon Simple Storage Service API Reference\nKey\nKey for which the PUT action was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nVersion ID used to reference a specific version of the object.\nNote\nThis functionality is not supported for directory buckets.\nx-amz-acl\nThe canned ACL to apply to the object. For more information, see Canned ACL.\nValid Values: private | public-read | public-read-write | authenticated-read\n| aws-exec-read | bucket-owner-read | bucket-owner-full-control\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-grant-full-control\nAllows grantee the read, write, read ACP, and write ACP permissions on the bucket.\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read\nAllows grantee to list the objects in the bucket.\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-read-acp\nAllows grantee to read the bucket ACL.\nAmazon S3 API Version 2006-03-01 655",
      "start_idx": 829736,
      "end_idx": 830875,
      "metadata": {
        "num_sentences": 14,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_661",
      "text": "Amazon Simple Storage Service API Reference\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-grant-write\nAllows grantee to create new objects in the bucket.\nFor the bucket and object owners of existing objects, also allows deletions and overwrites of\nthose objects.\nx-amz-grant-write-acp\nAllows grantee to write the ACL for the applicable bucket.\nThis functionality is not supported for Amazon S3 on Outposts.\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 656",
      "start_idx": 830877,
      "end_idx": 832497,
      "metadata": {
        "num_sentences": 17,
        "num_words": 246,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_663",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: requester\nErrors\nNoSuchKey\nThe specified key does not exist.\nHTTP Status Code: 404\nExamples\nSample Request\nThe following request grants access permission to an existing object. The request specifies the ACL\nin the body. In addition to granting full control to the object owner, the XML specifies full control\nto an AWS account identified by its canonical user ID.\nPUT /my-image.jpg?acl HTTP/1.1\nHost: bucket.s3.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2009 22:32:00 GMT\nAuthorization: authorization string\nContent-Length: 124\n<AccessControlPolicy>\n<Owner>\n<ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>\n<DisplayName>CustomersName@amazon.com</DisplayName>\n</Owner>\n<AccessControlList>\n<Grant>\n<Grantee xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"\nxsi:type=\"CanonicalUser\">\n<ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeeExampleCanonicalUserID</ID>\n<DisplayName>CustomerName@amazon.com</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n</AccessControlList>\n</AccessControlPolicy>\nAmazon S3 API Version 2006-03-01 658",
      "start_idx": 833279,
      "end_idx": 834405,
      "metadata": {
        "num_sentences": 5,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_667",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectLegalHold\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nApplies a legal hold configuration to the specified object. For more information, see Locking\nObjects.\nThis functionality is not supported for Amazon S3 on Outposts.\nRequest Syntax\nPUT /{Key+}?legal-hold&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LegalHold xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Status>string</Status>\n</LegalHold>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object that you want to place a legal hold on.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 662",
      "start_idx": 837172,
      "end_idx": 838648,
      "metadata": {
        "num_sentences": 12,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_668",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nKey\nThe key name for the object that you want to place a legal hold on.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID of the object that you want to place a legal hold on.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nAmazon S3 API Version 2006-03-01 663",
      "start_idx": 838650,
      "end_idx": 840100,
      "metadata": {
        "num_sentences": 15,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_669",
      "text": "Amazon Simple Storage Service API Reference\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nLegalHold\nRoot level tag for the LegalHold parameters.\nRequired: Yes\nStatus\nIndicates whether the specified object has a legal hold in place.\nType: String\nValid Values: ON | OFF\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nAmazon S3 API Version 2006-03-01 664",
      "start_idx": 840102,
      "end_idx": 841148,
      "metadata": {
        "num_sentences": 11,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_671",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectLockConfiguration\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPlaces an Object Lock configuration on the specified bucket. The rule specified in the Object Lock\nconfiguration will be applied by default to every new object placed in the specified bucket. For\nmore information, see Locking Objects.\nNote\n\u2022 The DefaultRetention settings require both a mode and a period.\n\u2022 The DefaultRetention period can be either Days or Years but you must select one.\nYou cannot specify Days and Years at the same time.\n\u2022 You can enable Object Lock for new or existing buckets. For more information, see\nConfiguring Object Lock.\nRequest Syntax\nPUT /?object-lock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-bucket-object-lock-token: Token\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ObjectLockConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<ObjectLockEnabled>string</ObjectLockEnabled>\n<Rule>\n<DefaultRetention>\n<Days>integer</Days>\n<Mode>string</Mode>\n<Years>integer</Years>\n</DefaultRetention>\nAmazon S3 API Version 2006-03-01 666",
      "start_idx": 841632,
      "end_idx": 842901,
      "metadata": {
        "num_sentences": 10,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_672",
      "text": "Amazon Simple Storage Service API Reference\n</Rule>\n</ObjectLockConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket whose Object Lock configuration you want to create or replace.\nRequired: Yes\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-bucket-object-lock-token\nA token to allow Object Lock to be enabled for an existing bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 667",
      "start_idx": 842903,
      "end_idx": 844215,
      "metadata": {
        "num_sentences": 13,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_673",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nObjectLockConfiguration\nRoot level tag for the ObjectLockConfiguration parameters.\nRequired: Yes\nObjectLockEnabled\nIndicates whether this bucket has an Object Lock configuration enabled. Enable\nObjectLockEnabled when you apply ObjectLockConfiguration to a bucket.\nType: String\nValid Values: Enabled\nRequired: No\nRule\nSpecifies the Object Lock rule for the specified object. Enable the this rule when you apply\nObjectLockConfiguration to a bucket. Bucket settings require both a mode and a period.\nThe period can be either Days or Years but you must select one. You cannot specify Days and\nYears at the same time.\nType: ObjectLockRule data type\nAmazon S3 API Version 2006-03-01 668",
      "start_idx": 844217,
      "end_idx": 845619,
      "metadata": {
        "num_sentences": 16,
        "num_words": 212,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_676",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectRetention\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPlaces an Object Retention configuration on an object. For more information, see Locking Objects.\nUsers or accounts require the s3:PutObjectRetention permission in order to place an Object\nRetention configuration on objects. Bypassing a Governance Retention configuration requires the\ns3:BypassGovernanceRetention permission.\nThis functionality is not supported for Amazon S3 on Outposts.\nRequest Syntax\nPUT /{Key+}?retention&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nx-amz-request-payer: RequestPayer\nx-amz-bypass-governance-retention: BypassGovernanceRetention\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Retention xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Mode>string</Mode>\n<RetainUntilDate>timestamp</RetainUntilDate>\n</Retention>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name that contains the object you want to apply this Object Retention\nconfiguration to.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\nAmazon S3 API Version 2006-03-01 671",
      "start_idx": 846511,
      "end_idx": 847935,
      "metadata": {
        "num_sentences": 10,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_677",
      "text": "Amazon Simple Storage Service API Reference\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nRequired: Yes\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nKey\nThe key name for the object that you want to apply this Object Retention configuration to.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe version ID for the object that you want to apply this Object Retention configuration to.\nx-amz-bypass-governance-retention\nIndicates whether this action should bypass Governance-mode restrictions.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 672",
      "start_idx": 847937,
      "end_idx": 849635,
      "metadata": {
        "num_sentences": 17,
        "num_words": 257,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_678",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nRetention\nRoot level tag for the Retention parameters.\nRequired: Yes\nMode\nIndicates the Retention mode for the specified object.\nType: String\nValid Values: GOVERNANCE | COMPLIANCE\nRequired: No\nRetainUntilDate\nThe date on which this Object Lock Retention will expire.\nAmazon S3 API Version 2006-03-01 673",
      "start_idx": 849637,
      "end_idx": 850750,
      "metadata": {
        "num_sentences": 12,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_681",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectTagging\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nSets the supplied tag-set to an object that already exists in a bucket. A tag is a key-value pair. For\nmore information, see Object Tagging.\nYou can associate tags with an object by sending a PUT request against the tagging subresource\nthat is associated with the object. You can retrieve tags by sending a GET request. For more\ninformation, see GetObjectTagging.\nFor tagging-related restrictions related to characters and encodings, see Tag Restrictions. Note that\nAmazon S3 limits the maximum number of tags to 10 tags per object.\nTo use this operation, you must have permission to perform the s3:PutObjectTagging action.\nBy default, the bucket owner has this permission and can grant this permission to others.\nTo put tags of any other version, use the versionId query parameter. You also need permission\nfor the s3:PutObjectVersionTagging action.\nPutObjectTagging has the following special errors. For more Amazon S3 errors see, Error\nResponses.\n\u2022 InvalidTag - The tag provided was not a valid tag. This error can occur if the tag did not pass\ninput validation. For more information, see Object Tagging.\n\u2022 MalformedXML - The XML provided does not match the schema.\n\u2022 OperationAborted - A conflicting conditional action is currently in progress against this\nresource. Please try again.\n\u2022 InternalError - The service was unable to apply the provided tag to the object.\nThe following operations are related to PutObjectTagging:\n\u2022 GetObjectTagging\n\u2022 DeleteObjectTagging\nAmazon S3 API Version 2006-03-01 676",
      "start_idx": 851658,
      "end_idx": 853303,
      "metadata": {
        "num_sentences": 23,
        "num_words": 257,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_682",
      "text": "Amazon Simple Storage Service API Reference\nRequest Syntax\nPUT /{Key+}?tagging&versionId=VersionId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nx-amz-request-payer: RequestPayer\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<TagSet>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</TagSet>\n</Tagging>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 677",
      "start_idx": 853305,
      "end_idx": 855017,
      "metadata": {
        "num_sentences": 13,
        "num_words": 234,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_683",
      "text": "Amazon Simple Storage Service API Reference\nContent-MD5\nThe MD5 hash for the request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nKey\nName of the object key.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nversionId\nThe versionId of the object that the tag-set will be added to.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nAmazon S3 API Version 2006-03-01 678",
      "start_idx": 855019,
      "end_idx": 856405,
      "metadata": {
        "num_sentences": 15,
        "num_words": 217,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_684",
      "text": "Amazon Simple Storage Service API Reference\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nA collection for a set of tags\nType: Array of Tag data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nx-amz-version-id: VersionId\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nx-amz-version-id\nThe versionId of the object the tag-set was added to.\nAmazon S3 API Version 2006-03-01 679",
      "start_idx": 856407,
      "end_idx": 857365,
      "metadata": {
        "num_sentences": 10,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_687",
      "text": "Amazon Simple Storage Service API Reference\nPutPublicAccessBlock\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nCreates or modifies the PublicAccessBlock configuration for an Amazon S3 bucket. To use\nthis operation, you must have the s3:PutBucketPublicAccessBlock permission. For more\ninformation about Amazon S3 permissions, see Specifying Permissions in a Policy.\nImportant\nWhen Amazon S3 evaluates the PublicAccessBlock configuration for a bucket or an\nobject, it checks the PublicAccessBlock configuration for both the bucket (or the bucket\nthat contains the object) and the bucket owner's account. If the PublicAccessBlock\nconfigurations are different between the bucket and the account, Amazon S3 uses the most\nrestrictive combination of the bucket-level and account-level settings.\nFor more information about when Amazon S3 considers a bucket or an object public, see The\nMeaning of \"Public\".\nThe following operations are related to PutPublicAccessBlock:\n\u2022 GetPublicAccessBlock\n\u2022 DeletePublicAccessBlock\n\u2022 GetBucketPolicyStatus\n\u2022 Using Amazon S3 Block Public Access\nRequest Syntax\nPUT /?publicAccessBlock HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nAmazon S3 API Version 2006-03-01 682",
      "start_idx": 858547,
      "end_idx": 859886,
      "metadata": {
        "num_sentences": 8,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_688",
      "text": "Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the Amazon S3 bucket whose PublicAccessBlock configuration you want to\nset.\nRequired: Yes\nContent-MD5\nThe MD5 hash of the PutPublicAccessBlock request body.\nFor requests made using the AWS Command Line Interface (CLI) or AWS SDKs, this field is\ncalculated automatically.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nAmazon S3 API Version 2006-03-01 683",
      "start_idx": 859888,
      "end_idx": 861513,
      "metadata": {
        "num_sentences": 13,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_689",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nPublicAccessBlockConfiguration\nRoot level tag for the PublicAccessBlockConfiguration parameters.\nRequired: Yes\nBlockPublicAcls\nSpecifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and\nobjects in this bucket. Setting this element to TRUE causes the following behavior:\n\u2022 PUT Bucket ACL and PUT Object ACL calls fail if the specified ACL is public.\n\u2022 PUT Object calls fail if the request includes a public ACL.\n\u2022 PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't affect existing policies or ACLs.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpecifies whether Amazon S3 should block public bucket policies for this bucket. Setting this\nelement to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket\npolicy allows public access.\nEnabling this setting doesn't affect existing bucket policies.\nType: Boolean\nRequired: No\nIgnorePublicAcls\nSpecifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this\nbucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket\nand objects in this bucket.\nEnabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent\nnew public ACLs from being set.\nAmazon S3 API Version 2006-03-01 684",
      "start_idx": 861515,
      "end_idx": 862944,
      "metadata": {
        "num_sentences": 14,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_690",
      "text": "Amazon Simple Storage Service API Reference\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpecifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this\nelement to TRUE restricts access to this bucket to only AWS service principals and authorized\nusers within this account if the bucket has a public policy.\nEnabling this setting doesn't affect previously stored bucket policies, except that public and\ncross-account access within any public bucket policy, including non-public delegation to specific\naccounts, is blocked.\nType: Boolean\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nFirst Sample Request\nThe following request puts a bucket PublicAccessBlock configuration that rejects public ACLs.\nPUT /?publicAccessBlock HTTP/1.1\nHost: <bucket-name>.s3.<Region>.amazonaws.com\nx-amz-date: <Thu, 15 Nov 2016 00:17:21 GMT>\nAuthorization: <signatureValue>\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<BlockPublicAcls>TRUE</BlockPublicAcls>\n<IgnorePublicAcls>FALSE</IgnorePublicAcls>\n<BlockPublicPolicy>FALSE</BlockPublicPolicy>\nAmazon S3 API Version 2006-03-01 685",
      "start_idx": 862946,
      "end_idx": 864241,
      "metadata": {
        "num_sentences": 6,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_693",
      "text": "Amazon Simple Storage Service API Reference\nRestoreObject\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nRestores an archived copy of an object back into Amazon S3\nThis functionality is not supported for Amazon S3 on Outposts.\nThis action performs the following types of requests:\n\u2022 restore an archive - Restore an archived object\nFor more information about the S3 structure in the request body, see the following:\n\u2022 PutObject\n\u2022 Managing Access with ACLs in the Amazon S3 User Guide\n\u2022 Protecting Data Using Server-Side Encryption in the Amazon S3 User Guide\nPermissions\nTo use this operation, you must have permissions to perform the s3:RestoreObject action.\nThe bucket owner has this permission by default and can grant this permission to others.\nFor more information about permissions, see Permissions Related to Bucket Subresource\nOperations and Managing Access Permissions to Your Amazon S3 Resources in the Amazon S3\nUser Guide.\nRestoring objects\nObjects that you archive to the S3 Glacier Flexible Retrieval Flexible Retrieval or S3 Glacier Deep\nArchive storage class, and S3 Intelligent-Tiering Archive or S3 Intelligent-Tiering Deep Archive\ntiers, are not accessible in real time. For objects in the S3 Glacier Flexible Retrieval Flexible\nRetrieval or S3 Glacier Deep Archive storage classes, you must first initiate a restore request,\nand then wait until a temporary copy of the object is available. If you want a permanent copy\nof the object, create a copy of it in the Amazon S3 Standard storage class in your S3 bucket.\nTo access an archived object, you must restore the object for the duration (number of days)\nAmazon S3 API Version 2006-03-01 688",
      "start_idx": 866013,
      "end_idx": 867704,
      "metadata": {
        "num_sentences": 9,
        "num_words": 272,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_694",
      "text": "Amazon Simple Storage Service API Reference\nthat you specify. For objects in the Archive Access or Deep Archive Access tiers of S3 Intelligent-\nTiering, you must first initiate a restore request, and then wait until the object is moved into the\nFrequent Access tier.\nTo restore a specific object version, you can provide a version ID. If you don't provide a version\nID, Amazon S3 restores the current version.\nWhen restoring an archived object, you can specify one of the following data access tier options\nin the Tier element of the request body:\n\u2022 Expedited - Expedited retrievals allow you to quickly access your data stored in the S3\nGlacier Flexible Retrieval Flexible Retrieval storage class or S3 Intelligent-Tiering Archive\ntier when occasional urgent requests for restoring archives are required. For all but the\nlargest archived objects (250 MB+), data accessed using Expedited retrievals is typically\nmade available within 1\u20135 minutes. Provisioned capacity ensures that retrieval capacity\nfor Expedited retrievals is available when you need it. Expedited retrievals and provisioned\ncapacity are not available for objects stored in the S3 Glacier Deep Archive storage class or S3\nIntelligent-Tiering Deep Archive tier.\n\u2022 Standard - Standard retrievals allow you to access any of your archived objects within\nseveral hours. This is the default option for retrieval requests that do not specify the retrieval\noption. Standard retrievals typically finish within 3\u20135 hours for objects stored in the S3\nGlacier Flexible Retrieval Flexible Retrieval storage class or S3 Intelligent-Tiering Archive tier.\nThey typically finish within 12 hours for objects stored in the S3 Glacier Deep Archive storage\nclass or S3 Intelligent-Tiering Deep Archive tier. Standard retrievals are free for objects stored\nin S3 Intelligent-Tiering.\n\u2022 Bulk - Bulk retrievals free for objects stored in the S3 Glacier Flexible Retrieval and S3\nIntelligent-Tiering storage classes, enabling you to retrieve large amounts, even petabytes,\nof data at no cost. Bulk retrievals typically finish within 5\u201312 hours for objects stored in the\nS3 Glacier Flexible Retrieval Flexible Retrieval storage class or S3 Intelligent-Tiering Archive\ntier. Bulk retrievals are also the lowest-cost retrieval option when restoring objects from S3\nGlacier Deep Archive. They typically finish within 48 hours for objects stored in the S3 Glacier\nDeep Archive storage class or S3 Intelligent-Tiering Deep Archive tier.\nFor more information about archive retrieval options and provisioned capacity for Expedited\ndata access, see Restoring Archived Objects in the Amazon S3 User Guide.\nYou can use Amazon S3 restore speed upgrade to change the restore speed to a faster speed\nwhile it is in progress. For more information, see Upgrading the speed of an in-progress restore\nin the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 689",
      "start_idx": 867706,
      "end_idx": 870597,
      "metadata": {
        "num_sentences": 21,
        "num_words": 447,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_695",
      "text": "Amazon Simple Storage Service API Reference\nTo get the status of object restoration, you can send a HEAD request. Operations return the\nx-amz-restore header, which provides information about the restoration status, in the\nresponse. You can use Amazon S3 event notifications to notify you when a restore is initiated\nor completed. For more information, see Configuring Amazon S3 Event Notifications in the\nAmazon S3 User Guide.\nAfter restoring an archived object, you can update the restoration period by reissuing the\nrequest with a new period. Amazon S3 updates the restoration period relative to the current\ntime and charges only for the request-there are no data transfer charges. You cannot update\nthe restoration period when Amazon S3 is actively processing your current restore request for\nthe object.\nIf your bucket has a lifecycle configuration with a rule that includes an expiration action, the\nobject expiration overrides the life span that you specify in a restore request. For example,\nif you restore an object copy for 10 days, but the object is scheduled to expire in 3 days,\nAmazon S3 deletes the object in 3 days. For more information about lifecycle configuration, see\nPutBucketLifecycleConfiguration and Object Lifecycle Management in Amazon S3 User Guide.\nResponses\nA successful action returns either the 200 OK or 202 Accepted status code.\n\u2022 If the object is not previously restored, then Amazon S3 returns 202 Accepted in the\nresponse.\n\u2022 If the object is previously restored, Amazon S3 returns 200 OK in the response.\n\u2022 Special errors:\n\u2022 Code: RestoreAlreadyInProgress\n\u2022 Cause: Object restore is already in progress.\n\u2022 HTTP Status Code: 409 Conflict\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: GlacierExpeditedRetrievalNotAvailable\n\u2022 Cause: expedited retrievals are currently not available. Try again later. (Returned if there is\ninsufficient capacity to process the Expedited request. This error applies only to Expedited\nretrievals and not to S3 Standard or Bulk retrievals.)\n\u2022 HTTP Status Code: 503\n\u2022 SOAP Fault Code Prefix: N/A\nAmazon S3 API Version 2006-03-01 690",
      "start_idx": 870599,
      "end_idx": 872688,
      "metadata": {
        "num_sentences": 19,
        "num_words": 331,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_698",
      "text": "Amazon Simple Storage Service API Reference\n<MetadataEntry>\n<Name>string</Name>\n<Value>string</Value>\n</MetadataEntry>\n</UserMetadata>\n</S3>\n</OutputLocation>\n</RestoreRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name containing the object to restore.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nObject key for which the action was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nAmazon S3 API Version 2006-03-01 693",
      "start_idx": 874989,
      "end_idx": 876522,
      "metadata": {
        "num_sentences": 15,
        "num_words": 234,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_699",
      "text": "Amazon Simple Storage Service API Reference\nversionId\nVersionId used to reference a specific version of the object.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequest Body\nThe request accepts the following data in XML format.\nAmazon S3 API Version 2006-03-01 694",
      "start_idx": 876524,
      "end_idx": 878127,
      "metadata": {
        "num_sentences": 16,
        "num_words": 247,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_700",
      "text": "Amazon Simple Storage Service API Reference\nRestoreRequest\nRoot level tag for the RestoreRequest parameters.\nRequired: Yes\nDays\nLifetime of the active copy in days. Do not use with restores that specify OutputLocation.\nThe Days element is required for regular restores, and must not be provided for select requests.\nType: Integer\nRequired: No\nDescription\nThe optional description for the job.\nType: String\nRequired: No\nGlacierJobParameters\nS3 Glacier related parameters pertaining to this job. Do not use with restores that specify\nOutputLocation.\nType: GlacierJobParameters data type\nRequired: No\nOutputLocation\nDescribes the location where the restore job's output is stored.\nType: OutputLocation data type\nRequired: No\nSelectParameters\nDescribes the parameters for Select job types.\nType: SelectParameters data type\nRequired: No\nAmazon S3 API Version 2006-03-01 695",
      "start_idx": 878129,
      "end_idx": 878997,
      "metadata": {
        "num_sentences": 10,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_704",
      "text": "Amazon Simple Storage Service API Reference\nSelectObjectContent\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nThis action filters the contents of an Amazon S3 object based on a simple structured query\nlanguage (SQL) statement. In the request, along with the SQL expression, you must also specify a\ndata serialization format (JSON, CSV, or Apache Parquet) of the object. Amazon S3 uses this format\nto parse object data into records, and returns only records that match the specified SQL expression.\nYou must also specify the data serialization format for the response.\nThis functionality is not supported for Amazon S3 on Outposts.\nFor more information about Amazon S3 Select, see Selecting Content from Objects and SELECT\nCommand in the Amazon S3 User Guide.\nPermissions\nYou must have the s3:GetObject permission for this operation. Amazon S3 Select does\nnot support anonymous access. For more information about permissions, see Specifying\nPermissions in a Policy in the Amazon S3 User Guide.\nObject Data Formats\nYou can use Amazon S3 Select to query objects that have the following format properties:\n\u2022 CSV, JSON, and Parquet - Objects must be in CSV, JSON, or Parquet format.\n\u2022 UTF-8 - UTF-8 is the only encoding type Amazon S3 Select supports.\n\u2022 GZIP or BZIP2 - CSV and JSON files can be compressed using GZIP or BZIP2. GZIP and BZIP2\nare the only compression formats that Amazon S3 Select supports for CSV and JSON files.\nAmazon S3 Select supports columnar compression for Parquet using GZIP or Snappy. Amazon\nS3 Select does not support whole-object compression for Parquet objects.\n\u2022 Server-side encryption - Amazon S3 Select supports querying objects that are protected with\nserver-side encryption.\nFor objects that are encrypted with customer-provided encryption keys (SSE-C), you must\nuse HTTPS, and you must use the headers that are documented in the GetObject. For more\nAmazon S3 API Version 2006-03-01 699",
      "start_idx": 881459,
      "end_idx": 883407,
      "metadata": {
        "num_sentences": 19,
        "num_words": 313,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_705",
      "text": "Amazon Simple Storage Service API Reference\ninformation about SSE-C, see Server-Side Encryption (Using Customer-Provided Encryption\nKeys) in the Amazon S3 User Guide.\nFor objects that are encrypted with Amazon S3 managed keys (SSE-S3) and AWS KMS keys\n(SSE-KMS), server-side encryption is handled transparently, so you don't need to specify\nanything. For more information about server-side encryption, including SSE-S3 and SSE-KMS,\nsee Protecting Data Using Server-Side Encryption in the Amazon S3 User Guide.\nWorking with the Response Body\nGiven the response size is unknown, Amazon S3 Select streams the response as a series of\nmessages and includes a Transfer-Encoding header with chunked as its value in the\nresponse. For more information, see Appendix: SelectObjectContent Response.\nGetObject Support\nThe SelectObjectContent action does not support the following GetObject functionality.\nFor more information, see GetObject.\n\u2022 Range: Although you can specify a scan range for an Amazon S3 Select request (see\nSelectObjectContentRequest - ScanRange in the request parameters), you cannot specify the\nrange of bytes of an object to return.\n\u2022 The GLACIER, DEEP_ARCHIVE, and REDUCED_REDUNDANCY storage classes, or the\nARCHIVE_ACCESS and DEEP_ARCHIVE_ACCESS access tiers of the INTELLIGENT_TIERING\nstorage class: You cannot query objects in the GLACIER, DEEP_ARCHIVE, or\nREDUCED_REDUNDANCY storage classes, nor objects in the ARCHIVE_ACCESS or\nDEEP_ARCHIVE_ACCESS access tiers of the INTELLIGENT_TIERING storage class. For more\ninformation about storage classes, see Using Amazon S3 storage classes in the Amazon S3\nUser Guide.\nSpecial Errors\nFor a list of special errors for this operation, see List of SELECT Object Content Error Codes\nThe following operations are related to SelectObjectContent:\n\u2022 GetObject\n\u2022 GetBucketLifecycleConfiguration\n\u2022 PutBucketLifecycleConfiguration\nAmazon S3 API Version 2006-03-01 700",
      "start_idx": 883409,
      "end_idx": 885324,
      "metadata": {
        "num_sentences": 11,
        "num_words": 268,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_707",
      "text": "Amazon Simple Storage Service API Reference\n<ScanRange>\n<End>long</End>\n<Start>long</Start>\n</ScanRange>\n</SelectObjectContentRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe S3 bucket.\nRequired: Yes\nKey\nThe object key.\nLength Constraints: Minimum length of 1.\nRequired: Yes\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-server-side-encryption-customer-algorithm\nThe server-side encryption (SSE) algorithm used to encrypt the object. This parameter is needed\nonly when the object was created using a checksum algorithm. For more information, see\nProtecting data using SSE-C keys in the Amazon S3 User Guide.\nx-amz-server-side-encryption-customer-key\nThe server-side encryption (SSE) customer managed key. This parameter is needed only when\nthe object was created using a checksum algorithm. For more information, see Protecting data\nusing SSE-C keys in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 702",
      "start_idx": 886774,
      "end_idx": 887920,
      "metadata": {
        "num_sentences": 13,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_708",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key-MD5\nThe MD5 server-side encryption (SSE) customer managed key. This parameter is needed only\nwhen the object was created using a checksum algorithm. For more information, see Protecting\ndata using SSE-C keys in the Amazon S3 User Guide.\nRequest Body\nThe request accepts the following data in XML format.\nSelectObjectContentRequest\nRoot level tag for the SelectObjectContentRequest parameters.\nRequired: Yes\nExpression\nThe expression that is used to query the object.\nType: String\nRequired: Yes\nExpressionType\nThe type of the provided expression (for example, SQL).\nType: String\nValid Values: SQL\nRequired: Yes\nInputSerialization\nDescribes the format of the data in the object that is being queried.\nType: InputSerialization data type\nRequired: Yes\nOutputSerialization\nDescribes the format of the data that you want Amazon S3 to return in response.\nType: OutputSerialization data type\nAmazon S3 API Version 2006-03-01 703",
      "start_idx": 887922,
      "end_idx": 888928,
      "metadata": {
        "num_sentences": 10,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_709",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nRequestProgress\nSpecifies if periodic request progress information should be enabled.\nType: RequestProgress data type\nRequired: No\nScanRange\nSpecifies the byte range of the object to get the records from. A record is processed when its\nfirst byte is contained by the range. This parameter is optional, but when specified, it must not\nbe empty. See RFC 2616, Section 14.35.1 about how to specify the start and end of the range.\nScanRangemay be used in the following ways:\n\u2022 <scanrange><start>50</start><end>100</end></scanrange> - process only the\nrecords starting between the bytes 50 and 100 (inclusive, counting from zero)\n\u2022 <scanrange><start>50</start></scanrange> - process only the records starting after\nthe byte 50\n\u2022 <scanrange><end>50</end></scanrange> - process only the records within the last 50\nbytes of the file.\nType: ScanRange data type\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Payload>\n<Records>\n<Payload>blob</Payload>\n</Records>\n<Stats>\n<Details>\n<BytesProcessed>long</BytesProcessed>\n<BytesReturned>long</BytesReturned>\n<BytesScanned>long</BytesScanned>\n</Details>\nAmazon S3 API Version 2006-03-01 704",
      "start_idx": 888930,
      "end_idx": 890149,
      "metadata": {
        "num_sentences": 7,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_714",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nDate: Tue, 17 Oct 2017 23:54:05 GMT\nA series of messages\nExample 3: Parquet object\n\u2022 The InputSerialization element describes the format of the data in the object that is being\nqueried. It must specify CSV, JSON, or Parquet.\n\u2022 The OutputSerialization element describes the format of the data that you want Amazon\nS3 to return in response to the query. It must specify CSV, JSON. Amazon S3 doesn't support\noutputting data in the Parquet format.\n\u2022 The format of the InputSerialization doesn't need to match the format of the\nOutputSerialization. So, for example, you can specify JSON in the InputSerialization\nand CSV in the OutputSerialization.\nPOST /exampleobject.parquet?select&select-type=2 HTTP/1.1\nHost: examplebucket.s3.<Region>.amazonaws.com\nDate: Tue, 17 Oct 2017 01:49:52 GMT\nAuthorization: authorization string\nContent-Length: content length\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<SelectRequest>\n<Expression>Select * from S3Object</Expression>\n<ExpressionType>SQL</ExpressionType>\n<InputSerialization>\n<CompressionType>NONE</CompressionType>\n<Parquet>\n</Parquet>\n</InputSerialization>\n<OutputSerialization>\n<CSV>\n<QuoteFields>ASNEEDED</QuoteFields>\n<RecordDelimiter>\\n</RecordDelimiter>\nAmazon S3 API Version 2006-03-01 709",
      "start_idx": 894241,
      "end_idx": 895659,
      "metadata": {
        "num_sentences": 8,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_716",
      "text": "Amazon Simple Storage Service API Reference\nUploadPart\nService: Amazon S3\nUploads a part in a multipart upload.\nNote\nIn this operation, you provide new data as a part of an object in your request. However,\nyou have an option to specify your existing Amazon S3 object as a data source for the part\nyou are uploading. To upload a part from an existing object, you use the UploadPartCopy\noperation.\nYou must initiate a multipart upload (see CreateMultipartUpload) before you can upload any part.\nIn response to your initiate request, Amazon S3 returns an upload ID, a unique identifier that you\nmust include in your upload part request.\nPart numbers can be any number from 1 to 10,000, inclusive. A part number uniquely identifies\na part and also defines its position within the object being created. If you upload a new part\nusing the same part number that was used with a previous part, the previously uploaded part is\noverwritten.\nFor information about maximum and minimum part sizes and other multipart upload\nspecifications, see Multipart upload limits in the Amazon S3 User Guide.\nNote\nAfter you initiate multipart upload and upload one or more parts, you must either\ncomplete or abort multipart upload in order to stop getting charged for storage of the\nuploaded parts. Only after you either complete or abort multipart upload, Amazon S3 frees\nup the parts storage and stops charging you for the parts storage.\nFor more information on multipart uploads, go to Multipart Upload Overview in the Amazon S3\nUser Guide .\nAmazon S3 API Version 2006-03-01 711",
      "start_idx": 896219,
      "end_idx": 897775,
      "metadata": {
        "num_sentences": 14,
        "num_words": 262,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_717",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nPermissions\n\u2022 General purpose bucket permissions - To perform a multipart upload with encryption\nusing an AWS Key Management Service key, the requester must have permission to the\nkms:Decrypt and kms:GenerateDataKey actions on the key. The requester must also have\npermissions for the kms:GenerateDataKey action for the CreateMultipartUpload API.\nThen, the requester needs permissions for the kms:Decrypt action on the UploadPart and\nUploadPartCopy APIs.\nThese permissions are required because Amazon S3 must decrypt and read data from the\nencrypted file parts before it completes the multipart upload. For more information about\nKMS permissions, see Protecting data using server-side encryption with AWS KMS in the\nAmazon S3 User Guide. For information about the permissions required to use the multipart\nupload API, see Multipart upload and permissions and Multipart upload API and permissions\nin the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - To grant access to this API operation on a directory\nbucket, we recommend that you use the CreateSession API operation for session-based\nauthorization. Specifically, you grant the s3express:CreateSession permission to the\ndirectory bucket in a bucket policy or an IAM identity-based policy. Then, you make the\nCreateSession API call on the bucket to obtain a session token. With the session token in\nyour request header, you can make API requests to this operation. After the session token\nexpires, you make another CreateSession API call to generate a new session token for\nuse. AWS CLI or SDKs create session and refresh the session token automatically to avoid\nservice interruptions when a session expires. For more information about authorization, see\nCreateSession.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key.\nAmazon S3 API Version 2006-03-01 712",
      "start_idx": 897777,
      "end_idx": 900151,
      "metadata": {
        "num_sentences": 19,
        "num_words": 351,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_718",
      "text": "Amazon Simple Storage Service API Reference\nData integrity\nGeneral purpose bucket - To ensure that data is not corrupted traversing the network, specify\nthe Content-MD5 header in the upload part request. Amazon S3 checks the part data against\nthe provided MD5 value. If they do not match, Amazon S3 returns an error. If the upload\nrequest is signed with Signature Version 4, then AWS S3 uses the x-amz-content-sha256\nheader as a checksum instead of Content-MD5. For more information see Authenticating\nRequests: Using the Authorization Header (AWS Signature Version 4).\nNote\nDirectory buckets - MD5 is not supported by directory buckets. You can use checksum\nalgorithms to check object integrity.\nEncryption\n\u2022 General purpose bucket - Server-side encryption is for data encryption at rest. Amazon S3\nencrypts your data as it writes it to disks in its data centers and decrypts it when you access it.\nYou have mutually exclusive options to protect data using server-side encryption in Amazon\nS3, depending on how you choose to manage the encryption keys. Specifically, the encryption\nkey options are Amazon S3 managed keys (SSE-S3), AWS KMS keys (SSE-KMS), and Customer-\nProvided Keys (SSE-C). Amazon S3 encrypts data with server-side encryption using Amazon\nS3 managed keys (SSE-S3) by default. You can optionally tell Amazon S3 to encrypt data\nat rest using server-side encryption with other key options. The option you use depends on\nwhether you want to use KMS keys (SSE-KMS) or provide your own encryption key (SSE-C).\nServer-side encryption is supported by the S3 Multipart Upload operations. Unless you are\nusing a customer-provided encryption key (SSE-C), you don't need to specify the encryption\nparameters in each UploadPart request. Instead, you only need to specify the server-side\nencryption parameters in the initial Initiate Multipart request. For more information, see\nCreateMultipartUpload.\nIf you request server-side encryption using a customer-provided encryption key (SSE-C) in\nyour initiate multipart upload request, you must provide identical encryption information in\neach part upload using the following request headers.\n\u2022 x-amz-server-side-encryption-customer-algorithm\n\u2022 x-amz-server-side-encryption-customer-key\nAmazon S3 API Version 2006-03-01 713",
      "start_idx": 900153,
      "end_idx": 902427,
      "metadata": {
        "num_sentences": 20,
        "num_words": 337,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_719",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 x-amz-server-side-encryption-customer-key-MD5\nFor more information, see Using Server-Side Encryption in the Amazon S3 User Guide.\n\u2022 Directory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256)\nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms).\nSpecial errors\n\u2022 Error Code: NoSuchUpload\n\u2022 Description: The specified multipart upload does not exist. The upload ID might be invalid,\nor the multipart upload might have been aborted or completed.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\nHTTP Host header syntax\nDirectory buckets - The HTTP Host header syntax is\nBucket_name.s3express-az_id.region.amazonaws.com.\nThe following operations are related to UploadPart:\n\u2022 CreateMultipartUpload\n\u2022 CompleteMultipartUpload\n\u2022 AbortMultipartUpload\n\u2022 ListParts\n\u2022 ListMultipartUploads\nRequest Syntax\nPUT /Key+?partNumber=PartNumber&uploadId=UploadId HTTP/1.1\nHost: Bucket.s3.amazonaws.com\nContent-Length: ContentLength\nContent-MD5: ContentMD5\nx-amz-sdk-checksum-algorithm: ChecksumAlgorithm\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nAmazon S3 API Version 2006-03-01 714",
      "start_idx": 902429,
      "end_idx": 903789,
      "metadata": {
        "num_sentences": 6,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_720",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key: SSECustomerKey\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-request-payer: RequestPayer\nx-amz-expected-bucket-owner: ExpectedBucketOwner\nBody\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe name of the bucket to which the multipart upload was initiated.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nAmazon S3 API Version 2006-03-01 715",
      "start_idx": 903791,
      "end_idx": 905739,
      "metadata": {
        "num_sentences": 16,
        "num_words": 255,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_721",
      "text": "Amazon Simple Storage Service API Reference\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nContent-Length\nSize of the body in bytes. This parameter is useful when the size of the body cannot be\ndetermined automatically.\nContent-MD5\nThe base64-encoded 128-bit MD5 digest of the part data. This parameter is auto-populated\nwhen using the command from the CLI. This parameter is required if object lock parameters are\nspecified.\nNote\nThis functionality is not supported for directory buckets.\nKey\nObject key for which the multipart upload was initiated.\nLength Constraints: Minimum length of 1.\nRequired: Yes\npartNumber\nPart number of part being uploaded. This is a positive integer between 1 and 10,000.\nRequired: Yes\nuploadId\nUpload ID identifying the multipart upload whose part is being uploaded.\nRequired: Yes\nx-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32\nAmazon S3 API Version 2006-03-01 716",
      "start_idx": 905741,
      "end_idx": 907002,
      "metadata": {
        "num_sentences": 16,
        "num_words": 203,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_722",
      "text": "Amazon Simple Storage Service API Reference\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nx-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32C\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nx-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 160-bit SHA-1 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nx-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 256-bit SHA-256 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nx-amz-expected-bucket-owner\nThe account ID of the expected bucket owner. If the account ID that you provide does not match\nthe actual owner of the bucket, the request fails with the HTTP status code 403 Forbidden\n(access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nAmazon S3 API Version 2006-03-01 717",
      "start_idx": 907004,
      "end_idx": 908886,
      "metadata": {
        "num_sentences": 19,
        "num_words": 294,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_723",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-sdk-checksum-algorithm\nIndicates the algorithm used to create the checksum for the object when you use the SDK. This\nheader will not provide any additional functionality if you don't use the SDK. When you send\nthis header, there must be a corresponding x-amz-checksum or x-amz-trailer header sent.\nOtherwise, Amazon S3 fails the request with the HTTP status code 400 Bad Request. For\nmore information, see Checking object integrity in the Amazon S3 User Guide.\nIf you provide an individual checksum, Amazon S3 ignores any provided ChecksumAlgorithm\nparameter.\nThis checksum algorithm must be the same for all parts and it match the checksum value\nsupplied in the CreateMultipartUpload request.\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded; Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-\namz-server-side-encryption-customer-algorithm header. This must be the same\nencryption key specified in the initiate multipart upload request.\nNote\nThis functionality is not supported for directory buckets.\nAmazon S3 API Version 2006-03-01 718",
      "start_idx": 908888,
      "end_idx": 910428,
      "metadata": {
        "num_sentences": 15,
        "num_words": 224,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_724",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nNote\nThis functionality is not supported for directory buckets.\nRequest Body\nThe request accepts the following binary data.\nBody\nResponse Syntax\nHTTP/1.1 200\nx-amz-server-side-encryption: ServerSideEncryption\nETag: ETag\nx-amz-checksum-crc32: ChecksumCRC32\nx-amz-checksum-crc32c: ChecksumCRC32C\nx-amz-checksum-sha1: ChecksumSHA1\nx-amz-checksum-sha256: ChecksumSHA256\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nETag\nEntity tag for the uploaded object.\nAmazon S3 API Version 2006-03-01 719",
      "start_idx": 910430,
      "end_idx": 911600,
      "metadata": {
        "num_sentences": 8,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_725",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-checksum-crc32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-checksum-crc32c\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-checksum-sha1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nx-amz-checksum-sha256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nx-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nAmazon S3 API Version 2006-03-01 720",
      "start_idx": 911602,
      "end_idx": 913844,
      "metadata": {
        "num_sentences": 22,
        "num_words": 357,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_727",
      "text": "Amazon Simple Storage Service API Reference\nExamples\nSample Request for general purpose buckets\nThe following PUT request uploads a part (part number 1) in a multipart upload. The request\nincludes the upload ID that you get in response to your Initiate Multipart Upload request.\nPUT /my-movie.m2ts?\npartNumber=1&uploadId=VCVsb2FkIElEIGZvciBlbZZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZR\nHTTP/1.1\nHost: example-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nContent-Length: 10485760\nContent-MD5: pUNXr/BjKK5G2UKvaRRrOA==\nAuthorization: authorization string\n***part data omitted***\nSample Response for general purpose buckets\nThe response includes the ETag header. You need to retain this value for use when you send the\nComplete Multipart Upload request.\nHTTP/1.1 200 OK\nx-amz-id-2: Vvag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 1 Nov 2010 20:34:56 GMT\nETag: \"b54357faf0632cce46e942fa68356b38\"\nContent-Length: 0\nConnection: keep-alive\nServer: AmazonS3\nExample for general purpose buckets: Upload a part with an encryption key in the request for\nserver-side encryption\nIf you initiated a multipart upload with a request to save an object using server-side encryption\nwith a customer-provided encryption key, each part upload must also include the same set of\nencryption-specific headers as shown in the following example request.\nAmazon S3 API Version 2006-03-01 722",
      "start_idx": 915131,
      "end_idx": 916582,
      "metadata": {
        "num_sentences": 7,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_730",
      "text": "Amazon Simple Storage Service API Reference\nUploadPartCopy\nService: Amazon S3\nUploads a part by copying data from an existing object as data source. To specify the data source,\nyou add the request header x-amz-copy-source in your request. To specify a byte range, you\nadd the request header x-amz-copy-source-range in your request.\nFor information about maximum and minimum part sizes and other multipart upload\nspecifications, see Multipart upload limits in the Amazon S3 User Guide.\nNote\nInstead of copying data from an existing object as part data, you might use the UploadPart\naction to upload new data as a part of an object in your request.\nYou must initiate a multipart upload before you can upload any part. In response to your initiate\nrequest, Amazon S3 returns the upload ID, a unique identifier that you must include in your upload\npart request.\nFor conceptual information about multipart uploads, see Uploading Objects Using Multipart\nUpload in the Amazon S3 User Guide. For information about copying objects using a single atomic\naction vs. a multipart upload, see Operations on Objects in the Amazon S3 User Guide.\nNote\nDirectory buckets - For directory buckets, you must make requests for this API operation\nto the Zonal endpoint. These endpoints support virtual-hosted-style requests in the format\nhttps://bucket_name.s3express-az_id.region.amazonaws.com/key-name\n. Path-style requests are not supported. For more information, see Regional and Zonal\nendpoints in the Amazon S3 User Guide.\nAuthentication and authorization\nAll UploadPartCopy requests must be authenticated and signed by using IAM credentials\n(access key ID and secret access key for the IAM identities). All headers with the x-amz-\nprefix, including x-amz-copy-source, must be signed. For more information, see REST\nAuthentication.\nAmazon S3 API Version 2006-03-01 725",
      "start_idx": 918118,
      "end_idx": 919969,
      "metadata": {
        "num_sentences": 17,
        "num_words": 280,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_731",
      "text": "Amazon Simple Storage Service API Reference\nDirectory buckets - You must use IAM credentials to authenticate and authorize your access\nto the UploadPartCopy API operation, instead of using the temporary security credentials\nthrough the CreateSession API operation.\nAWS CLI or SDKs handles authentication and authorization on your behalf.\nPermissions\nYou must have READ access to the source object and WRITE access to the destination bucket.\n\u2022 General purpose bucket permissions - You must have the permissions in a policy based\non the bucket types of your source bucket and destination bucket in an UploadPartCopy\noperation.\n\u2022 If the source object is in a general purpose bucket, you must have the s3:GetObject\npermission to read the source object that is being copied.\n\u2022 If the destination bucket is a general purpose bucket, you must have the s3:PutObject\npermission to write the object copy to the destination bucket.\n\u2022 To perform a multipart upload with encryption using an AWS Key Management\nService key, the requester must have permission to the kms:Decrypt and\nkms:GenerateDataKey actions on the key. The requester must also have permissions\nfor the kms:GenerateDataKey action for the CreateMultipartUpload API. Then,\nthe requester needs permissions for the kms:Decrypt action on the UploadPart and\nUploadPartCopy APIs. These permissions are required because Amazon S3 must decrypt\nand read data from the encrypted file parts before it completes the multipart upload. For\nmore information about KMS permissions, see Protecting data using server-side encryption\nwith AWS KMS in the Amazon S3 User Guide. For information about the permissions\nrequired to use the multipart upload API, see Multipart upload and permissions and\nMultipart upload API and permissions in the Amazon S3 User Guide.\n\u2022 Directory bucket permissions - You must have permissions in a bucket policy or an\nIAM identity-based policy based on the source and destination bucket types in an\nUploadPartCopy operation.\n\u2022 If the source object that you want to copy is in a directory bucket, you must have the\ns3express:CreateSession permission in the Action element of a policy to read the\nobject. By default, the session is in the ReadWrite mode. If you want to restrict the access,\nyou can explicitly set the s3express:SessionMode condition key to ReadOnly on the\ncopy source bucket.\n\u2022 If the copy destination is a directory bucket, you must have the\ns3express:CreateSession permission in the Action element of a policy to write the\nAmazon S3 API Version 2006-03-01 726",
      "start_idx": 919971,
      "end_idx": 922510,
      "metadata": {
        "num_sentences": 17,
        "num_words": 401,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_732",
      "text": "Amazon Simple Storage Service API Reference\nobject to the destination. The s3express:SessionMode condition key cannot be set to\nReadOnly on the copy destination.\nIf the object is encrypted with SSE-KMS, you must also have the kms:GenerateDataKey and\nkms:Decrypt permissions in IAM identity-based policies and AWS KMS key policies for the\nAWS KMS key.\nFor example policies, see Example bucket policies for S3 Express One Zone and AWS Identity\nand Access Management (IAM) identity-based policies for S3 Express One Zone in the Amazon\nS3 User Guide.\nEncryption\n\u2022 General purpose buckets - For information about using server-side encryption with\ncustomer-provided encryption keys with the UploadPartCopy operation, see CopyObject\nand UploadPart.\n\u2022 Directory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256)\nand server-side encryption with AWS KMS keys (SSE-KMS) (aws:kms). For more information,\nsee Protecting data with server-side encryption in the Amazon S3 User Guide.\nNote\nFor directory buckets, when you perform a CreateMultipartUpload operation\nand an UploadPartCopy operation, the request headers you provide in the\nCreateMultipartUpload request must match the default encryption configuration\nof the destination bucket.\nS3 Bucket Keys aren't supported, when you copy SSE-KMS encrypted objects from general\npurpose buckets to directory buckets, from directory buckets to general purpose buckets, or\nbetween directory buckets, through UploadPartCopy. In this case, Amazon S3 makes a call to\nAWS KMS every time a copy request is made for a KMS-encrypted object.\nSpecial errors\n\u2022 Error Code: NoSuchUpload\n\u2022 Description: The specified multipart upload does not exist. The upload ID might be invalid,\nor the multipart upload might have been aborted or completed.\n\u2022 HTTP Status Code: 404 Not Found\nAmazon S3 API Version 2006-03-01 727",
      "start_idx": 922512,
      "end_idx": 924462,
      "metadata": {
        "num_sentences": 13,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_734",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nBucket\nThe bucket name.\nDirectory buckets - When you use this operation with a directory\nbucket, you must use virtual-hosted-style requests in the format\nBucket_name.s3express-az_id.region.amazonaws.com. Path-style requests are not\nsupported. Directory bucket names must be unique in the chosen Availability Zone. Bucket\nnames must follow the format bucket_base_name--az-id--x-s3 (for example, DOC-\nEXAMPLE-BUCKET--usw2-az1--x-s3). For information about bucket naming restrictions, see\nDirectory bucket naming rules in the Amazon S3 User Guide.\nAccess points - When you use this action with an access point, you must provide the alias of the\naccess point in place of the bucket name or specify the access point ARN. When using the access\npoint ARN, you must direct requests to the access point hostname. The access point hostname\ntakes the form AccessPointName-AccountId.s3-accesspoint.Region.amazonaws.com. When using\nthis action with an access point through the AWS SDKs, you provide the access point ARN in\nplace of the bucket name. For more information about access point ARNs, see Using access\npoints in the Amazon S3 User Guide.\nNote\nAccess points and Object Lambda access points are not supported by directory buckets.\nS3 on Outposts - When you use this action with Amazon S3 on Outposts, you must direct\nrequests to the S3 on Outposts hostname. The S3 on Outposts hostname takes the form\nAccessPointName-AccountId.outpostID.s3-outposts.Region.amazonaws.com.\nWhen you use this action with S3 on Outposts through the AWS SDKs, you provide the Outposts\naccess point ARN in place of the bucket name. For more information about S3 on Outposts\nARNs, see What is S3 on Outposts? in the Amazon S3 User Guide.\nRequired: Yes\nKey\nObject key for which the multipart upload was initiated.\nAmazon S3 API Version 2006-03-01 729",
      "start_idx": 926004,
      "end_idx": 927938,
      "metadata": {
        "num_sentences": 20,
        "num_words": 293,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_735",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.\nRequired: Yes\npartNumber\nPart number of part being copied. This is a positive integer between 1 and 10,000.\nRequired: Yes\nuploadId\nUpload ID identifying the multipart upload whose part is being copied.\nRequired: Yes\nx-amz-copy-source\nSpecifies the source object for the copy operation. You specify the value in one of two formats,\ndepending on whether you want to access the source object through an access point:\n\u2022 For objects not accessed through an access point, specify the name of the source bucket and\nkey of the source object, separated by a slash (/). For example, to copy the object reports/\njanuary.pdf from the bucket awsexamplebucket, use awsexamplebucket/reports/\njanuary.pdf. The value must be URL-encoded.\n\u2022 For objects accessed through access points, specify the Amazon Resource\nName (ARN) of the object as accessed through the access point, in the format\narn:aws:s3:<Region>:<account-id>:accesspoint/<access-point-name>/\nobject/<key>. For example, to copy the object reports/january.pdf through access\npoint my-access-point owned by account 123456789012 in Region us-west-2, use the\nURL encoding of arn:aws:s3:us-west-2:123456789012:accesspoint/my-access-\npoint/object/reports/january.pdf. The value must be URL encoded.\nNote\n\u2022 Amazon S3 supports copy operations using Access points only when the source and\ndestination buckets are in the same AWS Region.\n\u2022 Access points are not supported by directory buckets.\nAlternatively, for objects accessed through Amazon S3 on Outposts, specify the ARN of\nthe object as accessed in the format arn:aws:s3-outposts:<Region>:<account-\nAmazon S3 API Version 2006-03-01 730",
      "start_idx": 927940,
      "end_idx": 929652,
      "metadata": {
        "num_sentences": 14,
        "num_words": 242,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_736",
      "text": "Amazon Simple Storage Service API Reference\nid>:outpost/<outpost-id>/object/<key>. For example, to copy the object\nreports/january.pdf through outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/object/reports/january.pdf. The\nvalue must be URL-encoded.\nIf your bucket has versioning enabled, you could have multiple versions of the same\nobject. By default, x-amz-copy-source identifies the current version of the source\nobject to copy. To copy a specific version of the source object to copy, append ?\nversionId=<version-id> to the x-amz-copy-source request header (for\nexample, x-amz-copy-source: /awsexamplebucket/reports/january.pdf?\nversionId=QUpfdndhfd8438MNFDN93jdnJFkdmqnh893).\nIf the current version is a delete marker and you don't specify a versionId in the x-amz-copy-\nsource request header, Amazon S3 returns a 404 Not Found error, because the object does\nnot exist. If you specify versionId in the x-amz-copy-source and the versionId is a delete\nmarker, Amazon S3 returns an HTTP 400 Bad Request error, because you are not allowed to\nspecify a delete marker as a version for the x-amz-copy-source.\nNote\nDirectory buckets - S3 Versioning isn't enabled and supported for directory buckets.\nPattern: \\/.+\\/.+\nRequired: Yes\nx-amz-copy-source-if-match\nCopies the object if its entity tag (ETag) matches the specified tag.\nIf both of the x-amz-copy-source-if-match and x-amz-copy-source-if-unmodified-\nsince headers are present in the request as follows:\nx-amz-copy-source-if-match condition evaluates to true, and;\nx-amz-copy-source-if-unmodified-since condition evaluates to false;\nAmazon S3 returns 200 OK and copies the data.\nAmazon S3 API Version 2006-03-01 731",
      "start_idx": 929654,
      "end_idx": 931433,
      "metadata": {
        "num_sentences": 14,
        "num_words": 233,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_737",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-copy-source-if-modified-since\nCopies the object if it has been modified since the specified time.\nIf both of the x-amz-copy-source-if-none-match and x-amz-copy-source-if-\nmodified-since headers are present in the request as follows:\nx-amz-copy-source-if-none-match condition evaluates to false, and;\nx-amz-copy-source-if-modified-since condition evaluates to true;\nAmazon S3 returns 412 Precondition Failed response code.\nx-amz-copy-source-if-none-match\nCopies the object if its entity tag (ETag) is different than the specified ETag.\nIf both of the x-amz-copy-source-if-none-match and x-amz-copy-source-if-\nmodified-since headers are present in the request as follows:\nx-amz-copy-source-if-none-match condition evaluates to false, and;\nx-amz-copy-source-if-modified-since condition evaluates to true;\nAmazon S3 returns 412 Precondition Failed response code.\nx-amz-copy-source-if-unmodified-since\nCopies the object if it hasn't been modified since the specified time.\nIf both of the x-amz-copy-source-if-match and x-amz-copy-source-if-unmodified-\nsince headers are present in the request as follows:\nx-amz-copy-source-if-match condition evaluates to true, and;\nx-amz-copy-source-if-unmodified-since condition evaluates to false;\nAmazon S3 returns 200 OK and copies the data.\nx-amz-copy-source-range\nThe range of bytes to copy from the source object. The range value must use the form\nbytes=first-last, where the first and last are the zero-based byte offsets to copy. For example,\nbytes=0-9 indicates that you want to copy the first 10 bytes of the source. You can copy a range\nonly if the source object is greater than 5 MB.\nAmazon S3 API Version 2006-03-01 732",
      "start_idx": 931435,
      "end_idx": 933147,
      "metadata": {
        "num_sentences": 11,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_738",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-copy-source-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when decrypting the source object (for example, AES256).\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use to decrypt the source\nobject. The encryption key provided in this header must be one that was used when the source\nobject was created.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-copy-source-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nNote\nThis functionality is not supported when the source object is in a directory bucket.\nx-amz-expected-bucket-owner\nThe account ID of the expected destination bucket owner. If the account ID that you provide\ndoes not match the actual owner of the destination bucket, the request fails with the HTTP\nstatus code 403 Forbidden (access denied).\nx-amz-request-payer\nConfirms that the requester knows that they will be charged for the request. Bucket owners\nneed not specify this parameter in their requests. If either the source or destination S3\nAmazon S3 API Version 2006-03-01 733",
      "start_idx": 933149,
      "end_idx": 934617,
      "metadata": {
        "num_sentences": 13,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_739",
      "text": "Amazon Simple Storage Service API Reference\nbucket has Requester Pays enabled, the requester will pay for corresponding charges to copy\nthe object. For information about downloading objects from Requester Pays buckets, see\nDownloading Objects in Requester Pays Buckets in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-server-side-encryption-customer-algorithm\nSpecifies the algorithm to use when encrypting the object (for example, AES256).\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-server-side-encryption-customer-key\nSpecifies the customer-provided encryption key for Amazon S3 to use in encrypting data.\nThis value is used to store the object and then it is discarded; Amazon S3 does not store the\nencryption key. The key must be appropriate for use with the algorithm specified in the x-\namz-server-side-encryption-customer-algorithm header. This must be the same\nencryption key specified in the initiate multipart upload request.\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-server-side-encryption-customer-key-MD5\nSpecifies the 128-bit MD5 digest of the encryption key according to RFC 1321. Amazon S3 uses\nthis header for a message integrity check to ensure that the encryption key was transmitted\nwithout error.\nAmazon S3 API Version 2006-03-01 734",
      "start_idx": 934619,
      "end_idx": 936058,
      "metadata": {
        "num_sentences": 13,
        "num_words": 202,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_740",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported when the destination bucket is a directory bucket.\nx-amz-source-expected-bucket-owner\nThe account ID of the expected source bucket owner. If the account ID that you provide does not\nmatch the actual owner of the source bucket, the request fails with the HTTP status code 403\nForbidden (access denied).\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nx-amz-copy-source-version-id: CopySourceVersionId\nx-amz-server-side-encryption: ServerSideEncryption\nx-amz-server-side-encryption-customer-algorithm: SSECustomerAlgorithm\nx-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nx-amz-request-charged: RequestCharged\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CopyPartResult>\n<ETag>string</ETag>\n<LastModified>timestamp</LastModified>\n<ChecksumCRC32>string</ChecksumCRC32>\n<ChecksumCRC32C>string</ChecksumCRC32C>\n<ChecksumSHA1>string</ChecksumSHA1>\n<ChecksumSHA256>string</ChecksumSHA256>\n</CopyPartResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nAmazon S3 API Version 2006-03-01 735",
      "start_idx": 936060,
      "end_idx": 937392,
      "metadata": {
        "num_sentences": 7,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_742",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis functionality is not supported for directory buckets.\nx-amz-server-side-encryption-customer-key-MD5\nIf server-side encryption with a customer-provided encryption key was requested, the\nresponse will include this header to provide the round-trip message integrity verification of the\ncustomer-provided encryption key.\nNote\nThis functionality is not supported for directory buckets.\nThe following data is returned in XML format by the service.\nCopyPartResult\nRoot level tag for the CopyPartResult parameters.\nRequired: Yes\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nAmazon S3 API Version 2006-03-01 737",
      "start_idx": 938615,
      "end_idx": 940137,
      "metadata": {
        "num_sentences": 15,
        "num_words": 230,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_743",
      "text": "Amazon Simple Storage Service API Reference\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nType: String\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nETag\nEntity tag of the object.\nType: String\nLastModified\nDate and time at which the object was uploaded.\nType: Timestamp\nAmazon S3 API Version 2006-03-01 738",
      "start_idx": 940139,
      "end_idx": 941510,
      "metadata": {
        "num_sentences": 14,
        "num_words": 222,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_744",
      "text": "Amazon Simple Storage Service API Reference\nExamples\nSample Request for general purpose buckets\nThe following PUT request uploads a part (part number 2) in a multipart upload. The request\nspecifies a byte range from an existing object as the source of this upload. The request includes the\nupload ID that you get in response to your Initiate Multipart Upload request.\nPUT /newobject?\npartNumber=2&uploadId=VCVsb2FkIElEIGZvciBlbZZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZR\nHTTP/1.1\nHost: target-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 11 Apr 2011 20:34:56 GMT\nx-amz-copy-source: /source-bucket/sourceobject\nx-amz-copy-source-range:bytes=500-6291456\nAuthorization: authorization string\nSample Response for general purpose buckets\nThe response includes the ETag value. You need to retain this value to use when you send the\nComplete Multipart Upload request.\nHTTP/1.1 200 OK\nx-amz-id-2: Vvag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nDate: Mon, 11 Apr 2011 20:34:56 GMT\nServer: AmazonS3\n<CopyPartResult>\n<LastModified>2011-04-11T20:34:56.000Z</LastModified>\n<ETag>\"9b2cf535f27731c974343645a3985328\"</ETag>\n</CopyPartResult>\nSample Request for general purpose buckets\nThe following PUT request uploads a part (part number 2) in a multipart upload. The request does\nnot specify the optional byte range header, but requests the entire source object copy as part\nAmazon S3 API Version 2006-03-01 739",
      "start_idx": 941512,
      "end_idx": 942962,
      "metadata": {
        "num_sentences": 8,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_745",
      "text": "Amazon Simple Storage Service API Reference\n2. The request includes the upload ID that you got in response to your Initiate Multipart Upload\nrequest.\nPUT /newobject?\npartNumber=2&uploadId=VCVsb2FkIElEIGZvciBlbZZpbmcncyBteS1tb3ZpZS5tMnRzIHVwbG9hZR\nHTTP/1.1\nHost: target-bucket.s3.<Region>.amazonaws.com\nDate: Mon, 11 Apr 2011 20:34:56 GMT\nx-amz-copy-source: /source-bucket/sourceobject?versionId=3/L4kqtJlcpXroDTDmJ\n+rmSpXd3dIbrHY+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo\nAuthorization: authorization string\nSample Response for general purpose buckets\nThe response includes the ETag value. You need to retain this value to use when you send the\nComplete Multipart Upload request.\nHTTP/1.1 200 OK\nx-amz-id-2: Vvag1LuByRx9e6j5Onimru9pO4ZVKnJ2Qz7/C1NPcfTWAtRPfTaOFg==\nx-amz-request-id: 656c76696e6727732072657175657374\nx-amz-copy-source-version-id: 3/L4kqtJlcpXroDTDmJ+rmSpXd3dIbrHY\n+MTRCxf3vjVBH40Nr8X8gdRQBpUMLUo\nDate: Mon, 11 Apr 2011 20:34:56 GMT\nServer: AmazonS3\n<CopyPartResult>\n<LastModified>2011-04-11T20:34:56.000Z</LastModified>\n<ETag>\"9b2cf535f27731c974343645a3985328\"</ETag>\n</CopyPartResult>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\nAmazon S3 API Version 2006-03-01 740",
      "start_idx": 942964,
      "end_idx": 944251,
      "metadata": {
        "num_sentences": 6,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_747",
      "text": "Amazon Simple Storage Service API Reference\nWriteGetObjectResponse\nService: Amazon S3\nNote\nThis operation is not supported by directory buckets.\nPasses transformed objects to a GetObject operation when using Object Lambda access points.\nFor information about Object Lambda access points, see Transforming objects with Object Lambda\naccess points in the Amazon S3 User Guide.\nThis operation supports metadata that can be returned by GetObject, in addition to\nRequestRoute, RequestToken, StatusCode, ErrorCode, and ErrorMessage. The GetObject\nresponse metadata is supported so that the WriteGetObjectResponse caller, typically an AWS\nLambda function, can provide the same metadata when it internally invokes GetObject. When\nWriteGetObjectResponse is called by a customer-owned Lambda function, the metadata\nreturned to the end user GetObject call might differ from what Amazon S3 would normally\nreturn.\nYou can include any number of metadata headers. When including a metadata header, it should be\nprefaced with x-amz-meta. For example, x-amz-meta-my-custom-header: MyCustomValue.\nThe primary use case for this is to forward GetObject metadata.\nAWS provides some prebuilt Lambda functions that you can use with S3 Object Lambda to detect\nand redact personally identifiable information (PII) and decompress S3 objects. These Lambda\nfunctions are available in the AWS Serverless Application Repository, and can be selected through\nthe AWS Management Console when you create your Object Lambda access point.\nExample 1: PII Access Control - This Lambda function uses Amazon Comprehend, a natural\nlanguage processing (NLP) service using machine learning to find insights and relationships in text.\nIt automatically detects personally identifiable information (PII) such as names, addresses, dates,\ncredit card numbers, and social security numbers from documents in your Amazon S3 bucket.\nExample 2: PII Redaction - This Lambda function uses Amazon Comprehend, a natural language\nprocessing (NLP) service using machine learning to find insights and relationships in text. It\nautomatically redacts personally identifiable information (PII) such as names, addresses, dates,\ncredit card numbers, and social security numbers from documents in your Amazon S3 bucket.\nAmazon S3 API Version 2006-03-01 742",
      "start_idx": 944487,
      "end_idx": 946777,
      "metadata": {
        "num_sentences": 17,
        "num_words": 326,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_749",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-fwd-header-x-amz-server-side-encryption-aws-kms-key-id: SSEKMSKeyId\nx-amz-fwd-header-x-amz-server-side-encryption-customer-key-MD5: SSECustomerKeyMD5\nx-amz-fwd-header-x-amz-storage-class: StorageClass\nx-amz-fwd-header-x-amz-tagging-count: TagCount\nx-amz-fwd-header-x-amz-version-id: VersionId\nx-amz-fwd-header-x-amz-server-side-encryption-bucket-key-enabled: BucketKeyEnabled\nBody\nURI Request Parameters\nThe request uses the following URI parameters.\nContent-Length\nThe size of the content body in bytes.\nx-amz-fwd-error-code\nA string that uniquely identifies an error condition. Returned in the <Code> tag of the error XML\nresponse for a corresponding GetObject call. Cannot be used with a successful StatusCode\nheader or when the transformed object is provided in the body. All error codes from S3 are\nsentence-cased. The regular expression (regex) value is \"^[A-Z][a-zA-Z]+$\".\nx-amz-fwd-error-message\nContains a generic description of the error condition. Returned in the <Message> tag of the\nerror XML response for a corresponding GetObject call. Cannot be used with a successful\nStatusCode header or when the transformed object is provided in body.\nx-amz-fwd-header-accept-ranges\nIndicates that a range of bytes was specified.\nx-amz-fwd-header-Cache-Control\nSpecifies caching behavior along the request/reply chain.\nx-amz-fwd-header-Content-Disposition\nSpecifies presentational information for the object.\nx-amz-fwd-header-Content-Encoding\nSpecifies what content encodings have been applied to the object and thus what decoding\nmechanisms must be applied to obtain the media-type referenced by the Content-Type header\nfield.\nAmazon S3 API Version 2006-03-01 744",
      "start_idx": 948847,
      "end_idx": 950563,
      "metadata": {
        "num_sentences": 15,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_750",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-fwd-header-Content-Language\nThe language the content is in.\nx-amz-fwd-header-Content-Range\nThe portion of the object returned in the response.\nx-amz-fwd-header-Content-Type\nA standard MIME type describing the format of the object data.\nx-amz-fwd-header-ETag\nAn opaque identifier assigned by a web server to a specific version of a resource found at a URL.\nx-amz-fwd-header-Expires\nThe date and time at which the object is no longer cacheable.\nx-amz-fwd-header-Last-Modified\nThe date and time that the object was last modified.\nx-amz-fwd-header-x-amz-checksum-crc32\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This specifies the base64-encoded, 32-bit CRC-32 checksum of\nthe object returned by the Object Lambda function. This may not match the checksum for the\nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only\nwhen the original GetObject request required checksum validation. For more information\nabout checksums, see Checking object integrity in the Amazon S3 User Guide.\nOnly one checksum header can be specified at a time. If you supply multiple checksum headers,\nthis request will fail.\nx-amz-fwd-header-x-amz-checksum-crc32c\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This specifies the base64-encoded, 32-bit CRC-32C checksum of\nthe object returned by the Object Lambda function. This may not match the checksum for the\nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only\nwhen the original GetObject request required checksum validation. For more information\nabout checksums, see Checking object integrity in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 745",
      "start_idx": 950565,
      "end_idx": 952436,
      "metadata": {
        "num_sentences": 19,
        "num_words": 279,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_751",
      "text": "Amazon Simple Storage Service API Reference\nOnly one checksum header can be specified at a time. If you supply multiple checksum headers,\nthis request will fail.\nx-amz-fwd-header-x-amz-checksum-sha1\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This specifies the base64-encoded, 160-bit SHA-1 digest of the\nobject returned by the Object Lambda function. This may not match the checksum for the\nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only\nwhen the original GetObject request required checksum validation. For more information\nabout checksums, see Checking object integrity in the Amazon S3 User Guide.\nOnly one checksum header can be specified at a time. If you supply multiple checksum headers,\nthis request will fail.\nx-amz-fwd-header-x-amz-checksum-sha256\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This specifies the base64-encoded, 256-bit SHA-256 digest of\nthe object returned by the Object Lambda function. This may not match the checksum for the\nobject stored in Amazon S3. Amazon S3 will perform validation of the checksum values only\nwhen the original GetObject request required checksum validation. For more information\nabout checksums, see Checking object integrity in the Amazon S3 User Guide.\nOnly one checksum header can be specified at a time. If you supply multiple checksum headers,\nthis request will fail.\nx-amz-fwd-header-x-amz-delete-marker\nSpecifies whether an object stored in Amazon S3 is (true) or is not (false) a delete marker.\nx-amz-fwd-header-x-amz-expiration\nIf the object expiration is configured (see PUT Bucket lifecycle), the response includes this\nheader. It includes the expiry-date and rule-id key-value pairs that provide the object\nexpiration information. The value of the rule-id is URL-encoded.\nx-amz-fwd-header-x-amz-missing-meta\nSet to the number of metadata entries not returned in x-amz-meta headers. This can happen\nif you create metadata using an API like SOAP that supports more flexible metadata than the\nREST API. For example, using SOAP, you can create metadata whose values are not legal HTTP\nheaders.\nAmazon S3 API Version 2006-03-01 746",
      "start_idx": 952438,
      "end_idx": 954737,
      "metadata": {
        "num_sentences": 24,
        "num_words": 350,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_752",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-fwd-header-x-amz-mp-parts-count\nThe count of parts this object has.\nx-amz-fwd-header-x-amz-object-lock-legal-hold\nIndicates whether an object stored in Amazon S3 has an active legal hold.\nValid Values: ON | OFF\nx-amz-fwd-header-x-amz-object-lock-mode\nIndicates whether an object stored in Amazon S3 has Object Lock enabled. For more\ninformation about S3 Object Lock, see Object Lock.\nValid Values: GOVERNANCE | COMPLIANCE\nx-amz-fwd-header-x-amz-object-lock-retain-until-date\nThe date and time when Object Lock is configured to expire.\nx-amz-fwd-header-x-amz-replication-status\nIndicates if request involves bucket that is either a source or destination in a Replication rule.\nFor more information about S3 Replication, see Replication.\nValid Values: COMPLETE | PENDING | FAILED | REPLICA | COMPLETED\nx-amz-fwd-header-x-amz-request-charged\nIf present, indicates that the requester was successfully charged for the request.\nNote\nThis functionality is not supported for directory buckets.\nValid Values: requester\nx-amz-fwd-header-x-amz-restore\nProvides information about object restoration operation and expiration time of the restored\nobject copy.\nx-amz-fwd-header-x-amz-server-side-encryption\nThe server-side encryption algorithm used when storing requested object in Amazon S3 (for\nexample, AES256, aws:kms).\nAmazon S3 API Version 2006-03-01 747",
      "start_idx": 954739,
      "end_idx": 956134,
      "metadata": {
        "num_sentences": 12,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_753",
      "text": "Amazon Simple Storage Service API Reference\nValid Values: AES256 | aws:kms | aws:kms:dsse\nx-amz-fwd-header-x-amz-server-side-encryption-aws-kms-key-id\nIf present, specifies the ID (Key ID, Key ARN, or Key Alias) of the AWS Key Management Service\n(AWS KMS) symmetric encryption customer managed key that was used for stored in Amazon\nS3 object.\nx-amz-fwd-header-x-amz-server-side-encryption-bucket-key-enabled\nIndicates whether the object stored in Amazon S3 uses an S3 bucket key for server-side\nencryption with AWS KMS (SSE-KMS).\nx-amz-fwd-header-x-amz-server-side-encryption-customer-algorithm\nEncryption algorithm used if server-side encryption with a customer-provided encryption key\nwas specified for object stored in Amazon S3.\nx-amz-fwd-header-x-amz-server-side-encryption-customer-key-MD5\n128-bit MD5 digest of customer-provided encryption key used in Amazon S3 to encrypt data\nstored in S3. For more information, see Protecting data using server-side encryption with\ncustomer-provided encryption keys (SSE-C).\nx-amz-fwd-header-x-amz-storage-class\nProvides storage class information of the object. Amazon S3 returns this header for all objects\nexcept for S3 Standard storage class objects.\nFor more information, see Storage Classes.\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nx-amz-fwd-header-x-amz-tagging-count\nThe number of tags, if any, on the object.\nx-amz-fwd-header-x-amz-version-id\nAn ID used to reference a specific version of the object.\nx-amz-fwd-status\nThe integer status code for an HTTP response of a corresponding GetObject request. The\nfollowing is a list of status codes.\nAmazon S3 API Version 2006-03-01 748",
      "start_idx": 956136,
      "end_idx": 957893,
      "metadata": {
        "num_sentences": 13,
        "num_words": 223,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_760",
      "text": "Amazon Simple Storage Service API Reference\nAssociateAccessGrantsIdentityCenter\nService: Amazon S3 Control\nAssociate your S3 Access Grants instance with an AWS IAM Identity Center instance. Use this action\nif you want to create access grants for users or groups from your corporate identity directory.\nFirst, you must add your corporate identity directory to AWS IAM Identity Center. Then, you can\nassociate this IAM Identity Center instance with your S3 Access Grants instance.\nPermissions\nYou must have the s3:AssociateAccessGrantsIdentityCenter permission to use this\noperation.\nAdditional Permissions\nYou must also have the following permissions: sso:CreateApplication,\nsso:PutApplicationGrant, and sso:PutApplicationAuthenticationMethod.\nRequest Syntax\nPOST /v20180820/accessgrantsinstance/identitycenter HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<AssociateAccessGrantsIdentityCenterRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<IdentityCenterArn>string</IdentityCenterArn>\n</AssociateAccessGrantsIdentityCenterRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 755",
      "start_idx": 962872,
      "end_idx": 964243,
      "metadata": {
        "num_sentences": 10,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_761",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request accepts the following data in XML format.\nAssociateAccessGrantsIdentityCenterRequest\nRoot level tag for the AssociateAccessGrantsIdentityCenterRequest parameters.\nRequired: Yes\nIdentityCenterArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are\nassociating with your S3 Access Grants instance. An IAM Identity Center instance is your\ncorporate identity directory that you added to the IAM Identity Center. You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 756",
      "start_idx": 964245,
      "end_idx": 965378,
      "metadata": {
        "num_sentences": 10,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_763",
      "text": "Amazon Simple Storage Service API Reference\nCreateAccessGrant\nService: Amazon S3 Control\nCreates an access grant that gives a grantee access to your S3 data. The grantee can be an IAM user\nor role or a directory user, or group. Before you can create a grant, you must have an S3 Access\nGrants instance in the same Region as the S3 data. You can create an S3 Access Grants instance\nusing the CreateAccessGrantsInstance. You must also have registered at least one S3 data location\nin your S3 Access Grants instance using CreateAccessGrantsLocation.\nPermissions\nYou must have the s3:CreateAccessGrant permission to use this operation.\nAdditional Permissions\nFor any directory identity - sso:DescribeInstance and sso:DescribeApplication\nFor directory users - identitystore:DescribeUser\nFor directory groups - identitystore:DescribeGroup\nRequest Syntax\nPOST /v20180820/accessgrantsinstance/grant HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\n<AccessGrantsLocationConfiguration>\n<S3SubPrefix>string</S3SubPrefix>\n</AccessGrantsLocationConfiguration>\n<Grantee>\n<GranteeIdentifier>string</GranteeIdentifier>\n<GranteeType>string</GranteeType>\n</Grantee>\n<Permission>string</Permission>\n<ApplicationArn>string</ApplicationArn>\n<S3PrefixType>string</S3PrefixType>\n<Tags>\n<Tag>\n<Key>string</Key>\nAmazon S3 Control API Version 2006-03-01 758",
      "start_idx": 965604,
      "end_idx": 967134,
      "metadata": {
        "num_sentences": 7,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_764",
      "text": "Amazon Simple Storage Service API Reference\n<Value>string</Value>\n</Tag>\n</Tags>\n</CreateAccessGrantRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessGrantRequest\nRoot level tag for the CreateAccessGrantRequest parameters.\nRequired: Yes\nAccessGrantsLocationConfiguration\nThe configuration options of the grant location. The grant location is the S3 path to the data to\nwhich you are granting access. It contains the S3SubPrefix field. The grant scope is the result\nof appending the subprefix to the location scope of the registered location.\nType: AccessGrantsLocationConfiguration data type\nRequired: No\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nAmazon S3 Control API Version 2006-03-01 759",
      "start_idx": 967136,
      "end_idx": 968334,
      "metadata": {
        "num_sentences": 13,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_765",
      "text": "Amazon Simple Storage Service API Reference\nIf you are passing the default location, you cannot create an access grant for the entire\ndefault location. You must also specify a bucket or a bucket and prefix in the Subprefix field.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with\nyour Identity Center instance. If an application ARN is included in the request to create an\naccess grant, the grantee can only access the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nGrantee\nThe user, group, or role to which you are granting access. You can grant access to an IAM user\nor role. If you have added your corporate directory to AWS IAM Identity Center and associated\nyour Identity Center instance with your S3 Access Grants instance, the grantee can also be a\ncorporate directory user or group.\nType: Grantee data type\nRequired: Yes\nPermission\nThe type of access that you are granting to your S3 data, which can be set to one of the\nfollowing values:\n\u2022 READ \u2013 Grant read-only access to the S3 data.\n\u2022 WRITE \u2013 Grant write-only access to the S3 data.\n\u2022 READWRITE \u2013 Grant both read and write access to the S3 data.\nAmazon S3 Control API Version 2006-03-01 760",
      "start_idx": 968336,
      "end_idx": 969782,
      "metadata": {
        "num_sentences": 16,
        "num_words": 241,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_766",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nValid Values: READ | WRITE | READWRITE\nRequired: Yes\nS3PrefixType\nThe type of S3SubPrefix. The only possible value is Object. Pass this value if the access grant\nscope is an object. Do not pass this value if the access grant scope is a bucket or a bucket and a\nprefix.\nType: String\nValid Values: Object\nRequired: No\nTags\nThe AWS resource tags that you are adding to the access grant. Each tag is a label consisting of\na user-defined key and value. Tags can help you manage, identify, organize, search for, and filter\nresources.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantResult>\n<CreatedAt>timestamp</CreatedAt>\n<AccessGrantId>string</AccessGrantId>\n<AccessGrantArn>string</AccessGrantArn>\n<Grantee>\n<GranteeIdentifier>string</GranteeIdentifier>\n<GranteeType>string</GranteeType>\n</Grantee>\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\n<AccessGrantsLocationConfiguration>\nAmazon S3 Control API Version 2006-03-01 761",
      "start_idx": 969784,
      "end_idx": 970924,
      "metadata": {
        "num_sentences": 10,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_767",
      "text": "Amazon Simple Storage Service API Reference\n<S3SubPrefix>string</S3SubPrefix>\n</AccessGrantsLocationConfiguration>\n<Permission>string</Permission>\n<ApplicationArn>string</ApplicationArn>\n<GrantScope>string</GrantScope>\n</CreateAccessGrantResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessGrantResult\nRoot level tag for the CreateAccessGrantResult parameters.\nRequired: Yes\nAccessGrantArn\nThe Amazon Resource Name (ARN) of the access grant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/grant/[a-zA-\nZ0-9\\-]+\nAccessGrantId\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access\ngrant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nAccessGrantsLocationConfiguration\nThe configuration options of the grant location. The grant location is the S3 path to the data to\nwhich you are granting access.\nAmazon S3 Control API Version 2006-03-01 762",
      "start_idx": 970926,
      "end_idx": 972072,
      "metadata": {
        "num_sentences": 13,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_768",
      "text": "Amazon Simple Storage Service API Reference\nType: AccessGrantsLocationConfiguration data type\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with\nyour Identity Center instance. If the grant includes an application ARN, the grantee can only\naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nCreatedAt\nThe date and time when you created the access grant.\nType: Timestamp\nGrantee\nThe user, group, or role to which you are granting access. You can grant access to an IAM user\nor role. If you have added your corporate directory to AWS IAM Identity Center and associated\nyour Identity Center instance with your S3 Access Grants instance, the grantee can also be a\ncorporate directory user or group.\nType: Grantee data type\nGrantScope\nThe S3 path of the data to which you are granting access. It is the result of appending the\nSubprefix to the location scope.\nAmazon S3 Control API Version 2006-03-01 763",
      "start_idx": 972074,
      "end_idx": 973542,
      "metadata": {
        "num_sentences": 17,
        "num_words": 228,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_769",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nPermission\nThe type of access that you are granting to your S3 data, which can be set to one of the\nfollowing values:\n\u2022 READ \u2013 Grant read-only access to the S3 data.\n\u2022 WRITE \u2013 Grant write-only access to the S3 data.\n\u2022 READWRITE \u2013 Grant both read and write access to the S3 data.\nType: String\nValid Values: READ | WRITE | READWRITE\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 764",
      "start_idx": 973544,
      "end_idx": 974367,
      "metadata": {
        "num_sentences": 6,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_770",
      "text": "Amazon Simple Storage Service API Reference\nCreateAccessGrantsInstance\nService: Amazon S3 Control\nCreates an S3 Access Grants instance, which serves as a logical grouping for access grants. You can\ncreate one S3 Access Grants instance per Region per account.\nPermissions\nYou must have the s3:CreateAccessGrantsInstance permission to use this operation.\nAdditional Permissions\nTo associate an IAM Identity Center instance with your S3 Access Grants instance,\nyou must also have the sso:DescribeInstance, sso:CreateApplication,\nsso:PutApplicationGrant, and sso:PutApplicationAuthenticationMethod\npermissions.\nRequest Syntax\nPOST /v20180820/accessgrantsinstance HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsInstanceRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<IdentityCenterArn>string</IdentityCenterArn>\n<Tags>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Tags>\n</CreateAccessGrantsInstanceRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nAmazon S3 Control API Version 2006-03-01 765",
      "start_idx": 974369,
      "end_idx": 975565,
      "metadata": {
        "num_sentences": 7,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_771",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessGrantsInstanceRequest\nRoot level tag for the CreateAccessGrantsInstanceRequest parameters.\nRequired: Yes\nIdentityCenterArn\nIf you would like to associate your S3 Access Grants instance with an AWS IAM Identity Center\ninstance, use this field to pass the Amazon Resource Name (ARN) of the AWS IAM Identity\nCenter instance that you are associating with your S3 Access Grants instance. An IAM Identity\nCenter instance is your corporate identity directory that you added to the IAM Identity Center.\nYou can use the ListInstances API operation to retrieve a list of your Identity Center instances\nand their ARNs.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: No\nTags\nThe AWS resource tags that you are adding to the S3 Access Grants instance. Each tag is a label\nconsisting of a user-defined key and value. Tags can help you manage, identify, organize, search\nfor, and filter resources.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 766",
      "start_idx": 975567,
      "end_idx": 976897,
      "metadata": {
        "num_sentences": 15,
        "num_words": 202,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_772",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsInstanceResult>\n<CreatedAt>timestamp</CreatedAt>\n<AccessGrantsInstanceId>string</AccessGrantsInstanceId>\n<AccessGrantsInstanceArn>string</AccessGrantsInstanceArn>\n<IdentityCenterArn>string</IdentityCenterArn>\n<IdentityCenterInstanceArn>string</IdentityCenterInstanceArn>\n<IdentityCenterApplicationArn>string</IdentityCenterApplicationArn>\n</CreateAccessGrantsInstanceResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessGrantsInstanceResult\nRoot level tag for the CreateAccessGrantsInstanceResult parameters.\nRequired: Yes\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are\nassociating with your S3 Access Grants instance. An IAM Identity Center instance is your\ncorporate identity directory that you added to the IAM Identity Center. You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance. The ID is default. You can have one S3 Access Grants\ninstance per Region per account.\nType: String\nAmazon S3 Control API Version 2006-03-01 767",
      "start_idx": 976899,
      "end_idx": 978415,
      "metadata": {
        "num_sentences": 12,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_773",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nIdentityCenterApplicationArn\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this\nfield returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application;\na subresource of the original Identity Center instance. S3 Access Grants creates this Identity\nCenter application for the specific S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nIdentityCenterArn\nThis parameter has been deprecated.\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this\nfield returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application;\na subresource of the original Identity Center instance. S3 Access Grants creates this Identity\nCenter application for the specific S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nIdentityCenterInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are\nassociating with your S3 Access Grants instance. An IAM Identity Center instance is your\ncorporate identity directory that you added to the IAM Identity Center. You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nAmazon S3 Control API Version 2006-03-01 768",
      "start_idx": 978417,
      "end_idx": 980103,
      "metadata": {
        "num_sentences": 18,
        "num_words": 241,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_774",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 769",
      "start_idx": 980105,
      "end_idx": 980635,
      "metadata": {
        "num_sentences": 4,
        "num_words": 96,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_775",
      "text": "Amazon Simple Storage Service API Reference\nCreateAccessGrantsLocation\nService: Amazon S3 Control\nThe S3 data location that you would like to register in your S3 Access Grants instance. Your S3\ndata must be in the same Region as your S3 Access Grants instance. The location can be one of the\nfollowing:\n\u2022 The default S3 location s3://\n\u2022 A bucket - S3://<bucket-name>\n\u2022 A bucket and prefix - S3://<bucket-name>/<prefix>\nWhen you register a location, you must include the IAM role that has permission to manage the\nS3 location that you are registering. Give S3 Access Grants permission to assume this role using a\npolicy. S3 Access Grants assumes this role to manage access to the location and to vend temporary\ncredentials to grantees or client applications.\nPermissions\nYou must have the s3:CreateAccessGrantsLocation permission to use this operation.\nAdditional Permissions\nYou must also have the following permission for the specified IAM role: iam:PassRole\nRequest Syntax\nPOST /v20180820/accessgrantsinstance/location HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsLocationRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<LocationScope>string</LocationScope>\n<IAMRoleArn>string</IAMRoleArn>\n<Tags>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Tags>\nAmazon S3 Control API Version 2006-03-01 770",
      "start_idx": 980637,
      "end_idx": 982042,
      "metadata": {
        "num_sentences": 7,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_776",
      "text": "Amazon Simple Storage Service API Reference\n</CreateAccessGrantsLocationRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessGrantsLocationRequest\nRoot level tag for the CreateAccessGrantsLocationRequest parameters.\nRequired: Yes\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants\nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: Yes\nLocationScope\nThe S3 path to the location that you are registering. The location scope can be the default S3\nlocation s3://, the S3 path to a bucket s3://<bucket>, or the S3 path to a bucket and prefix\nAmazon S3 Control API Version 2006-03-01 771",
      "start_idx": 982044,
      "end_idx": 983067,
      "metadata": {
        "num_sentences": 12,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_777",
      "text": "Amazon Simple Storage Service API Reference\ns3://<bucket>/<prefix>. A prefix in S3 is a string of characters at the beginning of an\nobject key name used to organize the objects that you store in your S3 buckets. For example,\nobject key names that start with the engineering/ prefix or object key names that start with\nthe marketing/campaigns/ prefix.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: Yes\nTags\nThe AWS resource tags that you are adding to the S3 Access Grants location. Each tag is a label\nconsisting of a user-defined key and value. Tags can help you manage, identify, organize, search\nfor, and filter resources.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessGrantsLocationResult>\n<CreatedAt>timestamp</CreatedAt>\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\n<AccessGrantsLocationArn>string</AccessGrantsLocationArn>\n<LocationScope>string</LocationScope>\n<IAMRoleArn>string</IAMRoleArn>\n</CreateAccessGrantsLocationResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 772",
      "start_idx": 983069,
      "end_idx": 984417,
      "metadata": {
        "num_sentences": 13,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_778",
      "text": "Amazon Simple Storage Service API Reference\nCreateAccessGrantsLocationResult\nRoot level tag for the CreateAccessGrantsLocationResult parameters.\nRequired: Yes\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the location you are registering.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants\nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nAmazon S3 Control API Version 2006-03-01 773",
      "start_idx": 984419,
      "end_idx": 985636,
      "metadata": {
        "num_sentences": 16,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_779",
      "text": "Amazon Simple Storage Service API Reference\nLocationScope\nThe S3 URI path to the location that you are registering. The location scope can be the default\nS3 location s3://, the S3 path to a bucket, or the S3 path to a bucket and prefix. A prefix\nin S3 is a string of characters at the beginning of an object key name used to organize the\nobjects that you store in your S3 buckets. For example, object key names that start with the\nengineering/ prefix or object key names that start with the marketing/campaigns/ prefix.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 774",
      "start_idx": 985638,
      "end_idx": 986606,
      "metadata": {
        "num_sentences": 7,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_780",
      "text": "Amazon Simple Storage Service API Reference\nCreateAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates an access point and associates it with the specified bucket. For more information, see\nManaging Data Access with Amazon S3 Access Points in the Amazon S3 User Guide.\nNote\nS3 on Outposts only supports VPC-style access points.\nFor more information, see Accessing Amazon S3 on Outposts using virtual private cloud\n(VPC) only access points in the Amazon S3 User Guide.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to CreateAccessPoint:\n\u2022 GetAccessPoint\n\u2022 DeleteAccessPoint\n\u2022 ListAccessPoints\nRequest Syntax\nPUT /v20180820/accesspoint/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\nAmazon S3 Control API Version 2006-03-01 775",
      "start_idx": 986608,
      "end_idx": 987967,
      "metadata": {
        "num_sentences": 9,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_781",
      "text": "Amazon Simple Storage Service API Reference\n<Bucket>string</Bucket>\n<VpcConfiguration>\n<VpcId>string</VpcId>\n</VpcConfiguration>\n<PublicAccessBlockConfiguration>\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration>\n<BucketAccountId>string</BucketAccountId>\n</CreateAccessPointRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name you want to assign to this access point.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the account that owns the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessPointRequest\nRoot level tag for the CreateAccessPointRequest parameters.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 776",
      "start_idx": 987969,
      "end_idx": 989002,
      "metadata": {
        "num_sentences": 9,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_782",
      "text": "Amazon Simple Storage Service API Reference\nBucket\nThe name of the bucket that you want to associate this access point with.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nBucketAccountId\nThe AWS account ID associated with the S3 bucket associated with this access point.\nFor same account access point when your bucket and access point belong to the same account\nowner, the BucketAccountId is not required. For cross-account access point when your bucket\nand access point are not in the same account, the BucketAccountId is required.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nPublicAccessBlockConfiguration\nThe PublicAccessBlock configuration that you want to apply to the access point.\nType: PublicAccessBlockConfiguration data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 777",
      "start_idx": 989004,
      "end_idx": 990490,
      "metadata": {
        "num_sentences": 13,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_784",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nAlias\nThe name or alias of the access point.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{63}\nExamples\nSample request for creating an access point for an Amazon S3 on Outposts bucket\nThis request creates an access point for S3 on Outposts bucket.\nPUT /v20180820/accesspoint/example-access-point HTTP/1.1\nHost:s3-outposts.<Region>.amazonaws.com\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<Bucket>example-outpost-bucket </Bucket>\n</CreateAccessPointRequest>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\nAmazon S3 Control API Version 2006-03-01 779",
      "start_idx": 991397,
      "end_idx": 992406,
      "metadata": {
        "num_sentences": 6,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_786",
      "text": "Amazon Simple Storage Service API Reference\nCreateAccessPointForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates an Object Lambda Access Point. For more information, see Transforming objects with\nObject Lambda Access Points in the Amazon S3 User Guide.\nThe following actions are related to CreateAccessPointForObjectLambda:\n\u2022 DeleteAccessPointForObjectLambda\n\u2022 GetAccessPointForObjectLambda\n\u2022 ListAccessPointsForObjectLambda\nRequest Syntax\nPUT /v20180820/accesspointforobjectlambda/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointForObjectLambdaRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<Configuration>\n<AllowedFeatures>\n<AllowedFeature>string</AllowedFeature>\n</AllowedFeatures>\n<CloudWatchMetricsEnabled>boolean</CloudWatchMetricsEnabled>\n<SupportingAccessPoint>string</SupportingAccessPoint>\n<TransformationConfigurations>\n<TransformationConfiguration>\n<Actions>\n<Action>string</Action>\n</Actions>\n<ContentTransformation>\n<AwsLambda>\n<FunctionArn>string</FunctionArn>\n<FunctionPayload>string</FunctionPayload>\n</AwsLambda>\nAmazon S3 Control API Version 2006-03-01 781",
      "start_idx": 992612,
      "end_idx": 993848,
      "metadata": {
        "num_sentences": 4,
        "num_words": 94,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_787",
      "text": "Amazon Simple Storage Service API Reference\n</ContentTransformation>\n</TransformationConfiguration>\n</TransformationConfigurations>\n</Configuration>\n</CreateAccessPointForObjectLambdaRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name you want to assign to this Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for owner of the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateAccessPointForObjectLambdaRequest\nRoot level tag for the CreateAccessPointForObjectLambdaRequest parameters.\nRequired: Yes\nConfiguration\nObject Lambda Access Point configuration as a JSON document.\nAmazon S3 Control API Version 2006-03-01 782",
      "start_idx": 993850,
      "end_idx": 994780,
      "metadata": {
        "num_sentences": 10,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_788",
      "text": "Amazon Simple Storage Service API Reference\nType: ObjectLambdaConfiguration data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateAccessPointForObjectLambdaResult>\n<ObjectLambdaAccessPointArn>string</ObjectLambdaAccessPointArn>\n<Alias>\n<Status>string</Status>\n<Value>string</Value>\n</Alias>\n</CreateAccessPointForObjectLambdaResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateAccessPointForObjectLambdaResult\nRoot level tag for the CreateAccessPointForObjectLambdaResult parameters.\nRequired: Yes\nAlias\nThe alias of the Object Lambda Access Point.\nType: ObjectLambdaAccessPointAlias data type\nObjectLambdaAccessPointArn\nSpecifies the ARN for the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:s3-object-lambda:[^:]*:\\d{12}:accesspoint/.*\nAmazon S3 Control API Version 2006-03-01 783",
      "start_idx": 994782,
      "end_idx": 995803,
      "metadata": {
        "num_sentences": 9,
        "num_words": 106,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_790",
      "text": "Amazon Simple Storage Service API Reference\nCreateBucket\nService: Amazon S3 Control\nNote\nThis action creates an Amazon S3 on Outposts bucket. To create an S3 bucket, see Create\nBucket in the Amazon S3 API Reference.\nCreates a new Outposts bucket. By creating the bucket, you become the bucket owner. To create an\nOutposts bucket, you must have S3 on Outposts. For more information, see Using Amazon S3 on\nOutposts in Amazon S3 User Guide.\nNot every string is an acceptable bucket name. For information on bucket naming restrictions, see\nWorking with Amazon S3 Buckets.\nS3 on Outposts buckets support:\n\u2022 Tags\n\u2022 LifecycleConfigurations for deleting expired objects\nFor a complete list of restrictions and Amazon S3 feature limitations on S3 on Outposts, see\nAmazon S3 on Outposts Restrictions and Limitations.\nFor an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts\nendpoint hostname prefix and x-amz-outpost-id in your API request, see the Examples section.\nThe following actions are related to CreateBucket for Amazon S3 on Outposts:\n\u2022 PutObject\n\u2022 GetBucket\n\u2022 DeleteBucket\n\u2022 CreateAccessPoint\n\u2022 PutAccessPointPolicy\nRequest Syntax\nPUT /v20180820/bucket/name HTTP/1.1\nAmazon S3 Control API Version 2006-03-01 785",
      "start_idx": 996207,
      "end_idx": 997454,
      "metadata": {
        "num_sentences": 11,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_791",
      "text": "Amazon Simple Storage Service API Reference\nHost: Bucket.s3-control.amazonaws.com\nx-amz-acl: ACL\nx-amz-grant-full-control: GrantFullControl\nx-amz-grant-read: GrantRead\nx-amz-grant-read-acp: GrantReadACP\nx-amz-grant-write: GrantWrite\nx-amz-grant-write-acp: GrantWriteACP\nx-amz-bucket-object-lock-enabled: ObjectLockEnabledForBucket\nx-amz-outpost-id: OutpostId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateBucketConfiguration xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<LocationConstraint>string</LocationConstraint>\n</CreateBucketConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the bucket.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-acl\nThe canned ACL to apply to the bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nValid Values: private | public-read | public-read-write | authenticated-read\nx-amz-bucket-object-lock-enabled\nSpecifies whether you want S3 Object Lock to be enabled for the new bucket.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nAmazon S3 Control API Version 2006-03-01 786",
      "start_idx": 997456,
      "end_idx": 998595,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_793",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nx-amz-outpost-id\nThe ID of the Outposts where the bucket is being created.\nNote\nThis ID is required by Amazon S3 on Outposts buckets.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequest Body\nThe request accepts the following data in XML format.\nCreateBucketConfiguration\nRoot level tag for the CreateBucketConfiguration parameters.\nRequired: Yes\nLocationConstraint\nSpecifies the Region where the bucket will be created. If you are creating a bucket on the US\nEast (N. Virginia) Region (us-east-1), you do not need to specify the location.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: String\nValid Values: EU | eu-west-1 | us-west-1 | us-west-2 | ap-south-1 | ap-\nsoutheast-1 | ap-southeast-2 | ap-northeast-1 | sa-east-1 | cn-north-1 |\neu-central-1\nAmazon S3 Control API Version 2006-03-01 788",
      "start_idx": 999339,
      "end_idx": 1000278,
      "metadata": {
        "num_sentences": 11,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_794",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nLocation: Location\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateBucketResult>\n<BucketArn>string</BucketArn>\n</CreateBucketResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe response returns the following HTTP headers.\nLocation\nThe location of the bucket.\nThe following data is returned in XML format by the service.\nCreateBucketResult\nRoot level tag for the CreateBucketResult parameters.\nRequired: Yes\nBucketArn\nThe Amazon Resource Name (ARN) of the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nAmazon S3 Control API Version 2006-03-01 789",
      "start_idx": 1000280,
      "end_idx": 1001444,
      "metadata": {
        "num_sentences": 9,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_795",
      "text": "Amazon Simple Storage Service API Reference\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nErrors\nBucketAlreadyExists\nThe requested Outposts bucket name is not available. The bucket namespace is shared by all\nusers of the AWS Outposts in this Region. Select a different name and try again.\nHTTP Status Code: 400\nBucketAlreadyOwnedByYou\nThe Outposts bucket you tried to create already exists, and you own it.\nHTTP Status Code: 400\nExamples\nSample request to create an Amazon S3 on Outposts bucket\nThis request creates an Outposts bucket named example-outpost-bucket.\nPUT /v20180820/bucket/example-outpost-bucket/ HTTP/1.1\nHost:s3-outposts.<Region>.amazonaws.com\nx-amz-outpost-id: op-01ac5d28a6a232904\nContent-Length:\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAuthorization: authorization string\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 790",
      "start_idx": 1001446,
      "end_idx": 1002506,
      "metadata": {
        "num_sentences": 10,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_797",
      "text": "Amazon Simple Storage Service API Reference\nCreateJob\nService: Amazon S3 Control\nThis operation creates an S3 Batch Operations job.\nYou can use S3 Batch Operations to perform large-scale batch actions on Amazon S3 objects.\nBatch Operations can run a single action on lists of Amazon S3 objects that you specify. For more\ninformation, see S3 Batch Operations in the Amazon S3 User Guide.\nPermissions\nFor information about permissions required to use the Batch Operations, see Granting\npermissions for S3 Batch Operations in the Amazon S3 User Guide.\nRelated actions include:\n\u2022 DescribeJob\n\u2022 ListJobs\n\u2022 UpdateJobPriority\n\u2022 UpdateJobStatus\n\u2022 JobOperation\nRequest Syntax\nPOST /v20180820/jobs HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateJobRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<ConfirmationRequired>boolean</ConfirmationRequired>\n<Operation>\n<LambdaInvoke>\n<FunctionArn>string</FunctionArn>\n<InvocationSchemaVersion>string</InvocationSchemaVersion>\n<UserArguments>\n<entry>\n<key>string</key>\n<value>string</value>\n</entry>\nAmazon S3 Control API Version 2006-03-01 792",
      "start_idx": 1002798,
      "end_idx": 1003959,
      "metadata": {
        "num_sentences": 6,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_802",
      "text": "Amazon Simple Storage Service API Reference\n</ManifestGenerator>\n</CreateJobRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID that creates the job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateJobRequest\nRoot level tag for the CreateJobRequest parameters.\nRequired: Yes\nClientRequestToken\nAn idempotency token to ensure that you don't accidentally submit the same request twice. You\ncan use any string up to the maximum length.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: Yes\nConfirmationRequired\nIndicates whether confirmation is required before Amazon S3 runs the job. Confirmation is only\nrequired for jobs created through the Amazon S3 console.\nType: Boolean\nAmazon S3 Control API Version 2006-03-01 797",
      "start_idx": 1008834,
      "end_idx": 1009750,
      "metadata": {
        "num_sentences": 12,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_803",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nDescription\nA description for this job. You can use any string within the permitted length. Descriptions don't\nneed to be unique and can be used for multiple jobs.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nManifest\nConfiguration parameters for the manifest.\nType: JobManifest data type\nRequired: No\nManifestGenerator\nThe attribute container for the ManifestGenerator details. Jobs must be created with either a\nmanifest file or a ManifestGenerator, but not both.\nType: JobManifestGenerator data type\nNote: This object is a Union. Only one member of this object can be specified or returned.\nRequired: No\nOperation\nThe action that you want this job to perform on every object listed in the manifest. For more\ninformation about the available actions, see Operations in the Amazon S3 User Guide.\nType: JobOperation data type\nRequired: Yes\nPriority\nThe numerical priority for this job. Higher numbers indicate higher priority.\nType: Integer\nAmazon S3 Control API Version 2006-03-01 798",
      "start_idx": 1009752,
      "end_idx": 1010838,
      "metadata": {
        "num_sentences": 15,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_804",
      "text": "Amazon Simple Storage Service API Reference\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nRequired: Yes\nReport\nConfiguration parameters for the optional job-completion report.\nType: JobReport data type\nRequired: Yes\nRoleArn\nThe Amazon Resource Name (ARN) for the AWS Identity and Access Management (IAM) role that\nBatch Operations will use to run this job's action on every object in the manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: Yes\nTags\nA set of tags to associate with the S3 Batch Operations job. This is an optional parameter.\nType: Array of S3Tag data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateJobResult>\n<JobId>string</JobId>\n</CreateJobResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 799",
      "start_idx": 1010840,
      "end_idx": 1011790,
      "metadata": {
        "num_sentences": 11,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_805",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nCreateJobResult\nRoot level tag for the CreateJobResult parameters.\nRequired: Yes\nJobId\nThe ID for this job. Amazon S3 generates this ID automatically and returns it after a successful\nCreate Job request.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nErrors\nBadRequestException\nHTTP Status Code: 400\nIdempotencyException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 800",
      "start_idx": 1011792,
      "end_idx": 1012545,
      "metadata": {
        "num_sentences": 7,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_807",
      "text": "Amazon Simple Storage Service API Reference\nCreateMultiRegionAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates a Multi-Region Access Point and associates it with the specified buckets. For more\ninformation about creating Multi-Region Access Points, see Creating Multi-Region Access Points in\nthe Amazon S3 User Guide.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThis request is asynchronous, meaning that you might receive a response before the command has\ncompleted. When this request provides a response, it provides a token that you can use to monitor\nthe status of the request with DescribeMultiRegionAccessPointOperation.\nThe following actions are related to CreateMultiRegionAccessPoint:\n\u2022 DeleteMultiRegionAccessPoint\n\u2022 DescribeMultiRegionAccessPointOperation\n\u2022 GetMultiRegionAccessPoint\n\u2022 ListMultiRegionAccessPoints\nRequest Syntax\nPOST /v20180820/async-requests/mrap/create HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateMultiRegionAccessPointRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<ClientToken>string</ClientToken>\n<Details>\n<Name>string</Name>\n<PublicAccessBlock>\nAmazon S3 Control API Version 2006-03-01 802",
      "start_idx": 1012837,
      "end_idx": 1014310,
      "metadata": {
        "num_sentences": 8,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_808",
      "text": "Amazon Simple Storage Service API Reference\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlock>\n<Regions>\n<Region>\n<Bucket>string</Bucket>\n<BucketAccountId>string</BucketAccountId>\n</Region>\n</Regions>\n</Details>\n</CreateMultiRegionAccessPointRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point. The owner of the Multi-\nRegion Access Point also must own the underlying buckets.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nCreateMultiRegionAccessPointRequest\nRoot level tag for the CreateMultiRegionAccessPointRequest parameters.\nRequired: Yes\nClientToken\nAn idempotency token used to identify the request and guarantee that requests are unique.\nType: String\nAmazon S3 Control API Version 2006-03-01 803",
      "start_idx": 1014312,
      "end_idx": 1015380,
      "metadata": {
        "num_sentences": 8,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_809",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Maximum length of 64.\nPattern: \\S+\nRequired: Yes\nDetails\nA container element containing details about the Multi-Region Access Point.\nType: CreateMultiRegionAccessPointInput data type\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateMultiRegionAccessPointResult>\n<RequestTokenARN>string</RequestTokenARN>\n</CreateMultiRegionAccessPointResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nCreateMultiRegionAccessPointResult\nRoot level tag for the CreateMultiRegionAccessPointResult parameters.\nRequired: Yes\nRequestTokenARN\nThe request token associated with the request. You can use this token with\nDescribeMultiRegionAccessPointOperation to determine the status of asynchronous requests.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:.+\nAmazon S3 Control API Version 2006-03-01 804",
      "start_idx": 1015382,
      "end_idx": 1016419,
      "metadata": {
        "num_sentences": 10,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_811",
      "text": "Amazon Simple Storage Service API Reference\nCreateStorageLensGroup\nService: Amazon S3 Control\nCreates a new S3 Storage Lens group and associates it with the specified AWS account ID. An S3\nStorage Lens group is a custom grouping of objects based on prefix, suffix, object tags, object size,\nobject age, or a combination of these filters. For each Storage Lens group that you\u2019ve created, you\ncan also optionally add AWS resource tags. For more information about S3 Storage Lens groups,\nsee Working with S3 Storage Lens groups.\nTo use this operation, you must have the permission to perform the\ns3:CreateStorageLensGroup action. If you\u2019re trying to create a Storage Lens group with AWS\nresource tags, you must also have permission to perform the s3:TagResource action. For more\ninformation about the required Storage Lens Groups permissions, see Setting account permissions\nto use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nPOST /v20180820/storagelensgroup HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<CreateStorageLensGroupRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<StorageLensGroup>\n<Filter>\n<And>\n<MatchAnyPrefix>\n<Prefix>string</Prefix>\n</MatchAnyPrefix>\n<MatchAnySuffix>\n<Suffix>string</Suffix>\n</MatchAnySuffix>\n<MatchAnyTag>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</MatchAnyTag>\n<MatchObjectAge>\n<DaysGreaterThan>integer</DaysGreaterThan>\nAmazon S3 Control API Version 2006-03-01 806",
      "start_idx": 1016823,
      "end_idx": 1018408,
      "metadata": {
        "num_sentences": 9,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_814",
      "text": "Amazon Simple Storage Service API Reference\nType: StorageLensGroup data type\nRequired: Yes\nTags\nThe AWS resource tags that you're adding to your Storage Lens group. This parameter is\noptional.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nRequired: No\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 809",
      "start_idx": 1020315,
      "end_idx": 1021122,
      "metadata": {
        "num_sentences": 6,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_815",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessGrant\nService: Amazon S3 Control\nDeletes the access grant from the S3 Access Grants instance. You cannot undo an access grant\ndeletion and the grantee will no longer have access to the S3 data.\nPermissions\nYou must have the s3:DeleteAccessGrant permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/grant/id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access\ngrant.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 810",
      "start_idx": 1021124,
      "end_idx": 1022054,
      "metadata": {
        "num_sentences": 11,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_817",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessGrantsInstance\nService: Amazon S3 Control\nDeletes your S3 Access Grants instance. You must first delete the access grants and locations before\nS3 Access Grants can delete the instance. See DeleteAccessGrant and DeleteAccessGrantsLocation.\nIf you have associated an IAM Identity Center instance with your S3 Access Grants instance, you\nmust first dissassociate the Identity Center instance from the S3 Access Grants instance before\nyou can delete the S3 Access Grants instance. See AssociateAccessGrantsIdentityCenter and\nDissociateAccessGrantsIdentityCenter.\nPermissions\nYou must have the s3:DeleteAccessGrantsInstance permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 812",
      "start_idx": 1022658,
      "end_idx": 1023831,
      "metadata": {
        "num_sentences": 11,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_819",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessGrantsInstanceResourcePolicy\nService: Amazon S3 Control\nDeletes the resource policy of the S3 Access Grants instance. The resource policy is used to manage\ncross-account access to your S3 Access Grants instance. By deleting the resource policy, you delete\nany cross-account permissions to your S3 Access Grants instance.\nPermissions\nYou must have the s3:DeleteAccessGrantsInstanceResourcePolicy permission to use\nthis operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/resourcepolicy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 814",
      "start_idx": 1024351,
      "end_idx": 1025315,
      "metadata": {
        "num_sentences": 9,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_821",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessGrantsLocation\nService: Amazon S3 Control\nDeregisters a location from your S3 Access Grants instance. You can only delete a location\nregistration from an S3 Access Grants instance if there are no grants associated with this location.\nSee Delete a grant for information on how to delete grants. You need to have at least one\nregistered location in your S3 Access Grants instance in order to create access grants.\nPermissions\nYou must have the s3:DeleteAccessGrantsLocation permission to use this operation.\nRequest Syntax\nDELETE /v20180820/accessgrantsinstance/location/id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the registered location that you are deregistering from your S3 Access Grants instance.\nS3 Access Grants assigned this ID when you registered the location. S3 Access Grants assigns the\nID default to the default location s3:// and assigns an auto-generated ID to other locations\nthat you register.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 816",
      "start_idx": 1025835,
      "end_idx": 1027186,
      "metadata": {
        "num_sentences": 14,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_823",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the specified access point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to DeleteAccessPoint:\n\u2022 CreateAccessPoint\n\u2022 GetAccessPoint\n\u2022 ListAccessPoints\nRequest Syntax\nDELETE /v20180820/accesspoint/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point you want to delete.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nAmazon S3 Control API Version 2006-03-01 818",
      "start_idx": 1027804,
      "end_idx": 1028960,
      "metadata": {
        "num_sentences": 9,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_824",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you\nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name>. For example, to access the access point reports-ap through\nOutpost my-outpost owned by account 123456789012 in Region us-west-2, use the URL\nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap. The value must be URL encoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the account that owns the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nDeleteAccessPoint syntax for Amazon S3 on Outposts\nThe following request deletes the access point of the specified Outpost.\nDELETE /v20180820/accesspoint/example-access-point HTTP/1.1\nAmazon S3 Control API Version 2006-03-01 819",
      "start_idx": 1028962,
      "end_idx": 1030195,
      "metadata": {
        "num_sentences": 11,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_826",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessPointForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the specified Object Lambda Access Point.\nThe following actions are related to DeleteAccessPointForObjectLambda:\n\u2022 CreateAccessPointForObjectLambda\n\u2022 GetAccessPointForObjectLambda\n\u2022 ListAccessPointsForObjectLambda\nRequest Syntax\nDELETE /v20180820/accesspointforobjectlambda/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point you want to delete.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 821",
      "start_idx": 1030788,
      "end_idx": 1031735,
      "metadata": {
        "num_sentences": 9,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_828",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the access point policy for the specified access point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to DeleteAccessPointPolicy:\n\u2022 PutAccessPointPolicy\n\u2022 GetAccessPointPolicy\nRequest Syntax\nDELETE /v20180820/accesspoint/name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose policy you want to delete.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you\nmust specify the ARN of the access point accessed in the format arn:aws:s3-\nAmazon S3 Control API Version 2006-03-01 823",
      "start_idx": 1032371,
      "end_idx": 1033728,
      "metadata": {
        "num_sentences": 9,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_829",
      "text": "Amazon Simple Storage Service API Reference\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name>. For example, to access the access point reports-ap through\nOutpost my-outpost owned by account 123456789012 in Region us-west-2, use the URL\nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap. The value must be URL encoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request syntax for using the DeleteAccessPointPolicy action with Amazon S3 on\nOutposts access point\nThis example illustrates one usage of DeleteAccessPointPolicy.\nDELETE /v20180820/accesspoint/example-access-point/policy HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nAmazon S3 Control API Version 2006-03-01 824",
      "start_idx": 1033730,
      "end_idx": 1034902,
      "metadata": {
        "num_sentences": 11,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_831",
      "text": "Amazon Simple Storage Service API Reference\nDeleteAccessPointPolicyForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRemoves the resource policy for an Object Lambda Access Point.\nThe following actions are related to DeleteAccessPointPolicyForObjectLambda:\n\u2022 GetAccessPointPolicyForObjectLambda\n\u2022 PutAccessPointPolicyForObjectLambda\nRequest Syntax\nDELETE /v20180820/accesspointforobjectlambda/name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point you want to delete the policy for.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 826",
      "start_idx": 1035454,
      "end_idx": 1036455,
      "metadata": {
        "num_sentences": 9,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_833",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucket\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket. To delete an S3 bucket, see\nDeleteBucket in the Amazon S3 API Reference.\nDeletes the Amazon S3 on Outposts bucket. All objects (including all object versions and delete\nmarkers) in the bucket must be deleted before the bucket itself can be deleted. For more\ninformation, see Using Amazon S3 on Outposts in Amazon S3 User Guide.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nRelated Resources\n\u2022 CreateBucket\n\u2022 GetBucket\n\u2022 DeleteObject\nRequest Syntax\nDELETE /v20180820/bucket/name HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket being deleted.\nAmazon S3 Control API Version 2006-03-01 828",
      "start_idx": 1037073,
      "end_idx": 1038321,
      "metadata": {
        "num_sentences": 11,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_834",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID that owns the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request to delete an Amazon S3 on Outposts bucket\nThis request deletes the Outposts bucket named example-outpost-bucket.\nAmazon S3 Control API Version 2006-03-01 829",
      "start_idx": 1038323,
      "end_idx": 1039570,
      "metadata": {
        "num_sentences": 12,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_836",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketLifecycleConfiguration\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket's lifecycle configuration. To delete\nan S3 bucket's lifecycle configuration, see DeleteBucketLifecycle in the Amazon S3 API\nReference.\nDeletes the lifecycle configuration from the specified Outposts bucket. Amazon S3 on Outposts\nremoves all the lifecycle configuration rules in the lifecycle subresource associated with the bucket.\nYour objects never expire, and Amazon S3 on Outposts no longer automatically deletes any objects\non the basis of rules contained in the deleted lifecycle configuration. For more information, see\nUsing Amazon S3 on Outposts in Amazon S3 User Guide.\nTo use this operation, you must have permission to perform the s3-\noutposts:PutLifecycleConfiguration action. By default, the bucket owner has this\npermission and the Outposts bucket owner can grant this permission to others.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nFor more information about object expiration, see Elements to Describe Lifecycle Actions.\nRelated actions include:\n\u2022 PutBucketLifecycleConfiguration\n\u2022 GetBucketLifecycleConfiguration\nRequest Syntax\nDELETE /v20180820/bucket/name/lifecycleconfiguration HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nAmazon S3 Control API Version 2006-03-01 831",
      "start_idx": 1040220,
      "end_idx": 1042002,
      "metadata": {
        "num_sentences": 13,
        "num_words": 247,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_837",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID of the lifecycle configuration to delete.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 832",
      "start_idx": 1042004,
      "end_idx": 1043106,
      "metadata": {
        "num_sentences": 12,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_839",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketPolicy\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket policy. To delete an S3 bucket policy,\nsee DeleteBucketPolicy in the Amazon S3 API Reference.\nThis implementation of the DELETE action uses the policy subresource to delete the policy\nof a specified Amazon S3 on Outposts bucket. If you are using an identity other than the\nroot user of the AWS account that owns the bucket, the calling identity must have the s3-\noutposts:DeleteBucketPolicy permissions on the specified Outposts bucket and belong\nto the bucket owner's account to use this action. For more information, see Using Amazon S3 on\nOutposts in Amazon S3 User Guide.\nIf you don't have DeleteBucketPolicy permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the\nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed error.\nImportant\nAs a security precaution, the root user of the AWS account that owns a bucket can always\nuse this action, even if the policy explicitly denies the root user the ability to perform this\naction.\nFor more information about bucket policies, see Using Bucket Policies and User Policies.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to DeleteBucketPolicy:\n\u2022 GetBucketPolicy\n\u2022 PutBucketPolicy\nAmazon S3 Control API Version 2006-03-01 834",
      "start_idx": 1043994,
      "end_idx": 1045848,
      "metadata": {
        "num_sentences": 13,
        "num_words": 299,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_840",
      "text": "Amazon Simple Storage Service API Reference\nRequest Syntax\nDELETE /v20180820/bucket/name/policy HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 835",
      "start_idx": 1045850,
      "end_idx": 1047032,
      "metadata": {
        "num_sentences": 12,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_842",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketReplication\nService: Amazon S3 Control\nNote\nThis operation deletes an Amazon S3 on Outposts bucket's replication configuration. To\ndelete an S3 bucket's replication configuration, see DeleteBucketReplication in the Amazon\nS3 API Reference.\nDeletes the replication configuration from the specified S3 on Outposts bucket.\nTo use this operation, you must have permissions to perform the s3-\noutposts:PutReplicationConfiguration action. The Outposts bucket owner has this\npermission by default and can grant it to others. For more information about permissions, see\nSetting up IAM with S3 on Outposts and Managing access to S3 on Outposts buckets in the\nAmazon S3 User Guide.\nNote\nIt can take a while to propagate PUT or DELETE requests for a replication configuration\nto all S3 on Outposts systems. Therefore, the replication configuration that's returned\nby a GET request soon after a PUT or DELETE request might return a more recent result\nthan what's on the Outpost. If an Outpost is offline, the delay in updating the replication\nconfiguration on that Outpost can be significant.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nFor information about S3 replication on Outposts configuration, see Replicating objects for S3 on\nOutposts in the Amazon S3 User Guide.\nThe following operations are related to DeleteBucketReplication:\n\u2022 PutBucketReplication\nAmazon S3 Control API Version 2006-03-01 837",
      "start_idx": 1047908,
      "end_idx": 1049756,
      "metadata": {
        "num_sentences": 14,
        "num_words": 284,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_843",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 GetBucketReplication\nRequest Syntax\nDELETE /v20180820/bucket/name/replication HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the S3 on Outposts bucket to delete the replication configuration for.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket to delete the replication configuration for.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 838",
      "start_idx": 1049758,
      "end_idx": 1051020,
      "metadata": {
        "num_sentences": 11,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_844",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request\nThe following DELETE request deletes the replication subresource from the specified S3 on\nOutposts bucket. This request removes the replication configuration that is set for the bucket.\nDELETE /v20180820/bucket/example-outpost-bucket/replication HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nx-amz-outpost-id: op-01ac5d28a6a232904\nx-amz-account-id:example-account-id\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\nAmazon S3 Control API Version 2006-03-01 839",
      "start_idx": 1051022,
      "end_idx": 1051995,
      "metadata": {
        "num_sentences": 5,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_846",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketTagging\nService: Amazon S3 Control\nNote\nThis action deletes an Amazon S3 on Outposts bucket's tags. To delete an S3 bucket tags,\nsee DeleteBucketTagging in the Amazon S3 API Reference.\nDeletes the tags from the Outposts bucket. For more information, see Using Amazon S3 on\nOutposts in Amazon S3 User Guide.\nTo use this action, you must have permission to perform the PutBucketTagging action. By\ndefault, the bucket owner has this permission and can grant this permission to others.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to DeleteBucketTagging:\n\u2022 GetBucketTagging\n\u2022 PutBucketTagging\nRequest Syntax\nDELETE /v20180820/bucket/name/tagging HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe bucket ARN that has the tag set to be removed.\nAmazon S3 Control API Version 2006-03-01 841",
      "start_idx": 1052109,
      "end_idx": 1053484,
      "metadata": {
        "num_sentences": 12,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_847",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket tag set to be removed.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nExamples\nSample request to delete tags for Amazon S3 on Outposts bucket\nThe following DELETE request deletes the tag set from the Outposts bucket example-outpost-\nbucket.\nAmazon S3 Control API Version 2006-03-01 842",
      "start_idx": 1053486,
      "end_idx": 1054786,
      "metadata": {
        "num_sentences": 12,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_849",
      "text": "Amazon Simple Storage Service API Reference\nDeleteJobTagging\nService: Amazon S3 Control\nRemoves the entire tag set from the specified S3 Batch Operations job.\nPermissions\nTo use the DeleteJobTagging operation, you must have permission to perform the\ns3:DeleteJobTagging action. For more information, see Controlling access and labeling jobs\nusing tags in the Amazon S3 User Guide.\nRelated actions include:\n\u2022 CreateJob\n\u2022 GetJobTagging\n\u2022 PutJobTagging\nRequest Syntax\nDELETE /v20180820/jobs/id/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the S3 Batch Operations job whose tags you want to delete.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nAmazon S3 Control API Version 2006-03-01 844",
      "start_idx": 1055437,
      "end_idx": 1056375,
      "metadata": {
        "num_sentences": 9,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_852",
      "text": "Amazon Simple Storage Service API Reference\nDeleteMultiRegionAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes a Multi-Region Access Point. This action does not delete the buckets associated with the\nMulti-Region Access Point, only the Multi-Region Access Point itself.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThis request is asynchronous, meaning that you might receive a response before the command has\ncompleted. When this request provides a response, it provides a token that you can use to monitor\nthe status of the request with DescribeMultiRegionAccessPointOperation.\nThe following actions are related to DeleteMultiRegionAccessPoint:\n\u2022 CreateMultiRegionAccessPoint\n\u2022 DescribeMultiRegionAccessPointOperation\n\u2022 GetMultiRegionAccessPoint\n\u2022 ListMultiRegionAccessPoints\nRequest Syntax\nPOST /v20180820/async-requests/mrap/delete HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteMultiRegionAccessPointRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<ClientToken>string</ClientToken>\n<Details>\n<Name>string</Name>\n</Details>\n</DeleteMultiRegionAccessPointRequest>\nAmazon S3 Control API Version 2006-03-01 847",
      "start_idx": 1057284,
      "end_idx": 1058739,
      "metadata": {
        "num_sentences": 8,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_854",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<DeleteMultiRegionAccessPointResult>\n<RequestTokenARN>string</RequestTokenARN>\n</DeleteMultiRegionAccessPointResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nDeleteMultiRegionAccessPointResult\nRoot level tag for the DeleteMultiRegionAccessPointResult parameters.\nRequired: Yes\nRequestTokenARN\nThe request token associated with the request. You can use this token with\nDescribeMultiRegionAccessPointOperation to determine the status of asynchronous requests.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:.+\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 849",
      "start_idx": 1059579,
      "end_idx": 1060619,
      "metadata": {
        "num_sentences": 8,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_856",
      "text": "Amazon Simple Storage Service API Reference\nDeletePublicAccessBlock\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRemoves the PublicAccessBlock configuration for an AWS account. For more information, see\nUsing Amazon S3 block public access.\nRelated actions include:\n\u2022 GetPublicAccessBlock\n\u2022 PutPublicAccessBlock\nRequest Syntax\nDELETE /v20180820/configuration/publicAccessBlock HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe account ID for the AWS account whose PublicAccessBlock configuration you want to\nremove.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 851",
      "start_idx": 1060803,
      "end_idx": 1061641,
      "metadata": {
        "num_sentences": 8,
        "num_words": 106,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_858",
      "text": "Amazon Simple Storage Service API Reference\nDeleteStorageLensConfiguration\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the Amazon S3 Storage Lens configuration. For more information about S3 Storage Lens,\nsee Assessing your storage activity and usage with Amazon S3 Storage Lens in the Amazon S3 User\nGuide.\nNote\nTo use this action, you must have permission to perform the\ns3:DeleteStorageLensConfiguration action. For more information, see Setting\npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nDELETE /v20180820/storagelens/storagelensid HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the S3 Storage Lens configuration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 853",
      "start_idx": 1062190,
      "end_idx": 1063215,
      "metadata": {
        "num_sentences": 12,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_860",
      "text": "Amazon Simple Storage Service API Reference\nDeleteStorageLensConfigurationTagging\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nDeletes the Amazon S3 Storage Lens configuration tags. For more information about S3 Storage\nLens, see Assessing your storage activity and usage with Amazon S3 Storage Lens in the Amazon\nS3 User Guide.\nNote\nTo use this action, you must have permission to perform the\ns3:DeleteStorageLensConfigurationTagging action. For more information, see\nSetting permissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nDELETE /v20180820/storagelens/storagelensid/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the S3 Storage Lens configuration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 855",
      "start_idx": 1063893,
      "end_idx": 1064945,
      "metadata": {
        "num_sentences": 12,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_862",
      "text": "Amazon Simple Storage Service API Reference\nDeleteStorageLensGroup\nService: Amazon S3 Control\nDeletes an existing S3 Storage Lens group.\nTo use this operation, you must have the permission to perform the\ns3:DeleteStorageLensGroup action. For more information about the required Storage Lens\nGroups permissions, see Setting account permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nDELETE /v20180820/storagelensgroup/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Storage Lens group that you're trying to delete.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID used to create the Storage Lens group that you're trying to delete.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 857",
      "start_idx": 1065623,
      "end_idx": 1066738,
      "metadata": {
        "num_sentences": 12,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_864",
      "text": "Amazon Simple Storage Service API Reference\nDescribeJob\nService: Amazon S3 Control\nRetrieves the configuration parameters and status for a Batch Operations job. For more\ninformation, see S3 Batch Operations in the Amazon S3 User Guide.\nPermissions\nTo use the DescribeJob operation, you must have permission to perform the\ns3:DescribeJob action.\nRelated actions include:\n\u2022 CreateJob\n\u2022 ListJobs\n\u2022 UpdateJobPriority\n\u2022 UpdateJobStatus\nRequest Syntax\nGET /v20180820/jobs/id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the job whose information you want to retrieve.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nAmazon S3 Control API Version 2006-03-01 859",
      "start_idx": 1067287,
      "end_idx": 1068184,
      "metadata": {
        "num_sentences": 9,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_872",
      "text": "Amazon Simple Storage Service API Reference\nDescribeMultiRegionAccessPointOperation\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRetrieves the status of an asynchronous request to manage a Multi-Region Access Point. For more\ninformation about managing Multi-Region Access Points and how asynchronous requests work, see\nUsing Multi-Region Access Points in the Amazon S3 User Guide.\nThe following actions are related to GetMultiRegionAccessPoint:\n\u2022 CreateMultiRegionAccessPoint\n\u2022 DeleteMultiRegionAccessPoint\n\u2022 GetMultiRegionAccessPoint\n\u2022 ListMultiRegionAccessPoints\nRequest Syntax\nGET /v20180820/async-requests/mrap/request_token+ HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nrequest_token\nThe request token associated with the request you want to know about. This request token is\nreturned as part of the response when you make an asynchronous request. You provide this\ntoken to query about the status of the asynchronous action.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:.+\nAmazon S3 Control API Version 2006-03-01 867",
      "start_idx": 1075476,
      "end_idx": 1076665,
      "metadata": {
        "num_sentences": 10,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_878",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessGrant\nService: Amazon S3 Control\nGet the details of an access grant from your S3 Access Grants instance.\nPermissions\nYou must have the s3:GetAccessGrant permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/grant/id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access\ngrant.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 873",
      "start_idx": 1080666,
      "end_idx": 1081553,
      "metadata": {
        "num_sentences": 11,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_879",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantResult>\n<CreatedAt>timestamp</CreatedAt>\n<AccessGrantId>string</AccessGrantId>\n<AccessGrantArn>string</AccessGrantArn>\n<Grantee>\n<GranteeIdentifier>string</GranteeIdentifier>\n<GranteeType>string</GranteeType>\n</Grantee>\n<Permission>string</Permission>\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\n<AccessGrantsLocationConfiguration>\n<S3SubPrefix>string</S3SubPrefix>\n</AccessGrantsLocationConfiguration>\n<GrantScope>string</GrantScope>\n<ApplicationArn>string</ApplicationArn>\n</GetAccessGrantResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantResult\nRoot level tag for the GetAccessGrantResult parameters.\nRequired: Yes\nAccessGrantArn\nThe Amazon Resource Name (ARN) of the access grant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/grant/[a-zA-\nZ0-9\\-]+\nAmazon S3 Control API Version 2006-03-01 874",
      "start_idx": 1081555,
      "end_idx": 1082708,
      "metadata": {
        "num_sentences": 7,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_880",
      "text": "Amazon Simple Storage Service API Reference\nAccessGrantId\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access\ngrant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nAccessGrantsLocationConfiguration\nThe configuration options of the grant location. The grant location is the S3 path to the data to\nwhich you are granting access.\nType: AccessGrantsLocationConfiguration data type\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with\nyour Identity Center instance. If the grant includes an application ARN, the grantee can only\naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nCreatedAt\nThe date and time when you created the access grant.\nAmazon S3 Control API Version 2006-03-01 875",
      "start_idx": 1082710,
      "end_idx": 1084056,
      "metadata": {
        "num_sentences": 18,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_881",
      "text": "Amazon Simple Storage Service API Reference\nType: Timestamp\nGrantee\nThe user, group, or role to which you are granting access. You can grant access to an IAM user\nor role. If you have added a corporate directory to AWS IAM Identity Center and associated this\nIdentity Center instance with the S3 Access Grants instance, the grantee can also be a corporate\ndirectory user or group.\nType: Grantee data type\nGrantScope\nThe S3 path of the data to which you are granting access. It is the result of appending the\nSubprefix to the location scope.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nPermission\nThe type of permission that was granted in the access grant. Can be one of the following values:\n\u2022 READ \u2013 Grant read-only access to the S3 data.\n\u2022 WRITE \u2013 Grant write-only access to the S3 data.\n\u2022 READWRITE \u2013 Grant both read and write access to the S3 data.\nType: String\nValid Values: READ | WRITE | READWRITE\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\nAmazon S3 Control API Version 2006-03-01 876",
      "start_idx": 1084058,
      "end_idx": 1085234,
      "metadata": {
        "num_sentences": 12,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_883",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessGrantsInstance\nService: Amazon S3 Control\nRetrieves the S3 Access Grants instance for a Region in your account.\nPermissions\nYou must have the s3:GetAccessGrantsInstance permission to use this operation.\nNote\nGetAccessGrantsInstance is not supported for cross-account access. You can only call\nthe API from the account that owns the S3 Access Grants instance.\nRequest Syntax\nGET /v20180820/accessgrantsinstance HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 878",
      "start_idx": 1085460,
      "end_idx": 1086304,
      "metadata": {
        "num_sentences": 9,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_884",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsInstanceResult>\n<AccessGrantsInstanceArn>string</AccessGrantsInstanceArn>\n<AccessGrantsInstanceId>string</AccessGrantsInstanceId>\n<IdentityCenterArn>string</IdentityCenterArn>\n<IdentityCenterInstanceArn>string</IdentityCenterInstanceArn>\n<IdentityCenterApplicationArn>string</IdentityCenterApplicationArn>\n<CreatedAt>timestamp</CreatedAt>\n</GetAccessGrantsInstanceResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsInstanceResult\nRoot level tag for the GetAccessGrantsInstanceResult parameters.\nRequired: Yes\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance. The ID is default. You can have one S3 Access Grants\ninstance per Region per account.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nAmazon S3 Control API Version 2006-03-01 879",
      "start_idx": 1086306,
      "end_idx": 1087604,
      "metadata": {
        "num_sentences": 12,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_885",
      "text": "Amazon Simple Storage Service API Reference\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nIdentityCenterApplicationArn\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this\nfield returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application;\na subresource of the original Identity Center instance. S3 Access Grants creates this Identity\nCenter application for the specific S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nIdentityCenterArn\nThis parameter has been deprecated.\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this\nfield returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application;\na subresource of the original Identity Center instance. S3 Access Grants creates this Identity\nCenter application for the specific S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nIdentityCenterInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are\nassociating with your S3 Access Grants instance. An IAM Identity Center instance is your\ncorporate identity directory that you added to the IAM Identity Center. You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nAmazon S3 Control API Version 2006-03-01 880",
      "start_idx": 1087606,
      "end_idx": 1089284,
      "metadata": {
        "num_sentences": 18,
        "num_words": 241,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_887",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessGrantsInstanceForPrefix\nService: Amazon S3 Control\nRetrieve the S3 Access Grants instance that contains a particular prefix.\nPermissions\nYou must have the s3:GetAccessGrantsInstanceForPrefix permission for the caller\naccount to use this operation.\nAdditional Permissions\nThe prefix owner account must grant you the following permissions to their S3 Access Grants\ninstance: s3:GetAccessGrantsInstanceForPrefix.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/prefix?s3prefix=S3Prefix HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\ns3prefix\nThe S3 prefix of the access grants that you would like to retrieve.\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: Yes\nx-amz-account-id\nThe ID of the AWS account that is making this request.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 882",
      "start_idx": 1089739,
      "end_idx": 1090762,
      "metadata": {
        "num_sentences": 10,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_888",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsInstanceForPrefixResult>\n<AccessGrantsInstanceArn>string</AccessGrantsInstanceArn>\n<AccessGrantsInstanceId>string</AccessGrantsInstanceId>\n</GetAccessGrantsInstanceForPrefixResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsInstanceForPrefixResult\nRoot level tag for the GetAccessGrantsInstanceForPrefixResult parameters.\nRequired: Yes\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance. The ID is default. You can have one S3 Access Grants\ninstance per Region per account.\nType: String\nAmazon S3 Control API Version 2006-03-01 883",
      "start_idx": 1090764,
      "end_idx": 1091871,
      "metadata": {
        "num_sentences": 11,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_889",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 884",
      "start_idx": 1091873,
      "end_idx": 1092360,
      "metadata": {
        "num_sentences": 3,
        "num_words": 94,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_891",
      "text": "Amazon Simple Storage Service API Reference\n<CreatedAt>timestamp</CreatedAt>\n</GetAccessGrantsInstanceResourcePolicyResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsInstanceResourcePolicyResult\nRoot level tag for the GetAccessGrantsInstanceResourcePolicyResult parameters.\nRequired: Yes\nCreatedAt\nThe date and time when you created the S3 Access Grants instance resource policy.\nType: Timestamp\nOrganization\nThe Organization of the resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 12. Maximum length of 34.\nPattern: ^o-[a-z0-9]{10,32}$\nPolicy\nThe resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 350000.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 886",
      "start_idx": 1093261,
      "end_idx": 1094302,
      "metadata": {
        "num_sentences": 11,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_893",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessGrantsLocation\nService: Amazon S3 Control\nRetrieves the details of a particular location registered in your S3 Access Grants instance.\nPermissions\nYou must have the s3:GetAccessGrantsLocation permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/location/id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the registered location that you are retrieving. S3 Access Grants assigns this ID when\nyou register the location. S3 Access Grants assigns the ID default to the default location\ns3:// and assigns an auto-generated ID to other locations that you register.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 888",
      "start_idx": 1094565,
      "end_idx": 1095602,
      "metadata": {
        "num_sentences": 11,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_894",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessGrantsLocationResult>\n<CreatedAt>timestamp</CreatedAt>\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\n<AccessGrantsLocationArn>string</AccessGrantsLocationArn>\n<LocationScope>string</LocationScope>\n<IAMRoleArn>string</IAMRoleArn>\n</GetAccessGrantsLocationResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessGrantsLocationResult\nRoot level tag for the GetAccessGrantsLocationResult parameters.\nRequired: Yes\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nAmazon S3 Control API Version 2006-03-01 889",
      "start_idx": 1095604,
      "end_idx": 1096902,
      "metadata": {
        "num_sentences": 11,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_895",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants\nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nLocationScope\nThe S3 URI path to the registered location. The location scope can be the default S3 location\ns3://, the S3 path to a bucket, or the S3 path to a bucket and prefix. A prefix in S3 is a string\nof characters at the beginning of an object key name used to organize the objects that you\nstore in your S3 buckets. For example, object key names that start with the engineering/\nprefix or object key names that start with the marketing/campaigns/ prefix.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 890",
      "start_idx": 1096904,
      "end_idx": 1098149,
      "metadata": {
        "num_sentences": 15,
        "num_words": 202,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_897",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns configuration information about the specified access point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to GetAccessPoint:\n\u2022 CreateAccessPoint\n\u2022 DeleteAccessPoint\n\u2022 ListAccessPoints\nRequest Syntax\nGET /v20180820/accesspoint/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose configuration information you want to retrieve.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nAmazon S3 Control API Version 2006-03-01 892",
      "start_idx": 1098412,
      "end_idx": 1099628,
      "metadata": {
        "num_sentences": 9,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_898",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you\nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name>. For example, to access the access point reports-ap through\nOutpost my-outpost owned by account 123456789012 in Region us-west-2, use the URL\nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap. The value must be URL encoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the account that owns the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointResult>\n<Name>string</Name>\n<Bucket>string</Bucket>\n<NetworkOrigin>string</NetworkOrigin>\n<VpcConfiguration>\n<VpcId>string</VpcId>\n</VpcConfiguration>\n<PublicAccessBlockConfiguration>\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\nAmazon S3 Control API Version 2006-03-01 893",
      "start_idx": 1099630,
      "end_idx": 1100982,
      "metadata": {
        "num_sentences": 9,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_899",
      "text": "Amazon Simple Storage Service API Reference\n</PublicAccessBlockConfiguration>\n<CreationDate>timestamp</CreationDate>\n<Alias>string</Alias>\n<AccessPointArn>string</AccessPointArn>\n<Endpoints>\n<entry>\n<key>string</key>\n<value>string</value>\n</entry>\n</Endpoints>\n<BucketAccountId>string</BucketAccountId>\n</GetAccessPointResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointResult\nRoot level tag for the GetAccessPointResult parameters.\nRequired: Yes\nAccessPointArn\nThe ARN of the access point.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nAlias\nThe name or alias of the access point.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{63}\nBucket\nThe name of the bucket associated with the specified access point.\nAmazon S3 Control API Version 2006-03-01 894",
      "start_idx": 1100984,
      "end_idx": 1101920,
      "metadata": {
        "num_sentences": 10,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_900",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nBucketAccountId\nThe AWS account ID associated with the S3 bucket associated with this access point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nCreationDate\nThe date and time when the specified access point was created.\nType: Timestamp\nEndpoints\nThe VPC endpoint for the access point.\nType: String to string map\nKey Length Constraints: Minimum length of 1. Maximum length of 64.\nValue Length Constraints: Minimum length of 1. Maximum length of 1024.\nName\nThe name of the specified access point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nNetworkOrigin\nIndicates whether this access point allows access from the public internet. If\nVpcConfiguration is specified for this access point, then NetworkOrigin is VPC, and the\naccess point doesn't allow access from the public internet. Otherwise, NetworkOrigin is\nInternet, and the access point allows access from the public internet, subject to the access\npoint and bucket access policies.\nAmazon S3 Control API Version 2006-03-01 895",
      "start_idx": 1101922,
      "end_idx": 1103084,
      "metadata": {
        "num_sentences": 17,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_901",
      "text": "Amazon Simple Storage Service API Reference\nThis will always be true for an Amazon S3 on Outposts access point\nType: String\nValid Values: Internet | VPC\nPublicAccessBlockConfiguration\nThe PublicAccessBlock configuration that you want to apply to this Amazon S3 account.\nYou can enable the configuration options in any combination. For more information about when\nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3\nUser Guide.\nThis data type is not supported for Amazon S3 on Outposts.\nType: PublicAccessBlockConfiguration data type\nVpcConfiguration\nContains the virtual private cloud (VPC) configuration for the specified access point.\nNote\nThis element is empty if this access point is an Amazon S3 on Outposts access point that\nis used by other AWS services.\nType: VpcConfiguration data type\nExamples\nSample request syntax for getting an Amazon S3 on Outposts access point\nThe following request returns the access point of the specified S3 on Outposts access point.\nGET /v20180820/accesspoint/example-access-point HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2020 22:32:00 GMT\nAuthorization: authorization string\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nAmazon S3 Control API Version 2006-03-01 896",
      "start_idx": 1103086,
      "end_idx": 1104385,
      "metadata": {
        "num_sentences": 8,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_903",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPointConfigurationForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns configuration for an Object Lambda Access Point.\nThe following actions are related to GetAccessPointConfigurationForObjectLambda:\n\u2022 PutAccessPointConfigurationForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/name/configuration HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point you want to return the configuration for.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 898",
      "start_idx": 1104789,
      "end_idx": 1105772,
      "metadata": {
        "num_sentences": 9,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_906",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPointForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns configuration information about the specified Object Lambda Access Point\nThe following actions are related to GetAccessPointForObjectLambda:\n\u2022 CreateAccessPointForObjectLambda\n\u2022 DeleteAccessPointForObjectLambda\n\u2022 ListAccessPointsForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 901",
      "start_idx": 1107457,
      "end_idx": 1108424,
      "metadata": {
        "num_sentences": 8,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_908",
      "text": "Amazon Simple Storage Service API Reference\nCreationDate\nThe date and time when the specified Object Lambda Access Point was created.\nType: Timestamp\nName\nThe name of the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nPublicAccessBlockConfiguration\nConfiguration to block all public access. This setting is turned on and can not be edited.\nType: PublicAccessBlockConfiguration data type\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 903",
      "start_idx": 1109497,
      "end_idx": 1110339,
      "metadata": {
        "num_sentences": 7,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_909",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the access point policy associated with the specified access point.\nThe following actions are related to GetAccessPointPolicy:\n\u2022 PutAccessPointPolicy\n\u2022 DeleteAccessPointPolicy\nRequest Syntax\nGET /v20180820/accesspoint/name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose policy you want to retrieve.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you\nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name>. For example, to access the access point reports-ap through\nOutpost my-outpost owned by account 123456789012 in Region us-west-2, use the URL\nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap. The value must be URL encoded.\nAmazon S3 Control API Version 2006-03-01 904",
      "start_idx": 1110341,
      "end_idx": 1111622,
      "metadata": {
        "num_sentences": 9,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_910",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointPolicyResult>\n<Policy>string</Policy>\n</GetAccessPointPolicyResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointPolicyResult\nRoot level tag for the GetAccessPointPolicyResult parameters.\nRequired: Yes\nPolicy\nThe access point policy associated with the specified access point.\nType: String\nAmazon S3 Control API Version 2006-03-01 905",
      "start_idx": 1111624,
      "end_idx": 1112500,
      "metadata": {
        "num_sentences": 10,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_912",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPointPolicyForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the resource policy for an Object Lambda Access Point.\nThe following actions are related to GetAccessPointPolicyForObjectLambda:\n\u2022 DeleteAccessPointPolicyForObjectLambda\n\u2022 PutAccessPointPolicyForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 907",
      "start_idx": 1113251,
      "end_idx": 1114212,
      "metadata": {
        "num_sentences": 9,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_915",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPointPolicyStatus\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nIndicates whether the specified access point currently has a policy that allows public access. For\nmore information about public access through access points, see Managing Data Access with\nAmazon S3 access points in the Amazon S3 User Guide.\nRequest Syntax\nGET /v20180820/accesspoint/name/policyStatus HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point whose policy status you want to retrieve.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 910",
      "start_idx": 1115989,
      "end_idx": 1116999,
      "metadata": {
        "num_sentences": 11,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_918",
      "text": "Amazon Simple Storage Service API Reference\nGetAccessPointPolicyStatusForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the status of the resource policy associated with an Object Lambda Access Point.\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda/name/policyStatus HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 913",
      "start_idx": 1118069,
      "end_idx": 1118984,
      "metadata": {
        "num_sentences": 10,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_919",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetAccessPointPolicyStatusForObjectLambdaResult>\n<PolicyStatus>\n<IsPublic>boolean</IsPublic>\n</PolicyStatus>\n</GetAccessPointPolicyStatusForObjectLambdaResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetAccessPointPolicyStatusForObjectLambdaResult\nRoot level tag for the GetAccessPointPolicyStatusForObjectLambdaResult parameters.\nRequired: Yes\nPolicyStatus\nIndicates whether this access point policy is public. For more information about how Amazon\nS3 evaluates policies to determine whether they are public, see The Meaning of \"Public\" in the\nAmazon S3 User Guide.\nType: PolicyStatus data type\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 914",
      "start_idx": 1118986,
      "end_idx": 1120072,
      "metadata": {
        "num_sentences": 6,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_921",
      "text": "Amazon Simple Storage Service API Reference\nGetBucket\nService: Amazon S3 Control\nGets an Amazon S3 on Outposts bucket. For more information, see Using Amazon S3 on Outposts\nin the Amazon S3 User Guide.\nIf you are using an identity other than the root user of the AWS account that owns the Outposts\nbucket, the calling identity must have the s3-outposts:GetBucket permissions on the specified\nOutposts bucket and belong to the Outposts bucket owner's account in order to use this action.\nOnly users from Outposts bucket owner account with the right permissions can perform actions on\nan Outposts bucket.\nIf you don't have s3-outposts:GetBucket permissions or you're not using an identity that\nbelongs to the bucket owner's account, Amazon S3 returns a 403 Access Denied error.\nThe following actions are related to GetBucket for Amazon S3 on Outposts:\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\n\u2022 PutObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\nRequest Syntax\nGET /v20180820/bucket/name HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket.\nAmazon S3 Control API Version 2006-03-01 916",
      "start_idx": 1120256,
      "end_idx": 1121849,
      "metadata": {
        "num_sentences": 11,
        "num_words": 247,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_922",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketResult>\n<Bucket>string</Bucket>\n<PublicAccessBlockEnabled>boolean</PublicAccessBlockEnabled>\n<CreationDate>timestamp</CreationDate>\n</GetBucketResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 917",
      "start_idx": 1121851,
      "end_idx": 1123134,
      "metadata": {
        "num_sentences": 11,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_923",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nGetBucketResult\nRoot level tag for the GetBucketResult parameters.\nRequired: Yes\nBucket\nThe Outposts bucket requested.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nCreationDate\nThe creation date of the Outposts bucket.\nType: Timestamp\nPublicAccessBlockEnabled\nType: Boolean\nExamples\nSample request for getting Amazon S3 on Outposts bucket\nThis example illustrates one usage of GetBucket.\nGET /v20180820/bucket/example-outpost-bucket/ HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nx-amz-Date: 20200928T203757Z\nAuthorization: authorization string\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 918",
      "start_idx": 1123136,
      "end_idx": 1124054,
      "metadata": {
        "num_sentences": 8,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_925",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketLifecycleConfiguration\nService: Amazon S3 Control\nNote\nThis action gets an Amazon S3 on Outposts bucket's lifecycle configuration. To get an S3\nbucket's lifecycle configuration, see GetBucketLifecycleConfiguration in the Amazon S3 API\nReference.\nReturns the lifecycle configuration information set on the Outposts bucket. For more information,\nsee Using Amazon S3 on Outposts and for information about lifecycle configuration, see Object\nLifecycle Management in Amazon S3 User Guide.\nTo use this action, you must have permission to perform the s3-\noutposts:GetLifecycleConfiguration action. The Outposts bucket owner has this\npermission, by default. The bucket owner can grant this permission to others. For more information\nabout permissions, see Permissions Related to Bucket Subresource Operations and Managing\nAccess Permissions to Your Amazon S3 Resources.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nGetBucketLifecycleConfiguration has the following special error:\n\u2022 Error code: NoSuchLifecycleConfiguration\n\u2022 Description: The lifecycle configuration does not exist.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\nThe following actions are related to GetBucketLifecycleConfiguration:\n\u2022 PutBucketLifecycleConfiguration\n\u2022 DeleteBucketLifecycleConfiguration\nAmazon S3 Control API Version 2006-03-01 920",
      "start_idx": 1124346,
      "end_idx": 1126123,
      "metadata": {
        "num_sentences": 13,
        "num_words": 248,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_926",
      "text": "Amazon Simple Storage Service API Reference\nRequest Syntax\nGET /v20180820/bucket/name/lifecycleconfiguration HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe Amazon Resource Name (ARN) of the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 921",
      "start_idx": 1126125,
      "end_idx": 1127348,
      "metadata": {
        "num_sentences": 12,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_930",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketPolicy\nService: Amazon S3 Control\nNote\nThis action gets a bucket policy for an Amazon S3 on Outposts bucket. To get a policy for\nan S3 bucket, see GetBucketPolicy in the Amazon S3 API Reference.\nReturns the policy of a specified Outposts bucket. For more information, see Using Amazon S3 on\nOutposts in the Amazon S3 User Guide.\nIf you are using an identity other than the root user of the AWS account that owns the bucket, the\ncalling identity must have the GetBucketPolicy permissions on the specified bucket and belong\nto the bucket owner's account in order to use this action.\nOnly users from Outposts bucket owner account with the right permissions can perform actions\non an Outposts bucket. If you don't have s3-outposts:GetBucketPolicy permissions or\nyou're not using an identity that belongs to the bucket owner's account, Amazon S3 returns a 403\nAccess Denied error.\nImportant\nAs a security precaution, the root user of the AWS account that owns a bucket can always\nuse this action, even if the policy explicitly denies the root user the ability to perform this\naction.\nFor more information about bucket policies, see Using Bucket Policies and User Policies.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to GetBucketPolicy:\n\u2022 GetObject\nAmazon S3 Control API Version 2006-03-01 925",
      "start_idx": 1130137,
      "end_idx": 1131911,
      "metadata": {
        "num_sentences": 13,
        "num_words": 292,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_931",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 PutBucketPolicy\n\u2022 DeleteBucketPolicy\nRequest Syntax\nGET /v20180820/bucket/name/policy HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 926",
      "start_idx": 1131913,
      "end_idx": 1133080,
      "metadata": {
        "num_sentences": 11,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_934",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketReplication\nService: Amazon S3 Control\nNote\nThis operation gets an Amazon S3 on Outposts bucket's replication configuration. To get\nan S3 bucket's replication configuration, see GetBucketReplication in the Amazon S3 API\nReference.\nReturns the replication configuration of an S3 on Outposts bucket. For more information about\nS3 on Outposts, see Using Amazon S3 on Outposts in the Amazon S3 User Guide. For information\nabout S3 replication on Outposts configuration, see Replicating objects for S3 on Outposts in the\nAmazon S3 User Guide.\nNote\nIt can take a while to propagate PUT or DELETE requests for a replication configuration\nto all S3 on Outposts systems. Therefore, the replication configuration that's returned\nby a GET request soon after a PUT or DELETE request might return a more recent result\nthan what's on the Outpost. If an Outpost is offline, the delay in updating the replication\nconfiguration on that Outpost can be significant.\nThis action requires permissions for the s3-outposts:GetReplicationConfiguration action.\nThe Outposts bucket owner has this permission by default and can grant it to others. For more\ninformation about permissions, see Setting up IAM with S3 on Outposts and Managing access to S3\non Outposts bucket in the Amazon S3 User Guide.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nIf you include the Filter element in a replication configuration, you must also include the\nDeleteMarkerReplication, Status, and Priority elements. The response also returns those\nelements.\nAmazon S3 Control API Version 2006-03-01 929",
      "start_idx": 1134493,
      "end_idx": 1136497,
      "metadata": {
        "num_sentences": 17,
        "num_words": 313,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_935",
      "text": "Amazon Simple Storage Service API Reference\nFor information about S3 on Outposts replication failure reasons, see Replication failure reasons in\nthe Amazon S3 User Guide.\nThe following operations are related to GetBucketReplication:\n\u2022 PutBucketReplication\n\u2022 DeleteBucketReplication\nRequest Syntax\nGET /v20180820/bucket/name/replication HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket to get the replication information for.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nAmazon S3 Control API Version 2006-03-01 930",
      "start_idx": 1136499,
      "end_idx": 1137835,
      "metadata": {
        "num_sentences": 11,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_938",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketReplicationResult\nRoot level tag for the GetBucketReplicationResult parameters.\nRequired: Yes\nReplicationConfiguration\nA container for one or more replication rules. A replication configuration must have at least one\nrule and you can add up to 100 rules. The maximum size of a replication configuration is 128\nKB.\nType: ReplicationConfiguration data type\nExamples\nSample request to get the replication configuration of an Amazon S3 on Outposts bucket\nThe following example shows how to get the replication configuration of an Outposts bucket.\nGET /v20180820/bucket/example-outpost-bucket/replication HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nAuthorization: signatureValue\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 933",
      "start_idx": 1139709,
      "end_idx": 1140831,
      "metadata": {
        "num_sentences": 6,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_940",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketTagging\nService: Amazon S3 Control\nNote\nThis action gets an Amazon S3 on Outposts bucket's tags. To get an S3 bucket tags, see\nGetBucketTagging in the Amazon S3 API Reference.\nReturns the tag set associated with the Outposts bucket. For more information, see Using Amazon\nS3 on Outposts in the Amazon S3 User Guide.\nTo use this action, you must have permission to perform the GetBucketTagging action. By\ndefault, the bucket owner has this permission and can grant this permission to others.\nGetBucketTagging has the following special error:\n\u2022 Error code: NoSuchTagSetError\n\u2022 Description: There is no tag set associated with the bucket.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to GetBucketTagging:\n\u2022 PutBucketTagging\n\u2022 DeleteBucketTagging\nRequest Syntax\nGET /v20180820/bucket/name/tagging HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nAmazon S3 Control API Version 2006-03-01 935",
      "start_idx": 1140966,
      "end_idx": 1142363,
      "metadata": {
        "num_sentences": 11,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_941",
      "text": "Amazon Simple Storage Service API Reference\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 Control API Version 2006-03-01 936",
      "start_idx": 1142365,
      "end_idx": 1143492,
      "metadata": {
        "num_sentences": 12,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_944",
      "text": "Amazon Simple Storage Service API Reference\nGetBucketVersioning\nService: Amazon S3 Control\nNote\nThis operation returns the versioning state for S3 on Outposts buckets only. To return the\nversioning state for an S3 bucket, see GetBucketVersioning in the Amazon S3 API Reference.\nReturns the versioning state for an S3 on Outposts bucket. With S3 Versioning, you can save\nmultiple distinct copies of your objects and recover from unintended user actions and application\nfailures.\nIf you've never set versioning on your bucket, it has no versioning state. In that case, the\nGetBucketVersioning request does not return a versioning state value.\nFor more information about versioning, see Versioning in the Amazon S3 User Guide.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following operations are related to GetBucketVersioning for S3 on Outposts.\n\u2022 PutBucketVersioning\n\u2022 PutBucketLifecycleConfiguration\n\u2022 GetBucketLifecycleConfiguration\nRequest Syntax\nGET /v20180820/bucket/name/versioning HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 939",
      "start_idx": 1144883,
      "end_idx": 1146462,
      "metadata": {
        "num_sentences": 13,
        "num_words": 228,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_945",
      "text": "Amazon Simple Storage Service API Reference\nname\nThe S3 on Outposts bucket to return the versioning state for.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 on Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetBucketVersioningResult>\n<Status>string</Status>\n<MfaDelete>string</MfaDelete>\n</GetBucketVersioningResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetBucketVersioningResult\nRoot level tag for the GetBucketVersioningResult parameters.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 940",
      "start_idx": 1146464,
      "end_idx": 1147325,
      "metadata": {
        "num_sentences": 10,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_946",
      "text": "Amazon Simple Storage Service API Reference\nMFADelete\nSpecifies whether MFA delete is enabled in the bucket versioning configuration. This element is\nreturned only if the bucket has been configured with MFA delete. If MFA delete has never been\nconfigured for the bucket, this element is not returned.\nType: String\nValid Values: Enabled | Disabled\nStatus\nThe versioning state of the S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Suspended\nExamples\nSample GetBucketVersioning request on an S3 on Outposts bucket\nThis request returns the versioning state for an S3 on Outposts bucket that's named example-\noutpost-bucket.\nGET /v20180820/bucket/example-outpost-bucket/?versioning HTTP/1.1\nHost:s3-outposts.region-code.amazonaws.com\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nx-amz-date: Wed, 25 May 2022 00:14:21 GMT\nAuthorization: signatureValue\nSample GetBucketVersioning response on a versioning-enabled S3 on Outposts bucket\nIf you enabled versioning on a bucket, the response is:\n<VersioningConfiguration xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<Status>Enabled</Status>\nAmazon S3 Control API Version 2006-03-01 941",
      "start_idx": 1147327,
      "end_idx": 1148509,
      "metadata": {
        "num_sentences": 6,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_948",
      "text": "Amazon Simple Storage Service API Reference\nGetDataAccess\nService: Amazon S3 Control\nReturns a temporary access credential from S3 Access Grants to the grantee or client application.\nThe temporary credential is an AWS STS token that grants them access to the S3 data.\nPermissions\nYou must have the s3:GetDataAccess permission to use this operation.\nAdditional Permissions\nThe IAM role that S3 Access Grants assumes must have the following permissions specified in\nthe trust policy when registering the location: sts:AssumeRole, for directory users or groups\nsts:SetContext, and for IAM users or roles sts:SetSourceIdentity.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/dataaccess?\ndurationSeconds=DurationSeconds&permission=Permission&privilege=Privilege&target=Target&targetType=TargetType\nHTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\ndurationSeconds\nThe session duration, in seconds, of the temporary access credential that S3 Access Grants\nvends to the grantee or client application. The default value is 1 hour, but the grantee can\nspecify a range from 900 seconds (15 minutes) up to 43200 seconds (12 hours). If the grantee\nrequests a value higher than this maximum, the operation fails.\nValid Range: Minimum value of 900. Maximum value of 43200.\npermission\nThe type of permission granted to your S3 data, which can be set to one of the following\nvalues:\n\u2022 READ \u2013 Grant read-only access to the S3 data.\nAmazon S3 Control API Version 2006-03-01 943",
      "start_idx": 1149432,
      "end_idx": 1150983,
      "metadata": {
        "num_sentences": 12,
        "num_words": 217,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_949",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 WRITE \u2013 Grant write-only access to the S3 data.\n\u2022 READWRITE \u2013 Grant both read and write access to the S3 data.\nValid Values: READ | WRITE | READWRITE\nRequired: Yes\nprivilege\nThe scope of the temporary access credential that S3 Access Grants vends to the grantee or\nclient application.\n\u2022 Default \u2013 The scope of the returned temporary access token is the scope of the grant that is\nclosest to the target scope.\n\u2022 Minimal \u2013 The scope of the returned temporary access token is the same as the requested\ntarget scope as long as the requested scope is the same as or a subset of the grant scope.\nValid Values: Minimal | Default\ntarget\nThe S3 URI path of the data to which you are requesting temporary access credentials. If the\nrequesting account has an access grant for this data, S3 Access Grants vends temporary access\ncredentials in the response.\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: Yes\ntargetType\nThe type of Target. The only possible value is Object. Pass this value if the target data that\nyou would like to access is a path to an object. Do not pass this value if the target data is a\nbucket or a bucket and a prefix.\nValid Values: Object\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 944",
      "start_idx": 1150985,
      "end_idx": 1152381,
      "metadata": {
        "num_sentences": 16,
        "num_words": 248,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_951",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 946",
      "start_idx": 1153347,
      "end_idx": 1153839,
      "metadata": {
        "num_sentences": 3,
        "num_words": 96,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_952",
      "text": "Amazon Simple Storage Service API Reference\nGetJobTagging\nService: Amazon S3 Control\nReturns the tags on an S3 Batch Operations job.\nPermissions\nTo use the GetJobTagging operation, you must have permission to perform the\ns3:GetJobTagging action. For more information, see Controlling access and labeling jobs\nusing tags in the Amazon S3 User Guide.\nRelated actions include:\n\u2022 CreateJob\n\u2022 PutJobTagging\n\u2022 DeleteJobTagging\nRequest Syntax\nGET /v20180820/jobs/id/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the S3 Batch Operations job whose tags you want to retrieve.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 947",
      "start_idx": 1153841,
      "end_idx": 1154791,
      "metadata": {
        "num_sentences": 10,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_955",
      "text": "Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPoint\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns configuration information about the specified Multi-Region Access Point.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThe following actions are related to GetMultiRegionAccessPoint:\n\u2022 CreateMultiRegionAccessPoint\n\u2022 DeleteMultiRegionAccessPoint\n\u2022 DescribeMultiRegionAccessPointOperation\n\u2022 ListMultiRegionAccessPoints\nRequest Syntax\nGET /v20180820/mrap/instances/name+ HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Multi-Region Access Point whose configuration information you want to\nreceive. The name of the Multi-Region Access Point is different from the alias. For more\ninformation about the distinction between the name and the alias of an Multi-Region Access\nPoint, see Rules for naming Amazon S3 Multi-Region Access Points in the Amazon S3 User\nGuide.\nAmazon S3 Control API Version 2006-03-01 950",
      "start_idx": 1156038,
      "end_idx": 1157317,
      "metadata": {
        "num_sentences": 9,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_958",
      "text": "Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns the access control policy of the specified Multi-Region Access Point.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThe following actions are related to GetMultiRegionAccessPointPolicy:\n\u2022 GetMultiRegionAccessPointPolicyStatus\n\u2022 PutMultiRegionAccessPointPolicy\nRequest Syntax\nGET /v20180820/mrap/instances/name+/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the Multi-Region Access Point. The name of the Multi-Region Access Point is different\nfrom the alias. For more information about the distinction between the name and the alias of\nan Multi-Region Access Point, see Rules for naming Amazon S3 Multi-Region Access Points in\nthe Amazon S3 User Guide.\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nAmazon S3 Control API Version 2006-03-01 953",
      "start_idx": 1159159,
      "end_idx": 1160425,
      "metadata": {
        "num_sentences": 10,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_961",
      "text": "Amazon Simple Storage Service API Reference\nGetMultiRegionAccessPointPolicyStatus\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nIndicates whether the specified Multi-Region Access Point has an access control policy that allows\npublic access.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThe following actions are related to GetMultiRegionAccessPointPolicyStatus:\n\u2022 GetMultiRegionAccessPointPolicy\n\u2022 PutMultiRegionAccessPointPolicy\nRequest Syntax\nGET /v20180820/mrap/instances/name+/policystatus HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the Multi-Region Access Point. The name of the Multi-Region Access Point is different\nfrom the alias. For more information about the distinction between the name and the alias of\nan Multi-Region Access Point, see Rules for naming Amazon S3 Multi-Region Access Points in\nthe Amazon S3 User Guide.\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nAmazon S3 Control API Version 2006-03-01 956",
      "start_idx": 1161820,
      "end_idx": 1163134,
      "metadata": {
        "num_sentences": 10,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_962",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<GetMultiRegionAccessPointPolicyStatusResult>\n<Established>\n<IsPublic>boolean</IsPublic>\n</Established>\n</GetMultiRegionAccessPointPolicyStatusResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nGetMultiRegionAccessPointPolicyStatusResult\nRoot level tag for the GetMultiRegionAccessPointPolicyStatusResult parameters.\nRequired: Yes\nEstablished\nIndicates whether this access point policy is public. For more information about how Amazon\nS3 evaluates policies to determine whether they are public, see The Meaning of \"Public\" in the\nAmazon S3 User Guide.\nAmazon S3 Control API Version 2006-03-01 957",
      "start_idx": 1163136,
      "end_idx": 1164181,
      "metadata": {
        "num_sentences": 9,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_966",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Maximum length of 200.\nPattern: ^[a-zA-Z0-9\\:.-]{3,200}$\nRoutes\nThe different routes that make up the route configuration. Active routes return a value of 100,\nand passive routes return a value of 0.\nType: Array of MultiRegionAccessPointRoute data types\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 961",
      "start_idx": 1166407,
      "end_idx": 1167094,
      "metadata": {
        "num_sentences": 4,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_967",
      "text": "Amazon Simple Storage Service API Reference\nGetPublicAccessBlock\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nRetrieves the PublicAccessBlock configuration for an AWS account. For more information, see\nUsing Amazon S3 block public access.\nRelated actions include:\n\u2022 DeletePublicAccessBlock\n\u2022 PutPublicAccessBlock\nRequest Syntax\nGET /v20180820/configuration/publicAccessBlock HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe account ID for the AWS account whose PublicAccessBlock configuration you want to\nretrieve.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 962",
      "start_idx": 1167096,
      "end_idx": 1167935,
      "metadata": {
        "num_sentences": 8,
        "num_words": 106,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_968",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration>\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPublicAccessBlockConfiguration\nRoot level tag for the PublicAccessBlockConfiguration parameters.\nRequired: Yes\nBlockPublicAcls\nSpecifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this\naccount. Setting this element to TRUE causes the following behavior:\n\u2022 PutBucketAcl and PutObjectAcl calls fail if the specified ACL is public.\n\u2022 PUT Object calls fail if the request includes a public ACL.\n\u2022 PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't affect existing policies or ACLs.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nBlockPublicPolicy\nSpecifies whether Amazon S3 should block public bucket policies for buckets in this account.\nSetting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the\nspecified bucket policy allows public access.\nAmazon S3 Control API Version 2006-03-01 963",
      "start_idx": 1167937,
      "end_idx": 1169377,
      "metadata": {
        "num_sentences": 12,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_969",
      "text": "Amazon Simple Storage Service API Reference\nEnabling this setting doesn't affect existing bucket policies.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nIgnorePublicAcls\nSpecifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this\nelement to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any\nobjects that they contain.\nEnabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent\nnew public ACLs from being set.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRestrictPublicBuckets\nSpecifies whether Amazon S3 should restrict public bucket policies for buckets in this account.\nSetting this element to TRUE restricts access to buckets with public policies to only AWS service\nprincipals and authorized users within this account.\nEnabling this setting doesn't affect previously stored bucket policies, except that public and\ncross-account access within any public bucket policy, including non-public delegation to specific\naccounts, is blocked.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nErrors\nNoSuchPublicAccessBlockConfiguration\nAmazon S3 throws this exception if you make a GetPublicAccessBlock request against an\naccount that doesn't have a PublicAccessBlockConfiguration set.\nHTTP Status Code: 404\nAmazon S3 Control API Version 2006-03-01 964",
      "start_idx": 1169379,
      "end_idx": 1170806,
      "metadata": {
        "num_sentences": 12,
        "num_words": 207,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_971",
      "text": "Amazon Simple Storage Service API Reference\nGetStorageLensConfiguration\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nGets the Amazon S3 Storage Lens configuration. For more information, see Assessing your storage\nactivity and usage with Amazon S3 Storage Lens in the Amazon S3 User Guide. For a complete list\nof S3 Storage Lens metrics, see S3 Storage Lens metrics glossary in the Amazon S3 User Guide.\nNote\nTo use this action, you must have permission to perform the\ns3:GetStorageLensConfiguration action. For more information, see Setting\npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nGET /v20180820/storagelens/storagelensid HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the Amazon S3 Storage Lens configuration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 966",
      "start_idx": 1171210,
      "end_idx": 1172322,
      "metadata": {
        "num_sentences": 13,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_975",
      "text": "Amazon Simple Storage Service API Reference\nDataExport\nA container to specify the properties of your S3 Storage Lens metrics export including, the\ndestination, schema and format.\nType: StorageLensDataExport data type\nExclude\nA container for what is excluded in this configuration. This container can only be valid if there is\nno Include container submitted, and it's not empty.\nType: Exclude data type\nId\nA container for the Amazon S3 Storage Lens configuration ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nInclude\nA container for what is included in this configuration. This container can only be valid if there is\nno Exclude container submitted, and it's not empty.\nType: Include data type\nIsEnabled\nA container for whether the S3 Storage Lens configuration is enabled.\nType: Boolean\nStorageLensArn\nThe Amazon Resource Name (ARN) of the S3 Storage Lens configuration. This property is read-\nonly and follows the following format: arn:aws:s3:us-east-1:example-account-\nid:storage-lens/your-dashboard-name\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nAmazon S3 Control API Version 2006-03-01 970",
      "start_idx": 1175256,
      "end_idx": 1176447,
      "metadata": {
        "num_sentences": 14,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_977",
      "text": "Amazon Simple Storage Service API Reference\nGetStorageLensConfigurationTagging\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nGets the tags of Amazon S3 Storage Lens configuration. For more information about S3 Storage\nLens, see Assessing your storage activity and usage with Amazon S3 Storage Lens in the Amazon\nS3 User Guide.\nNote\nTo use this action, you must have permission to perform the\ns3:GetStorageLensConfigurationTagging action. For more information, see Setting\npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nGET /v20180820/storagelens/storagelensid/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nstoragelensid\nThe ID of the Amazon S3 Storage Lens configuration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nAmazon S3 Control API Version 2006-03-01 972",
      "start_idx": 1176913,
      "end_idx": 1177963,
      "metadata": {
        "num_sentences": 12,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_980",
      "text": "Amazon Simple Storage Service API Reference\nGetStorageLensGroup\nService: Amazon S3 Control\nRetrieves the Storage Lens group configuration details.\nTo use this operation, you must have the permission to perform the s3:GetStorageLensGroup\naction. For more information about the required Storage Lens Groups permissions, see Setting\naccount permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nGET /v20180820/storagelensgroup/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Storage Lens group that you're trying to retrieve the configuration details for.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the Storage Lens group that you're trying to retrieve the\ndetails for.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 975",
      "start_idx": 1179192,
      "end_idx": 1180307,
      "metadata": {
        "num_sentences": 11,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_983",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nFilter\nSets the criteria for the Storage Lens group data that is displayed. For multiple filter conditions,\nthe AND or OR logical operator is used.\nType: StorageLensGroupFilter data type\nName\nContains the name of the Storage Lens group.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nStorageLensGroupArn\nContains the Amazon Resource Name (ARN) of the Storage Lens group. This property is read-\nonly.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 978",
      "start_idx": 1182276,
      "end_idx": 1183249,
      "metadata": {
        "num_sentences": 11,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_985",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrants\nService: Amazon S3 Control\nReturns the list of access grants in your S3 Access Grants instance.\nPermissions\nYou must have the s3:ListAccessGrants permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/grants?\napplication_arn=ApplicationArn&granteeidentifier=GranteeIdentifier&granteetype=GranteeType&grantscope=GrantScope&maxResults=MaxResults&nextToken=NextToken&permission=Permission\nHTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\napplication_arn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with\nyour Identity Center instance. If the grant includes an application ARN, the grantee can only\naccess the S3 data through this application.\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\ngranteeidentifier\nThe unique identifer of the Grantee. If the grantee type is IAM, the identifier is the\nIAM Amazon Resource Name (ARN) of the user or role. If the grantee type is a directory\nuser or group, the identifier is 128-bit universally unique identifier (UUID) in the format\na1b2c3d4-5678-90ab-cdef-EXAMPLE11111. You can obtain this UUID from your AWS IAM\nIdentity Center instance.\ngranteetype\nThe type of the grantee to which access has been granted. It can be one of the following values:\nAmazon S3 Control API Version 2006-03-01 980",
      "start_idx": 1183384,
      "end_idx": 1184900,
      "metadata": {
        "num_sentences": 15,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_986",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 IAM - An IAM user or role.\n\u2022 DIRECTORY_USER - Your corporate directory user. You can use this option if you have added\nyour corporate identity directory to IAM Identity Center and associated the IAM Identity\nCenter instance with your S3 Access Grants instance.\n\u2022 DIRECTORY_GROUP - Your corporate directory group. You can use this option if you have\nadded your corporate identity directory to IAM Identity Center and associated the IAM\nIdentity Center instance with your S3 Access Grants instance.\nValid Values: DIRECTORY_USER | DIRECTORY_GROUP | IAM\ngrantscope\nThe S3 path of the data to which you are granting access. It is the result of appending the\nSubprefix to the location scope.\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nmaxResults\nThe maximum number of access grants that you would like returned in the List Access\nGrants response. If the results include the pagination token NextToken, make another call\nusing the NextToken to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nAccess Grants request in order to retrieve the next page of results.\npermission\nThe type of permission granted to your S3 data, which can be set to one of the following\nvalues:\n\u2022 READ \u2013 Grant read-only access to the S3 data.\n\u2022 WRITE \u2013 Grant write-only access to the S3 data.\n\u2022 READWRITE \u2013 Grant both read and write access to the S3 data.\nValid Values: READ | WRITE | READWRITE\nAmazon S3 Control API Version 2006-03-01 981",
      "start_idx": 1184902,
      "end_idx": 1186540,
      "metadata": {
        "num_sentences": 18,
        "num_words": 278,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_988",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nListAccessGrantsResult\nRoot level tag for the ListAccessGrantsResult parameters.\nRequired: Yes\nAccessGrantsList\nA container for a list of grants in an S3 Access Grants instance.\nType: Array of ListAccessGrantEntry data types\nNextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nAccess Grants request in order to retrieve the next page of results.\nType: String\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 983",
      "start_idx": 1187619,
      "end_idx": 1188492,
      "metadata": {
        "num_sentences": 6,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_989",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrantsInstances\nService: Amazon S3 Control\nReturns a list of S3 Access Grants instances. An S3 Access Grants instance serves as a logical\ngrouping for your individual access grants. You can only have one S3 Access Grants instance per\nRegion per account.\nPermissions\nYou must have the s3:ListAccessGrantsInstances permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstances?maxResults=MaxResults&nextToken=NextToken HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nThe maximum number of access grants that you would like returned in the List Access\nGrants response. If the results include the pagination token NextToken, make another call\nusing the NextToken to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nAccess Grants Instances request in order to retrieve the next page of results.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 984",
      "start_idx": 1188494,
      "end_idx": 1189800,
      "metadata": {
        "num_sentences": 13,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_990",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessGrantsInstancesResult>\n<NextToken>string</NextToken>\n<AccessGrantsInstancesList>\n<AccessGrantsInstance>\n<AccessGrantsInstanceArn>string</AccessGrantsInstanceArn>\n<AccessGrantsInstanceId>string</AccessGrantsInstanceId>\n<CreatedAt>timestamp</CreatedAt>\n<IdentityCenterApplicationArn>string</IdentityCenterApplicationArn>\n<IdentityCenterArn>string</IdentityCenterArn>\n<IdentityCenterInstanceArn>string</IdentityCenterInstanceArn>\n</AccessGrantsInstance>\n</AccessGrantsInstancesList>\n</ListAccessGrantsInstancesResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListAccessGrantsInstancesResult\nRoot level tag for the ListAccessGrantsInstancesResult parameters.\nRequired: Yes\nAccessGrantsInstancesList\nA container for a list of S3 Access Grants instances.\nType: Array of ListAccessGrantsInstanceEntry data types\nNextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nAccess Grants Instances request in order to retrieve the next page of results.\nAmazon S3 Control API Version 2006-03-01 985",
      "start_idx": 1189802,
      "end_idx": 1191125,
      "metadata": {
        "num_sentences": 8,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_992",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrantsLocations\nService: Amazon S3 Control\nReturns a list of the locations registered in your S3 Access Grants instance.\nPermissions\nYou must have the s3:ListAccessGrantsLocations permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/locations?\nlocationscope=LocationScope&maxResults=MaxResults&nextToken=NextToken HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nlocationscope\nThe S3 path to the location that you are registering. The location scope can be the default S3\nlocation s3://, the S3 path to a bucket s3://<bucket>, or the S3 path to a bucket and prefix\ns3://<bucket>/<prefix>. A prefix in S3 is a string of characters at the beginning of an\nobject key name used to organize the objects that you store in your S3 buckets. For example,\nobject key names that start with the engineering/ prefix or object key names that start with\nthe marketing/campaigns/ prefix.\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nmaxResults\nThe maximum number of access grants that you would like returned in the List Access\nGrants response. If the results include the pagination token NextToken, make another call\nusing the NextToken to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nAmazon S3 Control API Version 2006-03-01 987",
      "start_idx": 1191542,
      "end_idx": 1193013,
      "metadata": {
        "num_sentences": 15,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_993",
      "text": "Amazon Simple Storage Service API Reference\nnextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nAccess Grants Locations request in order to retrieve the next page of results.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessGrantsLocationsResult>\n<NextToken>string</NextToken>\n<AccessGrantsLocationsList>\n<AccessGrantsLocation>\n<AccessGrantsLocationArn>string</AccessGrantsLocationArn>\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\n<CreatedAt>timestamp</CreatedAt>\n<IAMRoleArn>string</IAMRoleArn>\n<LocationScope>string</LocationScope>\n</AccessGrantsLocation>\n</AccessGrantsLocationsList>\n</ListAccessGrantsLocationsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 988",
      "start_idx": 1193015,
      "end_idx": 1194127,
      "metadata": {
        "num_sentences": 8,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_994",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrantsLocationsResult\nRoot level tag for the ListAccessGrantsLocationsResult parameters.\nRequired: Yes\nAccessGrantsLocationsList\nA container for a list of registered locations in an S3 Access Grants instance.\nType: Array of ListAccessGrantsLocationsEntry data types\nNextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nAccess Grants Locations request in order to retrieve the next page of results.\nType: String\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 989",
      "start_idx": 1194129,
      "end_idx": 1195002,
      "metadata": {
        "num_sentences": 5,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_995",
      "text": "Amazon Simple Storage Service API Reference\nListAccessPoints\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns a list of the access points that are owned by the current account that's associated with\nthe specified bucket. You can retrieve up to 1000 access points per call. If the specified bucket has\nmore than 1,000 access points (or the number specified in maxResults, whichever is less), the\nresponse will include a continuation token that you can use to list the additional access points.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to ListAccessPoints:\n\u2022 CreateAccessPoint\n\u2022 DeleteAccessPoint\n\u2022 GetAccessPoint\nRequest Syntax\nGET /v20180820/accesspoint?bucket=Bucket&maxResults=MaxResults&nextToken=NextToken\nHTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nbucket\nThe name of the bucket whose associated access points you want to list.\nAmazon S3 Control API Version 2006-03-01 990",
      "start_idx": 1195004,
      "end_idx": 1196456,
      "metadata": {
        "num_sentences": 10,
        "num_words": 213,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_996",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nmaxResults\nThe maximum number of access points that you want to include in the list. If the specified\nbucket has more than this number of access points, then the response will include a\ncontinuation token in the NextToken field that you can use to retrieve the next page of access\npoints.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA continuation token. If a previous call to ListAccessPoints returned a continuation token\nin the NextToken field, then providing that value here causes Amazon S3 to retrieve the next\npage of results.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe AWS account ID for the account that owns the specified access points.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nAmazon S3 Control API Version 2006-03-01 991",
      "start_idx": 1196458,
      "end_idx": 1198058,
      "metadata": {
        "num_sentences": 15,
        "num_words": 242,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_998",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nExamples\nSample request syntax for ListAccessPoints for Amazon S3 on Outposts\nThe following request returns a list access points of the specified Amazon S3 on Outposts bucket\nexample-outpost-bucket.\nGET /v20180820/accesspoint?Bucket=example-outpost-\nbucket&MaxResults=MaxResults&NextToken=NextToken HTTP/1.1\nHost: s3-outposts.<Region>.amazonaws.com\nDate: Wed, 28 Oct 2020 22:32:00 GMT\nAuthorization: authorization string\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 993",
      "start_idx": 1199271,
      "end_idx": 1200246,
      "metadata": {
        "num_sentences": 4,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_999",
      "text": "Amazon Simple Storage Service API Reference\nListAccessPointsForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns some or all (up to 1,000) access points associated with the Object Lambda Access Point per\ncall. If there are more access points than what can be returned in one call, the response will include\na continuation token that you can use to list the additional access points.\nThe following actions are related to ListAccessPointsForObjectLambda:\n\u2022 CreateAccessPointForObjectLambda\n\u2022 DeleteAccessPointForObjectLambda\n\u2022 GetAccessPointForObjectLambda\nRequest Syntax\nGET /v20180820/accesspointforobjectlambda?maxResults=MaxResults&nextToken=NextToken\nHTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nThe maximum number of access points that you want to include in the list. The response may\ncontain fewer access points but will never contain more. If there are more than this number of\naccess points, then the response will include a continuation token in the NextToken field that\nyou can use to retrieve the next page of access points.\nValid Range: Minimum value of 0. Maximum value of 1000.\nAmazon S3 Control API Version 2006-03-01 994",
      "start_idx": 1200248,
      "end_idx": 1201545,
      "metadata": {
        "num_sentences": 10,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1000",
      "text": "Amazon Simple Storage Service API Reference\nnextToken\nIf the list has more access points than can be returned in one call to this API, this field contains\na continuation token that you can provide in subsequent calls to this API to retrieve additional\naccess points.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListAccessPointsForObjectLambdaResult>\n<ObjectLambdaAccessPointList>\n<ObjectLambdaAccessPoint>\n<Alias>\n<Status>string</Status>\n<Value>string</Value>\n</Alias>\n<Name>string</Name>\n<ObjectLambdaAccessPointArn>string</ObjectLambdaAccessPointArn>\n</ObjectLambdaAccessPoint>\n</ObjectLambdaAccessPointList>\n<NextToken>string</NextToken>\n</ListAccessPointsForObjectLambdaResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nAmazon S3 Control API Version 2006-03-01 995",
      "start_idx": 1201547,
      "end_idx": 1202684,
      "metadata": {
        "num_sentences": 7,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1001",
      "text": "Amazon Simple Storage Service API Reference\nThe following data is returned in XML format by the service.\nListAccessPointsForObjectLambdaResult\nRoot level tag for the ListAccessPointsForObjectLambdaResult parameters.\nRequired: Yes\nNextToken\nIf the list has more access points than can be returned in one call to this API, this field contains\na continuation token that you can provide in subsequent calls to this API to retrieve additional\naccess points.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nObjectLambdaAccessPointList\nReturns list of Object Lambda Access Points.\nType: Array of ObjectLambdaAccessPoint data types\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 996",
      "start_idx": 1202686,
      "end_idx": 1203696,
      "metadata": {
        "num_sentences": 7,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1002",
      "text": "Amazon Simple Storage Service API Reference\nListCallerAccessGrants\nService: Amazon S3 Control\nUse this API to list the access grants that grant the caller access to Amazon S3 data through S3\nAccess Grants. The caller (grantee) can be an AWS Identity and Access Management (IAM) identity\nor AWS Identity Center corporate directory identity. You must pass the AWS account of the S3\ndata owner (grantor) in the request. You can, optionally, narrow the results by GrantScope, using\na fragment of the data's S3 path, and S3 Access Grants will return only the grants with a path\nthat contains the path fragment. You can also pass the AllowedByApplication filter in the\nrequest, which returns only the grants authorized for applications, whether the application is the\ncaller's Identity Center application or any other application (ALL). For more information, see List\nthe caller's access grants in the Amazon S3 User Guide.\nPermissions\nYou must have the s3:ListCallerAccessGrants permission to use this operation.\nRequest Syntax\nGET /v20180820/accessgrantsinstance/caller/grants?\nallowedByApplication=AllowedByApplication&grantscope=GrantScope&maxResults=MaxResults&nextToken=NextToken\nHTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nallowedByApplication\nIf this optional parameter is passed in the request, a filter is applied to the results. The results\nwill include only the access grants for the caller's Identity Center application or for any other\napplications (ALL).\ngrantscope\nThe S3 path of the data that you would like to access. Must start with s3://. You can\noptionally pass only the beginning characters of a path, and S3 Access Grants will search for all\napplicable grants for the path fragment.\nAmazon S3 Control API Version 2006-03-01 997",
      "start_idx": 1203698,
      "end_idx": 1205536,
      "metadata": {
        "num_sentences": 15,
        "num_words": 264,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1003",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nmaxResults\nThe maximum number of access grants that you would like returned in the List Caller\nAccess Grants response. If the results include the pagination token NextToken, make\nanother call using the NextToken to determine if there are more results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results. Pass this value into a subsequent List\nCaller Access Grants request in order to retrieve the next page of results.\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListCallerAccessGrantsResult>\n<NextToken>string</NextToken>\n<CallerAccessGrantsList>\n<AccessGrant>\n<ApplicationArn>string</ApplicationArn>\n<GrantScope>string</GrantScope>\n<Permission>string</Permission>\n</AccessGrant>\n</CallerAccessGrantsList>\nAmazon S3 Control API Version 2006-03-01 998",
      "start_idx": 1205538,
      "end_idx": 1206706,
      "metadata": {
        "num_sentences": 11,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1004",
      "text": "Amazon Simple Storage Service API Reference\n</ListCallerAccessGrantsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListCallerAccessGrantsResult\nRoot level tag for the ListCallerAccessGrantsResult parameters.\nRequired: Yes\nCallerAccessGrantsList\nA list of the caller's access grants that were created using S3 Access Grants and that grant the\ncaller access to the S3 data of the AWS account ID that was specified in the request.\nType: Array of ListCallerAccessGrantsEntry data types\nNextToken\nA pagination token that you can use to request the next page of results. Pass this value into\na subsequent List Caller Access Grants request in order to retrieve the next page of\nresults.\nType: String\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 999",
      "start_idx": 1206708,
      "end_idx": 1207828,
      "metadata": {
        "num_sentences": 7,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1006",
      "text": "Amazon Simple Storage Service API Reference\nListJobs\nService: Amazon S3 Control\nLists current S3 Batch Operations jobs as well as the jobs that have ended within the last 90 days\nfor the AWS account making the request. For more information, see S3 Batch Operations in the\nAmazon S3 User Guide.\nPermissions\nTo use the ListJobs operation, you must have permission to perform the s3:ListJobs\naction.\nRelated actions include:\n\u2022 CreateJob\n\u2022 DescribeJob\n\u2022 UpdateJobPriority\n\u2022 UpdateJobStatus\nRequest Syntax\nGET /v20180820/jobs?jobStatuses=JobStatuses&maxResults=MaxResults&nextToken=NextToken\nHTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\njobStatuses\nThe List Jobs request returns jobs that match the statuses listed in this element.\nValid Values: Active | Cancelled | Cancelling | Complete | Completing\n| Failed | Failing | New | Paused | Pausing | Preparing | Ready |\nSuspended\nAmazon S3 Control API Version 2006-03-01 1001",
      "start_idx": 1207964,
      "end_idx": 1208975,
      "metadata": {
        "num_sentences": 6,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1007",
      "text": "Amazon Simple Storage Service API Reference\nmaxResults\nThe maximum number of jobs that Amazon S3 will include in the List Jobs response. If there\nare more jobs than this number, the response will include a pagination token in the NextToken\nfield to enable you to retrieve the next page of results.\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nA pagination token to request the next page of results. Use the token that Amazon S3 returned\nin the NextToken element of the ListJobsResult from the previous List Jobs request.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListJobsResult>\n<NextToken>string</NextToken>\n<Jobs>\n<JobListDescriptor>\n<CreationTime>timestamp</CreationTime>\n<Description>string</Description>\n<JobId>string</JobId>\nAmazon S3 Control API Version 2006-03-01 1002",
      "start_idx": 1208977,
      "end_idx": 1210114,
      "metadata": {
        "num_sentences": 11,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1008",
      "text": "Amazon Simple Storage Service API Reference\n<Operation>string</Operation>\n<Priority>integer</Priority>\n<ProgressSummary>\n<NumberOfTasksFailed>long</NumberOfTasksFailed>\n<NumberOfTasksSucceeded>long</NumberOfTasksSucceeded>\n<Timers>\n<ElapsedTimeInActiveSeconds>long</ElapsedTimeInActiveSeconds>\n</Timers>\n<TotalNumberOfTasks>long</TotalNumberOfTasks>\n</ProgressSummary>\n<Status>string</Status>\n<TerminationDate>timestamp</TerminationDate>\n</JobListDescriptor>\n</Jobs>\n</ListJobsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListJobsResult\nRoot level tag for the ListJobsResult parameters.\nRequired: Yes\nJobs\nThe list of current jobs and jobs that have ended within the last 30 days.\nType: Array of JobListDescriptor data types\nNextToken\nIf the List Jobs request produced more than the maximum number of results, you can pass\nthis value into a subsequent List Jobs request in order to retrieve the next page of results.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nAmazon S3 Control API Version 2006-03-01 1003",
      "start_idx": 1210116,
      "end_idx": 1211310,
      "metadata": {
        "num_sentences": 8,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1010",
      "text": "Amazon Simple Storage Service API Reference\nListMultiRegionAccessPoints\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns a list of the Multi-Region Access Points currently associated with the specified AWS\naccount. Each call can return up to 100 Multi-Region Access Points, the maximum number of Multi-\nRegion Access Points that can be associated with a single account.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThe following actions are related to ListMultiRegionAccessPoint:\n\u2022 CreateMultiRegionAccessPoint\n\u2022 DeleteMultiRegionAccessPoint\n\u2022 DescribeMultiRegionAccessPointOperation\n\u2022 GetMultiRegionAccessPoint\nRequest Syntax\nGET /v20180820/mrap/instances?maxResults=MaxResults&nextToken=NextToken HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nNot currently used. Do not use this parameter.\nValid Range: Minimum value of 0. Maximum value of 1000.\nAmazon S3 Control API Version 2006-03-01 1005",
      "start_idx": 1211863,
      "end_idx": 1213105,
      "metadata": {
        "num_sentences": 11,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1011",
      "text": "Amazon Simple Storage Service API Reference\nnextToken\nNot currently used. Do not use this parameter.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe AWS account ID for the owner of the Multi-Region Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListMultiRegionAccessPointsResult>\n<AccessPoints>\n<AccessPoint>\n<Alias>string</Alias>\n<CreatedAt>timestamp</CreatedAt>\n<Name>string</Name>\n<PublicAccessBlock>\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlock>\n<Regions>\n<Region>\n<Bucket>string</Bucket>\n<BucketAccountId>string</BucketAccountId>\n<Region>string</Region>\n</Region>\n</Regions>\n<Status>string</Status>\nAmazon S3 Control API Version 2006-03-01 1006",
      "start_idx": 1213107,
      "end_idx": 1214124,
      "metadata": {
        "num_sentences": 7,
        "num_words": 92,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1012",
      "text": "Amazon Simple Storage Service API Reference\n</AccessPoint>\n</AccessPoints>\n<NextToken>string</NextToken>\n</ListMultiRegionAccessPointsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListMultiRegionAccessPointsResult\nRoot level tag for the ListMultiRegionAccessPointsResult parameters.\nRequired: Yes\nAccessPoints\nThe list of Multi-Region Access Points associated with the user.\nType: Array of MultiRegionAccessPointReport data types\nNextToken\nIf the specified bucket has more Multi-Region Access Points than can be returned in one call to\nthis action, this field contains a continuation token. You can use this token tin subsequent calls\nto this action to retrieve additional Multi-Region Access Points.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\nAmazon S3 Control API Version 2006-03-01 1007",
      "start_idx": 1214126,
      "end_idx": 1215263,
      "metadata": {
        "num_sentences": 9,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1014",
      "text": "Amazon Simple Storage Service API Reference\nListRegionalBuckets\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nReturns a list of all Outposts buckets in an Outpost that are owned by the authenticated sender of\nthe request. For more information, see Using Amazon S3 on Outposts in the Amazon S3 User Guide.\nFor an example of the request syntax for Amazon S3 on Outposts that uses the S3 on Outposts\nendpoint hostname prefix and x-amz-outpost-id in your request, see the Examples section.\nRequest Syntax\nGET /v20180820/bucket?maxResults=MaxResults&nextToken=NextToken HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nx-amz-outpost-id: OutpostId\nURI Request Parameters\nThe request uses the following URI parameters.\nmaxResults\nValid Range: Minimum value of 0. Maximum value of 1000.\nnextToken\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1009",
      "start_idx": 1215470,
      "end_idx": 1216562,
      "metadata": {
        "num_sentences": 10,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1015",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-outpost-id\nThe ID of the AWS Outposts resource.\nNote\nThis ID is required by Amazon S3 on Outposts buckets.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListRegionalBucketsResult>\n<RegionalBucketList>\n<RegionalBucket>\n<Bucket>string</Bucket>\n<BucketArn>string</BucketArn>\n<CreationDate>timestamp</CreationDate>\n<OutpostId>string</OutpostId>\n<PublicAccessBlockEnabled>boolean</PublicAccessBlockEnabled>\n</RegionalBucket>\n</RegionalBucketList>\n<NextToken>string</NextToken>\n</ListRegionalBucketsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListRegionalBucketsResult\nRoot level tag for the ListRegionalBucketsResult parameters.\nAmazon S3 Control API Version 2006-03-01 1010",
      "start_idx": 1216564,
      "end_idx": 1217541,
      "metadata": {
        "num_sentences": 9,
        "num_words": 105,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1016",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nNextToken\nNextToken is sent when isTruncated is true, which means there are more buckets that\ncan be listed. The next list requests to Amazon S3 can be continued with this NextToken.\nNextToken is obfuscated and is not a real key.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRegionalBucketList\nType: Array of RegionalBucket data types\nExamples\nSample request to list an account's Outposts buckets\nThis request lists regional buckets.\nGET /v20180820/bucket HTTP /1.1\nHost:s3-outposts.us-west-2.amazonaws.com\nContent-Length: 0\nx-amz-outpost-id: op-01ac5d28a6a232904\nx-amz-account-id: example-account-id\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAuthorization: authorization string\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\nAmazon S3 Control API Version 2006-03-01 1011",
      "start_idx": 1217543,
      "end_idx": 1218550,
      "metadata": {
        "num_sentences": 7,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1018",
      "text": "Amazon Simple Storage Service API Reference\nListStorageLensConfigurations\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nGets a list of Amazon S3 Storage Lens configurations. For more information about S3 Storage Lens,\nsee Assessing your storage activity and usage with Amazon S3 Storage Lens in the Amazon S3 User\nGuide.\nNote\nTo use this action, you must have permission to perform the\ns3:ListStorageLensConfigurations action. For more information, see Setting\npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nGET /v20180820/storagelens?nextToken=NextToken HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nnextToken\nA pagination token to request the next page of results.\nx-amz-account-id\nThe account ID of the requester.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1013",
      "start_idx": 1218757,
      "end_idx": 1219750,
      "metadata": {
        "num_sentences": 10,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1021",
      "text": "Amazon Simple Storage Service API Reference\nListStorageLensGroups\nService: Amazon S3 Control\nLists all the Storage Lens groups in the specified home Region.\nTo use this operation, you must have the permission to perform the\ns3:ListStorageLensGroups action. For more information about the required Storage Lens\nGroups permissions, see Setting account permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nGET /v20180820/storagelensgroup?nextToken=NextToken HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nnextToken\nThe token for the next set of results, or null if there are no more results.\nx-amz-account-id\nThe AWS account ID that owns the Storage Lens groups.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\nAmazon S3 Control API Version 2006-03-01 1016",
      "start_idx": 1221287,
      "end_idx": 1222383,
      "metadata": {
        "num_sentences": 10,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1022",
      "text": "Amazon Simple Storage Service API Reference\n<ListStorageLensGroupsResult>\n<NextToken>string</NextToken>\n<StorageLensGroupList>\n<HomeRegion>string</HomeRegion>\n<Name>string</Name>\n<StorageLensGroupArn>string</StorageLensGroupArn>\n</StorageLensGroupList>\n...\n</ListStorageLensGroupsResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nListStorageLensGroupsResult\nRoot level tag for the ListStorageLensGroupsResult parameters.\nRequired: Yes\nNextToken\nIf NextToken is returned, there are more Storage Lens groups results available. The value of\nNextToken is a unique pagination token for each page. Make the call again using the returned\ntoken to retrieve the next page. Keep all other arguments unchanged. Each pagination token\nexpires after 24 hours.\nType: String\nStorageLensGroupList\nThe list of Storage Lens groups that exist in the specified home Region.\nType: Array of ListStorageLensGroupEntry data types\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\nAmazon S3 Control API Version 2006-03-01 1017",
      "start_idx": 1222385,
      "end_idx": 1223587,
      "metadata": {
        "num_sentences": 10,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1024",
      "text": "Amazon Simple Storage Service API Reference\nListTagsForResource\nService: Amazon S3 Control\nThis operation allows you to list all the AWS resource tags for a specified resource. Each tag is a\nlabel consisting of a user-defined key and value. Tags can help you manage, identify, organize,\nsearch for, and filter resources.\nPermissions\nYou must have the s3:ListTagsForResource permission to use this operation.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The\ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered\nlocation, or grant.\nFor more information about the required Storage Lens Groups permissions, see Setting account\npermissions to use S3 Storage Lens groups.\nFor information about S3 Tagging errors, see List of Amazon S3 Tagging error codes.\nRequest Syntax\nGET /v20180820/tags/resourceArn+ HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nresourceArn\nThe Amazon Resource Name (ARN) of the S3 resource that you want to list the tags for. The\ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered\nlocation, or grant.\nLength Constraints: Maximum length of 1011.\nAmazon S3 Control API Version 2006-03-01 1019",
      "start_idx": 1223851,
      "end_idx": 1225169,
      "metadata": {
        "num_sentences": 13,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1026",
      "text": "Amazon Simple Storage Service API Reference\nTags\nThe AWS resource tags that are associated with the resource.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1021",
      "start_idx": 1225940,
      "end_idx": 1226507,
      "metadata": {
        "num_sentences": 4,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1028",
      "text": "Amazon Simple Storage Service API Reference\nPutAccessGrantsInstanceResourcePolicyRequest\nRoot level tag for the PutAccessGrantsInstanceResourcePolicyRequest parameters.\nRequired: Yes\nOrganization\nThe Organization of the resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 12. Maximum length of 34.\nPattern: ^o-[a-z0-9]{10,32}$\nRequired: No\nPolicy\nThe resource policy of the S3 Access Grants instance that you are updating.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 350000.\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessGrantsInstanceResourcePolicyResult>\n<Policy>string</Policy>\n<Organization>string</Organization>\n<CreatedAt>timestamp</CreatedAt>\n</PutAccessGrantsInstanceResourcePolicyResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 1023",
      "start_idx": 1227500,
      "end_idx": 1228518,
      "metadata": {
        "num_sentences": 10,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1029",
      "text": "Amazon Simple Storage Service API Reference\nPutAccessGrantsInstanceResourcePolicyResult\nRoot level tag for the PutAccessGrantsInstanceResourcePolicyResult parameters.\nRequired: Yes\nCreatedAt\nThe date and time when you created the S3 Access Grants instance resource policy.\nType: Timestamp\nOrganization\nThe Organization of the resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 12. Maximum length of 34.\nPattern: ^o-[a-z0-9]{10,32}$\nPolicy\nThe updated resource policy of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 350000.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 1024",
      "start_idx": 1228520,
      "end_idx": 1229465,
      "metadata": {
        "num_sentences": 9,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1032",
      "text": "Amazon Simple Storage Service API Reference\n</PutAccessPointConfigurationForObjectLambdaRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nx-amz-account-id\nThe account ID for the account that owns the specified Object Lambda Access Point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutAccessPointConfigurationForObjectLambdaRequest\nRoot level tag for the PutAccessPointConfigurationForObjectLambdaRequest parameters.\nRequired: Yes\nConfiguration\nObject Lambda Access Point configuration document.\nType: ObjectLambdaConfiguration data type\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1027",
      "start_idx": 1230843,
      "end_idx": 1231734,
      "metadata": {
        "num_sentences": 10,
        "num_words": 106,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1034",
      "text": "Amazon Simple Storage Service API Reference\nPutAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nAssociates an access policy with the specified access point. Each access point can have only one\npolicy, so a request made to this API replaces any existing policy associated with the specified\naccess point.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to PutAccessPointPolicy:\n\u2022 GetAccessPointPolicy\n\u2022 DeleteAccessPointPolicy\nRequest Syntax\nPUT /v20180820/accesspoint/name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessPointPolicyRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<Policy>string</Policy>\n</PutAccessPointPolicyRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the access point that you want to associate with the specified policy.\nAmazon S3 Control API Version 2006-03-01 1029",
      "start_idx": 1232284,
      "end_idx": 1233701,
      "metadata": {
        "num_sentences": 9,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1035",
      "text": "Amazon Simple Storage Service API Reference\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you\nmust specify the ARN of the access point accessed in the format arn:aws:s3-\noutposts:<Region>:<account-id>:outpost/<outpost-id>/accesspoint/<my-\naccesspoint-name>. For example, to access the access point reports-ap through\nOutpost my-outpost owned by account 123456789012 in Region us-west-2, use the URL\nencoding of arn:aws:s3-outposts:us-west-2:123456789012:outpost/my-outpost/\naccesspoint/reports-ap. The value must be URL encoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID for owner of the bucket associated with the specified access point.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutAccessPointPolicyRequest\nRoot level tag for the PutAccessPointPolicyRequest parameters.\nRequired: Yes\nPolicy\nThe policy that you want to apply to the specified access point. For more information about\naccess point policies, see Managing data access with Amazon S3 access points in the Amazon S3\nUser Guide.\nType: String\nAmazon S3 Control API Version 2006-03-01 1030",
      "start_idx": 1233703,
      "end_idx": 1235079,
      "metadata": {
        "num_sentences": 13,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1038",
      "text": "Amazon Simple Storage Service API Reference\nPutAccessPointPolicyForObjectLambda\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates or replaces resource policy for an Object Lambda Access Point. For an example policy, see\nCreating Object Lambda Access Points in the Amazon S3 User Guide.\nThe following actions are related to PutAccessPointPolicyForObjectLambda:\n\u2022 DeleteAccessPointPolicyForObjectLambda\n\u2022 GetAccessPointPolicyForObjectLambda\nRequest Syntax\nPUT /v20180820/accesspointforobjectlambda/name/policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutAccessPointPolicyForObjectLambdaRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<Policy>string</Policy>\n</PutAccessPointPolicyForObjectLambdaRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Object Lambda Access Point.\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1033",
      "start_idx": 1236657,
      "end_idx": 1237773,
      "metadata": {
        "num_sentences": 8,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1041",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketLifecycleConfiguration\nService: Amazon S3 Control\nNote\nThis action puts a lifecycle configuration to an Amazon S3 on Outposts bucket. To put a\nlifecycle configuration to an S3 bucket, see PutBucketLifecycleConfiguration in the Amazon\nS3 API Reference.\nCreates a new lifecycle configuration for the S3 on Outposts bucket or replaces an existing lifecycle\nconfiguration. Outposts buckets only support lifecycle configurations that delete/expire objects\nafter a certain period of time and abort incomplete multipart uploads.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to PutBucketLifecycleConfiguration:\n\u2022 GetBucketLifecycleConfiguration\n\u2022 DeleteBucketLifecycleConfiguration\nRequest Syntax\nPUT /v20180820/bucket/name/lifecycleconfiguration HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<LifecycleConfiguration xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<Rules>\n<Rule>\n<AbortIncompleteMultipartUpload>\n<DaysAfterInitiation>integer</DaysAfterInitiation>\n</AbortIncompleteMultipartUpload>\n<Expiration>\n<Date>timestamp</Date>\nAmazon S3 Control API Version 2006-03-01 1036",
      "start_idx": 1239551,
      "end_idx": 1241186,
      "metadata": {
        "num_sentences": 8,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1043",
      "text": "Amazon Simple Storage Service API Reference\n</LifecycleConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the bucket for which to set the configuration.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nLifecycleConfiguration\nRoot level tag for the LifecycleConfiguration parameters.\nRequired: Yes\nRules\nA lifecycle rule for individual objects in an Outposts bucket.\nType: Array of LifecycleRule data types\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nAmazon S3 Control API Version 2006-03-01 1038",
      "start_idx": 1242333,
      "end_idx": 1243107,
      "metadata": {
        "num_sentences": 10,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1046",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketPolicy\nService: Amazon S3 Control\nNote\nThis action puts a bucket policy to an Amazon S3 on Outposts bucket. To put a policy on an\nS3 bucket, see PutBucketPolicy in the Amazon S3 API Reference.\nApplies an Amazon S3 bucket policy to an Outposts bucket. For more information, see Using\nAmazon S3 on Outposts in the Amazon S3 User Guide.\nIf you are using an identity other than the root user of the AWS account that owns the Outposts\nbucket, the calling identity must have the PutBucketPolicy permissions on the specified\nOutposts bucket and belong to the bucket owner's account in order to use this action.\nIf you don't have PutBucketPolicy permissions, Amazon S3 returns a 403 Access Denied\nerror. If you have the correct permissions, but you're not using an identity that belongs to the\nbucket owner's account, Amazon S3 returns a 405 Method Not Allowed error.\nImportant\nAs a security precaution, the root user of the AWS account that owns a bucket can always\nuse this action, even if the policy explicitly denies the root user the ability to perform this\naction.\nFor more information about bucket policies, see Using Bucket Policies and User Policies.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to PutBucketPolicy:\n\u2022 GetBucketPolicy\n\u2022 DeleteBucketPolicy\nAmazon S3 Control API Version 2006-03-01 1041",
      "start_idx": 1244438,
      "end_idx": 1246224,
      "metadata": {
        "num_sentences": 13,
        "num_words": 295,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1047",
      "text": "Amazon Simple Storage Service API Reference\nRequest Syntax\nPUT /v20180820/bucket/name/policy HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nx-amz-confirm-remove-self-bucket-access: ConfirmRemoveSelfBucketAccess\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutBucketPolicyRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<Policy>string</Policy>\n</PutBucketPolicyRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nSpecifies the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1042",
      "start_idx": 1246226,
      "end_idx": 1247598,
      "metadata": {
        "num_sentences": 11,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1051",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketReplication\nService: Amazon S3 Control\nNote\nThis action creates an Amazon S3 on Outposts bucket's replication configuration. To create\nan S3 bucket's replication configuration, see PutBucketReplication in the Amazon S3 API\nReference.\nCreates a replication configuration or replaces an existing one. For information about S3 replication\non Outposts configuration, see Replicating objects for S3 on Outposts in the Amazon S3 User\nGuide.\nNote\nIt can take a while to propagate PUT or DELETE requests for a replication configuration\nto all S3 on Outposts systems. Therefore, the replication configuration that's returned\nby a GET request soon after a PUT or DELETE request might return a more recent result\nthan what's on the Outpost. If an Outpost is offline, the delay in updating the replication\nconfiguration on that Outpost can be significant.\nSpecify the replication configuration in the request body. In the replication configuration, you\nprovide the following information:\n\u2022 The name of the destination bucket or buckets where you want S3 on Outposts to replicate\nobjects\n\u2022 The AWS Identity and Access Management (IAM) role that S3 on Outposts can assume to\nreplicate objects on your behalf\n\u2022 Other relevant information, such as replication rules\nA replication configuration must include at least one rule and can contain a maximum of 100. Each\nrule identifies a subset of objects to replicate by filtering the objects in the source Outposts bucket.\nTo choose additional subsets of objects to replicate, add a rule for each subset.\nTo specify a subset of the objects in the source Outposts bucket to apply a replication rule to, add\nthe Filter element as a child of the Rule element. You can filter objects based on an object key\nAmazon S3 Control API Version 2006-03-01 1046",
      "start_idx": 1249551,
      "end_idx": 1251382,
      "metadata": {
        "num_sentences": 13,
        "num_words": 293,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1052",
      "text": "Amazon Simple Storage Service API Reference\nprefix, one or more object tags, or both. When you add the Filter element in the configuration,\nyou must also add the following elements: DeleteMarkerReplication, Status, and Priority.\nUsing PutBucketReplication on Outposts requires that both the source and destination\nbuckets must have versioning enabled. For information about enabling versioning on a bucket, see\nManaging S3 Versioning for your S3 on Outposts bucket.\nFor information about S3 on Outposts replication failure reasons, see Replication failure reasons in\nthe Amazon S3 User Guide.\nHandling Replication of Encrypted Objects\nOutposts buckets are encrypted at all times. All the objects in the source Outposts bucket are\nencrypted and can be replicated. Also, all the replicas in the destination Outposts bucket are\nencrypted with the same encryption key as the objects in the source Outposts bucket.\nPermissions\nTo create a PutBucketReplication request, you must have s3-\noutposts:PutReplicationConfiguration permissions for the bucket. The Outposts bucket\nowner has this permission by default and can grant it to others. For more information about\npermissions, see Setting up IAM with S3 on Outposts and Managing access to S3 on Outposts\nbuckets.\nNote\nTo perform this operation, the user or role must also have the iam:CreateRole and\niam:PassRole permissions. For more information, see Granting a user permissions to pass\na role to an AWS service.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following operations are related to PutBucketReplication:\n\u2022 GetBucketReplication\nAmazon S3 Control API Version 2006-03-01 1047",
      "start_idx": 1251384,
      "end_idx": 1253416,
      "metadata": {
        "num_sentences": 17,
        "num_words": 311,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1055",
      "text": "Amazon Simple Storage Service API Reference\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nReplicationConfiguration\nRoot level tag for the ReplicationConfiguration parameters.\nRequired: Yes\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role\nthat S3 on Outposts assumes when replicating objects. For information about S3 replication on\nOutposts configuration, see Setting up replication in the Amazon S3 User Guide.\nType: String\nRequired: Yes\nRules\nA container for one or more replication rules. A replication configuration must have at least one\nrule and can contain an array of 100 rules at the most.\nAmazon S3 Control API Version 2006-03-01 1050",
      "start_idx": 1255579,
      "end_idx": 1256800,
      "metadata": {
        "num_sentences": 14,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1056",
      "text": "Amazon Simple Storage Service API Reference\nType: Array of ReplicationRule data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample Request: Add a replication configuration to an Amazon S3 on Outposts bucket\nThe following sample PUT request creates a replication subresource on the specified Outposts\nbucket named example-outpost-bucket and saves the replication configuration in it. The\nreplication configuration specifies a rule to replicate objects to the example-outpost-bucket\nbucket. The rule includes a filter to replicate only the objects that are created with the key name\nprefix TaxDocs and that have two specific tags.\nAfter you add a replication configuration to your Outposts bucket, S3 on Outposts assumes the\nAWS Identity and Access Management (IAM) role that's specified in the configuration to replicate\nobjects on behalf of the Outposts bucket owner. The bucket owner is the AWS account that created\nthe Outposts bucket.\nFiltering by using the Filter element is supported in the latest XML configuration. The earlier\nversion of the XML configuration isn't supported.\nFor more examples of S3 replication on Outposts configuration, see Creating replication rules on\nOutposts in the Amazon S3 User Guide.\nPUT /v20180820/bucket/example-outpost-bucket/replication HTTP/1.1\nHost:s3-outposts.<Region>.amazonaws.com\nx-amz-account-id: example-account-id\nx-amz-outpost-id: op-01ac5d28a6a232904\nAuthorization: authorization string\nAmazon S3 Control API Version 2006-03-01 1051",
      "start_idx": 1256802,
      "end_idx": 1258414,
      "metadata": {
        "num_sentences": 10,
        "num_words": 223,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1059",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketTagging\nService: Amazon S3 Control\nNote\nThis action puts tags on an Amazon S3 on Outposts bucket. To put tags on an S3 bucket,\nsee PutBucketTagging in the Amazon S3 API Reference.\nSets the tags for an S3 on Outposts bucket. For more information, see Using Amazon S3 on\nOutposts in the Amazon S3 User Guide.\nUse tags to organize your AWS bill to reflect your own cost structure. To do this, sign up to get\nyour AWS account bill with tag key values included. Then, to see the cost of combined resources,\norganize your billing information according to resources with the same tag key values. For example,\nyou can tag several resources with a specific application name, and then organize your billing\ninformation to see the total cost of that application across several services. For more information,\nsee Cost allocation and tagging.\nNote\nWithin a bucket, if you add a tag that has the same key as an existing tag, the new value\noverwrites the old value. For more information, see Using cost allocation in Amazon S3\nbucket tags.\nTo use this action, you must have permissions to perform the s3-outposts:PutBucketTagging\naction. The Outposts bucket owner has this permission by default and can grant this permission to\nothers. For more information about permissions, see Permissions Related to Bucket Subresource\nOperations and Managing access permissions to your Amazon S3 resources.\nPutBucketTagging has the following special errors:\n\u2022 Error code: InvalidTagError\n\u2022 Description: The tag provided was not a valid tag. This error can occur if the tag did not pass\ninput validation. For information about tag restrictions, see User-Defined Tag Restrictions and\nAWS-Generated Cost Allocation Tag Restrictions.\n\u2022 Error code: MalformedXMLError\nAmazon S3 Control API Version 2006-03-01 1054",
      "start_idx": 1259692,
      "end_idx": 1261525,
      "metadata": {
        "num_sentences": 18,
        "num_words": 294,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1060",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Description: The XML provided does not match the schema.\n\u2022 Error code: OperationAbortedError\n\u2022 Description: A conflicting conditional action is currently in progress against this resource. Try\nagain.\n\u2022 Error code: InternalError\n\u2022 Description: The service was unable to apply the provided tag to the bucket.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nThe following actions are related to PutBucketTagging:\n\u2022 GetBucketTagging\n\u2022 DeleteBucketTagging\nRequest Syntax\nPUT /v20180820/bucket/name/tagging HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Tagging xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<TagSet>\n<S3Tag>\n<Key>string</Key>\n<Value>string</Value>\n</S3Tag>\n</TagSet>\n</Tagging>\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1055",
      "start_idx": 1261527,
      "end_idx": 1262853,
      "metadata": {
        "num_sentences": 9,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1061",
      "text": "Amazon Simple Storage Service API Reference\nname\nThe Amazon Resource Name (ARN) of the bucket.\nFor using this parameter with Amazon S3 on Outposts with the REST API, you must specify the\nname and the x-amz-outpost-id as well.\nFor using this parameter with S3 on Outposts with the AWS SDK and CLI, you must specify the\nARN of the bucket accessed in the format arn:aws:s3-outposts:<Region>:<account-\nid>:outpost/<outpost-id>/bucket/<my-bucket-name>. For example, to access\nthe bucket reports through Outpost my-outpost owned by account 123456789012\nin Region us-west-2, use the URL encoding of arn:aws:s3-outposts:us-\nwest-2:123456789012:outpost/my-outpost/bucket/reports. The value must be URL\nencoded.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nTagging\nRoot level tag for the Tagging parameters.\nRequired: Yes\nTagSet\nA collection for a set of tags.\nAmazon S3 Control API Version 2006-03-01 1056",
      "start_idx": 1262855,
      "end_idx": 1263985,
      "metadata": {
        "num_sentences": 13,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1064",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketVersioning\nService: Amazon S3 Control\nNote\nThis operation sets the versioning state for S3 on Outposts buckets only. To set the\nversioning state for an S3 bucket, see PutBucketVersioning in the Amazon S3 API Reference.\nSets the versioning state for an S3 on Outposts bucket. With S3 Versioning, you can save multiple\ndistinct copies of your objects and recover from unintended user actions and application failures.\nYou can set the versioning state to one of the following:\n\u2022 Enabled - Enables versioning for the objects in the bucket. All objects added to the bucket\nreceive a unique version ID.\n\u2022 Suspended - Suspends versioning for the objects in the bucket. All objects added to the bucket\nreceive the version ID null.\nIf you've never set versioning on your bucket, it has no versioning state. In that case, a\nGetBucketVersioning request does not return a versioning state value.\nWhen you enable S3 Versioning, for each object in your bucket, you have a current version and zero\nor more noncurrent versions. You can configure your bucket S3 Lifecycle rules to expire noncurrent\nversions after a specified time period. For more information, see Creating and managing a lifecycle\nconfiguration for your S3 on Outposts bucket in the Amazon S3 User Guide.\nIf you have an object expiration lifecycle configuration in your non-versioned bucket and you want\nto maintain the same permanent delete behavior when you enable versioning, you must add a\nnoncurrent expiration policy. The noncurrent expiration lifecycle configuration will manage the\ndeletes of the noncurrent object versions in the version-enabled bucket. For more information, see\nVersioning in the Amazon S3 User Guide.\nAll Amazon S3 on Outposts REST API requests for this action require an additional parameter of\nx-amz-outpost-id to be passed with the request. In addition, you must use an S3 on Outposts\nendpoint hostname prefix instead of s3-control. For an example of the request syntax for\nAmazon S3 on Outposts that uses the S3 on Outposts endpoint hostname prefix and the x-amz-\noutpost-id derived by using the access point ARN, see the Examples section.\nAmazon S3 Control API Version 2006-03-01 1059",
      "start_idx": 1265255,
      "end_idx": 1267476,
      "metadata": {
        "num_sentences": 20,
        "num_words": 357,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1065",
      "text": "Amazon Simple Storage Service API Reference\nThe following operations are related to PutBucketVersioning for S3 on Outposts.\n\u2022 GetBucketVersioning\n\u2022 PutBucketLifecycleConfiguration\n\u2022 GetBucketLifecycleConfiguration\nRequest Syntax\nPUT /v20180820/bucket/name/versioning HTTP/1.1\nHost: Bucket.s3-control.amazonaws.com\nx-amz-account-id: AccountId\nx-amz-mfa: MFA\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<VersioningConfiguration xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<MfaDelete>string</MfaDelete>\n<Status>string</Status>\n</VersioningConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe S3 on Outposts bucket to set the versioning state for.\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 on Outposts bucket.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nx-amz-mfa\nThe concatenation of the authentication device's serial number, a space, and the value that is\ndisplayed on your authentication device.\nAmazon S3 Control API Version 2006-03-01 1060",
      "start_idx": 1267478,
      "end_idx": 1268582,
      "metadata": {
        "num_sentences": 9,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1068",
      "text": "Amazon Simple Storage Service API Reference\nPutJobTagging\nService: Amazon S3 Control\nSets the supplied tag-set on an S3 Batch Operations job.\nA tag is a key-value pair. You can associate S3 Batch Operations tags with any job by sending a PUT\nrequest against the tagging subresource that is associated with the job. To modify the existing tag\nset, you can either replace the existing tag set entirely, or make changes within the existing tag set\nby retrieving the existing tag set using GetJobTagging, modify that tag set, and use this operation\nto replace the tag set with the one you modified. For more information, see Controlling access and\nlabeling jobs using tags in the Amazon S3 User Guide.\nNote\n\u2022 If you send this request with an empty tag set, Amazon S3 deletes the existing tag set on\nthe Batch Operations job. If you use this method, you are charged for a Tier 1 Request\n(PUT). For more information, see Amazon S3 pricing.\n\u2022 For deleting existing tags for your Batch Operations job, a DeleteJobTagging request is\npreferred because it achieves the same result without incurring charges.\n\u2022 A few things to consider about using tags:\n\u2022 Amazon S3 limits the maximum number of tags to 50 tags per job.\n\u2022 You can associate up to 50 tags with a job as long as they have unique tag keys.\n\u2022 A tag key can be up to 128 Unicode characters in length, and tag values can be up to\n256 Unicode characters in length.\n\u2022 The key and values are case sensitive.\n\u2022 For tagging-related restrictions related to characters and encodings, see User-Defined\nTag Restrictions in the AWS Billing and Cost Management User Guide.\nPermissions\nTo use the PutJobTagging operation, you must have permission to perform the\ns3:PutJobTagging action.\nRelated actions include:\nAmazon S3 Control API Version 2006-03-01 1063",
      "start_idx": 1270344,
      "end_idx": 1272137,
      "metadata": {
        "num_sentences": 16,
        "num_words": 309,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1069",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 CreateJob\n\u2022 GetJobTagging\n\u2022 DeleteJobTagging\nRequest Syntax\nPUT /v20180820/jobs/id/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutJobTaggingRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<Tags>\n<S3Tag>\n<Key>string</Key>\n<Value>string</Value>\n</S3Tag>\n</Tags>\n</PutJobTaggingRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the S3 Batch Operations job whose tags you want to replace.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1064",
      "start_idx": 1272139,
      "end_idx": 1273007,
      "metadata": {
        "num_sentences": 7,
        "num_words": 101,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1072",
      "text": "Amazon Simple Storage Service API Reference\nPutMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nAssociates an access control policy with the specified Multi-Region Access Point. Each Multi-Region\nAccess Point can have only one policy, so a request made to this action replaces any existing policy\nthat is associated with the specified Multi-Region Access Point.\nThis action will always be routed to the US West (Oregon) Region. For more information about\nthe restrictions around working with Multi-Region Access Points, see Multi-Region Access Point\nrestrictions and limitations in the Amazon S3 User Guide.\nThe following actions are related to PutMultiRegionAccessPointPolicy:\n\u2022 GetMultiRegionAccessPointPolicy\n\u2022 GetMultiRegionAccessPointPolicyStatus\nRequest Syntax\nPOST /v20180820/async-requests/mrap/put-policy HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutMultiRegionAccessPointPolicyRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<ClientToken>string</ClientToken>\n<Details>\n<Name>string</Name>\n<Policy>string</Policy>\n</Details>\n</PutMultiRegionAccessPointPolicyRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1067",
      "start_idx": 1274179,
      "end_idx": 1275522,
      "metadata": {
        "num_sentences": 7,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1074",
      "text": "Amazon Simple Storage Service API Reference\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutMultiRegionAccessPointPolicyResult>\n<RequestTokenARN>string</RequestTokenARN>\n</PutMultiRegionAccessPointPolicyResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nPutMultiRegionAccessPointPolicyResult\nRoot level tag for the PutMultiRegionAccessPointPolicyResult parameters.\nRequired: Yes\nRequestTokenARN\nThe request token associated with the request. You can use this token with\nDescribeMultiRegionAccessPointOperation to determine the status of asynchronous requests.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:.+\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\nAmazon S3 Control API Version 2006-03-01 1069",
      "start_idx": 1276347,
      "end_idx": 1277420,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1076",
      "text": "Amazon Simple Storage Service API Reference\nPutPublicAccessBlock\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nCreates or modifies the PublicAccessBlock configuration for an AWS account. For this\noperation, users must have the s3:PutAccountPublicAccessBlock permission. For more\ninformation, see Using Amazon S3 block public access.\nRelated actions include:\n\u2022 GetPublicAccessBlock\n\u2022 DeletePublicAccessBlock\nRequest Syntax\nPUT /v20180820/configuration/publicAccessBlock HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PublicAccessBlockConfiguration xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<BlockPublicAcls>boolean</BlockPublicAcls>\n<IgnorePublicAcls>boolean</IgnorePublicAcls>\n<BlockPublicPolicy>boolean</BlockPublicPolicy>\n<RestrictPublicBuckets>boolean</RestrictPublicBuckets>\n</PublicAccessBlockConfiguration>\nURI Request Parameters\nThe request uses the following URI parameters.\nx-amz-account-id\nThe account ID for the AWS account whose PublicAccessBlock configuration you want to\nset.\nLength Constraints: Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 1071",
      "start_idx": 1277556,
      "end_idx": 1278752,
      "metadata": {
        "num_sentences": 8,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1077",
      "text": "Amazon Simple Storage Service API Reference\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPublicAccessBlockConfiguration\nRoot level tag for the PublicAccessBlockConfiguration parameters.\nRequired: Yes\nBlockPublicAcls\nSpecifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this\naccount. Setting this element to TRUE causes the following behavior:\n\u2022 PutBucketAcl and PutObjectAcl calls fail if the specified ACL is public.\n\u2022 PUT Object calls fail if the request includes a public ACL.\n\u2022 PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't affect existing policies or ACLs.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpecifies whether Amazon S3 should block public bucket policies for buckets in this account.\nSetting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the\nspecified bucket policy allows public access.\nEnabling this setting doesn't affect existing bucket policies.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1072",
      "start_idx": 1278754,
      "end_idx": 1279977,
      "metadata": {
        "num_sentences": 13,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1078",
      "text": "Amazon Simple Storage Service API Reference\nIgnorePublicAcls\nSpecifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this\nelement to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any\nobjects that they contain.\nEnabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent\nnew public ACLs from being set.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpecifies whether Amazon S3 should restrict public bucket policies for buckets in this account.\nSetting this element to TRUE restricts access to buckets with public policies to only AWS service\nprincipals and authorized users within this account.\nEnabling this setting doesn't affect previously stored bucket policies, except that public and\ncross-account access within any public bucket policy, including non-public delegation to specific\naccounts, is blocked.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1073",
      "start_idx": 1279979,
      "end_idx": 1281339,
      "metadata": {
        "num_sentences": 10,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1080",
      "text": "Amazon Simple Storage Service API Reference\nPutStorageLensConfiguration\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nPuts an Amazon S3 Storage Lens configuration. For more information about S3 Storage Lens, see\nWorking with Amazon S3 Storage Lens in the Amazon S3 User Guide. For a complete list of S3\nStorage Lens metrics, see S3 Storage Lens metrics glossary in the Amazon S3 User Guide.\nNote\nTo use this action, you must have permission to perform the\ns3:PutStorageLensConfiguration action. For more information, see Setting\npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nPUT /v20180820/storagelens/storagelensid HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutStorageLensConfigurationRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<StorageLensConfiguration>\n<AccountLevel>\n<ActivityMetrics>\n<IsEnabled>boolean</IsEnabled>\n</ActivityMetrics>\n<AdvancedCostOptimizationMetrics>\n<IsEnabled>boolean</IsEnabled>\n</AdvancedCostOptimizationMetrics>\n<AdvancedDataProtectionMetrics>\n<IsEnabled>boolean</IsEnabled>\n</AdvancedDataProtectionMetrics>\n<BucketLevel>\n<ActivityMetrics>\n<IsEnabled>boolean</IsEnabled>\nAmazon S3 Control API Version 2006-03-01 1075",
      "start_idx": 1281632,
      "end_idx": 1282945,
      "metadata": {
        "num_sentences": 7,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1083",
      "text": "Amazon Simple Storage Service API Reference\nstoragelensid\nThe ID of the S3 Storage Lens configuration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutStorageLensConfigurationRequest\nRoot level tag for the PutStorageLensConfigurationRequest parameters.\nRequired: Yes\nStorageLensConfiguration\nThe S3 Storage Lens configuration.\nType: StorageLensConfiguration data type\nRequired: Yes\nTags\nThe tag set of the S3 Storage Lens configuration.\nNote\nYou can set up to a maximum of 50 tags.\nAmazon S3 Control API Version 2006-03-01 1078",
      "start_idx": 1284897,
      "end_idx": 1285675,
      "metadata": {
        "num_sentences": 12,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1085",
      "text": "Amazon Simple Storage Service API Reference\nPutStorageLensConfigurationTagging\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nPut or replace tags on an existing Amazon S3 Storage Lens configuration. For more information\nabout S3 Storage Lens, see Assessing your storage activity and usage with Amazon S3 Storage Lens\nin the Amazon S3 User Guide.\nNote\nTo use this action, you must have permission to perform the\ns3:PutStorageLensConfigurationTagging action. For more information, see Setting\npermissions to use Amazon S3 Storage Lens in the Amazon S3 User Guide.\nRequest Syntax\nPUT /v20180820/storagelens/storagelensid/tagging HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<PutStorageLensConfigurationTaggingRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<Tags>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Tags>\n</PutStorageLensConfigurationTaggingRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1080",
      "start_idx": 1286279,
      "end_idx": 1287382,
      "metadata": {
        "num_sentences": 7,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1086",
      "text": "Amazon Simple Storage Service API Reference\nstoragelensid\nThe ID of the S3 Storage Lens configuration.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nx-amz-account-id\nThe account ID of the requester.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nPutStorageLensConfigurationTaggingRequest\nRoot level tag for the PutStorageLensConfigurationTaggingRequest parameters.\nRequired: Yes\nTags\nThe tag set of the S3 Storage Lens configuration.\nNote\nYou can set up to a maximum of 50 tags.\nType: Array of StorageLensTag data types\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1081",
      "start_idx": 1287384,
      "end_idx": 1288116,
      "metadata": {
        "num_sentences": 11,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1088",
      "text": "Amazon Simple Storage Service API Reference\nSubmitMultiRegionAccessPointRoutes\nService: Amazon S3 Control\nNote\nThis operation is not supported by directory buckets.\nSubmits an updated route configuration for a Multi-Region Access Point. This API operation\nupdates the routing status for the specified Regions from active to passive, or from passive to\nactive. A value of 0 indicates a passive status, which means that traffic won't be routed to the\nspecified Region. A value of 100 indicates an active status, which means that traffic will be routed\nto the specified Region. At least one Region must be active at all times.\nWhen the routing configuration is changed, any in-progress operations (uploads, copies, deletes,\nand so on) to formerly active Regions will continue to run to their final completion state (success or\nfailure). The routing configurations of any Regions that aren\u2019t specified remain unchanged.\nNote\nUpdated routing configurations might not be immediately applied. It can take up to 2\nminutes for your changes to take effect.\nTo submit routing control changes and failover requests, use the Amazon S3 failover control\ninfrastructure endpoints in these five AWS Regions:\n\u2022 us-east-1\n\u2022 us-west-2\n\u2022 ap-southeast-2\n\u2022 ap-northeast-1\n\u2022 eu-west-1\nRequest Syntax\nPATCH /v20180820/mrap/instances/mrap+/routes HTTP/1.1\nHost: s3-control.amazonaws.com\nAmazon S3 Control API Version 2006-03-01 1083",
      "start_idx": 1288666,
      "end_idx": 1290072,
      "metadata": {
        "num_sentences": 11,
        "num_words": 207,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1090",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\nRouteUpdates\nThe different routes that make up the new route configuration. Active routes return a value of\n100, and passive routes return a value of 0.\nType: Array of MultiRegionAccessPointRoute data types\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nExamples\nSample request for initiating failover\nIn the following example, the request to submit these routing changes to initiate a failover is sent\nto the failover control infrastructure in the us-east-1 Region. In this example, the eu-north-1\nRegion is set to active, and the ap-northeast-3 Region is set to passive. In other words, the ap-\nnortheast-3 Region is failed over to the eu-north-1 Region.\nPATCH /v20180820/mrap/instances/<Multi-Region Access Point>/routes HTTP/1.1\nHost: example-account-id.s3-control.us-east-1.amazonaws.com\n<SubmitMultiRegionAccessPointRoutesRequest>\n<RouteUpdates>\n<Route>\n<Region>eu-north-1</Region>\n<Bucket>example-bucket-eu-north-1</Bucket>\n<TrafficDialPercentage>100</TrafficDialPercentage>\n</Route>\n<Route>\n<Region>ap-northeast-3</Region>\n<Bucket>example-bucket-ap-northeast-3</Bucket>\nAmazon S3 Control API Version 2006-03-01 1085",
      "start_idx": 1291076,
      "end_idx": 1292369,
      "metadata": {
        "num_sentences": 7,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1091",
      "text": "Amazon Simple Storage Service API Reference\n<TrafficDialPercentage>0</TrafficDialPercentage>\n</Route>\n</RouteUpdates>\n</SubmitMultiRegionAccessPointRoutesRequest>\nSample request for setting a Region to active status\nThe following request updates the route configuration of the eu-north-1 Region to active. The\nrequest is sent to the failover control infrastructure in the eu-west-1 Region.\nPATCH /v20180820/mrap/instances/<Multi-Region Access Point>/routes HTTP/1.1\nHost: example-account-id.s3-control.eu-west-1.amazonaws.com\n<SubmitMultiRegionAccessPointRoutesRequest>\n<RouteUpdates>\n<Route>\n<Region>eu-north-1<Region>\n<Bucket>example-bucket-eu-north-1</Bucket>\n<TrafficDialPercentage>100</TrafficDialPercentage>\n</Route>\n</RouteUpdates>\n</SubmitMultiRegionAccessPointRoutesRequest>\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\nAmazon S3 Control API Version 2006-03-01 1086",
      "start_idx": 1292371,
      "end_idx": 1293490,
      "metadata": {
        "num_sentences": 3,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1093",
      "text": "Amazon Simple Storage Service API Reference\nTagResource\nService: Amazon S3 Control\nCreates a new AWS resource tag or updates an existing resource tag. Each tag is a label consisting\nof a user-defined key and value. Tags can help you manage, identify, organize, search for, and filter\nresources. You can add up to 50 AWS resource tags for each S3 resource.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The\ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered\nlocation, or grant.\nPermissions\nYou must have the s3:TagResource permission to use this operation.\nFor more information about the required Storage Lens Groups permissions, see Setting account\npermissions to use S3 Storage Lens groups.\nFor information about S3 Tagging errors, see List of Amazon S3 Tagging error codes.\nRequest Syntax\nPOST /v20180820/tags/resourceArn+ HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<TagResourceRequest xmlns=\"http://awss3control.amazonaws.com/doc/2018-08-20/\">\n<Tags>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</Tags>\n</TagResourceRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nAmazon S3 Control API Version 2006-03-01 1088",
      "start_idx": 1293605,
      "end_idx": 1294904,
      "metadata": {
        "num_sentences": 11,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1094",
      "text": "Amazon Simple Storage Service API Reference\nresourceArn\nThe Amazon Resource Name (ARN) of the S3 resource that you're trying to add tags to. The\ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered\nlocation, or grant.\nLength Constraints: Maximum length of 1011.\nPattern: arn:[^:]+:s3:[^:].*\nRequired: Yes\nx-amz-account-id\nThe AWS account ID that created the S3 resource that you're trying to add tags to or the\nrequester's account ID.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nTagResourceRequest\nRoot level tag for the TagResourceRequest parameters.\nRequired: Yes\nTags\nThe AWS resource tags that you want to add to the specified S3 resource.\nType: Array of Tag data types\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1089",
      "start_idx": 1294906,
      "end_idx": 1295842,
      "metadata": {
        "num_sentences": 12,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1096",
      "text": "Amazon Simple Storage Service API Reference\nUntagResource\nService: Amazon S3 Control\nThis operation removes the specified AWS resource tags from an S3 resource. Each tag is a label\nconsisting of a user-defined key and value. Tags can help you manage, identify, organize, search\nfor, and filter resources.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The\ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered\nlocation, or grant.\nPermissions\nYou must have the s3:UntagResource permission to use this operation.\nFor more information about the required Storage Lens Groups permissions, see Setting account\npermissions to use S3 Storage Lens groups.\nFor information about S3 Tagging errors, see List of Amazon S3 Tagging error codes.\nRequest Syntax\nDELETE /v20180820/tags/resourceArn+?tagKeys=TagKeys HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nresourceArn\nThe Amazon Resource Name (ARN) of the S3 resource that you're trying to remove the tags\nfrom.\nLength Constraints: Maximum length of 1011.\nPattern: arn:[^:]+:s3:[^:].*\nAmazon S3 Control API Version 2006-03-01 1091",
      "start_idx": 1296392,
      "end_idx": 1297631,
      "metadata": {
        "num_sentences": 13,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1097",
      "text": "Amazon Simple Storage Service API Reference\nRequired: Yes\ntagKeys\nThe array of tag key-value pairs that you're trying to remove from of the S3 resource.\nArray Members: Minimum number of 0 items. Maximum number of 50 items.\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nx-amz-account-id\nThe AWS account ID that owns the resource that you're trying to remove the tags from.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 204\nResponse Elements\nIf the action is successful, the service sends back an HTTP 204 response with an empty HTTP body.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\nAmazon S3 Control API Version 2006-03-01 1092",
      "start_idx": 1297633,
      "end_idx": 1298557,
      "metadata": {
        "num_sentences": 10,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1099",
      "text": "Amazon Simple Storage Service API Reference\nUpdateAccessGrantsLocation\nService: Amazon S3 Control\nUpdates the IAM role of a registered location in your S3 Access Grants instance.\nPermissions\nYou must have the s3:UpdateAccessGrantsLocation permission to use this operation.\nAdditional Permissions\nYou must also have the following permission: iam:PassRole\nRequest Syntax\nPUT /v20180820/accessgrantsinstance/location/id HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateAccessGrantsLocationRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<IAMRoleArn>string</IAMRoleArn>\n</UpdateAccessGrantsLocationRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the registered location that you are updating. S3 Access Grants assigns this ID when\nyou register the location. S3 Access Grants assigns the ID default to the default location\ns3:// and assigns an auto-generated ID to other locations that you register.\nThe ID of the registered location to which you are granting access. S3 Access Grants assigned\nthis ID when you registered the location. S3 Access Grants assigns the ID default to the\ndefault location s3:// and assigns an auto-generated ID to other locations that you register.\nIf you are passing the default location, you cannot create an access grant for the entire\ndefault location. You must also specify a bucket or a bucket and prefix in the Subprefix field.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nAmazon S3 Control API Version 2006-03-01 1094",
      "start_idx": 1298802,
      "end_idx": 1300397,
      "metadata": {
        "num_sentences": 14,
        "num_words": 214,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1100",
      "text": "Amazon Simple Storage Service API Reference\nPattern: [a-zA-Z0-9\\-]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the S3 Access Grants instance.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nUpdateAccessGrantsLocationRequest\nRoot level tag for the UpdateAccessGrantsLocationRequest parameters.\nRequired: Yes\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants\nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateAccessGrantsLocationResult>\n<CreatedAt>timestamp</CreatedAt>\n<AccessGrantsLocationId>string</AccessGrantsLocationId>\nAmazon S3 Control API Version 2006-03-01 1095",
      "start_idx": 1300399,
      "end_idx": 1301344,
      "metadata": {
        "num_sentences": 10,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1101",
      "text": "Amazon Simple Storage Service API Reference\n<AccessGrantsLocationArn>string</AccessGrantsLocationArn>\n<LocationScope>string</LocationScope>\n<IAMRoleArn>string</IAMRoleArn>\n</UpdateAccessGrantsLocationResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nUpdateAccessGrantsLocationResult\nRoot level tag for the UpdateAccessGrantsLocationResult parameters.\nRequired: Yes\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the registered location that you are updating.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigned\nthis ID when you registered the location. S3 Access Grants assigns the ID default to the\ndefault location s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nAmazon S3 Control API Version 2006-03-01 1096",
      "start_idx": 1301346,
      "end_idx": 1302613,
      "metadata": {
        "num_sentences": 13,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1102",
      "text": "Amazon Simple Storage Service API Reference\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role of the registered location. S3 Access Grants\nassumes this role to manage access to the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nLocationScope\nThe S3 URI path of the location that you are updating. You cannot update the scope of the\nregistered location. The location scope can be the default S3 location s3://, the S3 path to a\nbucket s3://<bucket>, or the S3 path to a bucket and prefix s3://<bucket>/<prefix>.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for JavaScript V3\n\u2022 AWS SDK for PHP V3\n\u2022 AWS SDK for Python\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1097",
      "start_idx": 1302615,
      "end_idx": 1303674,
      "metadata": {
        "num_sentences": 11,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1103",
      "text": "Amazon Simple Storage Service API Reference\nUpdateJobPriority\nService: Amazon S3 Control\nUpdates an existing S3 Batch Operations job's priority. For more information, see S3 Batch\nOperations in the Amazon S3 User Guide.\nPermissions\nTo use the UpdateJobPriority operation, you must have permission to perform the\ns3:UpdateJobPriority action.\nRelated actions include:\n\u2022 CreateJob\n\u2022 ListJobs\n\u2022 DescribeJob\n\u2022 UpdateJobStatus\nRequest Syntax\nPOST /v20180820/jobs/id/priority?priority=Priority HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID for the job whose priority you want to update.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\npriority\nThe priority you want to assign to this job.\nAmazon S3 Control API Version 2006-03-01 1098",
      "start_idx": 1303676,
      "end_idx": 1304560,
      "metadata": {
        "num_sentences": 9,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1104",
      "text": "Amazon Simple Storage Service API Reference\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nRequired: Yes\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateJobPriorityResult>\n<JobId>string</JobId>\n<Priority>integer</Priority>\n</UpdateJobPriorityResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nUpdateJobPriorityResult\nRoot level tag for the UpdateJobPriorityResult parameters.\nRequired: Yes\nJobId\nThe ID for the job whose priority Amazon S3 updated.\nType: String\nAmazon S3 Control API Version 2006-03-01 1099",
      "start_idx": 1304562,
      "end_idx": 1305431,
      "metadata": {
        "num_sentences": 10,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1105",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nPriority\nThe new priority assigned to the specified job.\nType: Integer\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nErrors\nBadRequestException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nNotFoundException\nHTTP Status Code: 400\nTooManyRequestsException\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Go v2\n\u2022 AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 1100",
      "start_idx": 1305433,
      "end_idx": 1306147,
      "metadata": {
        "num_sentences": 6,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1107",
      "text": "Amazon Simple Storage Service API Reference\nUpdateJobStatus\nService: Amazon S3 Control\nUpdates the status for the specified job. Use this operation to confirm that you want to run a job\nor to cancel an existing job. For more information, see S3 Batch Operations in the Amazon S3 User\nGuide.\nPermissions\nTo use the UpdateJobStatus operation, you must have permission to perform the\ns3:UpdateJobStatus action.\nRelated actions include:\n\u2022 CreateJob\n\u2022 ListJobs\n\u2022 DescribeJob\n\u2022 UpdateJobStatus\nRequest Syntax\nPOST /v20180820/jobs/id/status?\nrequestedJobStatus=RequestedJobStatus&statusUpdateReason=StatusUpdateReason HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\nURI Request Parameters\nThe request uses the following URI parameters.\nid\nThe ID of the job whose status you want to update.\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1102",
      "start_idx": 1306332,
      "end_idx": 1307283,
      "metadata": {
        "num_sentences": 10,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1108",
      "text": "Amazon Simple Storage Service API Reference\nrequestedJobStatus\nThe status that you want to move the specified job to.\nValid Values: Cancelled | Ready\nRequired: Yes\nstatusUpdateReason\nA description of the reason why you want to change the specified job's status. This field can be\nany string up to the maximum length.\nLength Constraints: Minimum length of 1. Maximum length of 256.\nx-amz-account-id\nThe AWS account ID associated with the S3 Batch Operations job.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateJobStatusResult>\n<JobId>string</JobId>\n<Status>string</Status>\n<StatusUpdateReason>string</StatusUpdateReason>\n</UpdateJobStatusResult>\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in XML format by the service.\nAmazon S3 Control API Version 2006-03-01 1103",
      "start_idx": 1307285,
      "end_idx": 1308285,
      "metadata": {
        "num_sentences": 10,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1109",
      "text": "Amazon Simple Storage Service API Reference\nUpdateJobStatusResult\nRoot level tag for the UpdateJobStatusResult parameters.\nRequired: Yes\nJobId\nThe ID for the job whose status was updated.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nStatus\nThe current status for the specified job.\nType: String\nValid Values: Active | Cancelled | Cancelling | Complete | Completing\n| Failed | Failing | New | Paused | Pausing | Preparing | Ready |\nSuspended\nStatusUpdateReason\nThe reason that the specified job's status was updated.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nErrors\nBadRequestException\nHTTP Status Code: 400\nInternalServiceException\nHTTP Status Code: 500\nAmazon S3 Control API Version 2006-03-01 1104",
      "start_idx": 1308287,
      "end_idx": 1309078,
      "metadata": {
        "num_sentences": 9,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1111",
      "text": "Amazon Simple Storage Service API Reference\nUpdateStorageLensGroup\nService: Amazon S3 Control\nUpdates the existing Storage Lens group.\nTo use this operation, you must have the permission to perform the\ns3:UpdateStorageLensGroup action. For more information about the required Storage Lens\nGroups permissions, see Setting account permissions to use S3 Storage Lens groups.\nFor information about Storage Lens groups errors, see List of Amazon S3 Storage Lens error codes.\nRequest Syntax\nPUT /v20180820/storagelensgroup/name HTTP/1.1\nHost: s3-control.amazonaws.com\nx-amz-account-id: AccountId\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<UpdateStorageLensGroupRequest xmlns=\"http://awss3control.amazonaws.com/\ndoc/2018-08-20/\">\n<StorageLensGroup>\n<Filter>\n<And>\n<MatchAnyPrefix>\n<Prefix>string</Prefix>\n</MatchAnyPrefix>\n<MatchAnySuffix>\n<Suffix>string</Suffix>\n</MatchAnySuffix>\n<MatchAnyTag>\n<Tag>\n<Key>string</Key>\n<Value>string</Value>\n</Tag>\n</MatchAnyTag>\n<MatchObjectAge>\n<DaysGreaterThan>integer</DaysGreaterThan>\n<DaysLessThan>integer</DaysLessThan>\n</MatchObjectAge>\n<MatchObjectSize>\n<BytesGreaterThan>long</BytesGreaterThan>\n<BytesLessThan>long</BytesLessThan>\n</MatchObjectSize>\n</And>\nAmazon S3 Control API Version 2006-03-01 1106",
      "start_idx": 1309611,
      "end_idx": 1310847,
      "metadata": {
        "num_sentences": 5,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1113",
      "text": "Amazon Simple Storage Service API Reference\n<StorageLensGroupArn>string</StorageLensGroupArn>\n</StorageLensGroup>\n</UpdateStorageLensGroupRequest>\nURI Request Parameters\nThe request uses the following URI parameters.\nname\nThe name of the Storage Lens group that you want to update.\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nx-amz-account-id\nThe AWS account ID of the Storage Lens group owner.\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nRequest Body\nThe request accepts the following data in XML format.\nUpdateStorageLensGroupRequest\nRoot level tag for the UpdateStorageLensGroupRequest parameters.\nRequired: Yes\nStorageLensGroup\nThe JSON file that contains the Storage Lens group configuration.\nType: StorageLensGroup data type\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1108",
      "start_idx": 1311841,
      "end_idx": 1312720,
      "metadata": {
        "num_sentences": 10,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1115",
      "text": "Amazon Simple Storage Service API Reference\nCreateEndpoint\nService: Amazon S3 on Outposts\nCreates an endpoint and associates it with the specified Outpost.\nNote\nIt can take up to 5 minutes for this action to finish.\nRelated actions include:\n\u2022 DeleteEndpoint\n\u2022 ListEndpoints\nRequest Syntax\nPOST /S3Outposts/CreateEndpoint HTTP/1.1\nContent-type: application/json\n{\n\"AccessType\": \"string\",\n\"CustomerOwnedIpv4Pool\": \"string\",\n\"OutpostId\": \"string\",\n\"SecurityGroupId\": \"string\",\n\"SubnetId\": \"string\"\n}\nURI Request Parameters\nThe request does not use any URI parameters.\nRequest Body\nThe request accepts the following data in JSON format.\nAccessType\nThe type of access for the network connectivity for the Amazon S3 on Outposts endpoint. To\nuse the AWS VPC, choose Private. To use the endpoint with an on-premises network, choose\nAmazon S3 on Outposts API Version 2006-03-01 1110",
      "start_idx": 1313451,
      "end_idx": 1314324,
      "metadata": {
        "num_sentences": 7,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1116",
      "text": "Amazon Simple Storage Service API Reference\nCustomerOwnedIp. If you choose CustomerOwnedIp, you must also provide the customer-\nowned IP address pool (CoIP pool).\nNote\nPrivate is the default access type value.\nType: String\nValid Values: Private | CustomerOwnedIp\nRequired: No\nCustomerOwnedIpv4Pool\nThe ID of the customer-owned IPv4 address pool (CoIP pool) for the endpoint. IP addresses are\nallocated from this pool for the endpoint.\nType: String\nPattern: ^ipv4pool-coip-([0-9a-f]{17})$\nRequired: No\nOutpostId\nThe ID of the AWS Outposts.\nType: String\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: Yes\nSecurityGroupId\nThe ID of the security group to use with the endpoint.\nType: String\nPattern: ^sg-([0-9a-f]{8}|[0-9a-f]{17})$\nRequired: Yes\nAmazon S3 on Outposts API Version 2006-03-01 1111",
      "start_idx": 1314326,
      "end_idx": 1315120,
      "metadata": {
        "num_sentences": 8,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1117",
      "text": "Amazon Simple Storage Service API Reference\nSubnetId\nThe ID of the subnet in the selected VPC. The endpoint subnet must belong to the Outpost that\nhas Amazon S3 on Outposts provisioned.\nType: String\nPattern: ^subnet-([0-9a-f]{8}|[0-9a-f]{17})$\nRequired: Yes\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\n{\n\"EndpointArn\": \"string\"\n}\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\nEndpointArn\nThe Amazon Resource Name (ARN) of the endpoint.\nType: String\nPattern: ^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):s3-outposts:[a-\nz\\-0-9]*:[0-9]{12}:outpost/(op-[a-f0-9]{17}|ec2)/endpoint/[a-zA-Z0-9]\n{19}$\nErrors\nAccessDeniedException\nAccess was denied for this action.\nAmazon S3 on Outposts API Version 2006-03-01 1112",
      "start_idx": 1315122,
      "end_idx": 1315956,
      "metadata": {
        "num_sentences": 7,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1118",
      "text": "Amazon Simple Storage Service API Reference\nHTTP Status Code: 403\nConflictException\nThere was a conflict with this action, and it could not be completed.\nHTTP Status Code: 409\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nOutpostOfflineException\nThe service link connection to your Outposts home Region is down. Check your connection and\ntry again.\nHTTP Status Code: 400\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\n\u2022 AWS SDK for .NET\nAmazon S3 on Outposts API Version 2006-03-01 1113",
      "start_idx": 1315958,
      "end_idx": 1316852,
      "metadata": {
        "num_sentences": 8,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1121",
      "text": "Amazon Simple Storage Service API Reference\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response with an empty HTTP body.\nErrors\nAccessDeniedException\nAccess was denied for this action.\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nOutpostOfflineException\nThe service link connection to your Outposts home Region is down. Check your connection and\ntry again.\nHTTP Status Code: 400\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nAmazon S3 on Outposts API Version 2006-03-01 1116",
      "start_idx": 1317719,
      "end_idx": 1318520,
      "metadata": {
        "num_sentences": 9,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1123",
      "text": "Amazon Simple Storage Service API Reference\nListEndpoints\nService: Amazon S3 on Outposts\nLists endpoints associated with the specified Outpost.\nRelated actions include:\n\u2022 CreateEndpoint\n\u2022 DeleteEndpoint\nRequest Syntax\nGET /S3Outposts/ListEndpoints?maxResults=MaxResults&nextToken=NextToken HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nMaxResults\nThe maximum number of endpoints that will be returned in the response.\nValid Range: Minimum value of 0. Maximum value of 100.\nNextToken\nIf a previous response from this operation included a NextToken value, provide that value here\nto retrieve the next page of results.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\nAmazon S3 on Outposts API Version 2006-03-01 1118",
      "start_idx": 1319016,
      "end_idx": 1319932,
      "metadata": {
        "num_sentences": 10,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1125",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nErrors\nAccessDeniedException\nAccess was denied for this action.\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nHTTP Status Code: 400\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS Command Line Interface\nAmazon S3 on Outposts API Version 2006-03-01 1120",
      "start_idx": 1320889,
      "end_idx": 1321685,
      "metadata": {
        "num_sentences": 8,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1127",
      "text": "Amazon Simple Storage Service API Reference\nListOutpostsWithS3\nService: Amazon S3 on Outposts\nLists the Outposts with S3 on Outposts capacity for your AWS account. Includes S3 on Outposts\nthat you have access to as the Outposts owner, or as a shared user from Resource Access Manager\n(RAM).\nRequest Syntax\nGET /S3Outposts/ListOutpostsWithS3?maxResults=MaxResults&nextToken=NextToken HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nMaxResults\nThe maximum number of Outposts to return. The limit is 100.\nValid Range: Minimum value of 0. Maximum value of 100.\nNextToken\nWhen you can get additional results from the ListOutpostsWithS3 call, a NextToken\nparameter is returned in the output. You can then pass in a subsequent command to the\nNextToken parameter to continue listing additional Outposts.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nRequest Body\nThe request does not have a request body.\nResponse Syntax\nHTTP/1.1 200\nContent-type: application/json\n{\n\"NextToken\": \"string\",\nAmazon S3 on Outposts API Version 2006-03-01 1122",
      "start_idx": 1321953,
      "end_idx": 1323072,
      "metadata": {
        "num_sentences": 13,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1128",
      "text": "Amazon Simple Storage Service API Reference\n\"Outposts\": [\n{\n\"CapacityInBytes\": number,\n\"OutpostArn\": \"string\",\n\"OutpostId\": \"string\",\n\"OwnerId\": \"string\",\n\"S3OutpostArn\": \"string\"\n}\n]\n}\nResponse Elements\nIf the action is successful, the service sends back an HTTP 200 response.\nThe following data is returned in JSON format by the service.\nNextToken\nReturns a token that you can use to call ListOutpostsWithS3 again and receive additional\nresults, if there are any.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nOutposts\nReturns the list of Outposts that have the following characteristics:\n\u2022 outposts that have S3 provisioned\n\u2022 outposts that are Active (not pending any provisioning nor decommissioned)\n\u2022 outposts to which the the calling AWS account has access\nType: Array of Outpost objects\nErrors\nAccessDeniedException\nAccess was denied for this action.\nAmazon S3 on Outposts API Version 2006-03-01 1123",
      "start_idx": 1323074,
      "end_idx": 1324051,
      "metadata": {
        "num_sentences": 7,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1130",
      "text": "Amazon Simple Storage Service API Reference\nListSharedEndpoints\nService: Amazon S3 on Outposts\nLists all endpoints associated with an Outpost that has been shared by AWS Resource Access\nManager (RAM).\nRelated actions include:\n\u2022 CreateEndpoint\n\u2022 DeleteEndpoint\nRequest Syntax\nGET /S3Outposts/ListSharedEndpoints?\nmaxResults=MaxResults&nextToken=NextToken&outpostId=OutpostId HTTP/1.1\nURI Request Parameters\nThe request uses the following URI parameters.\nMaxResults\nThe maximum number of endpoints that will be returned in the response.\nValid Range: Minimum value of 0. Maximum value of 100.\nNextToken\nIf a previous response from this operation included a NextToken value, you can provide that\nvalue here to retrieve the next page of results.\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nOutpostId\nThe ID of the AWS Outpost.\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: Yes\nAmazon S3 on Outposts API Version 2006-03-01 1125",
      "start_idx": 1324756,
      "end_idx": 1325740,
      "metadata": {
        "num_sentences": 11,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1132",
      "text": "Amazon Simple Storage Service API Reference\nEndpoints\nThe list of endpoints associated with the specified Outpost that have been shared by AWS\nResource Access Manager (RAM).\nType: Array of Endpoint objects\nNextToken\nIf the number of endpoints associated with the specified Outpost exceeds MaxResults, you\ncan include this value in subsequent calls to this operation to retrieve more results.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: ^[A-Za-z0-9\\+\\:\\/\\=\\?\\#-_]+$\nErrors\nAccessDeniedException\nAccess was denied for this action.\nHTTP Status Code: 403\nInternalServerException\nThere was an exception with the internal server.\nHTTP Status Code: 500\nResourceNotFoundException\nThe requested resource was not found.\nHTTP Status Code: 404\nThrottlingException\nThe request was denied due to request throttling.\nHTTP Status Code: 429\nValidationException\nThere was an exception validating this data.\nAmazon S3 on Outposts API Version 2006-03-01 1127",
      "start_idx": 1326523,
      "end_idx": 1327504,
      "metadata": {
        "num_sentences": 10,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1148",
      "text": "Amazon Simple Storage Service API Reference\nAbortIncompleteMultipartUpload\nService: Amazon S3\nSpecifies the days since the initiation of an incomplete multipart upload that Amazon S3 will\nwait before permanently removing all parts of the upload. For more information, see Aborting\nIncomplete Multipart Uploads Using a Bucket Lifecycle Configuration in the Amazon S3 User Guide.\nContents\nDaysAfterInitiation\nSpecifies the number of days after which Amazon S3 aborts an incomplete multipart upload.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1143",
      "start_idx": 1338209,
      "end_idx": 1338944,
      "metadata": {
        "num_sentences": 4,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1149",
      "text": "Amazon Simple Storage Service API Reference\nAccelerateConfiguration\nService: Amazon S3\nConfigures the transfer acceleration state for an Amazon S3 bucket. For more information, see\nAmazon S3 Transfer Acceleration in the Amazon S3 User Guide.\nContents\nStatus\nSpecifies the transfer acceleration status of the bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1144",
      "start_idx": 1338946,
      "end_idx": 1339533,
      "metadata": {
        "num_sentences": 4,
        "num_words": 95,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1151",
      "text": "Amazon Simple Storage Service API Reference\nAccessControlTranslation\nService: Amazon S3\nA container for information about access control for replicas.\nContents\nOwner\nSpecifies the replica ownership. For default and valid values, see PUT bucket replication in the\nAmazon S3 API Reference.\nType: String\nValid Values: Destination\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1146",
      "start_idx": 1340083,
      "end_idx": 1340635,
      "metadata": {
        "num_sentences": 4,
        "num_words": 89,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1152",
      "text": "Amazon Simple Storage Service API Reference\nAnalyticsAndOperator\nService: Amazon S3\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics filter. The operator\nmust have at least two predicates in any combination, and an object must match all of the\npredicates for the filter to apply.\nContents\nPrefix\nThe prefix to use when evaluating an AND predicate: The prefix that an object must have to be\nincluded in the metrics results.\nType: String\nRequired: No\nTags\nThe list of tags to use when evaluating an AND predicate.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1147",
      "start_idx": 1340637,
      "end_idx": 1341435,
      "metadata": {
        "num_sentences": 5,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1153",
      "text": "Amazon Simple Storage Service API Reference\nAnalyticsConfiguration\nService: Amazon S3\nSpecifies the configuration and any analyses for the analytics filter of an Amazon S3 bucket.\nContents\nId\nThe ID that identifies the analytics configuration.\nType: String\nRequired: Yes\nStorageClassAnalysis\nContains data related to access patterns to be collected and made available to analyze the\ntradeoffs between different storage classes.\nType: StorageClassAnalysis data type\nRequired: Yes\nFilter\nThe filter used to describe a set of objects for analyses. A filter must have exactly one prefix,\none tag, or one conjunction (AnalyticsAndOperator). If no filter is provided, all objects will be\nconsidered in any analysis.\nType: AnalyticsFilter data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1148",
      "start_idx": 1341437,
      "end_idx": 1342403,
      "metadata": {
        "num_sentences": 7,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1156",
      "text": "Amazon Simple Storage Service API Reference\nAnalyticsFilter\nService: Amazon S3\nThe filter used to describe a set of objects for analyses. A filter must have exactly one prefix,\none tag, or one conjunction (AnalyticsAndOperator). If no filter is provided, all objects will be\nconsidered in any analysis.\nContents\nAnd\nA conjunction (logical AND) of predicates, which is used in evaluating an analytics filter. The\noperator must have at least two predicates.\nType: AnalyticsAndOperator data type\nRequired: No\nPrefix\nThe prefix to use when evaluating an analytics filter.\nType: String\nRequired: No\nTag\nThe tag to use when evaluating an analytics filter.\nType: Tag data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1151",
      "start_idx": 1342968,
      "end_idx": 1343862,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1158",
      "text": "Amazon Simple Storage Service API Reference\nAnalyticsS3BucketDestination\nService: Amazon S3\nContains information about where to publish the analytics results.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the bucket to which data is exported.\nType: String\nRequired: Yes\nFormat\nSpecifies the file format used when exporting data to Amazon S3.\nType: String\nValid Values: CSV\nRequired: Yes\nBucketAccountId\nThe account ID that owns the destination S3 bucket. If no account ID is provided, the owner is\nnot validated before exporting data.\nNote\nAlthough this value is optional, we strongly recommend that you set it to help prevent\nproblems if the destination bucket ownership changes.\nType: String\nRequired: No\nPrefix\nThe prefix to use when exporting data. The prefix is prepended to all results.\nAmazon S3 API Version 2006-03-01 1153",
      "start_idx": 1343947,
      "end_idx": 1344781,
      "metadata": {
        "num_sentences": 9,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1160",
      "text": "Amazon Simple Storage Service API Reference\nBucket\nService: Amazon S3\nIn terms of implementation, a Bucket is a resource.\nContents\nBucketRegion\nBucketRegion indicates the AWS region where the bucket is located. If the request contains at\nleast one valid parameter, it is included in the response.\nType: String\nRequired: No\nCreationDate\nDate the bucket was created. This date can change when making changes to your bucket, such\nas editing its bucket policy.\nType: Timestamp\nRequired: No\nName\nThe name of the bucket.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1155",
      "start_idx": 1345066,
      "end_idx": 1345818,
      "metadata": {
        "num_sentences": 7,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1161",
      "text": "Amazon Simple Storage Service API Reference\nBucketInfo\nService: Amazon S3\nSpecifies the information about the bucket that will be created. For more information about\ndirectory buckets, see Directory buckets in the Amazon S3 User Guide.\nNote\nThis functionality is only supported by directory buckets.\nContents\nDataRedundancy\nThe number of Availability Zone that's used for redundancy for the bucket.\nType: String\nValid Values: SingleAvailabilityZone\nRequired: No\nType\nThe type of bucket.\nType: String\nValid Values: Directory\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1156",
      "start_idx": 1345820,
      "end_idx": 1346568,
      "metadata": {
        "num_sentences": 6,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1163",
      "text": "Amazon Simple Storage Service API Reference\nBucketLifecycleConfiguration\nService: Amazon S3\nSpecifies the lifecycle configuration for objects in an Amazon S3 bucket. For more information, see\nObject Lifecycle Management in the Amazon S3 User Guide.\nContents\nRules\nA lifecycle rule for individual objects in an Amazon S3 bucket.\nType: Array of LifecycleRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1158",
      "start_idx": 1346653,
      "end_idx": 1347246,
      "metadata": {
        "num_sentences": 4,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1164",
      "text": "Amazon Simple Storage Service API Reference\nBucketLoggingStatus\nService: Amazon S3\nContainer for logging status information.\nContents\nLoggingEnabled\nDescribes where logs are stored and the prefix that Amazon S3 assigns to all log object keys for\na bucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nType: LoggingEnabled data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1159",
      "start_idx": 1347248,
      "end_idx": 1347836,
      "metadata": {
        "num_sentences": 4,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1165",
      "text": "Amazon Simple Storage Service API Reference\nChecksum\nService: Amazon S3\nContains all the possible checksum or digest values for an object.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 1160",
      "start_idx": 1347838,
      "end_idx": 1349596,
      "metadata": {
        "num_sentences": 17,
        "num_words": 285,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1166",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1161",
      "start_idx": 1349598,
      "end_idx": 1350413,
      "metadata": {
        "num_sentences": 6,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1168",
      "text": "Amazon Simple Storage Service API Reference\nEvents\nBucket events for which to send notifications.\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nId\nAn optional unique identifier for configurations in a notification configuration. If you don't\nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nInvocationRole\nThe role supporting the invocation of the Lambda function\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1163",
      "start_idx": 1351675,
      "end_idx": 1352912,
      "metadata": {
        "num_sentences": 4,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1170",
      "text": "Amazon Simple Storage Service API Reference\nCommonPrefix\nService: Amazon S3\nContainer for all (if there are any) keys between Prefix and the next occurrence of the string\nspecified by a delimiter. CommonPrefixes lists keys that act like subdirectories in the directory\nspecified by Prefix. For example, if the prefix is notes/ and the delimiter is a slash (/) as in notes/\nsummer/july, the common prefix is notes/summer/.\nContents\nPrefix\nContainer for the specified common prefix.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1165",
      "start_idx": 1353171,
      "end_idx": 1353889,
      "metadata": {
        "num_sentences": 5,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1172",
      "text": "Amazon Simple Storage Service API Reference\nCompletedPart\nService: Amazon S3\nDetails of the parts that were uploaded.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 1167",
      "start_idx": 1354451,
      "end_idx": 1356188,
      "metadata": {
        "num_sentences": 17,
        "num_words": 281,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1173",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nETag\nEntity tag returned when the part was uploaded.\nType: String\nRequired: No\nPartNumber\nPart number that identifies the part. This is a positive integer between 1 and 10,000.\nNote\n\u2022 General purpose buckets - In CompleteMultipartUpload, when a additional\nchecksum (including x-amz-checksum-crc32, x-amz-checksum-crc32c, x-\namz-checksum-sha1, or x-amz-checksum-sha256) is applied to each part,\nthe PartNumber must start at 1 and the part numbers must be consecutive.\nOtherwise, Amazon S3 generates an HTTP 400 Bad Request status code and an\nInvalidPartOrder error code.\n\u2022 Directory buckets - In CompleteMultipartUpload, the PartNumber must start at\n1 and the part numbers must be consecutive.\nType: Integer\nAmazon S3 API Version 2006-03-01 1168",
      "start_idx": 1356190,
      "end_idx": 1357538,
      "metadata": {
        "num_sentences": 12,
        "num_words": 206,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1175",
      "text": "Amazon Simple Storage Service API Reference\nCondition\nService: Amazon S3\nA container for describing a condition that must be met for the specified redirect to apply. For\nexample, 1. If request is for pages in the /docs folder, redirect to the /documents folder. 2. If\nrequest results in HTTP error 4xx, redirect request to another host where you might process the\nerror.\nContents\nHttpErrorCodeReturnedEquals\nThe HTTP error code when the redirect is applied. In the event of an error, if the error code\nequals this value, then the specified redirect is applied. Required when parent element\nCondition is specified and sibling KeyPrefixEquals is not specified. If both are specified,\nthen both must be true for the redirect to be applied.\nType: String\nRequired: No\nKeyPrefixEquals\nThe object key name prefix when the redirect is applied. For example, to redirect requests\nfor ExamplePage.html, the key prefix will be ExamplePage.html. To redirect request for\nall pages with the prefix docs/, the key prefix will be /docs, which identifies all objects in\nthe docs/ folder. Required when the parent element Condition is specified and sibling\nHttpErrorCodeReturnedEquals is not specified. If both conditions are specified, both must\nbe true for the redirect to be applied.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1170",
      "start_idx": 1357810,
      "end_idx": 1359336,
      "metadata": {
        "num_sentences": 17,
        "num_words": 239,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1178",
      "text": "Amazon Simple Storage Service API Reference\nCopyObjectResult\nService: Amazon S3\nContainer for all response elements.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. For more information, see Checking object integrity in the Amazon\nS3 User Guide.\nType: String\nAmazon S3 API Version 2006-03-01 1173",
      "start_idx": 1359961,
      "end_idx": 1361075,
      "metadata": {
        "num_sentences": 14,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1179",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nETag\nReturns the ETag of the new object. The ETag reflects only changes to the contents of an object,\nnot its metadata.\nType: String\nRequired: No\nLastModified\nCreation date of the object.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1174",
      "start_idx": 1361077,
      "end_idx": 1361562,
      "metadata": {
        "num_sentences": 4,
        "num_words": 86,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1180",
      "text": "Amazon Simple Storage Service API Reference\nCopyPartResult\nService: Amazon S3\nContainer for all response elements.\nContents\nChecksumCRC32\nThe base64-encoded, 32-bit CRC-32 checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 1175",
      "start_idx": 1361564,
      "end_idx": 1363298,
      "metadata": {
        "num_sentences": 17,
        "num_words": 279,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1181",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nETag\nEntity tag of the object.\nType: String\nRequired: No\nLastModified\nDate and time at which the object was uploaded.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1176",
      "start_idx": 1363300,
      "end_idx": 1364262,
      "metadata": {
        "num_sentences": 8,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1182",
      "text": "Amazon Simple Storage Service API Reference\nCORSConfiguration\nService: Amazon S3\nDescribes the cross-origin access configuration for objects in an Amazon S3 bucket. For more\ninformation, see Enabling Cross-Origin Resource Sharing in the Amazon S3 User Guide.\nContents\nCORSRules\nA set of origins and methods (cross-origin access that you want to allow). You can add up to 100\nrules to the configuration.\nType: Array of CORSRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1177",
      "start_idx": 1364264,
      "end_idx": 1364927,
      "metadata": {
        "num_sentences": 5,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1183",
      "text": "Amazon Simple Storage Service API Reference\nCORSRule\nService: Amazon S3\nSpecifies a cross-origin access rule for an Amazon S3 bucket.\nContents\nAllowedMethods\nAn HTTP method that you allow the origin to execute. Valid values are GET, PUT, HEAD, POST,\nand DELETE.\nType: Array of strings\nRequired: Yes\nAllowedOrigins\nOne or more origins you want customers to be able to access the bucket from.\nType: Array of strings\nRequired: Yes\nAllowedHeaders\nHeaders that are specified in the Access-Control-Request-Headers header. These headers\nare allowed in a preflight OPTIONS request. In response to any preflight OPTIONS request,\nAmazon S3 returns any requested headers that are allowed.\nType: Array of strings\nRequired: No\nExposeHeaders\nOne or more headers in the response that you want customers to be able to access from their\napplications (for example, from a JavaScript XMLHttpRequest object).\nType: Array of strings\nRequired: No\nID\nUnique identifier for the rule. The value cannot be longer than 255 characters.\nAmazon S3 API Version 2006-03-01 1178",
      "start_idx": 1364929,
      "end_idx": 1365974,
      "metadata": {
        "num_sentences": 11,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1185",
      "text": "Amazon Simple Storage Service API Reference\nCreateBucketConfiguration\nService: Amazon S3\nThe configuration information for the bucket.\nContents\nBucket\nSpecifies the information about the bucket that will be created.\nNote\nThis functionality is only supported by directory buckets.\nType: BucketInfo data type\nRequired: No\nLocation\nSpecifies the location where the bucket will be created.\nFor directory buckets, the location type is Availability Zone.\nNote\nThis functionality is only supported by directory buckets.\nType: LocationInfo data type\nRequired: No\nLocationConstraint\nSpecifies the Region where the bucket will be created. You might choose a Region to optimize\nlatency, minimize costs, or address regulatory requirements. For example, if you reside in\nEurope, you will probably find it advantageous to create buckets in the Europe (Ireland) Region.\nFor more information, see Accessing a bucket in the Amazon S3 User Guide.\nAmazon S3 API Version 2006-03-01 1180",
      "start_idx": 1366401,
      "end_idx": 1367367,
      "metadata": {
        "num_sentences": 11,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1186",
      "text": "Amazon Simple Storage Service API Reference\nIf you don't specify a Region, the bucket is created in the US East (N. Virginia) Region (us-east-1)\nby default.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nValid Values: af-south-1 | ap-east-1 | ap-northeast-1 | ap-northeast-2 | ap-\nnortheast-3 | ap-south-1 | ap-south-2 | ap-southeast-1 | ap-southeast-2\n| ap-southeast-3 | ca-central-1 | cn-north-1 | cn-northwest-1 | EU | eu-\ncentral-1 | eu-north-1 | eu-south-1 | eu-south-2 | eu-west-1 | eu-west-2\n| eu-west-3 | me-south-1 | sa-east-1 | us-east-2 | us-gov-east-1 | us-\ngov-west-1 | us-west-1 | us-west-2\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1181",
      "start_idx": 1367369,
      "end_idx": 1368228,
      "metadata": {
        "num_sentences": 3,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1187",
      "text": "Amazon Simple Storage Service API Reference\nCSVInput\nService: Amazon S3\nDescribes how an uncompressed comma-separated values (CSV)-formatted input object is\nformatted.\nContents\nAllowQuotedRecordDelimiter\nSpecifies that CSV field values may contain quoted record delimiters and such records should be\nallowed. Default value is FALSE. Setting this value to TRUE may lower performance.\nType: Boolean\nRequired: No\nComments\nA single character used to indicate that a row should be ignored when the character is present\nat the start of that row. You can specify any character to indicate a comment line. The default\ncharacter is #.\nDefault: #\nType: String\nRequired: No\nFieldDelimiter\nA single character used to separate individual fields in a record. You can specify an arbitrary\ndelimiter.\nType: String\nRequired: No\nFileHeaderInfo\nDescribes the first line of input. Valid values are:\n\u2022 NONE: First line is not a header.\nAmazon S3 API Version 2006-03-01 1182",
      "start_idx": 1368230,
      "end_idx": 1369182,
      "metadata": {
        "num_sentences": 12,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1188",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 IGNORE: First line is a header, but you can't use the header values to indicate the column\nin an expression. You can use column position (such as _1, _2, \u2026) to indicate the column\n(SELECT s._1 FROM OBJECT s).\n\u2022 Use: First line is a header, and you can use the header value to identify a column in an\nexpression (SELECT \"name\" FROM OBJECT).\nType: String\nValid Values: USE | IGNORE | NONE\nRequired: No\nQuoteCharacter\nA single character used for escaping when the field delimiter is part of the value. For example, if\nthe value is a, b, Amazon S3 wraps this field value in quotation marks, as follows: \" a , b \".\nType: String\nDefault: \"\nAncestors: CSV\nType: String\nRequired: No\nQuoteEscapeCharacter\nA single character used for escaping the quotation mark character inside an already escaped\nvalue. For example, the value \"\"\" a , b \"\"\" is parsed as \" a , b \".\nType: String\nRequired: No\nRecordDelimiter\nA single character used to separate individual records in the input. Instead of the default value,\nyou can specify an arbitrary delimiter.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1183",
      "start_idx": 1369184,
      "end_idx": 1370330,
      "metadata": {
        "num_sentences": 10,
        "num_words": 202,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1190",
      "text": "Amazon Simple Storage Service API Reference\nCSVOutput\nService: Amazon S3\nDescribes how uncompressed comma-separated values (CSV)-formatted results are formatted.\nContents\nFieldDelimiter\nThe value used to separate individual fields in a record. You can specify an arbitrary delimiter.\nType: String\nRequired: No\nQuoteCharacter\nA single character used for escaping when the field delimiter is part of the value. For example, if\nthe value is a, b, Amazon S3 wraps this field value in quotation marks, as follows: \" a , b \".\nType: String\nRequired: No\nQuoteEscapeCharacter\nThe single character used for escaping the quote character inside an already escaped value.\nType: String\nRequired: No\nQuoteFields\nIndicates whether to use quotation marks around output fields.\n\u2022 ALWAYS: Always use quotation marks for output fields.\n\u2022 ASNEEDED: Use quotation marks for output fields when needed.\nType: String\nValid Values: ALWAYS | ASNEEDED\nRequired: No\nAmazon S3 API Version 2006-03-01 1185",
      "start_idx": 1370589,
      "end_idx": 1371563,
      "metadata": {
        "num_sentences": 10,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1191",
      "text": "Amazon Simple Storage Service API Reference\nRecordDelimiter\nA single character used to separate individual records in the output. Instead of the default\nvalue, you can specify an arbitrary delimiter.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1186",
      "start_idx": 1371565,
      "end_idx": 1372002,
      "metadata": {
        "num_sentences": 3,
        "num_words": 75,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1192",
      "text": "Amazon Simple Storage Service API Reference\nDefaultRetention\nService: Amazon S3\nThe container element for optionally specifying the default Object Lock retention settings for new\nobjects placed in the specified bucket.\nNote\n\u2022 The DefaultRetention settings require both a mode and a period.\n\u2022 The DefaultRetention period can be either Days or Years but you must select one.\nYou cannot specify Days and Years at the same time.\nContents\nDays\nThe number of days that you want to specify for the default retention period. Must be used\nwith Mode.\nType: Integer\nRequired: No\nMode\nThe default Object Lock retention mode you want to apply to new objects placed in the\nspecified bucket. Must be used with either Days or Years.\nType: String\nValid Values: GOVERNANCE | COMPLIANCE\nRequired: No\nYears\nThe number of years that you want to specify for the default retention period. Must be used\nwith Mode.\nType: Integer\nAmazon S3 API Version 2006-03-01 1187",
      "start_idx": 1372004,
      "end_idx": 1372945,
      "metadata": {
        "num_sentences": 11,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1194",
      "text": "Amazon Simple Storage Service API Reference\nDelete\nService: Amazon S3\nContainer for the objects to delete.\nContents\nObjects\nThe object to delete.\nNote\nDirectory buckets - For directory buckets, an object that's composed entirely of\nwhitespace characters is not supported by the DeleteObjects API operation. The\nrequest will receive a 400 Bad Request error and none of the objects in the request\nwill be deleted.\nType: Array of ObjectIdentifier data types\nRequired: Yes\nQuiet\nElement to enable quiet mode for the request. When you add this element, you must set its\nvalue to true.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1189",
      "start_idx": 1373217,
      "end_idx": 1374035,
      "metadata": {
        "num_sentences": 7,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1196",
      "text": "Amazon Simple Storage Service API Reference\nDeletedObject\nService: Amazon S3\nInformation about the deleted object.\nContents\nDeleteMarker\nIndicates whether the specified object version that was permanently deleted was (true) or was\nnot (false) a delete marker before deletion. In a simple DELETE, this header indicates whether\n(true) or not (false) the current version of the object is a delete marker.\nNote\nThis functionality is not supported for directory buckets.\nType: Boolean\nRequired: No\nDeleteMarkerVersionId\nThe version ID of the delete marker created as a result of the DELETE operation. If you delete a\nspecific object version, the value returned by this header is the version ID of the object version\ndeleted.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nKey\nThe name of the deleted object.\nType: String\nAmazon S3 API Version 2006-03-01 1191",
      "start_idx": 1374120,
      "end_idx": 1375016,
      "metadata": {
        "num_sentences": 9,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1200",
      "text": "Amazon Simple Storage Service API Reference\nDeleteMarkerReplication\nService: Amazon S3\nSpecifies whether Amazon S3 replicates delete markers. If you specify a Filter in your replication\nconfiguration, you must also include a DeleteMarkerReplication element. If your Filter\nincludes a Tag element, the DeleteMarkerReplication Status must be set to Disabled,\nbecause Amazon S3 does not support replicating delete markers for tag-based rules. For an\nexample configuration, see Basic Rule Configuration.\nFor more information about delete marker replication, see Basic Rule Configuration.\nNote\nIf you are using an earlier version of the replication configuration, Amazon S3\nhandles replication of delete markers differently. For more information, see Backward\nCompatibility.\nContents\nStatus\nIndicates whether to replicate delete markers.\nNote\nIndicates whether to replicate delete markers.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1195",
      "start_idx": 1376341,
      "end_idx": 1377434,
      "metadata": {
        "num_sentences": 10,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1202",
      "text": "Amazon Simple Storage Service API Reference\nDestination\nService: Amazon S3\nSpecifies information about where to publish analysis or configuration results for an Amazon S3\nbucket and S3 Replication Time Control (S3 RTC).\nContents\nBucket\nThe Amazon Resource Name (ARN) of the bucket where you want Amazon S3 to store the\nresults.\nType: String\nRequired: Yes\nAccessControlTranslation\nSpecify this only in a cross-account scenario (where source and destination bucket owners\nare not the same), and you want to change replica ownership to the AWS account that owns\nthe destination bucket. If this is not specified in the replication configuration, the replicas are\nowned by same AWS account that owns the source object.\nType: AccessControlTranslation data type\nRequired: No\nAccount\nDestination bucket owner account ID. In a cross-account scenario, if you direct Amazon S3 to\nchange replica ownership to the AWS account that owns the destination bucket by specifying\nthe AccessControlTranslation property, this is the account ID of the destination bucket\nowner. For more information, see Replication Additional Configuration: Changing the Replica\nOwner in the Amazon S3 User Guide.\nType: String\nRequired: No\nEncryptionConfiguration\nA container that provides information about encryption. If SourceSelectionCriteria is\nspecified, you must specify this element.\nAmazon S3 API Version 2006-03-01 1197",
      "start_idx": 1377581,
      "end_idx": 1378971,
      "metadata": {
        "num_sentences": 10,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1203",
      "text": "Amazon Simple Storage Service API Reference\nType: EncryptionConfiguration data type\nRequired: No\nMetrics\nA container specifying replication metrics-related settings enabling replication metrics and\nevents.\nType: Metrics data type\nRequired: No\nReplicationTime\nA container specifying S3 Replication Time Control (S3 RTC), including whether S3 RTC is\nenabled and the time when all objects and operations on objects must be replicated. Must be\nspecified together with a Metrics block.\nType: ReplicationTime data type\nRequired: No\nStorageClass\nThe storage class to use when replicating objects, such as S3 Standard or reduced redundancy.\nBy default, Amazon S3 uses the storage class of the source object to create the object replica.\nFor valid values, see the StorageClass element of the PUT Bucket replication action in the\nAmazon S3 API Reference.\nType: String\nValid Values: STANDARD | REDUCED_REDUNDANCY | STANDARD_IA | ONEZONE_IA |\nINTELLIGENT_TIERING | GLACIER | DEEP_ARCHIVE | OUTPOSTS | GLACIER_IR |\nSNOW | EXPRESS_ONEZONE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1198",
      "start_idx": 1378973,
      "end_idx": 1380160,
      "metadata": {
        "num_sentences": 7,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1205",
      "text": "Amazon Simple Storage Service API Reference\nEncryption\nService: Amazon S3\nContains the type of server-side encryption used.\nContents\nEncryptionType\nThe server-side encryption algorithm used when storing job results in Amazon S3 (for example,\nAES256, aws:kms).\nType: String\nValid Values: AES256 | aws:kms | aws:kms:dsse\nRequired: Yes\nKMSContext\nIf the encryption type is aws:kms, this optional value can be used to specify the encryption\ncontext for the restore results.\nType: String\nRequired: No\nKMSKeyId\nIf the encryption type is aws:kms, this optional value specifies the ID of the symmetric\nencryption customer managed key to use for encryption of job results. Amazon S3 only\nsupports symmetric encryption KMS keys. For more information, see Asymmetric keys in AWS\nKMS in the AWS Key Management Service Developer Guide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1200",
      "start_idx": 1380307,
      "end_idx": 1381305,
      "metadata": {
        "num_sentences": 7,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1207",
      "text": "Amazon Simple Storage Service API Reference\nEncryptionConfiguration\nService: Amazon S3\nSpecifies encryption-related information for an Amazon S3 bucket that is a destination for\nreplicated objects.\nNote\nIf you're specifying a customer managed KMS key, we recommend using a fully qualified\nKMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within the\nrequester\u2019s account. This behavior can result in data that's encrypted with a KMS key that\nbelongs to the requester, and not the bucket owner.\nContents\nReplicaKmsKeyID\nSpecifies the ID (Key ARN or Alias ARN) of the customer managed AWS KMS key stored in\nAWS Key Management Service (KMS) for the destination bucket. Amazon S3 uses this key to\nencrypt replica objects. Amazon S3 only supports symmetric encryption KMS keys. For more\ninformation, see Asymmetric keys in AWS KMS in the AWS Key Management Service Developer\nGuide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1202",
      "start_idx": 1381452,
      "end_idx": 1382594,
      "metadata": {
        "num_sentences": 9,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1208",
      "text": "Amazon Simple Storage Service API Reference\nEndEvent\nService: Amazon S3\nA message that indicates the request is complete and no more messages will be sent. You should\nnot assume that the request is complete until the client receives an EndEvent.\nContents\nThe members of this exception structure are context-dependent.\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1203",
      "start_idx": 1382596,
      "end_idx": 1383125,
      "metadata": {
        "num_sentences": 4,
        "num_words": 91,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1209",
      "text": "Amazon Simple Storage Service API Reference\nError\nService: Amazon S3\nContainer for all error elements.\nContents\nCode\nThe error code is a string that uniquely identifies an error condition. It is meant to be read\nand understood by programs that detect and handle errors by type. The following is a list of\nAmazon S3 error codes. For more information, see Error responses.\n\u2022 \u2022 Code: AccessDenied\n\u2022 Description: Access Denied\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: AccountProblem\n\u2022 Description: There is a problem with your AWS account that prevents the action from\ncompleting successfully. Contact AWS Support for further assistance.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: AllAccessDisabled\n\u2022 Description: All access to this Amazon S3 resource has been disabled. Contact AWS Support\nfor further assistance.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: AmbiguousGrantByEmailAddress\n\u2022 Description: The email address you provided is associated with more than one account.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: AuthorizationHeaderMalformed\n\u2022 Description: The authorization header you provided is invalid.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 HTTP Status Code: N/A\nAmazon S3 API Version 2006-03-01 1204",
      "start_idx": 1383127,
      "end_idx": 1384472,
      "metadata": {
        "num_sentences": 12,
        "num_words": 217,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1210",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 \u2022 Code: BadDigest\n\u2022 Description: The Content-MD5 you specified did not match what we received.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: BucketAlreadyExists\n\u2022 Description: The requested bucket name is not available. The bucket namespace is shared\nby all users of the system. Please select a different name and try again.\n\u2022 HTTP Status Code: 409 Conflict\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: BucketAlreadyOwnedByYou\n\u2022 Description: The bucket you tried to create already exists, and you own it. Amazon S3\nreturns this error in all AWS Regions except in the North Virginia Region. For legacy\ncompatibility, if you re-create an existing bucket that you already own in the North Virginia\nRegion, Amazon S3 returns 200 OK and resets the bucket access control lists (ACLs).\n\u2022 Code: 409 Conflict (in all Regions except the North Virginia Region)\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: BucketNotEmpty\n\u2022 Description: The bucket you tried to delete is not empty.\n\u2022 HTTP Status Code: 409 Conflict\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: CredentialsNotSupported\n\u2022 Description: This request does not support credentials.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: CrossLocationLoggingProhibited\n\u2022 Description: Cross-location logging not allowed. Buckets in one geographic location cannot\nlog information to a bucket in another location.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: EntityTooSmall\nAmazon S3 API Version 2006-03-01 1205\n\u2022 Description: Your proposed upload is smaller than the minimum allowed object size.",
      "start_idx": 1384474,
      "end_idx": 1386143,
      "metadata": {
        "num_sentences": 12,
        "num_words": 272,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1211",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: EntityTooLarge\n\u2022 Description: Your proposed upload exceeds the maximum allowed object size.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: ExpiredToken\n\u2022 Description: The provided token has expired.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: IllegalVersioningConfigurationException\n\u2022 Description: Indicates that the versioning configuration specified in the request is invalid.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: IncompleteBody\n\u2022 Description: You did not provide the number of bytes specified by the Content-Length\nHTTP header\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: IncorrectNumberOfFilesInPostRequest\n\u2022 Description: POST requires exactly one file upload per request.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InlineDataTooLarge\n\u2022 Description: Inline data exceeds the maximum allowed size.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InternalError\n\u2022 Description: We encountered an internal error. Please try again.\nAmazon S3 API Version 2006-03-01 1206\n\u2022 HTTP Status Code: 500 Internal Server Error",
      "start_idx": 1386145,
      "end_idx": 1387490,
      "metadata": {
        "num_sentences": 8,
        "num_words": 215,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1212",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 SOAP Fault Code Prefix: Server\n\u2022 \u2022 Code: InvalidAccessKeyId\n\u2022 Description: The AWS access key ID you provided does not exist in our records.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidAddressingHeader\n\u2022 Description: You must specify the Anonymous role.\n\u2022 HTTP Status Code: N/A\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidArgument\n\u2022 Description: Invalid Argument\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidBucketName\n\u2022 Description: The specified bucket is not valid.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidBucketState\n\u2022 Description: The request is not valid with the current state of the bucket.\n\u2022 HTTP Status Code: 409 Conflict\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidDigest\n\u2022 Description: The Content-MD5 you specified is not valid.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidEncryptionAlgorithmError\n\u2022 Description: The encryption request you specified is not valid. The valid value is AES256.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\nAmazon S3 API Version 2006-03-01 1207\n\u2022 \u2022 Code: InvalidLocationConstraint",
      "start_idx": 1387492,
      "end_idx": 1388765,
      "metadata": {
        "num_sentences": 8,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1213",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Description: The specified location constraint is not valid. For more information about\nRegions, see How to Select a Region for Your Buckets.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidObjectState\n\u2022 Description: The action is not valid for the current state of the object.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidPart\n\u2022 Description: One or more of the specified parts could not be found. The part might not\nhave been uploaded, or the specified entity tag might not have matched the part's entity\ntag.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidPartOrder\n\u2022 Description: The list of parts was not in ascending order. Parts list must be specified in order\nby part number.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidPayer\n\u2022 Description: All access to this object has been disabled. Please contact AWS Support for\nfurther assistance.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidPolicyDocument\n\u2022 Description: The content of the form does not meet the conditions specified in the policy\ndocument.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidRange\nAmazon \u2022S3Description: The requested range cannot be satisfied. API Version 2006-03-01 1208",
      "start_idx": 1388767,
      "end_idx": 1390199,
      "metadata": {
        "num_sentences": 12,
        "num_words": 243,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1215",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Code: N/A\n\u2022 \u2022 Code: InvalidRequest\n\u2022 Description: Amazon S3 Transfer Acceleration is not supported on this bucket. Contact AWS\nSupport for more information.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 Code: N/A\n\u2022 \u2022 Code: InvalidRequest\n\u2022 Description: Amazon S3 Transfer Acceleration cannot be enabled on this bucket. Contact\nAWS Support for more information.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 Code: N/A\n\u2022 \u2022 Code: InvalidSecurity\n\u2022 Description: The provided security credentials are not valid.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidSOAPRequest\n\u2022 Description: The SOAP request body is invalid.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidStorageClass\n\u2022 Description: The storage class you specified is not valid.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidTargetBucketForLogging\n\u2022 Description: The target bucket for logging does not exist, is not owned by you, or does not\nhave the appropriate grants for the log-delivery group.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidToken\n\u2022 Description: The provided token is malformed or otherwise invalid.\n\u2022 HTTP Status Code: 400 Bad Request\nAmazon S3 API Version 2006-03-01 1210",
      "start_idx": 1391464,
      "end_idx": 1392799,
      "metadata": {
        "num_sentences": 10,
        "num_words": 220,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1216",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: InvalidURI\n\u2022 Description: Couldn't parse the specified URI.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: KeyTooLongError\n\u2022 Description: Your key is too long.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MalformedACLError\n\u2022 Description: The XML you provided was not well-formed or did not validate against our\npublished schema.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MalformedPOSTRequest\n\u2022 Description: The body of your POST request is not well-formed multipart/form-data.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MalformedXML\n\u2022 Description: This happens when the user sends malformed XML (XML that doesn't conform\nto the published XSD) for the configuration. The error message is, \"The XML you provided\nwas not well-formed or did not validate against our published schema.\"\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MaxMessageLengthExceeded\n\u2022 Description: Your request was too big.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MaxPostPreDataLengthExceededError\n\u2022 Description: Your POST request fields preceding the upload file were too large.\n\u2022 HTTP Status Code: 400 Bad Request\nAmazon S3 API Version 2006-03-01 1211",
      "start_idx": 1392801,
      "end_idx": 1394221,
      "metadata": {
        "num_sentences": 9,
        "num_words": 234,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1217",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MetadataTooLarge\n\u2022 Description: Your metadata headers exceed the maximum allowed metadata size.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MethodNotAllowed\n\u2022 Description: The specified method is not allowed against this resource.\n\u2022 HTTP Status Code: 405 Method Not Allowed\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MissingAttachment\n\u2022 Description: A SOAP attachment was expected, but none were found.\n\u2022 HTTP Status Code: N/A\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MissingContentLength\n\u2022 Description: You must provide the Content-Length HTTP header.\n\u2022 HTTP Status Code: 411 Length Required\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MissingRequestBodyError\n\u2022 Description: This happens when the user sends an empty XML document as a request. The\nerror message is, \"Request body is empty.\"\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MissingSecurityElement\n\u2022 Description: The SOAP 1.1 request is missing a security element.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: MissingSecurityHeader\n\u2022 Description: Your request is missing a required header.\n\u2022 HTTP Status Code: 400 Bad Request\nAmazon S3 API Version 2006-03-01 1212\n\u2022 SOAP Fault Code Prefix: Client",
      "start_idx": 1394223,
      "end_idx": 1395572,
      "metadata": {
        "num_sentences": 9,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1218",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 \u2022 Code: NoLoggingStatusForKey\n\u2022 Description: There is no such thing as a logging status subresource for a key.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NoSuchBucket\n\u2022 Description: The specified bucket does not exist.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NoSuchBucketPolicy\n\u2022 Description: The specified bucket does not have a bucket policy.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NoSuchKey\n\u2022 Description: The specified key does not exist.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NoSuchLifecycleConfiguration\n\u2022 Description: The lifecycle configuration does not exist.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NoSuchUpload\n\u2022 Description: The specified multipart upload does not exist. The upload ID might be invalid,\nor the multipart upload might have been aborted or completed.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NoSuchVersion\n\u2022 Description: Indicates that the version ID specified in the request does not match an existing\nversion.\n\u2022 HTTP Status Code: 404 Not Found\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: NotImplemented\nAmazon S3 API Version 2006-03-01 1213",
      "start_idx": 1395574,
      "end_idx": 1396911,
      "metadata": {
        "num_sentences": 9,
        "num_words": 227,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1219",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Description: A header you provided implies functionality that is not implemented.\n\u2022 HTTP Status Code: 501 Not Implemented\n\u2022 SOAP Fault Code Prefix: Server\n\u2022 \u2022 Code: NotSignedUp\n\u2022 Description: Your account is not signed up for the Amazon S3 service. You must sign up\nbefore you can use Amazon S3. You can sign up at the following URL: Amazon S3\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: OperationAborted\n\u2022 Description: A conflicting conditional action is currently in progress against this resource.\nTry again.\n\u2022 HTTP Status Code: 409 Conflict\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: PermanentRedirect\n\u2022 Description: The bucket you are attempting to access must be addressed using the specified\nendpoint. Send all future requests to this endpoint.\n\u2022 HTTP Status Code: 301 Moved Permanently\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: PreconditionFailed\n\u2022 Description: At least one of the preconditions you specified did not hold.\n\u2022 HTTP Status Code: 412 Precondition Failed\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: Redirect\n\u2022 Description: Temporary redirect.\n\u2022 HTTP Status Code: 307 Moved Temporarily\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: RestoreAlreadyInProgress\n\u2022 Description: Object restore is already in progress.\n\u2022 HTTP Status Code: 409 Conflict\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: RequestIsNotMultiPartContent\nAmazon S3 API Version 2006-03-01 1214",
      "start_idx": 1396913,
      "end_idx": 1398362,
      "metadata": {
        "num_sentences": 11,
        "num_words": 236,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1220",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Description: Bucket POST must be of the enclosure-type multipart/form-data.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: RequestTimeout\n\u2022 Description: Your socket connection to the server was not read from or written to within the\ntimeout period.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: RequestTimeTooSkewed\n\u2022 Description: The difference between the request time and the server's time is too large.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: RequestTorrentOfBucketError\n\u2022 Description: Requesting the torrent file of a bucket is not permitted.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: SignatureDoesNotMatch\n\u2022 Description: The request signature we calculated does not match the signature you\nprovided. Check your AWS secret access key and signing method. For more information, see\nREST Authentication and SOAP Authentication for details.\n\u2022 HTTP Status Code: 403 Forbidden\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: ServiceUnavailable\n\u2022 Description: Service is unable to handle request.\n\u2022 HTTP Status Code: 503 Service Unavailable\n\u2022 SOAP Fault Code Prefix: Server\n\u2022 \u2022 Code: SlowDown\n\u2022 Description: Reduce your request rate.\n\u2022 HTTP Status Code: 503 Slow Down\n\u2022 SOAP Fault Code Prefix: Server\n\u2022 \u2022 Code: TemporaryRedirect\nAmazon S3 API Version 2006-03-01 1215",
      "start_idx": 1398364,
      "end_idx": 1399808,
      "metadata": {
        "num_sentences": 10,
        "num_words": 233,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1221",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Description: You are being redirected to the bucket while DNS updates.\n\u2022 HTTP Status Code: 307 Moved Temporarily\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: TokenRefreshRequired\n\u2022 Description: The provided token must be refreshed.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: TooManyBuckets\n\u2022 Description: You have attempted to create more buckets than allowed.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: UnexpectedContent\n\u2022 Description: This request does not support content.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: UnresolvableGrantByEmailAddress\n\u2022 Description: The email address you provided does not match any account on record.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\n\u2022 \u2022 Code: UserKeyMustBeSpecified\n\u2022 Description: The bucket POST must contain the specified field name. If it is specified, check\nthe order of the fields.\n\u2022 HTTP Status Code: 400 Bad Request\n\u2022 SOAP Fault Code Prefix: Client\nType: String\nRequired: No\nKey\nThe error key.\nType: String\nAmazon S3 API Version 2006-03-01 1216",
      "start_idx": 1399810,
      "end_idx": 1400984,
      "metadata": {
        "num_sentences": 9,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1222",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1.\nRequired: No\nMessage\nThe error message contains a generic description of the error condition in English. It is intended\nfor a human audience. Simple programs display the message directly to the end user if they\nencounter an error condition they don't know how or don't care to handle. Sophisticated\nprograms with more exhaustive error handling and proper internationalization are more likely\nto ignore the error message.\nType: String\nRequired: No\nVersionId\nThe version ID of the error.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1217",
      "start_idx": 1400986,
      "end_idx": 1401858,
      "metadata": {
        "num_sentences": 8,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1223",
      "text": "Amazon Simple Storage Service API Reference\nErrorDocument\nService: Amazon S3\nThe error information.\nContents\nKey\nThe object key name to use when a 4XX class error occurs.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1218",
      "start_idx": 1401860,
      "end_idx": 1402505,
      "metadata": {
        "num_sentences": 6,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1225",
      "text": "Amazon Simple Storage Service API Reference\nExistingObjectReplication\nService: Amazon S3\nOptional configuration to replicate existing source bucket objects.\nNote\nThis parameter is no longer supported. To replicate existing objects, see Replicating existing\nobjects with S3 Batch Replication in the Amazon S3 User Guide.\nContents\nStatus\nSpecifies whether Amazon S3 replicates existing source bucket objects.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1220",
      "start_idx": 1402949,
      "end_idx": 1403627,
      "metadata": {
        "num_sentences": 5,
        "num_words": 105,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1226",
      "text": "Amazon Simple Storage Service API Reference\nFilterRule\nService: Amazon S3\nSpecifies the Amazon S3 object key name to filter on. An object key name is the name assigned\nto an object in your Amazon S3 bucket. You specify whether to filter on the suffix or prefix of the\nobject key name. A prefix is a specific string of characters at the beginning of an object key name,\nwhich you can use to organize objects. For example, you can start the key names of related objects\nwith a prefix, such as 2023- or engineering/. Then, you can use FilterRule to find objects in\na bucket with key names that have the same prefix. A suffix is similar to a prefix, but it is at the end\nof the object key name instead of at the beginning.\nContents\nName\nThe object key name prefix or suffix identifying one or more objects to which the filtering rule\napplies. The maximum length is 1,024 characters. Overlapping prefixes and suffixes are not\nsupported. For more information, see Configuring Event Notifications in the Amazon S3 User\nGuide.\nType: String\nValid Values: prefix | suffix\nRequired: No\nValue\nThe value that the filter searches for in object key names.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\nAmazon S3 API Version 2006-03-01 1221",
      "start_idx": 1403629,
      "end_idx": 1404985,
      "metadata": {
        "num_sentences": 13,
        "num_words": 242,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1228",
      "text": "Amazon Simple Storage Service API Reference\nGetObjectAttributesParts\nService: Amazon S3\nA collection of parts associated with a multipart upload.\nContents\nIsTruncated\nIndicates whether the returned list of parts is truncated. A value of true indicates that the list\nwas truncated. A list can be truncated if the number of parts exceeds the limit returned in the\nMaxParts element.\nType: Boolean\nRequired: No\nMaxParts\nThe maximum number of parts allowed in the response.\nType: Integer\nRequired: No\nNextPartNumberMarker\nWhen a list is truncated, this element specifies the last part in the list, as well as the value to\nuse for the PartNumberMarker request parameter in a subsequent request.\nType: Integer\nRequired: No\nPartNumberMarker\nThe marker for the current part.\nType: Integer\nRequired: No\nParts\nA container for elements related to a particular part. A response can contain zero or more\nParts elements.\nAmazon S3 API Version 2006-03-01 1223",
      "start_idx": 1405092,
      "end_idx": 1406035,
      "metadata": {
        "num_sentences": 10,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1232",
      "text": "Amazon Simple Storage Service API Reference\nGrantee\nService: Amazon S3\nContainer for the person being granted permissions.\nContents\nType\nType of grantee\nType: String\nValid Values: CanonicalUser | AmazonCustomerByEmail | Group\nRequired: Yes\nDisplayName\nScreen name of the grantee.\nType: String\nRequired: No\nEmailAddress\nEmail address of the grantee.\nNote\nUsing email addresses to specify a grantee is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nAmazon S3 API Version 2006-03-01 1227",
      "start_idx": 1407886,
      "end_idx": 1408558,
      "metadata": {
        "num_sentences": 4,
        "num_words": 105,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1234",
      "text": "Amazon Simple Storage Service API Reference\nIndexDocument\nService: Amazon S3\nContainer for the Suffix element.\nContents\nSuffix\nA suffix that is appended to a request that is for a directory on the website endpoint. (For\nexample, if the suffix is index.html and you make a request to samplebucket/images/, the\ndata that is returned will be for the object with the key name images/index.html.) The suffix\nmust not be empty and must not include a slash character.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1229",
      "start_idx": 1409087,
      "end_idx": 1409981,
      "metadata": {
        "num_sentences": 7,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1235",
      "text": "Amazon Simple Storage Service API Reference\nInitiator\nService: Amazon S3\nContainer element that identifies who initiated the multipart upload.\nContents\nDisplayName\nName of the Principal.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nID\nIf the principal is an AWS account, it provides the Canonical User ID. If the principal is an IAM\nUser, it provides a user ARN value.\nNote\nDirectory buckets - If the principal is an AWS account, it provides the AWS account ID. If\nthe principal is an IAM User, it provides a user ARN value.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1230",
      "start_idx": 1409983,
      "end_idx": 1410746,
      "metadata": {
        "num_sentences": 8,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1237",
      "text": "Amazon Simple Storage Service API Reference\nInputSerialization\nService: Amazon S3\nDescribes the serialization format of the object.\nContents\nCompressionType\nSpecifies object's compression format. Valid values: NONE, GZIP, BZIP2. Default Value: NONE.\nType: String\nValid Values: NONE | GZIP | BZIP2\nRequired: No\nCSV\nDescribes the serialization of a CSV-encoded object.\nType: CSVInput data type\nRequired: No\nJSON\nSpecifies JSON as object's input serialization format.\nType: JSONInput data type\nRequired: No\nParquet\nSpecifies Parquet as object's input serialization format.\nType: ParquetInput data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1232",
      "start_idx": 1410875,
      "end_idx": 1411636,
      "metadata": {
        "num_sentences": 8,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1239",
      "text": "Amazon Simple Storage Service API Reference\nIntelligentTieringAndOperator\nService: Amazon S3\nA container for specifying S3 Intelligent-Tiering filters. The filters determine the subset of objects\nto which the rule applies.\nContents\nPrefix\nAn object key name prefix that identifies the subset of objects to which the configuration\napplies.\nType: String\nRequired: No\nTags\nAll of these tags must exist in the object's tag set in order for the configuration to apply.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1234",
      "start_idx": 1411783,
      "end_idx": 1412501,
      "metadata": {
        "num_sentences": 5,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1240",
      "text": "Amazon Simple Storage Service API Reference\nIntelligentTieringConfiguration\nService: Amazon S3\nSpecifies the S3 Intelligent-Tiering configuration for an Amazon S3 bucket.\nFor information about the S3 Intelligent-Tiering storage class, see Storage class for automatically\noptimizing frequently and infrequently accessed objects.\nContents\nId\nThe ID used to identify the S3 Intelligent-Tiering configuration.\nType: String\nRequired: Yes\nStatus\nSpecifies the status of the configuration.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nTierings\nSpecifies the S3 Intelligent-Tiering storage class tier of the configuration.\nType: Array of Tiering data types\nRequired: Yes\nFilter\nSpecifies a bucket filter. The configuration only includes objects that meet the filter's criteria.\nType: IntelligentTieringFilter data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1235",
      "start_idx": 1412503,
      "end_idx": 1413379,
      "metadata": {
        "num_sentences": 8,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1242",
      "text": "Amazon Simple Storage Service API Reference\nIntelligentTieringFilter\nService: Amazon S3\nThe Filter is used to identify objects that the S3 Intelligent-Tiering configuration applies to.\nContents\nAnd\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics filter. The\noperator must have at least two predicates, and an object must match all of the predicates in\norder for the filter to apply.\nType: IntelligentTieringAndOperator data type\nRequired: No\nPrefix\nAn object key name prefix that identifies the subset of objects to which the rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nTag\nA container of a key value name pair.\nType: Tag data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1237",
      "start_idx": 1413638,
      "end_idx": 1414656,
      "metadata": {
        "num_sentences": 8,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1244",
      "text": "Amazon Simple Storage Service API Reference\nInventoryConfiguration\nService: Amazon S3\nSpecifies the inventory configuration for an Amazon S3 bucket. For more information, see GET\nBucket inventory in the Amazon S3 API Reference.\nContents\nDestination\nContains information about where to publish the inventory results.\nType: InventoryDestination data type\nRequired: Yes\nId\nThe ID used to identify the inventory configuration.\nType: String\nRequired: Yes\nIncludedObjectVersions\nObject versions to include in the inventory list. If set to All, the list includes all the object\nversions, which adds the version-related fields VersionId, IsLatest, and DeleteMarker to\nthe list. If set to Current, the list does not contain these version-related fields.\nType: String\nValid Values: All | Current\nRequired: Yes\nIsEnabled\nSpecifies whether the inventory is enabled or disabled. If set to True, an inventory list is\ngenerated. If set to False, no inventory list is generated.\nType: Boolean\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1239",
      "start_idx": 1414803,
      "end_idx": 1415831,
      "metadata": {
        "num_sentences": 11,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1245",
      "text": "Amazon Simple Storage Service API Reference\nSchedule\nSpecifies the schedule for generating inventory results.\nType: InventorySchedule data type\nRequired: Yes\nFilter\nSpecifies an inventory filter. The inventory only includes objects that meet the filter's criteria.\nType: InventoryFilter data type\nRequired: No\nOptionalFields\nContains the optional fields that are included in the inventory results.\nType: Array of strings\nValid Values: Size | LastModifiedDate | StorageClass | ETag |\nIsMultipartUploaded | ReplicationStatus | EncryptionStatus |\nObjectLockRetainUntilDate | ObjectLockMode | ObjectLockLegalHoldStatus\n| IntelligentTieringAccessTier | BucketKeyStatus | ChecksumAlgorithm |\nObjectAccessControlList | ObjectOwner\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1240",
      "start_idx": 1415833,
      "end_idx": 1416781,
      "metadata": {
        "num_sentences": 5,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1248",
      "text": "Amazon Simple Storage Service API Reference\nInventoryFilter\nService: Amazon S3\nSpecifies an inventory filter. The inventory only includes objects that meet the filter's criteria.\nContents\nPrefix\nThe prefix that an object must have to be included in the inventory results.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1243",
      "start_idx": 1417965,
      "end_idx": 1418475,
      "metadata": {
        "num_sentences": 4,
        "num_words": 86,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1249",
      "text": "Amazon Simple Storage Service API Reference\nInventoryS3BucketDestination\nService: Amazon S3\nContains the bucket name, file format, bucket owner (optional), and prefix (optional) where\ninventory results are published.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the bucket where inventory results will be published.\nType: String\nRequired: Yes\nFormat\nSpecifies the output format of the inventory results.\nType: String\nValid Values: CSV | ORC | Parquet\nRequired: Yes\nAccountId\nThe account ID that owns the destination S3 bucket. If no account ID is provided, the owner is\nnot validated before exporting data.\nNote\nAlthough this value is optional, we strongly recommend that you set it to help prevent\nproblems if the destination bucket ownership changes.\nType: String\nRequired: No\nEncryption\nContains the type of server-side encryption used to encrypt the inventory results.\nAmazon S3 API Version 2006-03-01 1244",
      "start_idx": 1418477,
      "end_idx": 1419392,
      "metadata": {
        "num_sentences": 8,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1252",
      "text": "Amazon Simple Storage Service API Reference\nJSONInput\nService: Amazon S3\nSpecifies JSON as object's input serialization format.\nContents\nType\nThe type of JSON. Valid values: Document, Lines.\nType: String\nValid Values: DOCUMENT | LINES\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1247",
      "start_idx": 1420271,
      "end_idx": 1420730,
      "metadata": {
        "num_sentences": 4,
        "num_words": 78,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1253",
      "text": "Amazon Simple Storage Service API Reference\nJSONOutput\nService: Amazon S3\nSpecifies JSON as request's output serialization format.\nContents\nRecordDelimiter\nThe value used to separate individual records in the output. If no value is specified, Amazon S3\nuses a newline character ('\\n').\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1248",
      "start_idx": 1420732,
      "end_idx": 1421255,
      "metadata": {
        "num_sentences": 4,
        "num_words": 87,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1254",
      "text": "Amazon Simple Storage Service API Reference\nLambdaFunctionConfiguration\nService: Amazon S3\nA container for specifying the configuration for AWS Lambda notifications.\nContents\nEvents\nThe Amazon S3 bucket event for which to invoke the AWS Lambda function. For more\ninformation, see Supported Event Types in the Amazon S3 User Guide.\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: Yes\nLambdaFunctionArn\nThe Amazon Resource Name (ARN) of the AWS Lambda function that Amazon S3 invokes when\nthe specified event type occurs.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1249",
      "start_idx": 1421257,
      "end_idx": 1422627,
      "metadata": {
        "num_sentences": 5,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1255",
      "text": "Amazon Simple Storage Service API Reference\nFilter\nSpecifies object key name filtering rules. For information about key name filtering, see\nConfiguring event notifications using object key name filtering in the Amazon S3 User Guide.\nType: NotificationConfigurationFilter data type\nRequired: No\nId\nAn optional unique identifier for configurations in a notification configuration. If you don't\nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1250",
      "start_idx": 1422629,
      "end_idx": 1423300,
      "metadata": {
        "num_sentences": 5,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1256",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleConfiguration\nService: Amazon S3\nContainer for lifecycle rules. You can add as many as 1000 rules.\nFor more information see, Managing your storage lifecycle in the Amazon S3 User Guide.\nContents\nRules\nSpecifies lifecycle configuration rules for an Amazon S3 bucket.\nType: Array of Rule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1251",
      "start_idx": 1423302,
      "end_idx": 1423877,
      "metadata": {
        "num_sentences": 5,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1257",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleExpiration\nService: Amazon S3\nContainer for the expiration for the lifecycle of the object.\nFor more information see, Managing your storage lifecycle in the Amazon S3 User Guide.\nContents\nDate\nIndicates at what date the object is to be moved or deleted. The date value must conform to the\nISO 8601 format. The time is always midnight UTC.\nType: Timestamp\nRequired: No\nDays\nIndicates the lifetime, in days, of the objects that are subject to the rule. The value must be a\nnon-zero positive integer.\nType: Integer\nRequired: No\nExpiredObjectDeleteMarker\nIndicates whether Amazon S3 will remove a delete marker with no noncurrent versions. If set to\ntrue, the delete marker will be expired; if set to false the policy takes no action. This cannot be\nspecified with Days or Date in a Lifecycle Expiration Policy.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1252",
      "start_idx": 1423879,
      "end_idx": 1424934,
      "metadata": {
        "num_sentences": 11,
        "num_words": 175,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1259",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleRule\nService: Amazon S3\nA lifecycle rule for individual objects in an Amazon S3 bucket.\nFor more information see, Managing your storage lifecycle in the Amazon S3 User Guide.\nContents\nStatus\nIf 'Enabled', the rule is currently being applied. If 'Disabled', the rule is not currently being\napplied.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nAbortIncompleteMultipartUpload\nSpecifies the days since the initiation of an incomplete multipart upload that Amazon S3 will\nwait before permanently removing all parts of the upload. For more information, see Aborting\nIncomplete Multipart Uploads Using a Bucket Lifecycle Configuration in the Amazon S3 User\nGuide.\nType: AbortIncompleteMultipartUpload data type\nRequired: No\nExpiration\nSpecifies the expiration for the lifecycle of the object in the form of date, days and, whether the\nobject has a delete marker.\nType: LifecycleExpiration data type\nRequired: No\nFilter\nThe Filter is used to identify objects that a Lifecycle Rule applies to. A Filter must have\nexactly one of Prefix, Tag, or And specified. Filter is required if the LifecycleRule does\nnot contain a Prefix element.\nAmazon S3 API Version 2006-03-01 1254",
      "start_idx": 1425063,
      "end_idx": 1426294,
      "metadata": {
        "num_sentences": 11,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1260",
      "text": "Amazon Simple Storage Service API Reference\nType: LifecycleRuleFilter data type\nRequired: No\nID\nUnique identifier for the rule. The value cannot be longer than 255 characters.\nType: String\nRequired: No\nNoncurrentVersionExpiration\nSpecifies when noncurrent object versions expire. Upon expiration, Amazon S3 permanently\ndeletes the noncurrent object versions. You set this lifecycle configuration action on a bucket\nthat has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object\nversions at a specific period in the object's lifetime.\nType: NoncurrentVersionExpiration data type\nRequired: No\nNoncurrentVersionTransitions\nSpecifies the transition rule for the lifecycle rule that describes when noncurrent objects\ntransition to a specific storage class. If your bucket is versioning-enabled (or versioning is\nsuspended), you can set this action to request that Amazon S3 transition noncurrent object\nversions to a specific storage class at a set period in the object's lifetime.\nType: Array of NoncurrentVersionTransition data types\nRequired: No\nPrefix\nThis member has been deprecated.\nPrefix identifying one or more objects to which the rule applies. This is no longer used; use\nFilter instead.\nAmazon S3 API Version 2006-03-01 1255",
      "start_idx": 1426296,
      "end_idx": 1427558,
      "metadata": {
        "num_sentences": 11,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1261",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nTransitions\nSpecifies when an Amazon S3 object transitions to a specified storage class.\nType: Array of Transition data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1256",
      "start_idx": 1427560,
      "end_idx": 1428175,
      "metadata": {
        "num_sentences": 4,
        "num_words": 101,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1262",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleRuleAndOperator\nService: Amazon S3\nThis is used in a Lifecycle Rule Filter to apply a logical AND to two or more predicates. The Lifecycle\nRule will apply to any object matching all of the predicates configured inside the And operator.\nContents\nObjectSizeGreaterThan\nMinimum object size to which the rule applies.\nType: Long\nRequired: No\nObjectSizeLessThan\nMaximum object size to which the rule applies.\nType: Long\nRequired: No\nPrefix\nPrefix identifying one or more objects to which the rule applies.\nType: String\nRequired: No\nTags\nAll of these tags must exist in the object's tag set in order for the rule to apply.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1257",
      "start_idx": 1428177,
      "end_idx": 1429039,
      "metadata": {
        "num_sentences": 7,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1264",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleRuleFilter\nService: Amazon S3\nThe Filter is used to identify objects that a Lifecycle Rule applies to. A Filter can have exactly\none of Prefix, Tag, ObjectSizeGreaterThan, ObjectSizeLessThan, or And specified. If the\nFilter element is left empty, the Lifecycle Rule applies to all objects in the bucket.\nContents\nAnd\nThis is used in a Lifecycle Rule Filter to apply a logical AND to two or more predicates. The\nLifecycle Rule will apply to any object matching all of the predicates configured inside the And\noperator.\nType: LifecycleRuleAndOperator data type\nRequired: No\nObjectSizeGreaterThan\nMinimum object size to which the rule applies.\nType: Long\nRequired: No\nObjectSizeLessThan\nMaximum object size to which the rule applies.\nType: Long\nRequired: No\nPrefix\nPrefix identifying one or more objects to which the rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nAmazon S3 API Version 2006-03-01 1259",
      "start_idx": 1429186,
      "end_idx": 1430299,
      "metadata": {
        "num_sentences": 11,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1266",
      "text": "Amazon Simple Storage Service API Reference\nLocationInfo\nService: Amazon S3\nSpecifies the location where the bucket will be created.\nFor directory buckets, the location type is Availability Zone. For more information about directory\nbuckets, see Directory buckets in the Amazon S3 User Guide.\nNote\nThis functionality is only supported by directory buckets.\nContents\nName\nThe name of the location where the bucket will be created.\nFor directory buckets, the name of the location is the AZ ID of the Availability Zone where the\nbucket will be created. An example AZ ID value is usw2-az1.\nType: String\nRequired: No\nType\nThe type of location where the bucket will be created.\nType: String\nValid Values: AvailabilityZone\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1261",
      "start_idx": 1430697,
      "end_idx": 1431593,
      "metadata": {
        "num_sentences": 9,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1268",
      "text": "Amazon Simple Storage Service API Reference\nLoggingEnabled\nService: Amazon S3\nDescribes where logs are stored and the prefix that Amazon S3 assigns to all log object keys for a\nbucket. For more information, see PUT Bucket logging in the Amazon S3 API Reference.\nContents\nTargetBucket\nSpecifies the bucket where you want Amazon S3 to store server access logs. You can have your\nlogs delivered to any bucket that you own, including the same bucket that is being logged. You\ncan also configure multiple buckets to deliver their logs to the same target bucket. In this case,\nyou should choose a different TargetPrefix for each source bucket so that the delivered log\nfiles can be distinguished by key.\nType: String\nRequired: Yes\nTargetPrefix\nA prefix for all log object keys. If you store log files from multiple Amazon S3 buckets in a single\nbucket, you can use a prefix to distinguish which log files came from which bucket.\nType: String\nRequired: Yes\nTargetGrants\nContainer for granting information.\nBuckets that use the bucket owner enforced setting for Object Ownership don't support target\ngrants. For more information, see Permissions for server access log delivery in the Amazon S3\nUser Guide.\nType: Array of TargetGrant data types\nRequired: No\nTargetObjectKeyFormat\nAmazon S3 key format for log objects.\nAmazon S3 API Version 2006-03-01 1263",
      "start_idx": 1431722,
      "end_idx": 1433068,
      "metadata": {
        "num_sentences": 13,
        "num_words": 219,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1272",
      "text": "Amazon Simple Storage Service API Reference\nMetricsAndOperator\nService: Amazon S3\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics filter. The operator\nmust have at least two predicates, and an object must match all of the predicates in order for the\nfilter to apply.\nContents\nAccessPointArn\nThe access point ARN used when evaluating an AND predicate.\nType: String\nRequired: No\nPrefix\nThe prefix used when evaluating an AND predicate.\nType: String\nRequired: No\nTags\nThe list of tags used when evaluating an AND predicate.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1267",
      "start_idx": 1434519,
      "end_idx": 1435327,
      "metadata": {
        "num_sentences": 6,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1273",
      "text": "Amazon Simple Storage Service API Reference\nMetricsConfiguration\nService: Amazon S3\nSpecifies a metrics configuration for the CloudWatch request metrics (specified by the\nmetrics configuration ID) from an Amazon S3 bucket. If you're updating an existing metrics\nconfiguration, note that this is a full replacement of the existing metrics configuration. If\nyou don't include the elements you want to keep, they are erased. For more information, see\nPutBucketMetricsConfiguration.\nContents\nId\nThe ID used to identify the metrics configuration. The ID has a 64 character limit and can only\ncontain letters, numbers, periods, dashes, and underscores.\nType: String\nRequired: Yes\nFilter\nSpecifies a metrics configuration filter. The metrics configuration will only include objects\nthat meet the filter's criteria. A filter must be a prefix, an object tag, an access point ARN, or a\nconjunction (MetricsAndOperator).\nType: MetricsFilter data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1268",
      "start_idx": 1435329,
      "end_idx": 1436493,
      "metadata": {
        "num_sentences": 10,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1274",
      "text": "Amazon Simple Storage Service API Reference\nMetricsFilter\nService: Amazon S3\nSpecifies a metrics configuration filter. The metrics configuration only includes objects that meet\nthe filter's criteria. A filter must be a prefix, an object tag, an access point ARN, or a conjunction\n(MetricsAndOperator). For more information, see PutBucketMetricsConfiguration.\nContents\nAccessPointArn\nThe access point ARN used when evaluating a metrics filter.\nType: String\nRequired: No\nAnd\nA conjunction (logical AND) of predicates, which is used in evaluating a metrics filter. The\noperator must have at least two predicates, and an object must match all of the predicates in\norder for the filter to apply.\nType: MetricsAndOperator data type\nRequired: No\nPrefix\nThe prefix used when evaluating a metrics filter.\nType: String\nRequired: No\nTag\nThe tag used when evaluating a metrics filter.\nType: Tag data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1269",
      "start_idx": 1436495,
      "end_idx": 1437438,
      "metadata": {
        "num_sentences": 10,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1279",
      "text": "Amazon Simple Storage Service API Reference\nNoncurrentVersionExpiration\nService: Amazon S3\nSpecifies when noncurrent object versions expire. Upon expiration, Amazon S3 permanently\ndeletes the noncurrent object versions. You set this lifecycle configuration action on a bucket\nthat has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object\nversions at a specific period in the object's lifetime.\nContents\nNewerNoncurrentVersions\nSpecifies how many noncurrent versions Amazon S3 will retain. You can specify up to 100\nnoncurrent versions to retain. Amazon S3 will permanently delete any additional noncurrent\nversions beyond the specified number to retain. For more information about noncurrent\nversions, see Lifecycle configuration elements in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nNoncurrentDays\nSpecifies the number of days an object is noncurrent before Amazon S3 can perform the\nassociated action. The value must be a non-zero positive integer. For information about\nthe noncurrent days calculations, see How Amazon S3 Calculates When an Object Became\nNoncurrent in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1274",
      "start_idx": 1439370,
      "end_idx": 1440749,
      "metadata": {
        "num_sentences": 11,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1281",
      "text": "Amazon Simple Storage Service API Reference\nNoncurrentVersionTransition\nService: Amazon S3\nContainer for the transition rule that describes when noncurrent objects transition to\nthe STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, GLACIER_IR, GLACIER, or\nDEEP_ARCHIVE storage class. If your bucket is versioning-enabled (or versioning is suspended),\nyou can set this action to request that Amazon S3 transition noncurrent object versions to\nthe STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, GLACIER_IR, GLACIER, or\nDEEP_ARCHIVE storage class at a specific period in the object's lifetime.\nContents\nNewerNoncurrentVersions\nSpecifies how many noncurrent versions Amazon S3 will retain in the same storage class before\ntransitioning objects. You can specify up to 100 noncurrent versions to retain. Amazon S3 will\ntransition any additional noncurrent versions beyond the specified number to retain. For more\ninformation about noncurrent versions, see Lifecycle configuration elements in the Amazon S3\nUser Guide.\nType: Integer\nRequired: No\nNoncurrentDays\nSpecifies the number of days an object is noncurrent before Amazon S3 can perform the\nassociated action. For information about the noncurrent days calculations, see How Amazon S3\nCalculates How Long an Object Has Been Noncurrent in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING |\nDEEP_ARCHIVE | GLACIER_IR\nAmazon S3 API Version 2006-03-01 1276",
      "start_idx": 1440834,
      "end_idx": 1442377,
      "metadata": {
        "num_sentences": 10,
        "num_words": 215,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1283",
      "text": "Amazon Simple Storage Service API Reference\nNotificationConfiguration\nService: Amazon S3\nA container for specifying the notification configuration of the bucket. If this element is empty,\nnotifications are turned off for the bucket.\nContents\nEventBridgeConfiguration\nEnables delivery of events to Amazon EventBridge.\nType: EventBridgeConfiguration data type\nRequired: No\nLambdaFunctionConfigurations\nDescribes the AWS Lambda functions to invoke and the events for which to invoke them.\nType: Array of LambdaFunctionConfiguration data types\nRequired: No\nQueueConfigurations\nThe Amazon Simple Queue Service queues to publish messages to and the events for which to\npublish messages.\nType: Array of QueueConfiguration data types\nRequired: No\nTopicConfigurations\nThe topic to which notifications are sent and the events for which notifications are generated.\nType: Array of TopicConfiguration data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1278",
      "start_idx": 1442649,
      "end_idx": 1443711,
      "metadata": {
        "num_sentences": 7,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1285",
      "text": "Amazon Simple Storage Service API Reference\nNotificationConfigurationDeprecated\nService: Amazon S3\nContents\nCloudFunctionConfiguration\nContainer for specifying the AWS Lambda notification configuration.\nType: CloudFunctionConfiguration data type\nRequired: No\nQueueConfiguration\nThis data type is deprecated. This data type specifies the configuration for publishing messages\nto an Amazon Simple Queue Service (Amazon SQS) queue when Amazon S3 detects specified\nevents.\nType: QueueConfigurationDeprecated data type\nRequired: No\nTopicConfiguration\nThis data type is deprecated. A container for specifying the configuration for publication of\nmessages to an Amazon Simple Notification Service (Amazon SNS) topic when Amazon S3\ndetects specified events.\nType: TopicConfigurationDeprecated data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1280",
      "start_idx": 1443858,
      "end_idx": 1444877,
      "metadata": {
        "num_sentences": 6,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1286",
      "text": "Amazon Simple Storage Service API Reference\nNotificationConfigurationFilter\nService: Amazon S3\nSpecifies object key name filtering rules. For information about key name filtering, see Configuring\nevent notifications using object key name filtering in the Amazon S3 User Guide.\nContents\nKey\nA container for object key name prefix and suffix filtering rules.\nType: S3KeyFilter data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1281",
      "start_idx": 1444879,
      "end_idx": 1445488,
      "metadata": {
        "num_sentences": 4,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1287",
      "text": "Amazon Simple Storage Service API Reference\nObject\nService: Amazon S3\nAn object consists of data and its descriptive metadata.\nContents\nChecksumAlgorithm\nThe algorithm that was used to create a checksum of the object.\nType: Array of strings\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequired: No\nETag\nThe entity tag is a hash of the object. The ETag reflects changes only to the contents of an\nobject, not its metadata. The ETag may or may not be an MD5 digest of the object data.\nWhether or not it is depends on how the object was created and how it is encrypted as\ndescribed below:\n\u2022 Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS\nManagement Console, and are encrypted by SSE-S3 or plaintext, have ETags that are an MD5\ndigest of their object data.\n\u2022 Objects created by the PUT Object, POST Object, or Copy operation, or through the AWS\nManagement Console, and are encrypted by SSE-C or SSE-KMS, have ETags that are not an\nMD5 digest of their object data.\n\u2022 If an object is created by either the Multipart Upload or Part Copy operation, the ETag is not\nan MD5 digest, regardless of the method of encryption. If an object is larger than 16 MB,\nthe AWS Management Console will upload or copy that object as a Multipart Upload, and\ntherefore the ETag will not be an MD5 digest.\nNote\nDirectory buckets - MD5 is not supported by directory buckets.\nType: String\nAmazon S3 API Version 2006-03-01 1282",
      "start_idx": 1445490,
      "end_idx": 1446927,
      "metadata": {
        "num_sentences": 11,
        "num_words": 258,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1288",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nKey\nThe name that you assign to an object. You use the object key to retrieve the object.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: No\nLastModified\nCreation date of the object.\nType: Timestamp\nRequired: No\nOwner\nThe owner of the object\nNote\nDirectory buckets - The bucket owner is returned as the object owner.\nType: Owner data type\nRequired: No\nRestoreStatus\nSpecifies the restoration status of an object. Objects in certain storage classes must be restored\nbefore they can be retrieved. For more information about these storage classes and how to\nwork with archived objects, see Working with archived objects in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone\nstorage class is supported by directory buckets to store objects.\nAmazon S3 API Version 2006-03-01 1283",
      "start_idx": 1446929,
      "end_idx": 1447844,
      "metadata": {
        "num_sentences": 11,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1290",
      "text": "Amazon Simple Storage Service API Reference\nObjectIdentifier\nService: Amazon S3\nObject Identifier is unique value to identify objects.\nContents\nKey\nKey name of the object.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nLength Constraints: Minimum length of 1.\nRequired: Yes\nVersionId\nVersion ID for the specific version of the object to delete.\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1285",
      "start_idx": 1448576,
      "end_idx": 1449321,
      "metadata": {
        "num_sentences": 8,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1292",
      "text": "Amazon Simple Storage Service API Reference\nObjectLockConfiguration\nService: Amazon S3\nThe container element for Object Lock configuration parameters.\nContents\nObjectLockEnabled\nIndicates whether this bucket has an Object Lock configuration enabled. Enable\nObjectLockEnabled when you apply ObjectLockConfiguration to a bucket.\nType: String\nValid Values: Enabled\nRequired: No\nRule\nSpecifies the Object Lock rule for the specified object. Enable the this rule when you apply\nObjectLockConfiguration to a bucket. Bucket settings require both a mode and a period.\nThe period can be either Days or Years but you must select one. You cannot specify Days and\nYears at the same time.\nType: ObjectLockRule data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1287",
      "start_idx": 1449468,
      "end_idx": 1450399,
      "metadata": {
        "num_sentences": 9,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1295",
      "text": "Amazon Simple Storage Service API Reference\nObjectLockRule\nService: Amazon S3\nThe container element for an Object Lock rule.\nContents\nDefaultRetention\nThe default Object Lock retention mode and period that you want to apply to new objects\nplaced in the specified bucket. Bucket settings require both a mode and a period. The period\ncan be either Days or Years but you must select one. You cannot specify Days and Years at\nthe same time.\nType: DefaultRetention data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1290",
      "start_idx": 1451443,
      "end_idx": 1452137,
      "metadata": {
        "num_sentences": 6,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1296",
      "text": "Amazon Simple Storage Service API Reference\nObjectPart\nService: Amazon S3\nA container for elements related to an individual part.\nContents\nChecksumCRC32\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1291",
      "start_idx": 1452139,
      "end_idx": 1453708,
      "metadata": {
        "num_sentences": 15,
        "num_words": 253,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1297",
      "text": "Amazon Simple Storage Service API Reference\nChecksumSHA256\nThe base64-encoded, 256-bit SHA-256 digest of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nPartNumber\nThe part number identifying the part. This value is a positive integer between 1 and 10,000.\nType: Integer\nRequired: No\nSize\nThe size of the uploaded part in bytes.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1292",
      "start_idx": 1453710,
      "end_idx": 1454699,
      "metadata": {
        "num_sentences": 9,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1299",
      "text": "Amazon Simple Storage Service API Reference\nType: Timestamp\nRequired: No\nOwner\nSpecifies the owner of the object.\nType: Owner data type\nRequired: No\nRestoreStatus\nSpecifies the restoration status of an object. Objects in certain storage classes must be restored\nbefore they can be retrieved. For more information about these storage classes and how to\nwork with archived objects, see Working with archived objects in the Amazon S3 User Guide.\nType: RestoreStatus data type\nRequired: No\nSize\nSize in bytes of the object.\nType: Long\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nType: String\nValid Values: STANDARD\nRequired: No\nVersionId\nVersion ID of an object.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1294",
      "start_idx": 1455382,
      "end_idx": 1456133,
      "metadata": {
        "num_sentences": 8,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1303",
      "text": "Amazon Simple Storage Service API Reference\nOwner\nService: Amazon S3\nContainer for the owner's display name and ID.\nContents\nDisplayName\nContainer for the display name of the owner. This value is only supported in the following AWS\nRegions:\n\u2022 US East (N. Virginia)\n\u2022 US West (N. California)\n\u2022 US West (Oregon)\n\u2022 Asia Pacific (Singapore)\n\u2022 Asia Pacific (Sydney)\n\u2022 Asia Pacific (Tokyo)\n\u2022 Europe (Ireland)\n\u2022 South America (S\u00e3o Paulo)\nNote\nThis functionality is not supported for directory buckets.\nType: String\nRequired: No\nID\nContainer for the ID of the owner.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1298",
      "start_idx": 1457444,
      "end_idx": 1458066,
      "metadata": {
        "num_sentences": 5,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1306",
      "text": "Amazon Simple Storage Service API Reference\nOwnershipControlsRule\nService: Amazon S3\nThe container element for an ownership control rule.\nContents\nObjectOwnership\nThe container element for object ownership for a bucket's ownership controls.\nBucketOwnerPreferred - Objects uploaded to the bucket change ownership to the bucket\nowner if the objects are uploaded with the bucket-owner-full-control canned ACL.\nObjectWriter - The uploading account will own the object if the object is uploaded with the\nbucket-owner-full-control canned ACL.\nBucketOwnerEnforced - Access control lists (ACLs) are disabled and no longer affect\npermissions. The bucket owner automatically owns and has full control over every object in\nthe bucket. The bucket only accepts PUT requests that don't specify an ACL or specify bucket\nowner full control ACLs (such as the predefined bucket-owner-full-control canned ACL or\na custom ACL in XML format that grants the same permissions).\nBy default, ObjectOwnership is set to BucketOwnerEnforced and ACLs are disabled. We\nrecommend keeping ACLs disabled, except in uncommon use cases where you must control\naccess for each object individually. For more information about S3 Object Ownership, see\nControlling ownership of objects and disabling ACLs for your bucket in the Amazon S3 User\nGuide.\nNote\nThis functionality is not supported for directory buckets. Directory buckets use the\nbucket owner enforced setting for S3 Object Ownership.\nType: String\nValid Values: BucketOwnerPreferred | ObjectWriter | BucketOwnerEnforced\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1301",
      "start_idx": 1458806,
      "end_idx": 1460397,
      "metadata": {
        "num_sentences": 13,
        "num_words": 230,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1309",
      "text": "Amazon Simple Storage Service API Reference\nPart\nService: Amazon S3\nContainer for elements related to a part.\nContents\nChecksumCRC32\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 32-bit CRC-32\nchecksum of the object. For more information, see Checking object integrity in the Amazon S3\nUser Guide.\nType: String\nRequired: No\nChecksumCRC32C\nThe base64-encoded, 32-bit CRC-32C checksum of the object. This will only be present if it was\nuploaded with the object. When you use an API operation on an object that was uploaded using\nmultipart uploads, this value may not be a direct checksum value of the full object. Instead,\nit's a calculation based on the checksum values of each individual part. For more information\nabout how checksums are calculated with multipart uploads, see Checking object integrity in\nthe Amazon S3 User Guide.\nType: String\nRequired: No\nChecksumSHA1\nThe base64-encoded, 160-bit SHA-1 digest of the object. This will only be present if it was\nuploaded with the object. When you use the API operation on an object that was uploaded\nusing multipart uploads, this value may not be a direct checksum value of the full object.\nInstead, it's a calculation based on the checksum values of each individual part. For more\ninformation about how checksums are calculated with multipart uploads, see Checking object\nintegrity in the Amazon S3 User Guide.\nType: String\nRequired: No\nAmazon S3 API Version 2006-03-01 1304",
      "start_idx": 1461040,
      "end_idx": 1462589,
      "metadata": {
        "num_sentences": 15,
        "num_words": 251,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1310",
      "text": "Amazon Simple Storage Service API Reference\nChecksumSHA256\nThis header can be used as a data integrity check to verify that the data received is the same\ndata that was originally sent. This header specifies the base64-encoded, 256-bit SHA-256 digest\nof the object. For more information, see Checking object integrity in the Amazon S3 User Guide.\nType: String\nRequired: No\nETag\nEntity tag returned when the part was uploaded.\nType: String\nRequired: No\nLastModified\nDate and time at which the part was uploaded.\nType: Timestamp\nRequired: No\nPartNumber\nPart number identifying the part. This is a positive integer between 1 and 10,000.\nType: Integer\nRequired: No\nSize\nSize in bytes of the uploaded part data.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1305",
      "start_idx": 1462591,
      "end_idx": 1463470,
      "metadata": {
        "num_sentences": 9,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1312",
      "text": "Amazon Simple Storage Service API Reference\nPartitionedPrefix\nService: Amazon S3\nAmazon S3 keys for log objects are partitioned in the following format:\n[DestinationPrefix][SourceAccountId]/[SourceRegion]/[SourceBucket]/[YYYY]/\n[MM]/[DD]/[YYYY]-[MM]-[DD]-[hh]-[mm]-[ss]-[UniqueString]\nPartitionedPrefix defaults to EventTime delivery when server access logs are delivered.\nContents\nPartitionDateSource\nSpecifies the partition date source for the partitioned prefix. PartitionDateSource can be\nEventTime or DeliveryTime.\nFor DeliveryTime, the time in the log file names corresponds to the delivery time for the log\nfiles.\nFor EventTime, The logs delivered are for a specific day only. The year, month, and day\ncorrespond to the day on which the event occurred, and the hour, minutes and seconds are set\nto 00 in the key.\nType: String\nValid Values: EventTime | DeliveryTime\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1307",
      "start_idx": 1463617,
      "end_idx": 1464713,
      "metadata": {
        "num_sentences": 7,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1313",
      "text": "Amazon Simple Storage Service API Reference\nPolicyStatus\nService: Amazon S3\nThe container element for a bucket's policy status.\nContents\nIsPublic\nThe policy status for this bucket. TRUE indicates that this bucket is public. FALSE indicates that\nthe bucket is not public.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1308",
      "start_idx": 1464715,
      "end_idx": 1465224,
      "metadata": {
        "num_sentences": 5,
        "num_words": 87,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1316",
      "text": "Amazon Simple Storage Service API Reference\nPublicAccessBlockConfiguration\nService: Amazon S3\nThe PublicAccessBlock configuration that you want to apply to this Amazon S3 bucket. You can\nenable the configuration options in any combination. For more information about when Amazon\nS3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 User Guide.\nContents\nBlockPublicAcls\nSpecifies whether Amazon S3 should block public access control lists (ACLs) for this bucket and\nobjects in this bucket. Setting this element to TRUE causes the following behavior:\n\u2022 PUT Bucket ACL and PUT Object ACL calls fail if the specified ACL is public.\n\u2022 PUT Object calls fail if the request includes a public ACL.\n\u2022 PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't affect existing policies or ACLs.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpecifies whether Amazon S3 should block public bucket policies for this bucket. Setting this\nelement to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the specified bucket\npolicy allows public access.\nEnabling this setting doesn't affect existing bucket policies.\nType: Boolean\nRequired: No\nIgnorePublicAcls\nSpecifies whether Amazon S3 should ignore public ACLs for this bucket and objects in this\nbucket. Setting this element to TRUE causes Amazon S3 to ignore all public ACLs on this bucket\nand objects in this bucket.\nEnabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent\nnew public ACLs from being set.\nAmazon S3 API Version 2006-03-01 1311",
      "start_idx": 1466318,
      "end_idx": 1467911,
      "metadata": {
        "num_sentences": 15,
        "num_words": 251,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1317",
      "text": "Amazon Simple Storage Service API Reference\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpecifies whether Amazon S3 should restrict public bucket policies for this bucket. Setting this\nelement to TRUE restricts access to this bucket to only AWS service principals and authorized\nusers within this account if the bucket has a public policy.\nEnabling this setting doesn't affect previously stored bucket policies, except that public and\ncross-account access within any public bucket policy, including non-public delegation to specific\naccounts, is blocked.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1312",
      "start_idx": 1467913,
      "end_idx": 1468711,
      "metadata": {
        "num_sentences": 4,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1319",
      "text": "Amazon Simple Storage Service API Reference\nFilter\nSpecifies object key name filtering rules. For information about key name filtering, see\nConfiguring event notifications using object key name filtering in the Amazon S3 User Guide.\nType: NotificationConfigurationFilter data type\nRequired: No\nId\nAn optional unique identifier for configurations in a notification configuration. If you don't\nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1314",
      "start_idx": 1470072,
      "end_idx": 1470743,
      "metadata": {
        "num_sentences": 5,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1320",
      "text": "Amazon Simple Storage Service API Reference\nQueueConfigurationDeprecated\nService: Amazon S3\nThis data type is deprecated. Use QueueConfiguration for the same purposes. This data type\nspecifies the configuration for publishing messages to an Amazon Simple Queue Service (Amazon\nSQS) queue when Amazon S3 detects specified events.\nContents\nEvent\nThis member has been deprecated.\nThe bucket event for which to send notifications.\nType: String\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nEvents\nA collection of bucket events for which to send notifications.\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\nAmazon S3 API Version 2006-03-01 1315",
      "start_idx": 1470745,
      "end_idx": 1472266,
      "metadata": {
        "num_sentences": 7,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1321",
      "text": "Amazon Simple Storage Service API Reference\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nId\nAn optional unique identifier for configurations in a notification configuration. If you don't\nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nQueue\nThe Amazon Resource Name (ARN) of the Amazon SQS queue to which Amazon S3 publishes a\nmessage when it detects events of the specified type.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1316",
      "start_idx": 1472268,
      "end_idx": 1473538,
      "metadata": {
        "num_sentences": 4,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1323",
      "text": "Amazon Simple Storage Service API Reference\nRecordsEvent\nService: Amazon S3\nThe container for the records event.\nContents\nPayload\nThe byte array of partial, one or more result records. S3 Select doesn't guarantee that a record\nwill be self-contained in one record frame. To ensure continuous streaming of data, S3 Select\nmight split the same record across multiple record frames instead of aggregating the results in\nmemory. Some S3 clients (for example, the AWS SDK for Java) handle this behavior by creating\na ByteStream out of the response by default. Other clients might not handle this behavior\nby default. In those cases, you must aggregate the results on the client side and parse the\nresponse.\nType: Base64-encoded binary data object\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1318",
      "start_idx": 1473623,
      "end_idx": 1474589,
      "metadata": {
        "num_sentences": 8,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1324",
      "text": "Amazon Simple Storage Service API Reference\nRedirect\nService: Amazon S3\nSpecifies how requests are redirected. In the event of an error, you can specify a different error\ncode to return.\nContents\nHostName\nThe host name to use in the redirect request.\nType: String\nRequired: No\nHttpRedirectCode\nThe HTTP redirect code to use on the response. Not required if one of the siblings is present.\nType: String\nRequired: No\nProtocol\nProtocol to use when redirecting requests. The default is the protocol that is used in the original\nrequest.\nType: String\nValid Values: http | https\nRequired: No\nReplaceKeyPrefixWith\nThe object key prefix to use in the redirect request. For example, to redirect requests for all\npages with prefix docs/ (objects in the docs/ folder) to documents/, you can set a condition\nblock with KeyPrefixEquals set to docs/ and in the Redirect set ReplaceKeyPrefixWith\nto /documents. Not required if one of the siblings is present. Can be present only if\nReplaceKeyWith is not provided.\nAmazon S3 API Version 2006-03-01 1319",
      "start_idx": 1474591,
      "end_idx": 1475627,
      "metadata": {
        "num_sentences": 12,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1325",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nReplaceKeyWith\nThe specific object key to use in the redirect request. For example, redirect request\nto error.html. Not required if one of the siblings is present. Can be present only if\nReplaceKeyPrefixWith is not provided.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1320",
      "start_idx": 1475629,
      "end_idx": 1476551,
      "metadata": {
        "num_sentences": 9,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1326",
      "text": "Amazon Simple Storage Service API Reference\nRedirectAllRequestsTo\nService: Amazon S3\nSpecifies the redirect behavior of all requests to a website endpoint of an Amazon S3 bucket.\nContents\nHostName\nName of the host where requests are redirected.\nType: String\nRequired: Yes\nProtocol\nProtocol to use when redirecting requests. The default is the protocol that is used in the original\nrequest.\nType: String\nValid Values: http | https\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1321",
      "start_idx": 1476553,
      "end_idx": 1477207,
      "metadata": {
        "num_sentences": 5,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1327",
      "text": "Amazon Simple Storage Service API Reference\nReplicaModifications\nService: Amazon S3\nA filter that you can specify for selection for modifications on replicas. Amazon S3 doesn't replicate\nreplica modifications by default. In the latest version of replication configuration (when Filter is\nspecified), you can specify this element and set the status to Enabled to replicate modifications on\nreplicas.\nNote\nIf you don't specify the Filter element, Amazon S3 assumes that the replication\nconfiguration is the earlier version, V1. In the earlier version, this element is not allowed.\nContents\nStatus\nSpecifies whether Amazon S3 replicates modifications on replicas.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1322",
      "start_idx": 1477209,
      "end_idx": 1478141,
      "metadata": {
        "num_sentences": 7,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1328",
      "text": "Amazon Simple Storage Service API Reference\nReplicationConfiguration\nService: Amazon S3\nA container for replication rules. You can add up to 1,000 rules. The maximum size of a replication\nconfiguration is 2 MB.\nContents\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role\nthat Amazon S3 assumes when replicating objects. For more information, see How to Set Up\nReplication in the Amazon S3 User Guide.\nType: String\nRequired: Yes\nRules\nA container for one or more replication rules. A replication configuration must have at least one\nrule and can contain a maximum of 1,000 rules.\nType: Array of ReplicationRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1323",
      "start_idx": 1478143,
      "end_idx": 1479027,
      "metadata": {
        "num_sentences": 8,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1329",
      "text": "Amazon Simple Storage Service API Reference\nReplicationRule\nService: Amazon S3\nSpecifies which Amazon S3 objects to replicate and where to store the replicas.\nContents\nDestination\nA container for information about the replication destination and its configurations including\nenabling the S3 Replication Time Control (S3 RTC).\nType: Destination data type\nRequired: Yes\nStatus\nSpecifies whether the rule is enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nDeleteMarkerReplication\nSpecifies whether Amazon S3 replicates delete markers. If you specify a Filter in your\nreplication configuration, you must also include a DeleteMarkerReplication element. If\nyour Filter includes a Tag element, the DeleteMarkerReplication Status must be set to\nDisabled, because Amazon S3 does not support replicating delete markers for tag-based rules.\nFor an example configuration, see Basic Rule Configuration.\nFor more information about delete marker replication, see Basic Rule Configuration.\nNote\nIf you are using an earlier version of the replication configuration, Amazon S3\nhandles replication of delete markers differently. For more information, see Backward\nCompatibility.\nAmazon S3 API Version 2006-03-01 1324",
      "start_idx": 1479029,
      "end_idx": 1480247,
      "metadata": {
        "num_sentences": 11,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1330",
      "text": "Amazon Simple Storage Service API Reference\nType: DeleteMarkerReplication data type\nRequired: No\nExistingObjectReplication\nOptional configuration to replicate existing source bucket objects.\nNote\nThis parameter is no longer supported. To replicate existing objects, see Replicating\nexisting objects with S3 Batch Replication in the Amazon S3 User Guide.\nType: ExistingObjectReplication data type\nRequired: No\nFilter\nA filter that identifies the subset of objects to which the replication rule applies. A Filter must\nspecify exactly one Prefix, Tag, or an And child element.\nType: ReplicationRuleFilter data type\nRequired: No\nID\nA unique identifier for the rule. The maximum value is 255 characters.\nType: String\nRequired: No\nPrefix\nThis member has been deprecated.\nAn object key name prefix that identifies the object or objects to which the rule applies. The\nmaximum prefix length is 1,024 characters. To include all objects in a bucket, specify an empty\nstring.\nAmazon S3 API Version 2006-03-01 1325",
      "start_idx": 1480249,
      "end_idx": 1481250,
      "metadata": {
        "num_sentences": 12,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1331",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nPriority\nThe priority indicates which rule has precedence whenever two or more replication rules\nconflict. Amazon S3 will attempt to replicate objects according to all replication rules. However,\nif there are two or more rules with the same destination bucket, then objects will be replicated\naccording to the rule with the highest priority. The higher the number, the higher the priority.\nFor more information, see Replication in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nSourceSelectionCriteria\nA container that describes additional filters for identifying the source objects that you want\nto replicate. You can choose to enable or disable the replication of these objects. Currently,\nAmazon S3 supports only the filter that you can specify for objects created with server-side\nencryption using a customer managed key stored in AWS Key Management Service (SSE-KMS).\nType: SourceSelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\nAmazon S3 API Version 2006-03-01 1326",
      "start_idx": 1481252,
      "end_idx": 1482616,
      "metadata": {
        "num_sentences": 11,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1333",
      "text": "Amazon Simple Storage Service API Reference\nReplicationRuleAndOperator\nService: Amazon S3\nA container for specifying rule filters. The filters determine the subset of objects to which the rule\napplies. This element is required only if you specify more than one filter.\nFor example:\n\u2022 If you specify both a Prefix and a Tag filter, wrap these filters in an And tag.\n\u2022 If you specify a filter based on multiple tags, wrap the Tag elements in an And tag.\nContents\nPrefix\nAn object key name prefix that identifies the subset of objects to which the rule applies.\nType: String\nRequired: No\nTags\nAn array of tags containing key and value pairs.\nType: Array of Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1328",
      "start_idx": 1482745,
      "end_idx": 1483638,
      "metadata": {
        "num_sentences": 8,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1334",
      "text": "Amazon Simple Storage Service API Reference\nReplicationRuleFilter\nService: Amazon S3\nA filter that identifies the subset of objects to which the replication rule applies. A Filter must\nspecify exactly one Prefix, Tag, or an And child element.\nContents\nAnd\nA container for specifying rule filters. The filters determine the subset of objects to which the\nrule applies. This element is required only if you specify more than one filter. For example:\n\u2022 If you specify both a Prefix and a Tag filter, wrap these filters in an And tag.\n\u2022 If you specify a filter based on multiple tags, wrap the Tag elements in an And tag.\nType: ReplicationRuleAndOperator data type\nRequired: No\nPrefix\nAn object key name prefix that identifies the subset of objects to which the rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: No\nTag\nA container for specifying a tag key and value.\nThe rule applies only to objects that have the tag in their tag set.\nType: Tag data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1329",
      "start_idx": 1483640,
      "end_idx": 1484824,
      "metadata": {
        "num_sentences": 13,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1339",
      "text": "Amazon Simple Storage Service API Reference\nRequestProgress\nService: Amazon S3\nContainer for specifying if periodic QueryProgress messages should be sent.\nContents\nEnabled\nSpecifies whether periodic QueryProgress frames should be sent. Valid values: TRUE, FALSE.\nDefault value: FALSE.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1334",
      "start_idx": 1486898,
      "end_idx": 1487421,
      "metadata": {
        "num_sentences": 5,
        "num_words": 83,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1340",
      "text": "Amazon Simple Storage Service API Reference\nRestoreRequest\nService: Amazon S3\nContainer for restore job parameters.\nContents\nDays\nLifetime of the active copy in days. Do not use with restores that specify OutputLocation.\nThe Days element is required for regular restores, and must not be provided for select requests.\nType: Integer\nRequired: No\nDescription\nThe optional description for the job.\nType: String\nRequired: No\nGlacierJobParameters\nS3 Glacier related parameters pertaining to this job. Do not use with restores that specify\nOutputLocation.\nType: GlacierJobParameters data type\nRequired: No\nOutputLocation\nDescribes the location where the restore job's output is stored.\nType: OutputLocation data type\nRequired: No\nSelectParameters\nDescribes the parameters for Select job types.\nAmazon S3 API Version 2006-03-01 1335",
      "start_idx": 1487423,
      "end_idx": 1488248,
      "metadata": {
        "num_sentences": 10,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1342",
      "text": "Amazon Simple Storage Service API Reference\nRestoreStatus\nService: Amazon S3\nSpecifies the restoration status of an object. Objects in certain storage classes must be restored\nbefore they can be retrieved. For more information about these storage classes and how to work\nwith archived objects, see Working with archived objects in the Amazon S3 User Guide.\nNote\nThis functionality is not supported for directory buckets. Only the S3 Express One Zone\nstorage class is supported by directory buckets to store objects.\nContents\nIsRestoreInProgress\nSpecifies whether the object is currently being restored. If the object restoration is in progress,\nthe header returns the value TRUE. For example:\nx-amz-optional-object-attributes: IsRestoreInProgress=\"true\"\nIf the object restoration has completed, the header returns the value FALSE. For example:\nx-amz-optional-object-attributes: IsRestoreInProgress=\"false\",\nRestoreExpiryDate=\"2012-12-21T00:00:00.000Z\"\nIf the object hasn't been restored, there is no header response.\nType: Boolean\nRequired: No\nRestoreExpiryDate\nIndicates when the restored copy will expire. This value is populated only if the object has\nalready been restored. For example:\nx-amz-optional-object-attributes: IsRestoreInProgress=\"false\",\nRestoreExpiryDate=\"2012-12-21T00:00:00.000Z\"\nType: Timestamp\nAmazon S3 API Version 2006-03-01 1337",
      "start_idx": 1488758,
      "end_idx": 1490110,
      "metadata": {
        "num_sentences": 12,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1344",
      "text": "Amazon Simple Storage Service API Reference\nRoutingRule\nService: Amazon S3\nSpecifies the redirect behavior and when a redirect is applied. For more information about routing\nrules, see Configuring advanced conditional redirects in the Amazon S3 User Guide.\nContents\nRedirect\nContainer for redirect information. You can redirect requests to another host, to another page,\nor with another protocol. In the event of an error, you can specify a different error code to\nreturn.\nType: Redirect data type\nRequired: Yes\nCondition\nA container for describing a condition that must be met for the specified redirect to apply. For\nexample, 1. If request is for pages in the /docs folder, redirect to the /documents folder. 2. If\nrequest results in HTTP error 4xx, redirect request to another host where you might process the\nerror.\nType: Condition data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1339",
      "start_idx": 1490382,
      "end_idx": 1491452,
      "metadata": {
        "num_sentences": 11,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1345",
      "text": "Amazon Simple Storage Service API Reference\nRule\nService: Amazon S3\nSpecifies lifecycle rules for an Amazon S3 bucket. For more information, see Put Bucket\nLifecycle Configuration in the Amazon S3 API Reference. For examples, see Put Bucket Lifecycle\nConfiguration Examples.\nContents\nPrefix\nObject key prefix that identifies one or more objects to which this rule applies.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related\nobject key constraints.\nType: String\nRequired: Yes\nStatus\nIf Enabled, the rule is currently being applied. If Disabled, the rule is not currently being\napplied.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nAbortIncompleteMultipartUpload\nSpecifies the days since the initiation of an incomplete multipart upload that Amazon S3 will\nwait before permanently removing all parts of the upload. For more information, see Aborting\nIncomplete Multipart Uploads Using a Bucket Lifecycle Configuration in the Amazon S3 User\nGuide.\nAmazon S3 API Version 2006-03-01 1340",
      "start_idx": 1491454,
      "end_idx": 1492571,
      "metadata": {
        "num_sentences": 11,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1346",
      "text": "Amazon Simple Storage Service API Reference\nType: AbortIncompleteMultipartUpload data type\nRequired: No\nExpiration\nSpecifies the expiration for the lifecycle of the object.\nType: LifecycleExpiration data type\nRequired: No\nID\nUnique identifier for the rule. The value can't be longer than 255 characters.\nType: String\nRequired: No\nNoncurrentVersionExpiration\nSpecifies when noncurrent object versions expire. Upon expiration, Amazon S3 permanently\ndeletes the noncurrent object versions. You set this lifecycle configuration action on a bucket\nthat has versioning enabled (or suspended) to request that Amazon S3 delete noncurrent object\nversions at a specific period in the object's lifetime.\nType: NoncurrentVersionExpiration data type\nRequired: No\nNoncurrentVersionTransition\nContainer for the transition rule that describes when noncurrent objects transition to\nthe STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, GLACIER_IR, GLACIER, or\nDEEP_ARCHIVE storage class. If your bucket is versioning-enabled (or versioning is suspended),\nyou can set this action to request that Amazon S3 transition noncurrent object versions to\nthe STANDARD_IA, ONEZONE_IA, INTELLIGENT_TIERING, GLACIER_IR, GLACIER, or\nDEEP_ARCHIVE storage class at a specific period in the object's lifetime.\nType: NoncurrentVersionTransition data type\nRequired: No\nAmazon S3 API Version 2006-03-01 1341",
      "start_idx": 1492573,
      "end_idx": 1493940,
      "metadata": {
        "num_sentences": 9,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1347",
      "text": "Amazon Simple Storage Service API Reference\nTransition\nSpecifies when an object transitions to a specified storage class. For more information about\nAmazon S3 lifecycle configuration rules, see Transitioning Objects Using Amazon S3 Lifecycle in\nthe Amazon S3 User Guide.\nType: Transition data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1342",
      "start_idx": 1493942,
      "end_idx": 1494464,
      "metadata": {
        "num_sentences": 3,
        "num_words": 87,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1351",
      "text": "Amazon Simple Storage Service API Reference\nScanRange\nService: Amazon S3\nSpecifies the byte range of the object to get the records from. A record is processed when its first\nbyte is contained by the range. This parameter is optional, but when specified, it must not be\nempty. See RFC 2616, Section 14.35.1 about how to specify the start and end of the range.\nContents\nEnd\nSpecifies the end of the byte range. This parameter is optional. Valid values: non-negative\nintegers. The default value is one less than the size of the object being queried. If only the End\nparameter is supplied, it is interpreted to mean scan the last N bytes of the file. For example,\n<scanrange><end>50</end></scanrange> means scan the last 50 bytes.\nType: Long\nRequired: No\nStart\nSpecifies the start of the byte range. This parameter is optional. Valid values: non-negative\nintegers. The default value is 0. If only start is supplied, it means scan from that point to the\nend of the file. For example, <scanrange><start>50</start></scanrange> means scan\nfrom byte 50 until the end of the file.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1346",
      "start_idx": 1496589,
      "end_idx": 1497895,
      "metadata": {
        "num_sentences": 17,
        "num_words": 225,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1356",
      "text": "Amazon Simple Storage Service API Reference\nServerSideEncryptionByDefault\nService: Amazon S3\nDescribes the default server-side encryption to apply to new objects in the bucket. If a PUT Object\nrequest doesn't specify any server-side encryption, this default encryption will be applied. For more\ninformation, see PutBucketEncryption.\nNote\n\u2022 General purpose buckets - If you don't specify a customer managed key at\nconfiguration, Amazon S3 automatically creates an AWS KMS key (aws/s3) in your AWS\naccount the first time that you add an object encrypted with SSE-KMS to a bucket. By\ndefault, Amazon S3 uses this KMS key for SSE-KMS.\n\u2022 Directory buckets - Your SSE-KMS configuration can only support 1 customer managed\nkey per directory bucket for the lifetime of the bucket. The AWS managed key (aws/s3)\nisn't supported.\n\u2022 Directory buckets - For directory buckets, there are only two supported options for\nserver-side encryption: SSE-S3 and SSE-KMS.\nContents\nSSEAlgorithm\nServer-side encryption algorithm to use for the default encryption.\nNote\nFor directory buckets, there are only two supported values for server-side encryption:\nAES256 and aws:kms.\nType: String\nValid Values: AES256 | aws:kms | aws:kms:dsse\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1351",
      "start_idx": 1499581,
      "end_idx": 1500842,
      "metadata": {
        "num_sentences": 11,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1357",
      "text": "Amazon Simple Storage Service API Reference\nKMSMasterKeyID\nAWS Key Management Service (KMS) customer managed key ID to use for the default\nencryption.\nNote\n\u2022 General purpose buckets - This parameter is allowed if and only if SSEAlgorithm is\nset to aws:kms or aws:kms:dsse.\n\u2022 Directory buckets - This parameter is allowed if and only if SSEAlgorithm is set to\naws:kms.\nYou can specify the key ID, key alias, or the Amazon Resource Name (ARN) of the KMS key.\n\u2022 Key ID: 1234abcd-12ab-34cd-56ef-1234567890ab\n\u2022 Key ARN: arn:aws:kms:us-\neast-2:111122223333:key/1234abcd-12ab-34cd-56ef-1234567890ab\n\u2022 Key Alias: alias/alias-name\nIf you are using encryption with cross-account or AWS service operations, you must use a\nfully qualified KMS key ARN. For more information, see Using encryption for cross-account\noperations.\nNote\n\u2022 General purpose buckets - If you're specifying a customer managed KMS key, we\nrecommend using a fully qualified KMS key ARN. If you use a KMS key alias instead,\nthen AWS KMS resolves the key within the requester\u2019s account. This behavior can\nresult in data that's encrypted with a KMS key that belongs to the requester, and\nnot the bucket owner. Also, if you use a key ID, you can run into a LogDestination\nundeliverable error when creating a VPC flow log.\n\u2022 Directory buckets - When you specify an AWS KMS customer managed key for\nencryption in your directory bucket, only use the key ID or key ARN. The key alias\nformat of the KMS key isn't supported.\nAmazon S3 API Version 2006-03-01 1352",
      "start_idx": 1500844,
      "end_idx": 1502354,
      "metadata": {
        "num_sentences": 13,
        "num_words": 247,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1358",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nAmazon S3 only supports symmetric encryption KMS keys. For more information, see\nAsymmetric keys in AWS KMS in the AWS Key Management Service Developer Guide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1353",
      "start_idx": 1502356,
      "end_idx": 1502806,
      "metadata": {
        "num_sentences": 3,
        "num_words": 78,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1360",
      "text": "Amazon Simple Storage Service API Reference\nServerSideEncryptionRule\nService: Amazon S3\nSpecifies the default server-side encryption configuration.\nNote\n\u2022 General purpose buckets - If you're specifying a customer managed KMS key, we\nrecommend using a fully qualified KMS key ARN. If you use a KMS key alias instead, then\nAWS KMS resolves the key within the requester\u2019s account. This behavior can result in data\nthat's encrypted with a KMS key that belongs to the requester, and not the bucket owner.\n\u2022 Directory buckets - When you specify an AWS KMS customer managed key for\nencryption in your directory bucket, only use the key ID or key ARN. The key alias format\nof the KMS key isn't supported.\nContents\nApplyServerSideEncryptionByDefault\nSpecifies the default server-side encryption to apply to new objects in the bucket. If a PUT\nObject request doesn't specify any server-side encryption, this default encryption will be\napplied.\nType: ServerSideEncryptionByDefault data type\nRequired: No\nBucketKeyEnabled\nSpecifies whether Amazon S3 should use an S3 Bucket Key with server-side encryption using\nKMS (SSE-KMS) for new objects in the bucket. Existing objects are not affected. Setting the\nBucketKeyEnabled element to true causes Amazon S3 to use an S3 Bucket Key.\nNote\n\u2022 General purpose buckets - By default, S3 Bucket Key is not enabled. For more\ninformation, see Amazon S3 Bucket Keys in the Amazon S3 User Guide.\n\u2022 Directory buckets - S3 Bucket Keys are always enabled for GET and PUT operations in\na directory bucket and can\u2019t be disabled. S3 Bucket Keys aren't supported, when you\nAmazon S3 API Version 2006-03-01 1355",
      "start_idx": 1503346,
      "end_idx": 1504972,
      "metadata": {
        "num_sentences": 15,
        "num_words": 260,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1361",
      "text": "Amazon Simple Storage Service API Reference\ncopy SSE-KMS encrypted objects from general purpose buckets to directory buckets,\nfrom directory buckets to general purpose buckets, or between directory buckets,\nthrough CopyObject, UploadPartCopy, the Copy operation in Batch Operations, or\nthe import jobs. In this case, Amazon S3 makes a call to AWS KMS every time a copy\nrequest is made for a KMS-encrypted object.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1356",
      "start_idx": 1504974,
      "end_idx": 1505625,
      "metadata": {
        "num_sentences": 3,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1362",
      "text": "Amazon Simple Storage Service API Reference\nSessionCredentials\nService: Amazon S3\nThe established temporary security credentials of the session.\nNote\nDirectory buckets - These session credentials are only supported for the authentication\nand authorization of Zonal endpoint API operations on directory buckets.\nContents\nAccessKeyId\nA unique identifier that's associated with a secret access key. The access key ID and the secret\naccess key are used together to sign programmatic AWS requests cryptographically.\nType: String\nRequired: Yes\nExpiration\nTemporary security credentials expire after a specified interval. After temporary credentials\nexpire, any calls that you make with those credentials will fail. So you must generate a new set\nof temporary credentials. Temporary credentials cannot be extended or refreshed beyond the\noriginal specified interval.\nType: Timestamp\nRequired: Yes\nSecretAccessKey\nA key that's used with the access key ID to cryptographically sign programmatic AWS requests.\nSigning a request identifies the sender and prevents the request from being altered.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1357",
      "start_idx": 1505627,
      "end_idx": 1506776,
      "metadata": {
        "num_sentences": 11,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1363",
      "text": "Amazon Simple Storage Service API Reference\nSessionToken\nA part of the temporary security credentials. The session token is used to validate the\ntemporary security credentials.\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1358",
      "start_idx": 1506778,
      "end_idx": 1507193,
      "metadata": {
        "num_sentences": 3,
        "num_words": 71,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1365",
      "text": "Amazon Simple Storage Service API Reference\nSourceSelectionCriteria\nService: Amazon S3\nA container that describes additional filters for identifying the source objects that you want to\nreplicate. You can choose to enable or disable the replication of these objects. Currently, Amazon\nS3 supports only the filter that you can specify for objects created with server-side encryption\nusing a customer managed key stored in AWS Key Management Service (SSE-KMS).\nContents\nReplicaModifications\nA filter that you can specify for selections for modifications on replicas. Amazon S3 doesn't\nreplicate replica modifications by default. In the latest version of replication configuration\n(when Filter is specified), you can specify this element and set the status to Enabled to\nreplicate modifications on replicas.\nNote\nIf you don't specify the Filter element, Amazon S3 assumes that the replication\nconfiguration is the earlier version, V1. In the earlier version, this element is not allowed\nType: ReplicaModifications data type\nRequired: No\nSseKmsEncryptedObjects\nA container for filter information for the selection of Amazon S3 objects encrypted with AWS\nKMS. If you include SourceSelectionCriteria in the replication configuration, this element\nis required.\nType: SseKmsEncryptedObjects data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1360",
      "start_idx": 1507709,
      "end_idx": 1509163,
      "metadata": {
        "num_sentences": 10,
        "num_words": 211,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1373",
      "text": "Amazon Simple Storage Service API Reference\nStorageClassAnalysisDataExport\nService: Amazon S3\nContainer for data related to the storage class analysis for an Amazon S3 bucket for export.\nContents\nDestination\nThe place to store the data for an analysis.\nType: AnalyticsExportDestination data type\nRequired: Yes\nOutputSchemaVersion\nThe version of the output schema to use when exporting data. Must be V_1.\nType: String\nValid Values: V_1\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1368",
      "start_idx": 1512509,
      "end_idx": 1513169,
      "metadata": {
        "num_sentences": 5,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1376",
      "text": "Amazon Simple Storage Service API Reference\nTargetGrant\nService: Amazon S3\nContainer for granting information.\nBuckets that use the bucket owner enforced setting for Object Ownership don't support target\ngrants. For more information, see Permissions server access log delivery in the Amazon S3 User\nGuide.\nContents\nGrantee\nContainer for the person being granted permissions.\nType: Grantee data type\nRequired: No\nPermission\nLogging permissions assigned to the grantee for the bucket.\nType: String\nValid Values: FULL_CONTROL | READ | WRITE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1371",
      "start_idx": 1514051,
      "end_idx": 1514813,
      "metadata": {
        "num_sentences": 6,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1377",
      "text": "Amazon Simple Storage Service API Reference\nTargetObjectKeyFormat\nService: Amazon S3\nAmazon S3 key format for log objects. Only one format, PartitionedPrefix or SimplePrefix, is\nallowed.\nContents\nPartitionedPrefix\nPartitioned S3 key for log objects.\nType: PartitionedPrefix data type\nRequired: No\nSimplePrefix\nTo use the simple format for S3 keys for log objects. To specify SimplePrefix format, set\nSimplePrefix to {}.\nType: SimplePrefix data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1372",
      "start_idx": 1514815,
      "end_idx": 1515488,
      "metadata": {
        "num_sentences": 6,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1378",
      "text": "Amazon Simple Storage Service API Reference\nTiering\nService: Amazon S3\nThe S3 Intelligent-Tiering storage class is designed to optimize storage costs by automatically\nmoving data to the most cost-effective storage access tier, without additional operational\noverhead.\nContents\nAccessTier\nS3 Intelligent-Tiering access tier. See Storage class for automatically optimizing frequently and\ninfrequently accessed objects for a list of access tiers in the S3 Intelligent-Tiering storage class.\nType: String\nValid Values: ARCHIVE_ACCESS | DEEP_ARCHIVE_ACCESS\nRequired: Yes\nDays\nThe number of consecutive days of no access after which an object will be eligible to be\ntransitioned to the corresponding tier. The minimum number of days specified for Archive\nAccess tier must be at least 90 days and Deep Archive Access tier must be at least 180 days. The\nmaximum can be up to 2 years (730 days).\nType: Integer\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1373",
      "start_idx": 1515490,
      "end_idx": 1516616,
      "metadata": {
        "num_sentences": 7,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1379",
      "text": "Amazon Simple Storage Service API Reference\nTopicConfiguration\nService: Amazon S3\nA container for specifying the configuration for publication of messages to an Amazon Simple\nNotification Service (Amazon SNS) topic when Amazon S3 detects specified events.\nContents\nEvents\nThe Amazon S3 bucket event about which to send notifications. For more information, see\nSupported Event Types in the Amazon S3 User Guide.\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: Yes\nTopicArn\nThe Amazon Resource Name (ARN) of the Amazon SNS topic to which Amazon S3 publishes a\nmessage when it detects events of the specified type.\nType: String\nRequired: Yes\nAmazon S3 API Version 2006-03-01 1374",
      "start_idx": 1516618,
      "end_idx": 1518080,
      "metadata": {
        "num_sentences": 5,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1380",
      "text": "Amazon Simple Storage Service API Reference\nFilter\nSpecifies object key name filtering rules. For information about key name filtering, see\nConfiguring event notifications using object key name filtering in the Amazon S3 User Guide.\nType: NotificationConfigurationFilter data type\nRequired: No\nId\nAn optional unique identifier for configurations in a notification configuration. If you don't\nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1375",
      "start_idx": 1518082,
      "end_idx": 1518753,
      "metadata": {
        "num_sentences": 5,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1381",
      "text": "Amazon Simple Storage Service API Reference\nTopicConfigurationDeprecated\nService: Amazon S3\nA container for specifying the configuration for publication of messages to an Amazon Simple\nNotification Service (Amazon SNS) topic when Amazon S3 detects specified events. This data type\nis deprecated. Use TopicConfiguration instead.\nContents\nEvent\nThis member has been deprecated.\nBucket event for which to send notifications.\nType: String\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nEvents\nA collection of events related to objects\nType: Array of strings\nValid Values: s3:ReducedRedundancyLostObject | s3:ObjectCreated:* |\ns3:ObjectCreated:Put | s3:ObjectCreated:Post | s3:ObjectCreated:Copy\nAmazon S3 API Version 2006-03-01 1376",
      "start_idx": 1518755,
      "end_idx": 1520250,
      "metadata": {
        "num_sentences": 6,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1382",
      "text": "Amazon Simple Storage Service API Reference\n| s3:ObjectCreated:CompleteMultipartUpload | s3:ObjectRemoved:* |\ns3:ObjectRemoved:Delete | s3:ObjectRemoved:DeleteMarkerCreated |\ns3:ObjectRestore:* | s3:ObjectRestore:Post | s3:ObjectRestore:Completed\n| s3:Replication:* | s3:Replication:OperationFailedReplication |\ns3:Replication:OperationNotTracked |\ns3:Replication:OperationMissedThreshold |\ns3:Replication:OperationReplicatedAfterThreshold |\ns3:ObjectRestore:Delete | s3:LifecycleTransition |\ns3:IntelligentTiering | s3:ObjectAcl:Put | s3:LifecycleExpiration:* |\ns3:LifecycleExpiration:Delete |\ns3:LifecycleExpiration:DeleteMarkerCreated | s3:ObjectTagging:* |\ns3:ObjectTagging:Put | s3:ObjectTagging:Delete\nRequired: No\nId\nAn optional unique identifier for configurations in a notification configuration. If you don't\nprovide one, Amazon S3 will assign an ID.\nType: String\nRequired: No\nTopic\nAmazon SNS topic to which Amazon S3 will publish a message to report the specified events for\nthe bucket.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1377",
      "start_idx": 1520252,
      "end_idx": 1521488,
      "metadata": {
        "num_sentences": 4,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1384",
      "text": "Amazon Simple Storage Service API Reference\nTransition\nService: Amazon S3\nSpecifies when an object transitions to a specified storage class. For more information about\nAmazon S3 lifecycle configuration rules, see Transitioning Objects Using Amazon S3 Lifecycle in\nthe Amazon S3 User Guide.\nContents\nDate\nIndicates when objects are transitioned to the specified storage class. The date value must be in\nISO 8601 format. The time is always midnight UTC.\nType: Timestamp\nRequired: No\nDays\nIndicates the number of days after creation when objects are transitioned to the specified\nstorage class. The value must be a positive integer.\nType: Integer\nRequired: No\nStorageClass\nThe storage class to which you want the object to transition.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING |\nDEEP_ARCHIVE | GLACIER_IR\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 API Version 2006-03-01 1379",
      "start_idx": 1521573,
      "end_idx": 1522579,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1386",
      "text": "Amazon Simple Storage Service API Reference\nVersioningConfiguration\nService: Amazon S3\nDescribes the versioning state of an Amazon S3 bucket. For more information, see PUT Bucket\nversioning in the Amazon S3 API Reference.\nContents\nMFADelete\nSpecifies whether MFA delete is enabled in the bucket versioning configuration. This element is\nonly returned if the bucket has been configured with MFA delete. If the bucket has never been\nso configured, this element is not returned.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nStatus\nThe versioning state of the bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 API Version 2006-03-01 1381",
      "start_idx": 1522726,
      "end_idx": 1523575,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1395",
      "text": "Amazon Simple Storage Service API Reference\nAccessGrantsLocationConfiguration\nService: Amazon S3 Control\nThe configuration options of the S3 Access Grants location. It contains the S3SubPrefix field. The\ngrant scope, the data to which you are granting access, is the result of appending the Subprefix\nfield to the scope of the registered location.\nContents\nS3SubPrefix\nThe S3SubPrefix is appended to the location scope creating the grant scope. Use this field\nto narrow the scope of the grant to a subset of the location scope. This field is required if the\nlocation scope is the default location s3:// because you cannot create a grant for all of your\nS3 data in the Region and must narrow the scope. For example, if the location scope is the\ndefault location s3://, the S3SubPrefx can be a <bucket-name>/*, so the full grant scope\npath would be s3://<bucket-name>/*. Or the S3SubPrefx can be <bucket-name>/\n<prefix-name>*, so the full grant scope path would be or s3://<bucket-name>/<prefix-\nname>*.\nIf the S3SubPrefix includes a prefix, append the wildcard character * after the prefix to\nindicate that you want to include all object key names in the bucket that start with that prefix.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1390",
      "start_idx": 1529193,
      "end_idx": 1530707,
      "metadata": {
        "num_sentences": 12,
        "num_words": 251,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1397",
      "text": "Amazon Simple Storage Service API Reference\nAccessPoint\nService: Amazon S3 Control\nAn access point used to access a bucket.\nContents\nBucket\nThe name of the bucket associated with this access point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nName\nThe name of this access point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nNetworkOrigin\nIndicates whether this access point allows access from the public internet. If\nVpcConfiguration is specified for this access point, then NetworkOrigin is VPC, and the\naccess point doesn't allow access from the public internet. Otherwise, NetworkOrigin is\nInternet, and the access point allows access from the public internet, subject to the access\npoint and bucket access policies.\nType: String\nValid Values: Internet | VPC\nRequired: Yes\nAccessPointArn\nThe ARN for the access point.\nAmazon S3 Control API Version 2006-03-01 1392",
      "start_idx": 1530800,
      "end_idx": 1531758,
      "metadata": {
        "num_sentences": 12,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1398",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nRequired: No\nAlias\nThe name or alias of the access point.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{63}\nRequired: No\nBucketAccountId\nThe AWS account ID associated with the S3 bucket associated with this access point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nVpcConfiguration\nThe virtual private cloud (VPC) configuration for this access point, if one exists.\nNote\nThis element is empty if this access point is an Amazon S3 on Outposts access point that\nis used by other AWS services.\nType: VpcConfiguration data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1393",
      "start_idx": 1531760,
      "end_idx": 1532536,
      "metadata": {
        "num_sentences": 9,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1400",
      "text": "Amazon Simple Storage Service API Reference\nAccountLevel\nService: Amazon S3 Control\nA container element for the account-level Amazon S3 Storage Lens configuration.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3\nStorage Lens in the Amazon S3 User Guide. For a complete list of S3 Storage Lens metrics, see S3\nStorage Lens metrics glossary in the Amazon S3 User Guide.\nContents\nBucketLevel\nA container element for the S3 Storage Lens bucket-level configuration.\nType: BucketLevel data type\nRequired: Yes\nActivityMetrics\nA container element for S3 Storage Lens activity metrics.\nType: ActivityMetrics data type\nRequired: No\nAdvancedCostOptimizationMetrics\nA container element for S3 Storage Lens advanced cost-optimization metrics.\nType: AdvancedCostOptimizationMetrics data type\nRequired: No\nAdvancedDataProtectionMetrics\nA container element for S3 Storage Lens advanced data-protection metrics.\nType: AdvancedDataProtectionMetrics data type\nRequired: No\nDetailedStatusCodesMetrics\nA container element for detailed status code metrics.\nAmazon S3 Control API Version 2006-03-01 1395",
      "start_idx": 1532803,
      "end_idx": 1533933,
      "metadata": {
        "num_sentences": 9,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1402",
      "text": "Amazon Simple Storage Service API Reference\nActivityMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens activity metrics. Activity metrics show details\nabout how your storage is requested, such as requests (for example, All requests, Get requests, Put\nrequests), bytes uploaded or downloaded, and errors.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3\nStorage Lens in the Amazon S3 User Guide. For a complete list of S3 Storage Lens metrics, see S3\nStorage Lens metrics glossary in the Amazon S3 User Guide.\nContents\nIsEnabled\nA container that indicates whether activity metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1397",
      "start_idx": 1534385,
      "end_idx": 1535306,
      "metadata": {
        "num_sentences": 6,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1403",
      "text": "Amazon Simple Storage Service API Reference\nAdvancedCostOptimizationMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens advanced cost-optimization metrics. Advanced\ncost-optimization metrics provide insights that you can use to manage and optimize your storage\ncosts, for example, lifecycle rule counts for transitions, expirations, and incomplete multipart\nuploads.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3\nStorage Lens in the Amazon S3 User Guide. For a complete list of S3 Storage Lens metrics, see S3\nStorage Lens metrics glossary in the Amazon S3 User Guide.\nContents\nIsEnabled\nA container that indicates whether advanced cost-optimization metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1398",
      "start_idx": 1535308,
      "end_idx": 1536309,
      "metadata": {
        "num_sentences": 6,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1404",
      "text": "Amazon Simple Storage Service API Reference\nAdvancedDataProtectionMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens advanced data-protection metrics. Advanced\ndata-protection metrics provide insights that you can use to perform audits and protect your data,\nfor example replication rule counts within and across Regions.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3\nStorage Lens in the Amazon S3 User Guide. For a complete list of S3 Storage Lens metrics, see S3\nStorage Lens metrics glossary in the Amazon S3 User Guide.\nContents\nIsEnabled\nA container that indicates whether advanced data-protection metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1399",
      "start_idx": 1536311,
      "end_idx": 1537266,
      "metadata": {
        "num_sentences": 6,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1408",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:.+\nRequired: No\nResponseDetails\nThe details of the response.\nType: AsyncResponseDetails data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1403",
      "start_idx": 1539011,
      "end_idx": 1539476,
      "metadata": {
        "num_sentences": 4,
        "num_words": 77,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1411",
      "text": "Amazon Simple Storage Service API Reference\nAwsLambdaTransformation\nService: Amazon S3 Control\nAWS Lambda function used to transform objects through an Object Lambda Access Point.\nContents\nFunctionArn\nThe Amazon Resource Name (ARN) of the AWS Lambda function.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: (arn:(aws[a-zA-Z-]*)?:lambda:)?([a-z]{2}((-gov)|(-iso(b?)))?-[a-\nz]+-\\d{1}:)?(\\d{12}:)?(function:)?([a-zA-Z0-9-_]+)(:(\\$LATEST|[a-zA-\nZ0-9-_]+))?\nRequired: Yes\nFunctionPayload\nAdditional JSON that provides supplemental data to the Lambda function used to transform\nobjects.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1406",
      "start_idx": 1541072,
      "end_idx": 1541938,
      "metadata": {
        "num_sentences": 9,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1414",
      "text": "Amazon Simple Storage Service API Reference\nCloudWatchMetrics\nService: Amazon S3 Control\nA container for enabling Amazon CloudWatch publishing for S3 Storage Lens metrics.\nFor more information about publishing S3 Storage Lens metrics to CloudWatch, see Monitor S3\nStorage Lens metrics in CloudWatch in the Amazon S3 User Guide.\nContents\nIsEnabled\nA container that indicates whether CloudWatch publishing for S3 Storage Lens metrics is\nenabled. A value of true indicates that CloudWatch publishing for S3 Storage Lens metrics is\nenabled.\nType: Boolean\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1409",
      "start_idx": 1543318,
      "end_idx": 1544102,
      "metadata": {
        "num_sentences": 5,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1415",
      "text": "Amazon Simple Storage Service API Reference\nCreateBucketConfiguration\nService: Amazon S3 Control\nThe container for the bucket configuration.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nLocationConstraint\nSpecifies the Region where the bucket will be created. If you are creating a bucket on the US\nEast (N. Virginia) Region (us-east-1), you do not need to specify the location.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: String\nValid Values: EU | eu-west-1 | us-west-1 | us-west-2 | ap-south-1 | ap-\nsoutheast-1 | ap-southeast-2 | ap-northeast-1 | sa-east-1 | cn-north-1 |\neu-central-1\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1410",
      "start_idx": 1544104,
      "end_idx": 1544972,
      "metadata": {
        "num_sentences": 6,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1416",
      "text": "Amazon Simple Storage Service API Reference\nCreateMultiRegionAccessPointInput\nService: Amazon S3 Control\nA container for the information associated with a CreateMultiRegionAccessPoint request.\nContents\nName\nThe name of the Multi-Region Access Point associated with this request.\nType: String\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: Yes\nRegions\nThe buckets in different Regions that are associated with the Multi-Region Access Point.\nType: Array of Region data types\nRequired: Yes\nPublicAccessBlock\nThe PublicAccessBlock configuration that you want to apply to this Amazon S3 account.\nYou can enable the configuration options in any combination. For more information about when\nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3\nUser Guide.\nThis data type is not supported for Amazon S3 on Outposts.\nType: PublicAccessBlockConfiguration data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1411",
      "start_idx": 1544974,
      "end_idx": 1546086,
      "metadata": {
        "num_sentences": 9,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1420",
      "text": "Amazon Simple Storage Service API Reference\nDeleteMarkerReplication\nService: Amazon S3 Control\nSpecifies whether S3 on Outposts replicates delete markers. If you specify a Filter element in\nyour replication configuration, you must also include a DeleteMarkerReplication element. If\nyour Filter includes a Tag element, the DeleteMarkerReplication element's Status child\nelement must be set to Disabled, because S3 on Outposts does not support replicating delete\nmarkers for tag-based rules.\nFor more information about delete marker replication, see How delete operations affect replication\nin the Amazon S3 User Guide.\nContents\nStatus\nIndicates whether to replicate delete markers.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1415",
      "start_idx": 1547390,
      "end_idx": 1548350,
      "metadata": {
        "num_sentences": 6,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1422",
      "text": "Amazon Simple Storage Service API Reference\nDestination\nService: Amazon S3 Control\nSpecifies information about the replication destination bucket and its settings for an S3 on\nOutposts replication configuration.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the access point for the destination bucket where you\nwant S3 on Outposts to store the replication results.\nType: String\nRequired: Yes\nAccessControlTranslation\nSpecify this property only in a cross-account scenario (where the source and destination bucket\nowners are not the same), and you want to change replica ownership to the AWS account that\nowns the destination bucket. If this property is not specified in the replication configuration, the\nreplicas are owned by same AWS account that owns the source object.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: AccessControlTranslation data type\nRequired: No\nAccount\nThe destination bucket owner's account ID.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1417",
      "start_idx": 1548964,
      "end_idx": 1550026,
      "metadata": {
        "num_sentences": 8,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1423",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nEncryptionConfiguration\nA container that provides information about encryption. If SourceSelectionCriteria is\nspecified, you must specify this element.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: EncryptionConfiguration data type\nRequired: No\nMetrics\nA container that specifies replication metrics-related settings.\nType: Metrics data type\nRequired: No\nReplicationTime\nA container that specifies S3 Replication Time Control (S3 RTC) settings, including whether S3\nRTC is enabled and the time when all objects and operations on objects must be replicated.\nMust be specified together with a Metrics block.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: ReplicationTime data type\nRequired: No\nStorageClass\nThe storage class to use when replicating objects. All objects stored on S3 on Outposts are\nstored in the OUTPOSTS storage class. S3 on Outposts uses the OUTPOSTS storage class to\ncreate the object replicas.\nAmazon S3 Control API Version 2006-03-01 1418",
      "start_idx": 1550028,
      "end_idx": 1551084,
      "metadata": {
        "num_sentences": 11,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1425",
      "text": "Amazon Simple Storage Service API Reference\nDetailedStatusCodesMetrics\nService: Amazon S3 Control\nThe container element for Amazon S3 Storage Lens detailed status code metrics. Detailed status\ncode metrics generate metrics for HTTP status codes, such as 200 OK, 403 Forbidden, 503\nService Unavailable and others.\nFor more information about S3 Storage Lens, see Assessing your storage activity and usage with S3\nStorage Lens in the Amazon S3 User Guide. For a complete list of S3 Storage Lens metrics, see S3\nStorage Lens metrics glossary in the Amazon S3 User Guide.\nContents\nIsEnabled\nA container that indicates whether detailed status code metrics are enabled.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1420",
      "start_idx": 1551594,
      "end_idx": 1552503,
      "metadata": {
        "num_sentences": 6,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1426",
      "text": "Amazon Simple Storage Service API Reference\nEncryptionConfiguration\nService: Amazon S3 Control\nSpecifies encryption-related information for an Amazon S3 bucket that is a destination for\nreplicated objects. If you're specifying a customer managed KMS key, we recommend using a fully\nqualified KMS key ARN. If you use a KMS key alias instead, then AWS KMS resolves the key within\nthe requester\u2019s account. This behavior can result in data that's encrypted with a KMS key that\nbelongs to the requester, and not the bucket owner.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nReplicaKmsKeyID\nSpecifies the ID of the customer managed AWS KMS key that's stored in AWS Key Management\nService (AWS KMS) for the destination bucket. This ID is either the Amazon Resource Name\n(ARN) for the KMS key or the alias ARN for the KMS key. Amazon S3 uses this KMS key to\nencrypt replica objects. Amazon S3 supports only symmetric encryption KMS keys. For\nmore information, see Symmetric encryption KMS keys in the AWS Key Management Service\nDeveloper Guide.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1421",
      "start_idx": 1552505,
      "end_idx": 1553813,
      "metadata": {
        "num_sentences": 11,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1427",
      "text": "Amazon Simple Storage Service API Reference\nEstablishedMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nThe last established access control policy for a Multi-Region Access Point.\nWhen you update the policy, the update is first listed as the proposed policy. After the update is\nfinished and all Regions have been updated, the proposed policy is listed as the established policy.\nIf both policies have the same version number, the proposed policy is the established policy.\nContents\nPolicy\nThe details of the last established policy.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1422",
      "start_idx": 1553815,
      "end_idx": 1554601,
      "metadata": {
        "num_sentences": 6,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1428",
      "text": "Amazon Simple Storage Service API Reference\nExclude\nService: Amazon S3 Control\nA container for what Amazon S3 Storage Lens will exclude.\nContents\nBuckets\nA container for the S3 Storage Lens bucket excludes.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: No\nRegions\nA container for the S3 Storage Lens Region excludes.\nType: Array of strings\nLength Constraints: Minimum length of 5. Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1423",
      "start_idx": 1554603,
      "end_idx": 1555335,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1431",
      "text": "Amazon Simple Storage Service API Reference\nGrantee\nService: Amazon S3 Control\nThe user, group, or role to which you are granting access. You can grant access to an IAM user or\nrole. If you have added your corporate directory to AWS IAM Identity Center and associated your\nIdentity Center instance with your S3 Access Grants instance, the grantee can also be a corporate\ndirectory user or group.\nContents\nGranteeIdentifier\nThe unique identifier of the Grantee. If the grantee type is IAM, the identifier is the\nIAM Amazon Resource Name (ARN) of the user or role. If the grantee type is a directory\nuser or group, the identifier is 128-bit universally unique identifier (UUID) in the format\na1b2c3d4-5678-90ab-cdef-EXAMPLE11111. You can obtain this UUID from your AWS IAM\nIdentity Center instance.\nType: String\nRequired: No\nGranteeType\nThe type of the grantee to which access has been granted. It can be one of the following values:\n\u2022 IAM - An IAM user or role.\n\u2022 DIRECTORY_USER - Your corporate directory user. You can use this option if you have added\nyour corporate identity directory to IAM Identity Center and associated the IAM Identity\nCenter instance with your S3 Access Grants instance.\n\u2022 DIRECTORY_GROUP - Your corporate directory group. You can use this option if you have\nadded your corporate identity directory to IAM Identity Center and associated the IAM\nIdentity Center instance with your S3 Access Grants instance.\nType: String\nValid Values: DIRECTORY_USER | DIRECTORY_GROUP | IAM\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1426",
      "start_idx": 1556591,
      "end_idx": 1558146,
      "metadata": {
        "num_sentences": 14,
        "num_words": 253,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1433",
      "text": "Amazon Simple Storage Service API Reference\nInclude\nService: Amazon S3 Control\nA container for what Amazon S3 Storage Lens configuration includes.\nContents\nBuckets\nA container for the S3 Storage Lens bucket includes.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: No\nRegions\nA container for the S3 Storage Lens Region includes.\nType: Array of strings\nLength Constraints: Minimum length of 5. Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1428",
      "start_idx": 1558413,
      "end_idx": 1559155,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1434",
      "text": "Amazon Simple Storage Service API Reference\nJobDescriptor\nService: Amazon S3 Control\nA container element for the job configuration and status information returned by a Describe Job\nrequest.\nContents\nConfirmationRequired\nIndicates whether confirmation is required before Amazon S3 begins running the specified job.\nConfirmation is required only for jobs created through the Amazon S3 console.\nType: Boolean\nRequired: No\nCreationTime\nA timestamp indicating when this job was created.\nType: Timestamp\nRequired: No\nDescription\nThe description for this job, if one was provided in this job's Create Job request.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nFailureReasons\nIf the specified job failed, this field contains information describing the failure.\nType: Array of JobFailure data types\nRequired: No\nGeneratedManifestDescriptor\nThe attribute of the JobDescriptor containing details about the job's generated manifest.\nAmazon S3 Control API Version 2006-03-01 1429",
      "start_idx": 1559157,
      "end_idx": 1560167,
      "metadata": {
        "num_sentences": 10,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1435",
      "text": "Amazon Simple Storage Service API Reference\nType: S3GeneratedManifestDescriptor data type\nRequired: No\nJobArn\nThe Amazon Resource Name (ARN) for this job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:[^:]+:s3:[a-zA-Z0-9\\-]+:\\d{12}:job\\/.*\nRequired: No\nJobId\nThe ID for the specified job.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: No\nManifest\nThe configuration information for the specified job's manifest object.\nType: JobManifest data type\nRequired: No\nManifestGenerator\nThe manifest generator that was used to generate a job manifest for this job.\nType: JobManifestGenerator data type\nNote: This object is a Union. Only one member of this object can be specified or returned.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1430",
      "start_idx": 1560169,
      "end_idx": 1561021,
      "metadata": {
        "num_sentences": 12,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1436",
      "text": "Amazon Simple Storage Service API Reference\nOperation\nThe operation that the specified job is configured to run on the objects listed in the manifest.\nType: JobOperation data type\nRequired: No\nPriority\nThe priority of the specified job.\nType: Integer\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nRequired: No\nProgressSummary\nDescribes the total number of tasks that the specified job has run, the number of tasks that\nsucceeded, and the number of tasks that failed.\nType: JobProgressSummary data type\nRequired: No\nReport\nContains the configuration information for the job-completion report if you requested one in\nthe Create Job request.\nType: JobReport data type\nRequired: No\nRoleArn\nThe Amazon Resource Name (ARN) for the AWS Identity and Access Management (IAM) role\nassigned to run the tasks for this job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nAmazon S3 Control API Version 2006-03-01 1431",
      "start_idx": 1561023,
      "end_idx": 1562012,
      "metadata": {
        "num_sentences": 11,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1437",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nStatus\nThe current status of the specified job.\nType: String\nValid Values: Active | Cancelled | Cancelling | Complete | Completing\n| Failed | Failing | New | Paused | Pausing | Preparing | Ready |\nSuspended\nRequired: No\nStatusUpdateReason\nThe reason for updating the job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nSuspendedCause\nThe reason why the specified job was suspended. A job is only suspended if you create it\nthrough the Amazon S3 console. When you create the job, it enters the Suspended state\nto await confirmation before running. After you confirm the job, it automatically exits the\nSuspended state.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nSuspendedDate\nThe timestamp when this job was suspended, if it has been suspended.\nType: Timestamp\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1432",
      "start_idx": 1562014,
      "end_idx": 1562980,
      "metadata": {
        "num_sentences": 12,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1438",
      "text": "Amazon Simple Storage Service API Reference\nTerminationDate\nA timestamp indicating when this job terminated. A job's termination date is the date and time\nwhen it succeeded, failed, or was canceled.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1433",
      "start_idx": 1562982,
      "end_idx": 1563429,
      "metadata": {
        "num_sentences": 3,
        "num_words": 77,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1439",
      "text": "Amazon Simple Storage Service API Reference\nJobFailure\nService: Amazon S3 Control\nIf this job failed, this element indicates why the job failed.\nContents\nFailureCode\nThe failure code, if any, for the specified job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nFailureReason\nThe failure reason, if any, for the specified job.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1434",
      "start_idx": 1563431,
      "end_idx": 1564109,
      "metadata": {
        "num_sentences": 8,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1440",
      "text": "Amazon Simple Storage Service API Reference\nJobListDescriptor\nService: Amazon S3 Control\nContains the configuration and status information for a single job retrieved as part of a job list.\nContents\nCreationTime\nA timestamp indicating when the specified job was created.\nType: Timestamp\nRequired: No\nDescription\nThe user-specified description that was included in the specified job's Create Job request.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 256.\nRequired: No\nJobId\nThe ID for the specified job.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 36.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: No\nOperation\nThe operation that the specified job is configured to run on every object listed in the manifest.\nType: String\nValid Values: LambdaInvoke | S3PutObjectCopy | S3PutObjectAcl |\nS3PutObjectTagging | S3DeleteObjectTagging | S3InitiateRestoreObject |\nS3PutObjectLegalHold | S3PutObjectRetention | S3ReplicateObject\nAmazon S3 Control API Version 2006-03-01 1435",
      "start_idx": 1564111,
      "end_idx": 1565120,
      "metadata": {
        "num_sentences": 10,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1441",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nPriority\nThe current priority for the specified job.\nType: Integer\nValid Range: Minimum value of 0. Maximum value of 2147483647.\nRequired: No\nProgressSummary\nDescribes the total number of tasks that the specified job has run, the number of tasks that\nsucceeded, and the number of tasks that failed.\nType: JobProgressSummary data type\nRequired: No\nStatus\nThe specified job's current status.\nType: String\nValid Values: Active | Cancelled | Cancelling | Complete | Completing\n| Failed | Failing | New | Paused | Pausing | Preparing | Ready |\nSuspended\nRequired: No\nTerminationDate\nA timestamp indicating when the specified job terminated. A job's termination date is the date\nand time when it succeeded, failed, or was canceled.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1436",
      "start_idx": 1565122,
      "end_idx": 1566091,
      "metadata": {
        "num_sentences": 8,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1443",
      "text": "Amazon Simple Storage Service API Reference\nJobManifest\nService: Amazon S3 Control\nContains the configuration information for a job's manifest.\nContents\nLocation\nContains the information required to locate the specified job's manifest. Manifests can't be\nimported from directory buckets. For more information, see Directory buckets.\nType: JobManifestLocation data type\nRequired: Yes\nSpec\nDescribes the format of the specified job's manifest. If the manifest is in CSV format, also\ndescribes the columns contained within the manifest.\nType: JobManifestSpec data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1438",
      "start_idx": 1566246,
      "end_idx": 1567045,
      "metadata": {
        "num_sentences": 7,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1448",
      "text": "Amazon Simple Storage Service API Reference\nJobManifestLocation\nService: Amazon S3 Control\nContains the information required to locate a manifest object. Manifests can't be imported from\ndirectory buckets. For more information, see Directory buckets.\nContents\nETag\nThe ETag for the specified manifest object.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: Yes\nObjectArn\nThe Amazon Resource Name (ARN) for a manifest object.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage\nreturns) in object keys with their equivalent XML entity codes. For more information, see\nXML-related object key constraints in the Amazon S3 User Guide.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nObjectVersionId\nThe optional version ID to identify a specific version of the manifest object.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nAmazon S3 Control API Version 2006-03-01 1443",
      "start_idx": 1569887,
      "end_idx": 1570937,
      "metadata": {
        "num_sentences": 16,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1450",
      "text": "Amazon Simple Storage Service API Reference\nJobManifestSpec\nService: Amazon S3 Control\nDescribes the format of a manifest. If the manifest is in CSV format, also describes the columns\ncontained within the manifest.\nContents\nFormat\nIndicates which of the available formats the specified manifest uses.\nType: String\nValid Values: S3BatchOperations_CSV_20180820 |\nS3InventoryReport_CSV_20161130\nRequired: Yes\nFields\nIf the specified manifest object is in the S3BatchOperations_CSV_20180820 format, this\nelement describes which columns contain the required data.\nType: Array of strings\nValid Values: Ignore | Bucket | Key | VersionId\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1445",
      "start_idx": 1571217,
      "end_idx": 1572079,
      "metadata": {
        "num_sentences": 5,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1451",
      "text": "Amazon Simple Storage Service API Reference\nJobOperation\nService: Amazon S3 Control\nThe operation that you want this job to perform on every object listed in the manifest. For more\ninformation about the available operations, see Operations in the Amazon S3 User Guide.\nContents\nLambdaInvoke\nDirects the specified job to invoke an AWS Lambda function on every object in the manifest.\nType: LambdaInvokeOperation data type\nRequired: No\nS3DeleteObjectTagging\nDirects the specified job to execute a DELETE Object tagging call on every object in the\nmanifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3DeleteObjectTaggingOperation data type\nRequired: No\nS3InitiateRestoreObject\nDirects the specified job to initiate restore requests for every archived object in the manifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3InitiateRestoreObjectOperation data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1446",
      "start_idx": 1572081,
      "end_idx": 1573051,
      "metadata": {
        "num_sentences": 8,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1452",
      "text": "Amazon Simple Storage Service API Reference\nS3PutObjectAcl\nDirects the specified job to run a PutObjectAcl call on every object in the manifest.\nNote\nThis functionality is not supported by directory buckets.\nType: S3SetObjectAclOperation data type\nRequired: No\nS3PutObjectCopy\nDirects the specified job to run a PUT Copy object call on every object in the manifest.\nType: S3CopyObjectOperation data type\nRequired: No\nS3PutObjectLegalHold\nContains the configuration for an S3 Object Lock legal hold operation that an S3 Batch\nOperations job passes to every object to the underlying PutObjectLegalHold API operation.\nFor more information, see Using S3 Object Lock legal hold with S3 Batch Operations in the\nAmazon S3 User Guide.\nNote\nThis functionality is not supported by directory buckets.\nType: S3SetObjectLegalHoldOperation data type\nRequired: No\nS3PutObjectRetention\nContains the configuration parameters for the Object Lock retention action for an S3 Batch\nOperations job. Batch Operations passes every object to the underlying PutObjectRetention\nAPI operation. For more information, see Using S3 Object Lock retention with S3 Batch\nOperations in the Amazon S3 User Guide.\nAmazon S3 Control API Version 2006-03-01 1447",
      "start_idx": 1573053,
      "end_idx": 1574275,
      "metadata": {
        "num_sentences": 10,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1457",
      "text": "Amazon Simple Storage Service API Reference\nJobReport\nService: Amazon S3 Control\nContains the configuration parameters for a job-completion report.\nContents\nEnabled\nIndicates whether the specified job will generate a job-completion report.\nType: Boolean\nRequired: Yes\nBucket\nThe Amazon Resource Name (ARN) for the bucket where specified job-completion report will be\nstored.\nNote\nDirectory buckets - Directory buckets aren't supported as a location for Batch\nOperations to store job completion reports.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: No\nFormat\nThe format of the specified job-completion report.\nType: String\nValid Values: Report_CSV_20180820\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1452",
      "start_idx": 1576102,
      "end_idx": 1576883,
      "metadata": {
        "num_sentences": 9,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1458",
      "text": "Amazon Simple Storage Service API Reference\nPrefix\nAn optional prefix to describe where in the specified bucket the job-completion report will\nbe stored. Amazon S3 stores the job-completion report at <prefix>/job-<job-id>/\nreport.json.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 512.\nRequired: No\nReportScope\nIndicates whether the job-completion report will include details of all tasks or only failed tasks.\nType: String\nValid Values: AllTasks | FailedTasksOnly\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1453",
      "start_idx": 1576885,
      "end_idx": 1577609,
      "metadata": {
        "num_sentences": 6,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1460",
      "text": "Amazon Simple Storage Service API Reference\nKeyNameConstraint\nService: Amazon S3 Control\nIf provided, the generated manifest includes only source bucket objects whose object\nkeys match the string constraints specified for MatchAnyPrefix, MatchAnySuffix, and\nMatchAnySubstring.\nContents\nMatchAnyPrefix\nIf provided, the generated manifest includes objects where the specified string appears at the\nstart of the object key string. Each KeyNameConstraint filter accepts an array of strings with a\nlength of 1 string.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nMatchAnySubstring\nIf provided, the generated manifest includes objects where the specified string appears\nanywhere within the object key string. Each KeyNameConstraint filter accepts an array of strings\nwith a length of 1 string.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nMatchAnySuffix\nIf provided, the generated manifest includes objects where the specified string appears at the\nend of the object key string. Each KeyNameConstraint filter accepts an array of strings with a\nlength of 1 string.\nType: Array of strings\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1455",
      "start_idx": 1578123,
      "end_idx": 1579439,
      "metadata": {
        "num_sentences": 14,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1462",
      "text": "Amazon Simple Storage Service API Reference\nLambdaInvokeOperation\nService: Amazon S3 Control\nContains the configuration parameters for a Lambda Invoke operation.\nContents\nFunctionArn\nThe Amazon Resource Name (ARN) for the AWS Lambda function that the specified job will\ninvoke on every object in the manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: (arn:(aws[a-zA-Z-]*)?:lambda:)?([a-z]{2}((-gov)|(-iso(b?)))?-[a-\nz]+-\\d{1}:)?(\\d{12}:)?(function:)?([a-zA-Z0-9-_]+)(:(\\$LATEST|[a-zA-\nZ0-9-_]+))?\nRequired: No\nInvocationSchemaVersion\nSpecifies the schema version for the payload that Batch Operations sends when invoking an\nAWS Lambda function. Version 1.0 is the default. Version 2.0 is required when you use Batch\nOperations to invoke AWS Lambda functions that act on directory buckets, or if you need to\nspecify UserArguments. For more information, see Automate object processing in Amazon S3\ndirectory buckets with S3 Batch Operations and AWS Lambda in the AWS Storage Blog.\nImportant\nEnsure that your AWS Lambda function code expects InvocationSchemaVersion\n2.0 and uses bucket name rather than bucket ARN. If the InvocationSchemaVersion\ndoes not match what your AWS Lambda function expects, your function might not work\nas expected.\nAmazon S3 Control API Version 2006-03-01 1457",
      "start_idx": 1579706,
      "end_idx": 1581036,
      "metadata": {
        "num_sentences": 14,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1463",
      "text": "Amazon Simple Storage Service API Reference\nNote\nDirectory buckets - To initiate AWS Lambda function to perform custom actions on\nobjects in directory buckets, you must specify 2.0.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nUserArguments\nKey-value pairs that are passed in the payload that Batch Operations sends when invoking an\nAWS Lambda function. You must specify InvocationSchemaVersion 2.0 for LambdaInvoke\noperations that include UserArguments. For more information, see Automate object\nprocessing in Amazon S3 directory buckets with S3 Batch Operations and AWS Lambda in the\nAWS Storage Blog.\nType: String to string map\nMap Entries: Maximum number of 10 items.\nKey Length Constraints: Minimum length of 1. Maximum length of 64.\nValue Length Constraints: Maximum length of 1024.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1458",
      "start_idx": 1581038,
      "end_idx": 1582103,
      "metadata": {
        "num_sentences": 11,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1465",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleExpiration\nService: Amazon S3 Control\nThe container of the Outposts bucket lifecycle expiration.\nContents\nDate\nIndicates at what date the object is to be deleted. Should be in GMT ISO 8601 format.\nType: Timestamp\nRequired: No\nDays\nIndicates the lifetime, in days, of the objects that are subject to the rule. The value must be a\nnon-zero positive integer.\nType: Integer\nRequired: No\nExpiredObjectDeleteMarker\nIndicates whether Amazon S3 will remove a delete marker with no noncurrent versions. If set to\ntrue, the delete marker will be expired. If set to false, the policy takes no action. This cannot be\nspecified with Days or Date in a Lifecycle Expiration Policy.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1460",
      "start_idx": 1582614,
      "end_idx": 1583580,
      "metadata": {
        "num_sentences": 10,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1467",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleRule\nService: Amazon S3 Control\nThe container for the Outposts bucket lifecycle rule.\nContents\nStatus\nIf 'Enabled', the rule is currently being applied. If 'Disabled', the rule is not currently being\napplied.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nAbortIncompleteMultipartUpload\nSpecifies the days since the initiation of an incomplete multipart upload that Amazon S3 waits\nbefore permanently removing all parts of the upload. For more information, see Aborting\nIncomplete Multipart Uploads Using a Bucket Lifecycle Configuration in the Amazon S3 User\nGuide.\nType: AbortIncompleteMultipartUpload data type\nRequired: No\nExpiration\nSpecifies the expiration for the lifecycle of the object in the form of date, days and, whether the\nobject has a delete marker.\nType: LifecycleExpiration data type\nRequired: No\nFilter\nThe container for the filter of lifecycle rule.\nType: LifecycleRuleFilter data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1462",
      "start_idx": 1583673,
      "end_idx": 1584703,
      "metadata": {
        "num_sentences": 8,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1468",
      "text": "Amazon Simple Storage Service API Reference\nID\nUnique identifier for the rule. The value cannot be longer than 255 characters.\nType: String\nRequired: No\nNoncurrentVersionExpiration\nThe noncurrent version expiration of the lifecycle rule.\nType: NoncurrentVersionExpiration data type\nRequired: No\nNoncurrentVersionTransitions\nSpecifies the transition rule for the lifecycle rule that describes when noncurrent objects\ntransition to a specific storage class. If your bucket is versioning-enabled (or versioning is\nsuspended), you can set this action to request that Amazon S3 transition noncurrent object\nversions to a specific storage class at a set period in the object's lifetime.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: Array of NoncurrentVersionTransition data types\nRequired: No\nTransitions\nSpecifies when an Amazon S3 object transitions to a specified storage class.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: Array of Transition data types\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1463",
      "start_idx": 1584705,
      "end_idx": 1585759,
      "metadata": {
        "num_sentences": 9,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1470",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleRuleAndOperator\nService: Amazon S3 Control\nThe container for the Outposts bucket lifecycle rule and operator.\nContents\nObjectSizeGreaterThan\nThe non-inclusive minimum object size for the lifecycle rule. Setting this property to 7 means\nthe rule applies to objects with a size that is greater than 7.\nType: Long\nRequired: No\nObjectSizeLessThan\nThe non-inclusive maximum object size for the lifecycle rule. Setting this property to 77 means\nthe rule applies to objects with a size that is less than 77.\nType: Long\nRequired: No\nPrefix\nPrefix identifying one or more objects to which the rule applies.\nType: String\nRequired: No\nTags\nAll of these tags must exist in the object's tag set in order for the rule to apply.\nType: Array of S3Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1465",
      "start_idx": 1586026,
      "end_idx": 1586995,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1472",
      "text": "Amazon Simple Storage Service API Reference\nLifecycleRuleFilter\nService: Amazon S3 Control\nThe container for the filter of the lifecycle rule.\nContents\nAnd\nThe container for the AND condition for the lifecycle rule.\nType: LifecycleRuleAndOperator data type\nRequired: No\nObjectSizeGreaterThan\nMinimum object size to which the rule applies.\nType: Long\nRequired: No\nObjectSizeLessThan\nMaximum object size to which the rule applies.\nType: Long\nRequired: No\nPrefix\nPrefix identifying one or more objects to which the rule applies.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage\nreturns) in object keys with their equivalent XML entity codes. For more information, see\nXML-related object key constraints in the Amazon S3 User Guide.\nType: String\nAmazon S3 Control API Version 2006-03-01 1467",
      "start_idx": 1587150,
      "end_idx": 1587984,
      "metadata": {
        "num_sentences": 8,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1474",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrantEntry\nService: Amazon S3 Control\nInformation about the access grant.\nContents\nAccessGrantArn\nThe Amazon Resource Name (ARN) of the access grant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/grant/[a-zA-\nZ0-9\\-]+\nRequired: No\nAccessGrantId\nThe ID of the access grant. S3 Access Grants auto-generates this ID when you create the access\ngrant.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nAccessGrantsLocationConfiguration\nThe configuration options of the grant location. The grant location is the S3 path to the data to\nwhich you are granting access.\nType: AccessGrantsLocationConfiguration data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1469",
      "start_idx": 1588342,
      "end_idx": 1589219,
      "metadata": {
        "num_sentences": 11,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1475",
      "text": "Amazon Simple Storage Service API Reference\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with\nyour Identity Center instance. If the grant includes an application ARN, the grantee can only\naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nRequired: No\nGrantee\nThe user, group, or role to which you are granting access. You can grant access to an IAM user\nor role. If you have added your corporate directory to AWS IAM Identity Center and associated\nyour Identity Center instance with your S3 Access Grants instance, the grantee can also be a\ncorporate directory user or group.\nType: Grantee data type\nAmazon S3 Control API Version 2006-03-01 1470",
      "start_idx": 1589221,
      "end_idx": 1590556,
      "metadata": {
        "num_sentences": 15,
        "num_words": 207,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1476",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nGrantScope\nThe S3 path of the data to which you are granting access. It is the result of appending the\nSubprefix to the location scope.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nPermission\nThe type of access granted to your S3 data, which can be set to one of the following values:\n\u2022 READ \u2013 Grant read-only access to the S3 data.\n\u2022 WRITE \u2013 Grant write-only access to the S3 data.\n\u2022 READWRITE \u2013 Grant both read and write access to the S3 data.\nType: String\nValid Values: READ | WRITE | READWRITE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1471",
      "start_idx": 1590558,
      "end_idx": 1591405,
      "metadata": {
        "num_sentences": 8,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1477",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrantsInstanceEntry\nService: Amazon S3 Control\nInformation about the S3 Access Grants instance.\nContents\nAccessGrantsInstanceArn\nThe Amazon Resource Name (ARN) of the S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/[a-zA-Z0-9\\-]+\nRequired: No\nAccessGrantsInstanceId\nThe ID of the S3 Access Grants instance. The ID is default. You can have one S3 Access Grants\ninstance per Region per account.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nCreatedAt\nThe date and time when you created the S3 Access Grants instance.\nType: Timestamp\nRequired: No\nIdentityCenterApplicationArn\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this\nfield returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application;\na subresource of the original Identity Center instance. S3 Access Grants creates this Identity\nCenter application for the specific S3 Access Grants instance.\nAmazon S3 Control API Version 2006-03-01 1472",
      "start_idx": 1591407,
      "end_idx": 1592611,
      "metadata": {
        "num_sentences": 13,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1478",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nIdentityCenterArn\nThis member has been deprecated.\nIf you associated your S3 Access Grants instance with an AWS IAM Identity Center instance, this\nfield returns the Amazon Resource Name (ARN) of the IAM Identity Center instance application;\na subresource of the original Identity Center instance. S3 Access Grants creates this Identity\nCenter application for the specific S3 Access Grants instance.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: No\nIdentityCenterInstanceArn\nThe Amazon Resource Name (ARN) of the AWS IAM Identity Center instance that you are\nassociating with your S3 Access Grants instance. An IAM Identity Center instance is your\ncorporate identity directory that you added to the IAM Identity Center. You can use the\nListInstances API operation to retrieve a list of your Identity Center instances and their ARNs.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::(\\d{12}){0,1}:instance/.*$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1473",
      "start_idx": 1592613,
      "end_idx": 1594022,
      "metadata": {
        "num_sentences": 16,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1480",
      "text": "Amazon Simple Storage Service API Reference\nListAccessGrantsLocationsEntry\nService: Amazon S3 Control\nA container for information about the registered location.\nContents\nAccessGrantsLocationArn\nThe Amazon Resource Name (ARN) of the registered location.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:access\\-grants\\/location/[a-zA-\nZ0-9\\-]+\nRequired: No\nAccessGrantsLocationId\nThe ID of the registered location to which you are granting access. S3 Access Grants assigns\nthis ID when you register the location. S3 Access Grants assigns the ID default to the default\nlocation s3:// and assigns an auto-generated ID to other locations that you register.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-]+\nRequired: No\nCreatedAt\nThe date and time when you registered the location.\nType: Timestamp\nRequired: No\nIAMRoleArn\nThe Amazon Resource Name (ARN) of the IAM role for the registered location. S3 Access Grants\nassumes this role to manage access to the registered location.\nAmazon S3 Control API Version 2006-03-01 1475",
      "start_idx": 1594177,
      "end_idx": 1595319,
      "metadata": {
        "num_sentences": 13,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1481",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:iam::\\d{12}:role/.*\nRequired: No\nLocationScope\nThe S3 path to the location that you are registering. The location scope can be the default S3\nlocation s3://, the S3 path to a bucket s3://<bucket>, or the S3 path to a bucket and prefix\ns3://<bucket>/<prefix>. A prefix in S3 is a string of characters at the beginning of an\nobject key name used to organize the objects that you store in your S3 buckets. For example,\nobject key names that start with the engineering/ prefix or object key names that start with\nthe marketing/campaigns/ prefix.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1476",
      "start_idx": 1595321,
      "end_idx": 1596328,
      "metadata": {
        "num_sentences": 10,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1482",
      "text": "Amazon Simple Storage Service API Reference\nListCallerAccessGrantsEntry\nService: Amazon S3 Control\nPart of ListCallerAccessGrantsResult. Each entry includes the permission level (READ,\nWRITE, or READWRITE) and the grant scope of the access grant. If the grant also includes an\napplication ARN, the grantee can only access the S3 data through this application.\nContents\nApplicationArn\nThe Amazon Resource Name (ARN) of an AWS IAM Identity Center application associated with\nyour Identity Center instance. If the grant includes an application ARN, the grantee can only\naccess the S3 data through this application.\nType: String\nLength Constraints: Minimum length of 10. Maximum length of 1224.\nPattern: arn:[^:]+:sso::\\d{12}:application/.*$\nRequired: No\nGrantScope\nThe S3 path of the data to which you have been granted access.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nPattern: ^.+$\nRequired: No\nPermission\nThe type of permission granted, which can be one of the following values:\n\u2022 READ - Grants read-only access to the S3 data.\n\u2022 WRITE - Grants write-only access to the S3 data.\n\u2022 READWRITE - Grants both read and write access to the S3 data.\nType: String\nAmazon S3 Control API Version 2006-03-01 1477",
      "start_idx": 1596330,
      "end_idx": 1597567,
      "metadata": {
        "num_sentences": 15,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1484",
      "text": "Amazon Simple Storage Service API Reference\nListStorageLensConfigurationEntry\nService: Amazon S3 Control\nPart of ListStorageLensConfigurationResult. Each entry includes the description of the\nS3 Storage Lens configuration, its home Region, whether it is enabled, its Amazon Resource Name\n(ARN), and config ID.\nContents\nHomeRegion\nA container for the S3 Storage Lens home Region. Your metrics data is stored and retained in\nyour designated S3 Storage Lens home Region.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: Yes\nId\nA container for the S3 Storage Lens configuration ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nStorageLensArn\nThe ARN of the S3 Storage Lens configuration. This property is read-only.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\/.*\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1479",
      "start_idx": 1597886,
      "end_idx": 1598928,
      "metadata": {
        "num_sentences": 16,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1485",
      "text": "Amazon Simple Storage Service API Reference\nIsEnabled\nA container for whether the S3 Storage Lens configuration is enabled. This property is required.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1480",
      "start_idx": 1598930,
      "end_idx": 1599327,
      "metadata": {
        "num_sentences": 3,
        "num_words": 69,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1486",
      "text": "Amazon Simple Storage Service API Reference\nListStorageLensGroupEntry\nService: Amazon S3 Control\nEach entry contains a Storage Lens group that exists in the specified home Region.\nContents\nHomeRegion\nContains the AWS Region where the Storage Lens group was created.\nType: String\nLength Constraints: Minimum length of 5. Maximum length of 30.\nPattern: [a-z0-9\\-]+\nRequired: Yes\nName\nContains the name of the Storage Lens group that exists in the specified home Region.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nStorageLensGroupArn\nContains the Amazon Resource Name (ARN) of the Storage Lens group. This property is read-\nonly.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1481",
      "start_idx": 1599329,
      "end_idx": 1600235,
      "metadata": {
        "num_sentences": 13,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1488",
      "text": "Amazon Simple Storage Service API Reference\nMatchObjectAge\nService: Amazon S3 Control\nA filter condition that specifies the object age range of included objects in days. Only integers are\nsupported.\nContents\nDaysGreaterThan\nSpecifies the maximum object age in days. Must be a positive whole number, greater than the\nminimum object age and less than or equal to 2,147,483,647.\nType: Integer\nRequired: No\nDaysLessThan\nSpecifies the minimum object age in days. The value must be a positive whole number, greater\nthan 0 and less than or equal to 2,147,483,647.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1483",
      "start_idx": 1600502,
      "end_idx": 1601305,
      "metadata": {
        "num_sentences": 7,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1489",
      "text": "Amazon Simple Storage Service API Reference\nMatchObjectSize\nService: Amazon S3 Control\nA filter condition that specifies the object size range of included objects in bytes. Only integers are\nsupported.\nContents\nBytesGreaterThan\nSpecifies the minimum object size in Bytes. The value must be a positive number, greater than 0\nand less than 5 TB.\nType: Long\nRequired: No\nBytesLessThan\nSpecifies the maximum object size in Bytes. The value must be a positive number, greater than\nthe minimum object size and less than 5 TB.\nType: Long\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1484",
      "start_idx": 1601307,
      "end_idx": 1602070,
      "metadata": {
        "num_sentences": 7,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1491",
      "text": "Amazon Simple Storage Service API Reference\nMultiRegionAccessPointPolicyDocument\nService: Amazon S3 Control\nThe Multi-Region Access Point access control policy.\nWhen you update the policy, the update is first listed as the proposed policy. After the update is\nfinished and all Regions have been updated, the proposed policy is listed as the established policy.\nIf both policies have the same version number, the proposed policy is the established policy.\nContents\nEstablished\nThe last established policy for the Multi-Region Access Point.\nType: EstablishedMultiRegionAccessPointPolicy data type\nRequired: No\nProposed\nThe proposed policy for the Multi-Region Access Point.\nType: ProposedMultiRegionAccessPointPolicy data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1486",
      "start_idx": 1602800,
      "end_idx": 1603757,
      "metadata": {
        "num_sentences": 7,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1492",
      "text": "Amazon Simple Storage Service API Reference\nMultiRegionAccessPointRegionalResponse\nService: Amazon S3 Control\nStatus information for a single Multi-Region Access Point Region.\nContents\nName\nThe name of the Region in the Multi-Region Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nRequestStatus\nThe current status of the Multi-Region Access Point in this Region.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1487",
      "start_idx": 1603759,
      "end_idx": 1604422,
      "metadata": {
        "num_sentences": 6,
        "num_words": 105,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1493",
      "text": "Amazon Simple Storage Service API Reference\nMultiRegionAccessPointReport\nService: Amazon S3 Control\nA collection of statuses for a Multi-Region Access Point in the various Regions it supports.\nContents\nAlias\nThe alias for the Multi-Region Access Point. For more information about the distinction between\nthe name and the alias of an Multi-Region Access Point, see Rules for naming Amazon S3 Multi-\nRegion Access Points.\nType: String\nLength Constraints: Maximum length of 63.\nPattern: ^[a-z][a-z0-9]*[.]mrap$\nRequired: No\nCreatedAt\nWhen the Multi-Region Access Point create request was received.\nType: Timestamp\nRequired: No\nName\nThe name of the Multi-Region Access Point.\nType: String\nLength Constraints: Maximum length of 50.\nPattern: ^[a-z0-9][-a-z0-9]{1,48}[a-z0-9]$\nRequired: No\nPublicAccessBlock\nThe PublicAccessBlock configuration that you want to apply to this Amazon S3 account.\nYou can enable the configuration options in any combination. For more information about when\nAmazon S3 Control API Version 2006-03-01 1488",
      "start_idx": 1604424,
      "end_idx": 1605449,
      "metadata": {
        "num_sentences": 11,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1494",
      "text": "Amazon Simple Storage Service API Reference\nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3\nUser Guide.\nThis data type is not supported for Amazon S3 on Outposts.\nType: PublicAccessBlockConfiguration data type\nRequired: No\nRegions\nA collection of the Regions and buckets associated with the Multi-Region Access Point.\nType: Array of RegionReport data types\nRequired: No\nStatus\nThe current status of the Multi-Region Access Point.\nCREATING and DELETING are temporary states that exist while the request is propagating and\nbeing completed. If a Multi-Region Access Point has a status of PARTIALLY_CREATED, you\ncan retry creation or send a request to delete the Multi-Region Access Point. If a Multi-Region\nAccess Point has a status of PARTIALLY_DELETED, you can retry a delete request to finish the\ndeletion of the Multi-Region Access Point.\nType: String\nValid Values: READY | INCONSISTENT_ACROSS_REGIONS | CREATING |\nPARTIALLY_CREATED | PARTIALLY_DELETED | DELETING\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1489",
      "start_idx": 1605451,
      "end_idx": 1606692,
      "metadata": {
        "num_sentences": 8,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1496",
      "text": "Amazon Simple Storage Service API Reference\nMultiRegionAccessPointRoute\nService: Amazon S3 Control\nA structure for a Multi-Region Access Point that indicates where Amazon S3 traffic can be routed.\nRoutes can be either active or passive. Active routes can process Amazon S3 requests through the\nMulti-Region Access Point, but passive routes are not eligible to process Amazon S3 requests.\nEach route contains the Amazon S3 bucket name and the AWS Region that the bucket is located\nin. The route also includes the TrafficDialPercentage value, which shows whether the bucket\nand Region are active (indicated by a value of 100) or passive (indicated by a value of 0).\nContents\nTrafficDialPercentage\nThe traffic state for the specified bucket or AWS Region.\nA value of 0 indicates a passive state, which means that no new traffic will be routed to the\nRegion.\nA value of 100 indicates an active state, which means that traffic will be routed to the specified\nRegion.\nWhen the routing configuration for a Region is changed from active to passive, any in-progress\noperations (uploads, copies, deletes, and so on) to the formerly active Region will continue to\nrun to until a final success or failure status is reached.\nIf all Regions in the routing configuration are designated as passive, you'll receive an\nInvalidRequest error.\nType: Integer\nValid Range: Minimum value of 0. Maximum value of 100.\nRequired: Yes\nBucket\nThe name of the Amazon S3 bucket for which you'll submit a routing configuration change.\nEither the Bucket or the Region value must be provided. If both are provided, the bucket must\nbe in the specified Region.\nType: String\nAmazon S3 Control API Version 2006-03-01 1491",
      "start_idx": 1606785,
      "end_idx": 1608467,
      "metadata": {
        "num_sentences": 16,
        "num_words": 274,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1497",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: No\nRegion\nThe AWS Region to which you'll be submitting a routing configuration change. Either the\nBucket or the Region value must be provided. If both are provided, the bucket must be in the\nspecified Region.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1492",
      "start_idx": 1608469,
      "end_idx": 1609104,
      "metadata": {
        "num_sentences": 8,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1499",
      "text": "Amazon Simple Storage Service API Reference\nNoncurrentVersionExpiration\nService: Amazon S3 Control\nThe container of the noncurrent version expiration.\nContents\nNewerNoncurrentVersions\nSpecifies how many noncurrent versions S3 on Outposts will retain. If there are this many\nmore recent noncurrent versions, S3 on Outposts will take the associated action. For more\ninformation about noncurrent versions, see Lifecycle configuration elements in the Amazon S3\nUser Guide.\nType: Integer\nRequired: No\nNoncurrentDays\nSpecifies the number of days an object is noncurrent before Amazon S3 can perform the\nassociated action. For information about the noncurrent days calculations, see How Amazon S3\nCalculates When an Object Became Noncurrent in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1494",
      "start_idx": 1609735,
      "end_idx": 1610744,
      "metadata": {
        "num_sentences": 7,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1500",
      "text": "Amazon Simple Storage Service API Reference\nNoncurrentVersionTransition\nService: Amazon S3 Control\nThe container for the noncurrent version transition.\nContents\nNoncurrentDays\nSpecifies the number of days an object is noncurrent before Amazon S3 can perform the\nassociated action. For information about the noncurrent days calculations, see How Amazon S3\nCalculates How Long an Object Has Been Noncurrent in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nStorageClass\nThe class of storage used to store the object.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING |\nDEEP_ARCHIVE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1495",
      "start_idx": 1610746,
      "end_idx": 1611598,
      "metadata": {
        "num_sentences": 5,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1501",
      "text": "Amazon Simple Storage Service API Reference\nObjectLambdaAccessPoint\nService: Amazon S3 Control\nAn access point with an attached AWS Lambda function used to access transformed data from an\nAmazon S3 bucket.\nContents\nName\nThe name of the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 45.\nPattern: ^[a-z0-9]([a-z0-9\\-]*[a-z0-9])?$\nRequired: Yes\nAlias\nThe alias of the Object Lambda Access Point.\nType: ObjectLambdaAccessPointAlias data type\nRequired: No\nObjectLambdaAccessPointArn\nSpecifies the ARN for the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:s3-object-lambda:[^:]*:\\d{12}:accesspoint/.*\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1496",
      "start_idx": 1611600,
      "end_idx": 1612498,
      "metadata": {
        "num_sentences": 10,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1503",
      "text": "Amazon Simple Storage Service API Reference\nObjectLambdaAccessPointAlias\nService: Amazon S3 Control\nThe alias of an Object Lambda Access Point. For more information, see How to use a bucket-style\nalias for your S3 bucket Object Lambda Access Point.\nContents\nStatus\nThe status of the Object Lambda Access Point alias. If the status is PROVISIONING, the Object\nLambda Access Point is provisioning the alias and the alias is not ready for use yet. If the status\nis READY, the Object Lambda Access Point alias is successfully provisioned and ready for use.\nType: String\nLength Constraints: Minimum length of 2. Maximum length of 16.\nValid Values: PROVISIONING | READY\nRequired: No\nValue\nThe alias value of the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 63.\nPattern: ^[0-9a-z\\\\-]{3,63}\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1498",
      "start_idx": 1612653,
      "end_idx": 1613723,
      "metadata": {
        "num_sentences": 11,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1505",
      "text": "Amazon Simple Storage Service API Reference\nObjectLambdaConfiguration\nService: Amazon S3 Control\nA configuration used when creating an Object Lambda Access Point.\nContents\nSupportingAccessPoint\nStandard access point associated with the Object Lambda Access Point.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nPattern: arn:[^:]+:s3:[^:]*:\\d{12}:accesspoint/.*\nRequired: Yes\nTransformationConfigurations\nA container for transformation configurations for an Object Lambda Access Point.\nType: Array of ObjectLambdaTransformationConfiguration data types\nRequired: Yes\nAllowedFeatures\nA container for allowed features. Valid inputs are GetObject-Range, GetObject-\nPartNumber, HeadObject-Range, and HeadObject-PartNumber.\nType: Array of strings\nValid Values: GetObject-Range | GetObject-PartNumber | HeadObject-Range |\nHeadObject-PartNumber\nRequired: No\nCloudWatchMetricsEnabled\nA container for whether the CloudWatch metrics configuration is enabled.\nType: Boolean\nAmazon S3 Control API Version 2006-03-01 1500",
      "start_idx": 1613816,
      "end_idx": 1614853,
      "metadata": {
        "num_sentences": 10,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1508",
      "text": "Amazon Simple Storage Service API Reference\nObjectLambdaTransformationConfiguration\nService: Amazon S3 Control\nA configuration used when creating an Object Lambda Access Point transformation.\nContents\nActions\nA container for the action of an Object Lambda Access Point configuration. Valid inputs are\nGetObject, ListObjects, HeadObject, and ListObjectsV2.\nType: Array of strings\nValid Values: GetObject | HeadObject | ListObjects | ListObjectsV2\nRequired: Yes\nContentTransformation\nA container for the content transformation of an Object Lambda Access Point configuration.\nType: ObjectLambdaContentTransformation data type\nNote: This object is a Union. Only one member of this object can be specified or returned.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1503",
      "start_idx": 1615726,
      "end_idx": 1616673,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1509",
      "text": "Amazon Simple Storage Service API Reference\nPolicyStatus\nService: Amazon S3 Control\nIndicates whether this access point policy is public. For more information about how Amazon S3\nevaluates policies to determine whether they are public, see The Meaning of \"Public\" in the Amazon\nS3 User Guide.\nContents\nIsPublic\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1504",
      "start_idx": 1616675,
      "end_idx": 1617232,
      "metadata": {
        "num_sentences": 3,
        "num_words": 94,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1512",
      "text": "Amazon Simple Storage Service API Reference\nProposedMultiRegionAccessPointPolicy\nService: Amazon S3 Control\nThe proposed access control policy for the Multi-Region Access Point.\nWhen you update the policy, the update is first listed as the proposed policy. After the update is\nfinished and all Regions have been updated, the proposed policy is listed as the established policy.\nIf both policies have the same version number, the proposed policy is the established policy.\nContents\nPolicy\nThe details of the proposed policy.\nType: String\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1507",
      "start_idx": 1618301,
      "end_idx": 1619070,
      "metadata": {
        "num_sentences": 6,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1513",
      "text": "Amazon Simple Storage Service API Reference\nPublicAccessBlockConfiguration\nService: Amazon S3 Control\nThe PublicAccessBlock configuration that you want to apply to this Amazon S3 account.\nYou can enable the configuration options in any combination. For more information about when\nAmazon S3 considers a bucket or object public, see The Meaning of \"Public\" in the Amazon S3 User\nGuide.\nThis data type is not supported for Amazon S3 on Outposts.\nContents\nBlockPublicAcls\nSpecifies whether Amazon S3 should block public access control lists (ACLs) for buckets in this\naccount. Setting this element to TRUE causes the following behavior:\n\u2022 PutBucketAcl and PutObjectAcl calls fail if the specified ACL is public.\n\u2022 PUT Object calls fail if the request includes a public ACL.\n\u2022 PUT Bucket calls fail if the request includes a public ACL.\nEnabling this setting doesn't affect existing policies or ACLs.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nBlockPublicPolicy\nSpecifies whether Amazon S3 should block public bucket policies for buckets in this account.\nSetting this element to TRUE causes Amazon S3 to reject calls to PUT Bucket policy if the\nspecified bucket policy allows public access.\nEnabling this setting doesn't affect existing bucket policies.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1508",
      "start_idx": 1619072,
      "end_idx": 1620494,
      "metadata": {
        "num_sentences": 15,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1514",
      "text": "Amazon Simple Storage Service API Reference\nIgnorePublicAcls\nSpecifies whether Amazon S3 should ignore public ACLs for buckets in this account. Setting this\nelement to TRUE causes Amazon S3 to ignore all public ACLs on buckets in this account and any\nobjects that they contain.\nEnabling this setting doesn't affect the persistence of any existing ACLs and doesn't prevent\nnew public ACLs from being set.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nRestrictPublicBuckets\nSpecifies whether Amazon S3 should restrict public bucket policies for buckets in this account.\nSetting this element to TRUE restricts access to buckets with public policies to only AWS service\nprincipals and authorized users within this account.\nEnabling this setting doesn't affect previously stored bucket policies, except that public and\ncross-account access within any public bucket policy, including non-public delegation to specific\naccounts, is blocked.\nThis property is not supported for Amazon S3 on Outposts.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1509",
      "start_idx": 1620496,
      "end_idx": 1621773,
      "metadata": {
        "num_sentences": 9,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1516",
      "text": "Amazon Simple Storage Service API Reference\nRegion\nService: Amazon S3 Control\nA Region that supports a Multi-Region Access Point as well as the associated bucket for the Region.\nContents\nBucket\nThe name of the associated bucket for the Region.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nBucketAccountId\nThe AWS account ID that owns the Amazon S3 bucket that's associated with this Multi-Region\nAccess Point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1511",
      "start_idx": 1622482,
      "end_idx": 1623243,
      "metadata": {
        "num_sentences": 7,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1517",
      "text": "Amazon Simple Storage Service API Reference\nRegionalBucket\nService: Amazon S3 Control\nThe container for the regional bucket.\nContents\nBucket\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: Yes\nCreationDate\nThe creation date of the regional bucket\nType: Timestamp\nRequired: Yes\nPublicAccessBlockEnabled\nType: Boolean\nRequired: Yes\nBucketArn\nThe Amazon Resource Name (ARN) for the regional bucket.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 128.\nRequired: No\nOutpostId\nThe AWS Outposts ID of the regional bucket.\nType: String\nAmazon S3 Control API Version 2006-03-01 1512",
      "start_idx": 1623245,
      "end_idx": 1623882,
      "metadata": {
        "num_sentences": 8,
        "num_words": 92,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1518",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1513",
      "start_idx": 1623884,
      "end_idx": 1624223,
      "metadata": {
        "num_sentences": 3,
        "num_words": 61,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1519",
      "text": "Amazon Simple Storage Service API Reference\nRegionReport\nService: Amazon S3 Control\nA combination of a bucket and Region that's part of a Multi-Region Access Point.\nContents\nBucket\nThe name of the bucket.\nType: String\nLength Constraints: Minimum length of 3. Maximum length of 255.\nRequired: No\nBucketAccountId\nThe AWS account ID that owns the Amazon S3 bucket that's associated with this Multi-Region\nAccess Point.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: No\nRegion\nThe name of the Region.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1514",
      "start_idx": 1624225,
      "end_idx": 1625004,
      "metadata": {
        "num_sentences": 10,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1521",
      "text": "Amazon Simple Storage Service API Reference\nReplicaModifications\nService: Amazon S3 Control\nA filter that you can use to specify whether replica modification sync is enabled. S3 on Outposts\nreplica modification sync can help you keep object metadata synchronized between replicas and\nsource objects. By default, S3 on Outposts replicates metadata from the source objects to the\nreplicas only. When replica modification sync is enabled, S3 on Outposts replicates metadata\nchanges made to the replica copies back to the source object, making the replication bidirectional.\nTo replicate object metadata modifications on replicas, you can specify this element and set the\nStatus of this element to Enabled.\nNote\nYou must enable replica modification sync on the source and destination buckets to\nreplicate replica metadata changes between the source and the replicas.\nContents\nStatus\nSpecifies whether S3 on Outposts replicates modifications to object metadata on replicas.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1516",
      "start_idx": 1625159,
      "end_idx": 1626407,
      "metadata": {
        "num_sentences": 8,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1522",
      "text": "Amazon Simple Storage Service API Reference\nReplicationConfiguration\nService: Amazon S3 Control\nA container for one or more replication rules. A replication configuration must have at least one\nrule and you can add up to 100 rules. The maximum size of a replication configuration is 128 KB.\nContents\nRole\nThe Amazon Resource Name (ARN) of the AWS Identity and Access Management (IAM) role\nthat S3 on Outposts assumes when replicating objects. For information about S3 replication on\nOutposts configuration, see Setting up replication in the Amazon S3 User Guide.\nType: String\nRequired: Yes\nRules\nA container for one or more replication rules. A replication configuration must have at least one\nrule and can contain an array of 100 rules at the most.\nType: Array of ReplicationRule data types\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1517",
      "start_idx": 1626409,
      "end_idx": 1627434,
      "metadata": {
        "num_sentences": 8,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1523",
      "text": "Amazon Simple Storage Service API Reference\nReplicationRule\nService: Amazon S3 Control\nSpecifies which S3 on Outposts objects to replicate and where to store the replicas.\nContents\nBucket\nThe Amazon Resource Name (ARN) of the access point for the source Outposts bucket that you\nwant S3 on Outposts to replicate the objects from.\nType: String\nRequired: Yes\nDestination\nA container for information about the replication destination and its configurations.\nType: Destination data type\nRequired: Yes\nStatus\nSpecifies whether the rule is enabled.\nType: String\nValid Values: Enabled | Disabled\nRequired: Yes\nDeleteMarkerReplication\nSpecifies whether S3 on Outposts replicates delete markers. If you specify a Filter element in\nyour replication configuration, you must also include a DeleteMarkerReplication element.\nIf your Filter includes a Tag element, the DeleteMarkerReplication element's Status\nchild element must be set to Disabled, because S3 on Outposts doesn't support replicating\ndelete markers for tag-based rules.\nFor more information about delete marker replication, see How delete operations affect\nreplication in the Amazon S3 User Guide.\nType: DeleteMarkerReplication data type\nAmazon S3 Control API Version 2006-03-01 1518",
      "start_idx": 1627436,
      "end_idx": 1628670,
      "metadata": {
        "num_sentences": 9,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1524",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nExistingObjectReplication\nAn optional configuration to replicate existing source bucket objects.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nType: ExistingObjectReplication data type\nRequired: No\nFilter\nA filter that identifies the subset of objects to which the replication rule applies. A Filter\nelement must specify exactly one Prefix, Tag, or And child element.\nType: ReplicationRuleFilter data type\nRequired: No\nID\nA unique identifier for the rule. The maximum value is 255 characters.\nType: String\nRequired: No\nPrefix\nThis member has been deprecated.\nAn object key name prefix that identifies the object or objects to which the rule applies. The\nmaximum prefix length is 1,024 characters. To include all objects in an Outposts bucket, specify\nan empty string.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage\nreturns) in object keys with their equivalent XML entity codes. For more information, see\nXML-related object key constraints in the Amazon S3 User Guide.\nAmazon S3 Control API Version 2006-03-01 1519",
      "start_idx": 1628672,
      "end_idx": 1629807,
      "metadata": {
        "num_sentences": 13,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1525",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nRequired: No\nPriority\nThe priority indicates which rule has precedence whenever two or more replication rules\nconflict. S3 on Outposts attempts to replicate objects according to all replication rules.\nHowever, if there are two or more rules with the same destination Outposts bucket, then\nobjects will be replicated according to the rule with the highest priority. The higher the number,\nthe higher the priority.\nFor more information, see Creating replication rules on Outposts in the Amazon S3 User Guide.\nType: Integer\nRequired: No\nSourceSelectionCriteria\nA container that describes additional filters for identifying the source Outposts objects that you\nwant to replicate. You can choose to enable or disable the replication of these objects.\nType: SourceSelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1520",
      "start_idx": 1629809,
      "end_idx": 1630884,
      "metadata": {
        "num_sentences": 8,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1526",
      "text": "Amazon Simple Storage Service API Reference\nReplicationRuleAndOperator\nService: Amazon S3 Control\nA container for specifying rule filters. The filters determine the subset of objects to which the rule\napplies. This element is required only if you specify more than one filter.\nFor example:\n\u2022 If you specify both a Prefix and a Tag filter, wrap these filters in an And element.\n\u2022 If you specify a filter based on multiple tags, wrap the Tag elements in an And element.\nContents\nPrefix\nAn object key name prefix that identifies the subset of objects that the rule applies to.\nType: String\nRequired: No\nTags\nAn array of tags that contain key and value pairs.\nType: Array of S3Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1521",
      "start_idx": 1630886,
      "end_idx": 1631806,
      "metadata": {
        "num_sentences": 8,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1527",
      "text": "Amazon Simple Storage Service API Reference\nReplicationRuleFilter\nService: Amazon S3 Control\nA filter that identifies the subset of objects to which the replication rule applies. A Filter element\nmust specify exactly one Prefix, Tag, or And child element.\nContents\nAnd\nA container for specifying rule filters. The filters determine the subset of objects that the rule\napplies to. This element is required only if you specify more than one filter. For example:\n\u2022 If you specify both a Prefix and a Tag filter, wrap these filters in an And element.\n\u2022 If you specify a filter based on multiple tags, wrap the Tag elements in an And element.\nType: ReplicationRuleAndOperator data type\nRequired: No\nPrefix\nAn object key name prefix that identifies the subset of objects that the rule applies to.\nImportant\nWhen you're using XML requests, you must replace special characters (such as carriage\nreturns) in object keys with their equivalent XML entity codes. For more information, see\nXML-related object key constraints in the Amazon S3 User Guide.\nType: String\nRequired: No\nTag\nA container for a key-value name pair.\nType: S3Tag data type\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1522",
      "start_idx": 1631808,
      "end_idx": 1632998,
      "metadata": {
        "num_sentences": 12,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1531",
      "text": "Amazon Simple Storage Service API Reference\nReplicationTimeValue\nService: Amazon S3 Control\nA container that specifies the time value for S3 Replication Time Control (S3 RTC). This value is also\nused for the replication metrics EventThreshold element.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nContents\nMinutes\nContains an integer that specifies the time period in minutes.\nValid value: 15\nType: Integer\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1526",
      "start_idx": 1634240,
      "end_idx": 1634895,
      "metadata": {
        "num_sentences": 5,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1534",
      "text": "Amazon Simple Storage Service API Reference\nS3BucketDestination\nService: Amazon S3 Control\nA container for the bucket where the Amazon S3 Storage Lens metrics export files are located.\nContents\nAccountId\nThe account ID of the owner of the S3 Storage Lens metrics export bucket.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nRequired: Yes\nArn\nThe Amazon Resource Name (ARN) of the bucket. This property is read-only and follows the\nfollowing format: arn:aws:s3:us-east-1:example-account-id:bucket/your-\ndestination-bucket-name\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nFormat\nType: String\nValid Values: CSV | Parquet\nRequired: Yes\nOutputSchemaVersion\nThe schema version of the export file.\nAmazon S3 Control API Version 2006-03-01 1529",
      "start_idx": 1635903,
      "end_idx": 1636738,
      "metadata": {
        "num_sentences": 9,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1536",
      "text": "Amazon Simple Storage Service API Reference\nS3CopyObjectOperation\nService: Amazon S3 Control\nContains the configuration parameters for a PUT Copy object operation. S3 Batch Operations\npasses every object to the underlying CopyObject API operation. For more information about the\nparameters for this operation, see CopyObject.\nContents\nAccessControlGrants\nNote\nThis functionality is not supported by directory buckets.\nType: Array of S3Grant data types\nRequired: No\nBucketKeyEnabled\nSpecifies whether Amazon S3 should use an S3 Bucket Key for object encryption with server-\nside encryption using AWS KMS (SSE-KMS). Setting this header to true causes Amazon S3 to\nuse an S3 Bucket Key for object encryption with SSE-KMS.\nSpecifying this header with an Copy action doesn\u2019t affect bucket-level settings for S3 Bucket\nKey.\nNote\nDirectory buckets - S3 Bucket Keys aren't supported, when you copy SSE-KMS\nencrypted objects from general purpose buckets to directory buckets, from directory\nbuckets to general purpose buckets, or between directory buckets, through the Copy\noperation in Batch Operations. In this case, Amazon S3 makes a call to AWS KMS every\ntime a copy request is made for a KMS-encrypted object.\nType: Boolean\nAmazon S3 Control API Version 2006-03-01 1531",
      "start_idx": 1637313,
      "end_idx": 1638578,
      "metadata": {
        "num_sentences": 10,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1537",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nCannedAccessControlList\nNote\nThis functionality is not supported by directory buckets.\nType: String\nValid Values: private | public-read | public-read-write | aws-exec-read |\nauthenticated-read | bucket-owner-read | bucket-owner-full-control\nRequired: No\nChecksumAlgorithm\nIndicates the algorithm that you want Amazon S3 to use to create the checksum. For more\ninformation, see Checking object integrity in the Amazon S3 User Guide.\nType: String\nValid Values: CRC32 | CRC32C | SHA1 | SHA256\nRequired: No\nMetadataDirective\nType: String\nValid Values: COPY | REPLACE\nRequired: No\nModifiedSinceConstraint\nType: Timestamp\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1532",
      "start_idx": 1638580,
      "end_idx": 1639311,
      "metadata": {
        "num_sentences": 4,
        "num_words": 100,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1538",
      "text": "Amazon Simple Storage Service API Reference\nNewObjectMetadata\nIf you don't provide this parameter, Amazon S3 copies all the metadata from the original\nobjects. If you specify an empty set, the new objects will have no tags. Otherwise, Amazon S3\nassigns the supplied tags to the new objects.\nType: S3ObjectMetadata data type\nRequired: No\nNewObjectTagging\nSpecifies a list of tags to add to the destination objects after they are copied. If\nNewObjectTagging is not specified, the tags of the source objects are copied to destination\nobjects by default.\nNote\nDirectory buckets - Tags aren't supported by directory buckets. If your source objects\nhave tags and your destination bucket is a directory bucket, specify an empty tag set in\nthe NewObjectTagging field to prevent copying the source object tags to the directory\nbucket.\nType: Array of S3Tag data types\nRequired: No\nObjectLockLegalHoldStatus\nThe legal hold status to be applied to all objects in the Batch Operations job.\nNote\nThis functionality is not supported by directory buckets.\nType: String\nValid Values: OFF | ON\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1533",
      "start_idx": 1639313,
      "end_idx": 1640447,
      "metadata": {
        "num_sentences": 10,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1539",
      "text": "Amazon Simple Storage Service API Reference\nObjectLockMode\nThe retention mode to be applied to all objects in the Batch Operations job.\nNote\nThis functionality is not supported by directory buckets.\nType: String\nValid Values: COMPLIANCE | GOVERNANCE\nRequired: No\nObjectLockRetainUntilDate\nThe date when the applied object retention configuration expires on all objects in the Batch\nOperations job.\nNote\nThis functionality is not supported by directory buckets.\nType: Timestamp\nRequired: No\nRedirectLocation\nIf the destination bucket is configured as a website, specifies an optional metadata property\nfor website redirects, x-amz-website-redirect-location. Allows webpage redirects if the\nobject copy is accessed through a website endpoint.\nNote\nThis functionality is not supported by directory buckets.\nType: String\nAmazon S3 Control API Version 2006-03-01 1534",
      "start_idx": 1640449,
      "end_idx": 1641311,
      "metadata": {
        "num_sentences": 8,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1540",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 2048.\nRequired: No\nRequesterPays\nNote\nThis functionality is not supported by directory buckets.\nType: Boolean\nRequired: No\nSSEAwsKmsKeyId\nSpecifies the AWS KMS key ID (Key ID, Key ARN, or Key Alias) to use for object encryption. If the\nKMS key doesn't exist in the same account that's issuing the command, you must use the full\nKey ARN not the Key ID.\nNote\nDirectory buckets - If you specify SSEAlgorithm with KMS, you must specify the\nSSEAwsKmsKeyId parameter with the ID (Key ID or Key ARN) of the AWS KMS\nsymmetric encryption customer managed key to use. Otherwise, you get an HTTP 400\nBad Request error. The key alias format of the KMS key isn't supported. To encrypt\nnew object copies in a directory bucket with SSE-KMS, you must specify SSE-KMS as\nthe directory bucket's default encryption configuration with a KMS key (specifically, a\ncustomer managed key). The AWS managed key (aws/s3) isn't supported. Your SSE-\nKMS configuration can only support 1 customer managed key per directory bucket for\nthe lifetime of the bucket. After you specify a customer managed key for SSE-KMS as\nthe bucket default encryption, you can't override the customer managed key for the\nbucket's SSE-KMS configuration. Then, when you specify server-side encryption settings\nfor new object copies with SSE-KMS, you must make sure the encryption key is the same\ncustomer managed key that you specified for the directory bucket's default encryption\nconfiguration.\nType: String\nAmazon S3 Control API Version 2006-03-01 1535",
      "start_idx": 1641313,
      "end_idx": 1642919,
      "metadata": {
        "num_sentences": 14,
        "num_words": 259,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1541",
      "text": "Amazon Simple Storage Service API Reference\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nRequired: No\nStorageClass\nSpecify the storage class for the destination objects in a Copy operation.\nNote\nDirectory buckets - This functionality is not supported by directory buckets.\nType: String\nValid Values: STANDARD | STANDARD_IA | ONEZONE_IA | GLACIER |\nINTELLIGENT_TIERING | DEEP_ARCHIVE | GLACIER_IR\nRequired: No\nTargetKeyPrefix\nSpecifies the folder prefix that you want the objects to be copied into. For example, to copy\nobjects into a folder named Folder1 in the destination bucket, set the TargetKeyPrefix\nproperty to Folder1.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nTargetResource\nSpecifies the destination bucket Amazon Resource Name (ARN) for the batch copy operation.\n\u2022 General purpose buckets - For example, to copy objects to a general purpose\nbucket named destinationBucket, set the TargetResource property to\narn:aws:s3:::destinationBucket.\n\u2022 Directory buckets - For example, to copy objects to a directory bucket named\ndestinationBucket in the Availability Zone; identified by the AZ ID usw2-az1, set\nthe TargetResource property to arn:aws:s3express:region:account_id:/\nbucket/destination_bucket_base_name--usw2-az1--x-s3.\nAmazon S3 Control API Version 2006-03-01 1536",
      "start_idx": 1642921,
      "end_idx": 1644269,
      "metadata": {
        "num_sentences": 12,
        "num_words": 186,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1542",
      "text": "Amazon Simple Storage Service API Reference\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:(s3|s3express):.*\nRequired: No\nUnModifiedSinceConstraint\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1537",
      "start_idx": 1644271,
      "end_idx": 1644716,
      "metadata": {
        "num_sentences": 4,
        "num_words": 70,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1544",
      "text": "Amazon Simple Storage Service API Reference\nS3GeneratedManifestDescriptor\nService: Amazon S3 Control\nDescribes the specified job's generated manifest. Batch Operations jobs created with a\nManifestGenerator populate details of this descriptor after execution of the ManifestGenerator.\nContents\nFormat\nThe format of the generated manifest.\nType: String\nValid Values: S3InventoryReport_CSV_20211130\nRequired: No\nLocation\nContains the information required to locate a manifest object. Manifests can't be imported from\ndirectory buckets. For more information, see Directory buckets.\nType: JobManifestLocation data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1539",
      "start_idx": 1645318,
      "end_idx": 1646164,
      "metadata": {
        "num_sentences": 7,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1546",
      "text": "Amazon Simple Storage Service API Reference\nS3Grantee\nService: Amazon S3 Control\nContents\nDisplayName\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nIdentifier\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nTypeIdentifier\nType: String\nValid Values: id | emailAddress | uri\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1541",
      "start_idx": 1646624,
      "end_idx": 1647217,
      "metadata": {
        "num_sentences": 5,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1547",
      "text": "Amazon Simple Storage Service API Reference\nS3InitiateRestoreObjectOperation\nService: Amazon S3 Control\nContains the configuration parameters for a POST Object restore job. S3 Batch Operations passes\nevery object to the underlying RestoreObject API operation. For more information about the\nparameters for this operation, see RestoreObject.\nContents\nExpirationInDays\nThis argument specifies how long the S3 Glacier or S3 Glacier Deep Archive object remains\navailable in Amazon S3. S3 Initiate Restore Object jobs that target S3 Glacier and S3 Glacier\nDeep Archive objects require ExpirationInDays set to 1 or greater.\nConversely, do not set ExpirationInDays when creating S3 Initiate Restore Object jobs\nthat target S3 Intelligent-Tiering Archive Access and Deep Archive Access tier objects. Objects\nin S3 Intelligent-Tiering archive access tiers are not subject to restore expiry, so specifying\nExpirationInDays results in restore request failure.\nS3 Batch Operations jobs can operate either on S3 Glacier and S3 Glacier Deep Archive storage\nclass objects or on S3 Intelligent-Tiering Archive Access and Deep Archive Access storage tier\nobjects, but not both types in the same job. If you need to restore objects of both types you\nmust create separate Batch Operations jobs.\nType: Integer\nValid Range: Minimum value of 1.\nRequired: No\nGlacierJobTier\nS3 Batch Operations supports STANDARD and BULK retrieval tiers, but not the EXPEDITED\nretrieval tier.\nType: String\nValid Values: BULK | STANDARD\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1542",
      "start_idx": 1647219,
      "end_idx": 1648773,
      "metadata": {
        "num_sentences": 12,
        "num_words": 229,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1549",
      "text": "Amazon Simple Storage Service API Reference\nS3JobManifestGenerator\nService: Amazon S3 Control\nThe container for the service that will create the S3 manifest.\nContents\nEnableManifestOutput\nDetermines whether or not to write the job's generated manifest to a bucket.\nType: Boolean\nRequired: Yes\nSourceBucket\nThe ARN of the source bucket used by the ManifestGenerator.\nNote\nDirectory buckets - Directory buckets aren't supported as the source buckets used by\nS3JobManifestGenerator to generate the job manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nExpectedBucketOwner\nThe AWS account ID that owns the bucket the generated manifest is written to. If provided the\ngenerated manifest bucket's owner AWS account ID must match this value, else the job fails.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1544",
      "start_idx": 1649040,
      "end_idx": 1649989,
      "metadata": {
        "num_sentences": 11,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1550",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nFilter\nSpecifies rules the S3JobManifestGenerator should use to decide whether an object in the\nsource bucket should or should not be included in the generated job manifest.\nType: JobManifestGeneratorFilter data type\nRequired: No\nManifestOutputLocation\nSpecifies the location the generated manifest will be written to. Manifests can't be written to\ndirectory buckets. For more information, see Directory buckets.\nType: S3ManifestOutputLocation data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1545",
      "start_idx": 1649991,
      "end_idx": 1650734,
      "metadata": {
        "num_sentences": 5,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1551",
      "text": "Amazon Simple Storage Service API Reference\nS3ManifestOutputLocation\nService: Amazon S3 Control\nLocation details for where the generated manifest should be written.\nContents\nBucket\nThe bucket ARN the generated manifest should be written to.\nNote\nDirectory buckets - Directory buckets aren't supported as the buckets to store the\ngenerated manifest.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: arn:[^:]+:s3:.*\nRequired: Yes\nManifestFormat\nThe format of the generated manifest.\nType: String\nValid Values: S3InventoryReport_CSV_20211130\nRequired: Yes\nExpectedManifestBucketOwner\nThe Account ID that owns the bucket the generated manifest is written to.\nType: String\nLength Constraints: Maximum length of 64.\nPattern: ^\\d{12}$\nAmazon S3 Control API Version 2006-03-01 1546",
      "start_idx": 1650736,
      "end_idx": 1651546,
      "metadata": {
        "num_sentences": 10,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1552",
      "text": "Amazon Simple Storage Service API Reference\nRequired: No\nManifestEncryption\nSpecifies what encryption should be used when the generated manifest objects are written.\nType: GeneratedManifestEncryption data type\nRequired: No\nManifestPrefix\nPrefix identifying one or more objects to which the manifest applies.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 512.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1547",
      "start_idx": 1651548,
      "end_idx": 1652165,
      "metadata": {
        "num_sentences": 5,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1554",
      "text": "Amazon Simple Storage Service API Reference\nS3ObjectMetadata\nService: Amazon S3 Control\nContents\nCacheControl\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentDisposition\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentEncoding\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentLanguage\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentLength\nThis member has been deprecated.\nType: Long\nAmazon S3 Control API Version 2006-03-01 1549",
      "start_idx": 1652731,
      "end_idx": 1653359,
      "metadata": {
        "num_sentences": 10,
        "num_words": 87,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1555",
      "text": "Amazon Simple Storage Service API Reference\nValid Range: Minimum value of 0.\nRequired: No\nContentMD5\nThis member has been deprecated.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nContentType\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nHttpExpiresDate\nType: Timestamp\nRequired: No\nRequesterCharged\nThis member has been deprecated.\nType: Boolean\nRequired: No\nSSEAlgorithm\nThe server-side encryption algorithm used when storing objects in Amazon S3.\nDirectory buckets - For directory buckets, there are only two supported options for server-\nside encryption: server-side encryption with Amazon S3 managed keys (SSE-S3) (AES256)\nand server-side encryption with AWS KMS keys (SSE-KMS) (KMS). For more information,\nAmazon S3 Control API Version 2006-03-01 1550",
      "start_idx": 1653361,
      "end_idx": 1654208,
      "metadata": {
        "num_sentences": 10,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1556",
      "text": "Amazon Simple Storage Service API Reference\nsee Protecting data with server-side encryption in the Amazon S3 User Guide. For the Copy\noperation in Batch Operations, see S3CopyObjectOperation.\nType: String\nValid Values: AES256 | KMS\nRequired: No\nUserMetadata\nType: String to string map\nMap Entries: Maximum number of 8192 items.\nKey Length Constraints: Minimum length of 1. Maximum length of 1024.\nValue Length Constraints: Maximum length of 1024.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1551",
      "start_idx": 1654210,
      "end_idx": 1654889,
      "metadata": {
        "num_sentences": 7,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1557",
      "text": "Amazon Simple Storage Service API Reference\nS3ObjectOwner\nService: Amazon S3 Control\nContents\nDisplayName\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nID\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1552",
      "start_idx": 1654891,
      "end_idx": 1655401,
      "metadata": {
        "num_sentences": 5,
        "num_words": 85,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1559",
      "text": "Amazon Simple Storage Service API Reference\nS3Retention\nService: Amazon S3 Control\nContains the S3 Object Lock retention mode to be applied to all objects in the S3 Batch Operations\njob. If you don't provide Mode and RetainUntilDate data types in your operation, you will\nremove the retention from your objects. For more information, see Using S3 Object Lock retention\nwith S3 Batch Operations in the Amazon S3 User Guide.\nContents\nMode\nThe Object Lock retention mode to be applied to all objects in the Batch Operations job.\nType: String\nValid Values: COMPLIANCE | GOVERNANCE\nRequired: No\nRetainUntilDate\nThe date when the applied Object Lock retention will expire on all objects set by the Batch\nOperations job.\nType: Timestamp\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1554",
      "start_idx": 1655885,
      "end_idx": 1656847,
      "metadata": {
        "num_sentences": 6,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1560",
      "text": "Amazon Simple Storage Service API Reference\nS3SetObjectAclOperation\nService: Amazon S3 Control\nContains the configuration parameters for a PUT Object ACL operation. S3 Batch Operations passes\nevery object to the underlying PutObjectAcl API operation. For more information about the\nparameters for this operation, see PutObjectAcl.\nContents\nAccessControlPolicy\nType: S3AccessControlPolicy data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1555",
      "start_idx": 1656849,
      "end_idx": 1657479,
      "metadata": {
        "num_sentences": 4,
        "num_words": 95,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1561",
      "text": "Amazon Simple Storage Service API Reference\nS3SetObjectLegalHoldOperation\nService: Amazon S3 Control\nContains the configuration for an S3 Object Lock legal hold operation that an S3 Batch Operations\njob passes to every object to the underlying PutObjectLegalHold API operation. For more\ninformation, see Using S3 Object Lock legal hold with S3 Batch Operations in the Amazon S3 User\nGuide.\nNote\nThis functionality is not supported by directory buckets.\nContents\nLegalHold\nContains the Object Lock legal hold status to be applied to all objects in the Batch Operations\njob.\nType: S3ObjectLockLegalHold data type\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1556",
      "start_idx": 1657481,
      "end_idx": 1658325,
      "metadata": {
        "num_sentences": 5,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1562",
      "text": "Amazon Simple Storage Service API Reference\nS3SetObjectRetentionOperation\nService: Amazon S3 Control\nContains the configuration parameters for the Object Lock retention action for an S3 Batch\nOperations job. Batch Operations passes every object to the underlying PutObjectRetention\nAPI operation. For more information, see Using S3 Object Lock retention with S3 Batch Operations\nin the Amazon S3 User Guide.\nNote\nThis functionality is not supported by directory buckets.\nContents\nRetention\nContains the Object Lock retention mode to be applied to all objects in the Batch Operations\njob. For more information, see Using S3 Object Lock retention with S3 Batch Operations in the\nAmazon S3 User Guide.\nType: S3Retention data type\nRequired: Yes\nBypassGovernanceRetention\nIndicates if the action should be applied to objects in the Batch Operations job even if they have\nObject Lock GOVERNANCE type in place.\nType: Boolean\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 1557",
      "start_idx": 1658327,
      "end_idx": 1659455,
      "metadata": {
        "num_sentences": 8,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1564",
      "text": "Amazon Simple Storage Service API Reference\nS3SetObjectTaggingOperation\nService: Amazon S3 Control\nContains the configuration parameters for a PUT Object Tagging operation. S3 Batch Operations\npasses every object to the underlying PutObjectTagging API operation. For more information\nabout the parameters for this operation, see PutObjectTagging.\nContents\nTagSet\nType: Array of S3Tag data types\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1559",
      "start_idx": 1659570,
      "end_idx": 1660197,
      "metadata": {
        "num_sentences": 4,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1565",
      "text": "Amazon Simple Storage Service API Reference\nS3Tag\nService: Amazon S3 Control\nA container for a key-value name pair.\nContents\nKey\nKey of the tag\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nValue\nValue of the tag\nType: String\nLength Constraints: Minimum length of 0. Maximum length of 256.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1560",
      "start_idx": 1660199,
      "end_idx": 1660849,
      "metadata": {
        "num_sentences": 6,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1566",
      "text": "Amazon Simple Storage Service API Reference\nSelectionCriteria\nService: Amazon S3 Control\nContents\nDelimiter\nA container for the delimiter of the selection criteria being used.\nType: String\nLength Constraints: Maximum length of 1.\nRequired: No\nMaxDepth\nThe max depth of the selection criteria\nType: Integer\nValid Range: Minimum value of 1. Maximum value of 10.\nRequired: No\nMinStorageBytesPercentage\nThe minimum number of storage bytes percentage whose metrics will be selected.\nNote\nYou must choose a value greater than or equal to 1.0.\nType: Double\nValid Range: Minimum value of 0.1. Maximum value of 100.\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1561",
      "start_idx": 1660851,
      "end_idx": 1661628,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1568",
      "text": "Amazon Simple Storage Service API Reference\nSourceSelectionCriteria\nService: Amazon S3 Control\nA container that describes additional filters for identifying the source objects that you want to\nreplicate. You can choose to enable or disable the replication of these objects.\nContents\nReplicaModifications\nA filter that you can use to specify whether replica modification sync is enabled. S3 on Outposts\nreplica modification sync can help you keep object metadata synchronized between replicas\nand source objects. By default, S3 on Outposts replicates metadata from the source objects\nto the replicas only. When replica modification sync is enabled, S3 on Outposts replicates\nmetadata changes made to the replica copies back to the source object, making the replication\nbidirectional.\nTo replicate object metadata modifications on replicas, you can specify this element and set the\nStatus of this element to Enabled.\nNote\nYou must enable replica modification sync on the source and destination buckets to\nreplicate replica metadata changes between the source and the replicas.\nType: ReplicaModifications data type\nRequired: No\nSseKmsEncryptedObjects\nA filter that you can use to select Amazon S3 objects that are encrypted with server-\nside encryption by using AWS Key Management Service (AWS KMS) keys. If you include\nSourceSelectionCriteria in the replication configuration, this element is required.\nNote\nThis is not supported by Amazon S3 on Outposts buckets.\nAmazon S3 Control API Version 2006-03-01 1563",
      "start_idx": 1661783,
      "end_idx": 1663290,
      "metadata": {
        "num_sentences": 12,
        "num_words": 223,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1570",
      "text": "Amazon Simple Storage Service API Reference\nSSEKMS\nService: Amazon S3 Control\nContents\nKeyId\nA container for the ARN of the SSE-KMS encryption. This property is read-only and\nfollows the following format: arn:aws:kms:us-east-1:example-account-\nid:key/example-9a73-4afc-8d29-8f5900cef44e\nType: String\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1565",
      "start_idx": 1663609,
      "end_idx": 1664142,
      "metadata": {
        "num_sentences": 2,
        "num_words": 80,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1572",
      "text": "Amazon Simple Storage Service API Reference\nSSEKMSEncryption\nService: Amazon S3 Control\nConfiguration for the use of SSE-KMS to encrypt generated manifest objects.\nContents\nKeyId\nSpecifies the ID of the AWS Key Management Service (AWS KMS) symmetric encryption\ncustomer managed key to use for encrypting generated manifest objects.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 2000.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1567",
      "start_idx": 1664885,
      "end_idx": 1665528,
      "metadata": {
        "num_sentences": 5,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1575",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensAwsOrg\nService: Amazon S3 Control\nThe AWS organization for your S3 Storage Lens.\nContents\nArn\nA container for the Amazon Resource Name (ARN) of the AWS organization. This property\nis read-only and follows the following format: arn:aws:organizations:us-\neast-1:example-account-id:organization/o-ex2l495dck\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:organizations::\\d{12}:organization\\/o-[a-z0-9]{10,32}\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1570",
      "start_idx": 1666355,
      "end_idx": 1667102,
      "metadata": {
        "num_sentences": 5,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1576",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensConfiguration\nService: Amazon S3 Control\nA container for the Amazon S3 Storage Lens configuration.\nContents\nAccountLevel\nA container for all the account-level configurations of your S3 Storage Lens configuration.\nType: AccountLevel data type\nRequired: Yes\nId\nA container for the Amazon S3 Storage Lens configuration ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_\\.]+\nRequired: Yes\nIsEnabled\nA container for whether the S3 Storage Lens configuration is enabled.\nType: Boolean\nRequired: Yes\nAwsOrg\nA container for the AWS organization for this S3 Storage Lens configuration.\nType: StorageLensAwsOrg data type\nRequired: No\nDataExport\nA container to specify the properties of your S3 Storage Lens metrics export including, the\ndestination, schema and format.\nAmazon S3 Control API Version 2006-03-01 1571",
      "start_idx": 1667104,
      "end_idx": 1668016,
      "metadata": {
        "num_sentences": 10,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1577",
      "text": "Amazon Simple Storage Service API Reference\nType: StorageLensDataExport data type\nRequired: No\nExclude\nA container for what is excluded in this configuration. This container can only be valid if there is\nno Include container submitted, and it's not empty.\nType: Exclude data type\nRequired: No\nInclude\nA container for what is included in this configuration. This container can only be valid if there is\nno Exclude container submitted, and it's not empty.\nType: Include data type\nRequired: No\nStorageLensArn\nThe Amazon Resource Name (ARN) of the S3 Storage Lens configuration. This property is read-\nonly and follows the following format: arn:aws:s3:us-east-1:example-account-\nid:storage-lens/your-dashboard-name\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\/.*\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\nAmazon S3 Control API Version 2006-03-01 1572",
      "start_idx": 1668018,
      "end_idx": 1669079,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1581",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensGroup\nService: Amazon S3 Control\nA custom grouping of objects that include filters for prefixes, suffixes, object tags, object size, or\nobject age. You can create an S3 Storage Lens group that includes a single filter or multiple filter\nconditions. To specify multiple filter conditions, you use AND or OR logical operators.\nContents\nFilter\nSets the criteria for the Storage Lens group data that is displayed. For multiple filter conditions,\nthe AND or OR logical operator is used.\nType: StorageLensGroupFilter data type\nRequired: Yes\nName\nContains the name of the Storage Lens group.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 64.\nPattern: [a-zA-Z0-9\\-\\_]+\nRequired: Yes\nStorageLensGroupArn\nContains the Amazon Resource Name (ARN) of the Storage Lens group. This property is read-\nonly.\nType: String\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: No\nAmazon S3 Control API Version 2006-03-01 1576",
      "start_idx": 1670519,
      "end_idx": 1671596,
      "metadata": {
        "num_sentences": 14,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1583",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensGroupAndOperator\nService: Amazon S3 Control\nA logical operator that allows multiple filter conditions to be joined for more complex comparisons\nof Storage Lens group data.\nContents\nMatchAnyPrefix\nContains a list of prefixes. At least one prefix must be specified. Up to 10 prefixes are allowed.\nType: Array of strings\nRequired: No\nMatchAnySuffix\nContains a list of suffixes. At least one suffix must be specified. Up to 10 suffixes are allowed.\nType: Array of strings\nRequired: No\nMatchAnyTag\nContains the list of object tags. At least one object tag must be specified. Up to 10 object tags\nare allowed.\nType: Array of S3Tag data types\nRequired: No\nMatchObjectAge\nContains DaysGreaterThan and DaysLessThan to define the object age range (minimum and\nmaximum number of days).\nType: MatchObjectAge data type\nRequired: No\nMatchObjectSize\nContains BytesGreaterThan and BytesLessThan to define the object size range (minimum\nand maximum number of Bytes).\nAmazon S3 Control API Version 2006-03-01 1578",
      "start_idx": 1671863,
      "end_idx": 1672913,
      "metadata": {
        "num_sentences": 13,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1585",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensGroupFilter\nService: Amazon S3 Control\nThe filter element sets the criteria for the Storage Lens group data that is displayed. For multiple\nfilter conditions, the AND or OR logical operator is used.\nContents\nAnd\nA logical operator that allows multiple filter conditions to be joined for more complex\ncomparisons of Storage Lens group data. Objects must match all of the listed filter conditions\nthat are joined by the And logical operator. Only one of each filter condition is allowed.\nType: StorageLensGroupAndOperator data type\nRequired: No\nMatchAnyPrefix\nContains a list of prefixes. At least one prefix must be specified. Up to 10 prefixes are allowed.\nType: Array of strings\nRequired: No\nMatchAnySuffix\nContains a list of suffixes. At least one suffix must be specified. Up to 10 suffixes are allowed.\nType: Array of strings\nRequired: No\nMatchAnyTag\nContains the list of S3 object tags. At least one object tag must be specified. Up to 10 object\ntags are allowed.\nType: Array of S3Tag data types\nRequired: No\nMatchObjectAge\nContains DaysGreaterThan and DaysLessThan to define the object age range (minimum and\nmaximum number of days).\nAmazon S3 Control API Version 2006-03-01 1580",
      "start_idx": 1673225,
      "end_idx": 1674465,
      "metadata": {
        "num_sentences": 16,
        "num_words": 196,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1586",
      "text": "Amazon Simple Storage Service API Reference\nType: MatchObjectAge data type\nRequired: No\nMatchObjectSize\nContains BytesGreaterThan and BytesLessThan to define the object size range (minimum\nand maximum number of Bytes).\nType: MatchObjectSize data type\nRequired: No\nOr\nA single logical operator that allows multiple filter conditions to be joined. Objects can match\nany of the listed filter conditions, which are joined by the Or logical operator. Only one of each\nfilter condition is allowed.\nType: StorageLensGroupOrOperator data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1581",
      "start_idx": 1674467,
      "end_idx": 1675234,
      "metadata": {
        "num_sentences": 5,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1587",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensGroupLevel\nService: Amazon S3 Control\nSpecifies the Storage Lens groups to include in the Storage Lens group aggregation.\nContents\nSelectionCriteria\nIndicates which Storage Lens group ARNs to include or exclude in the Storage Lens group\naggregation. If this value is left null, then all Storage Lens groups are selected.\nType: StorageLensGroupLevelSelectionCriteria data type\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1582",
      "start_idx": 1675236,
      "end_idx": 1675899,
      "metadata": {
        "num_sentences": 4,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1588",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensGroupLevelSelectionCriteria\nService: Amazon S3 Control\nIndicates which Storage Lens group ARNs to include or exclude in the Storage Lens group\naggregation. You can only attach Storage Lens groups to your Storage Lens dashboard if they're\nincluded in your Storage Lens group aggregation. If this value is left null, then all Storage Lens\ngroups are selected.\nContents\nExclude\nIndicates which Storage Lens group ARNs to exclude from the Storage Lens group aggregation.\nType: Array of strings\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: No\nInclude\nIndicates which Storage Lens group ARNs to include in the Storage Lens group aggregation.\nType: Array of strings\nLength Constraints: Minimum length of 4. Maximum length of 1024.\nPattern: arn:[a-z\\-]+:s3:[a-z0-9\\-]+:\\d{12}:storage\\-lens\\-group\\/.*\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1583",
      "start_idx": 1675901,
      "end_idx": 1677080,
      "metadata": {
        "num_sentences": 12,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1590",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensGroupOrOperator\nService: Amazon S3 Control\nA container element for specifying Or rule conditions. The rule conditions determine the subset of\nobjects to which the Or rule applies. Objects can match any of the listed filter conditions, which are\njoined by the Or logical operator. Only one of each filter condition is allowed.\nContents\nMatchAnyPrefix\nFilters objects that match any of the specified prefixes.\nType: Array of strings\nRequired: No\nMatchAnySuffix\nFilters objects that match any of the specified suffixes.\nType: Array of strings\nRequired: No\nMatchAnyTag\nFilters objects that match any of the specified S3 object tags.\nType: Array of S3Tag data types\nRequired: No\nMatchObjectAge\nFilters objects that match the specified object age range.\nType: MatchObjectAge data type\nRequired: No\nMatchObjectSize\nFilters objects that match the specified object size range.\nType: MatchObjectSize data type\nAmazon S3 Control API Version 2006-03-01 1585",
      "start_idx": 1677173,
      "end_idx": 1678173,
      "metadata": {
        "num_sentences": 10,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1592",
      "text": "Amazon Simple Storage Service API Reference\nStorageLensTag\nService: Amazon S3 Control\nContents\nKey\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nValue\nType: String\nLength Constraints: Minimum length of 0. Maximum length of 256.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1587",
      "start_idx": 1678453,
      "end_idx": 1679041,
      "metadata": {
        "num_sentences": 5,
        "num_words": 89,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1593",
      "text": "Amazon Simple Storage Service API Reference\nTag\nService: Amazon S3 Control\nAn AWS resource tag that's associated with your S3 resource. You can add tags to new objects\nwhen you upload them, or you can add object tags to existing objects.\nNote\nThis operation is only supported for S3 Storage Lens groups and for S3 Access Grants. The\ntagged resource can be an S3 Storage Lens group or S3 Access Grants instance, registered\nlocation, or grant.\nContents\nKey\nThe key of the key-value pair of a tag added to your AWS resource. A tag key can be up to 128\nUnicode characters in length and is case-sensitive. System created tags that begin with aws:\naren\u2019t supported.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 128.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nValue\nThe value of the key-value pair of a tag added to your AWS resource. A tag value can be up to\n256 Unicode characters in length and is case-sensitive.\nType: String\nLength Constraints: Minimum length of 0. Maximum length of 256.\nPattern: ^([\\p{L}\\p{Z}\\p{N}_.:/=+\\-@]*)$\nRequired: Yes\nAmazon S3 Control API Version 2006-03-01 1588",
      "start_idx": 1679043,
      "end_idx": 1680168,
      "metadata": {
        "num_sentences": 14,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1596",
      "text": "Amazon Simple Storage Service API Reference\nTransition\nService: Amazon S3 Control\nSpecifies when an object transitions to a specified storage class. For more information about\nAmazon S3 Lifecycle configuration rules, see Transitioning objects using Amazon S3 Lifecycle in\nthe Amazon S3 User Guide.\nContents\nDate\nIndicates when objects are transitioned to the specified storage class. The date value must be in\nISO 8601 format. The time is always midnight UTC.\nType: Timestamp\nRequired: No\nDays\nIndicates the number of days after creation when objects are transitioned to the specified\nstorage class. The value must be a positive integer.\nType: Integer\nRequired: No\nStorageClass\nThe storage class to which you want the object to transition.\nType: String\nValid Values: GLACIER | STANDARD_IA | ONEZONE_IA | INTELLIGENT_TIERING |\nDEEP_ARCHIVE\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\nAmazon S3 Control API Version 2006-03-01 1591",
      "start_idx": 1680829,
      "end_idx": 1681838,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1598",
      "text": "Amazon Simple Storage Service API Reference\nVersioningConfiguration\nService: Amazon S3 Control\nDescribes the versioning state of an Amazon S3 on Outposts bucket. For more information, see\nPutBucketVersioning.\nContents\nMFADelete\nSpecifies whether MFA delete is enabled or disabled in the bucket versioning configuration for\nthe S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Disabled\nRequired: No\nStatus\nSets the versioning state of the S3 on Outposts bucket.\nType: String\nValid Values: Enabled | Suspended\nRequired: No\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 Control API Version 2006-03-01 1593",
      "start_idx": 1681993,
      "end_idx": 1682744,
      "metadata": {
        "num_sentences": 5,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1599",
      "text": "Amazon Simple Storage Service API Reference\nVpcConfiguration\nService: Amazon S3 Control\nThe virtual private cloud (VPC) configuration for an access point.\nContents\nVpcId\nIf this field is specified, this access point will only allow connections from the specified VPC ID.\nType: String\nLength Constraints: Minimum length of 1. Maximum length of 1024.\nRequired: Yes\nSee Also\nFor more information about using this API in one of the language-specific AWS SDKs, see the\nfollowing:\n\u2022 AWS SDK for C++\n\u2022 AWS SDK for Java V2\n\u2022 AWS SDK for Ruby V3\nAmazon S3 on Outposts\nThe following data types are supported by Amazon S3 on Outposts:\n\u2022 Endpoint\n\u2022 FailedReason\n\u2022 NetworkInterface\n\u2022 Outpost\nAmazon S3 on Outposts API Version 2006-03-01 1594",
      "start_idx": 1682746,
      "end_idx": 1683474,
      "metadata": {
        "num_sentences": 5,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1600",
      "text": "Amazon Simple Storage Service API Reference\nEndpoint\nService: Amazon S3 on Outposts\nAmazon S3 on Outposts Access Points simplify managing data access at scale for shared datasets\nin S3 on Outposts. S3 on Outposts uses endpoints to connect to AWS Outposts buckets so that you\ncan perform actions within your virtual private cloud (VPC). For more information, see Accessing\nS3 on Outposts using VPC-only access points in the Amazon Simple Storage Service User Guide.\nContents\nAccessType\nThe type of connectivity used to access the Amazon S3 on Outposts endpoint.\nType: String\nValid Values: Private | CustomerOwnedIp\nRequired: No\nCidrBlock\nThe VPC CIDR committed by this endpoint.\nType: String\nRequired: No\nCreationTime\nThe time the endpoint was created.\nType: Timestamp\nRequired: No\nCustomerOwnedIpv4Pool\nThe ID of the customer-owned IPv4 address pool used for the endpoint.\nType: String\nPattern: ^ipv4pool-coip-([0-9a-f]{17})$\nRequired: No\nAmazon S3 on Outposts API Version 2006-03-01 1595",
      "start_idx": 1683476,
      "end_idx": 1684464,
      "metadata": {
        "num_sentences": 8,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1605",
      "text": "Amazon Simple Storage Service API Reference\nOutpost\nService: Amazon S3 on Outposts\nContains the details for the Outpost object.\nContents\nCapacityInBytes\nThe Amazon S3 capacity of the outpost in bytes.\nType: Long\nRequired: No\nOutpostArn\nSpecifies the unique Amazon Resource Name (ARN) for the outpost.\nType: String\nPattern: ^arn:(aws|aws-cn|aws-us-gov|aws-iso|aws-iso-b):outposts:[a-z\n\\-0-9]*:[0-9]{12}:outpost/(op-[a-f0-9]{17}|ec2)$\nRequired: No\nOutpostId\nSpecifies the unique identifier for the outpost.\nType: String\nPattern: ^(op-[a-f0-9]{17}|\\d{12}|ec2)$\nRequired: No\nOwnerId\nReturns the AWS account ID of the outpost owner. Useful for comparing owned versus shared\noutposts.\nType: String\nPattern: ^\\d{12}$\nAmazon S3 on Outposts API Version 2006-03-01 1600",
      "start_idx": 1686931,
      "end_idx": 1687690,
      "metadata": {
        "num_sentences": 7,
        "num_words": 95,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1607",
      "text": "Amazon Simple Storage Service API Reference\nDeveloping with Amazon S3\nThis section covers developer-related topics for using Amazon S3. For more information, review the\ntopics below.\nTopics\n\u2022 Making requests\n\u2022 Developing with Amazon S3 using the AWS CLI\n\u2022 Developing with Amazon S3 using the AWS SDKs\n\u2022 Getting Amazon S3 request IDs for AWS Support\nMaking requests\nAmazon S3 is a REST service. You can send requests to Amazon S3 using the REST API or the AWS\nSDK (see Sample Code and Libraries) wrapper libraries that wrap the underlying Amazon S3 REST\nAPI, simplifying your programming tasks.\nEvery interaction with Amazon S3 is either authenticated or anonymous. Authentication is a\nprocess of verifying the identity of the requester trying to access an Amazon Web Services (AWS)\nproduct. Authenticated requests must include a signature value that authenticates the request\nsender. The signature value is, in part, generated from the requester's AWS access keys (access\nkey ID and secret access key). For more information about getting access keys, see How Do I Get\nSecurity Credentials? in the AWS General Reference.\nIf you are using the AWS SDK, the libraries compute the signature from the keys you provide.\nHowever, if you make direct REST API calls in your application, you must write the code to compute\nthe signature and add it to the request.\nTopics\n\u2022 About access keys\n\u2022 Request endpoints\n\u2022 Making requests to Amazon S3 over IPv6\n\u2022 Making requests using the AWS SDKs\n\u2022 Making requests using the REST API\nMaking requests API Version 2006-03-01 1602",
      "start_idx": 1688233,
      "end_idx": 1689791,
      "metadata": {
        "num_sentences": 13,
        "num_words": 259,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1608",
      "text": "Amazon Simple Storage Service API Reference\nAbout access keys\nThe following sections review the types of access keys that you can use to make authenticated\nrequests.\nAWS account access keys\nThe account access keys provide full access to the AWS resources owned by the account. The\nfollowing are examples of access keys:\n\u2022 Access key ID (a 20-character, alphanumeric string). For example: AKIAIOSFODNN7EXAMPLE\n\u2022 Secret access key (a 40-character string). For example: wJalrXUtnFEMI/K7MDENG/\nbPxRfiCYEXAMPLEKEY\nThe access key ID uniquely identifies an AWS account. You can use these access keys to send\nauthenticated requests to Amazon S3.\nIAM user access keys\nYou can create one AWS account for your company; however, there may be several employees in\nthe organization who need access to your organization's AWS resources. Sharing your AWS account\naccess keys reduces security, and creating individual AWS accounts for each employee might not\nbe practical. Also, you cannot easily share resources such as buckets and objects because they are\nowned by different accounts. To share resources, you must grant permissions, which is additional\nwork.\nIn such scenarios, you can use AWS Identity and Access Management (IAM) to create users under\nyour AWS account with their own access keys and attach IAM user policies that grant appropriate\nresource access permissions to these users. To better manage these users, IAM enables you to\ncreate groups of users and grant group-level permissions that apply to all users in that group.\nThese users are referred to as IAM users that you create and manage within AWS. The parent\naccount controls a user's ability to access AWS. Any resources an IAM user creates are under the\ncontrol of and paid for by the parent AWS account. These IAM users can send authenticated\nrequests to Amazon S3 using their own security credentials. For more information about creating\nand managing users under your AWS account, go to the AWS Identity and Access Management\nproduct details page.\nAbout access keys API Version 2006-03-01 1603",
      "start_idx": 1689793,
      "end_idx": 1691845,
      "metadata": {
        "num_sentences": 18,
        "num_words": 327,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1609",
      "text": "Amazon Simple Storage Service API Reference\nTemporary security credentials\nIn addition to creating IAM users with their own access keys, IAM also enables you to grant\ntemporary security credentials (temporary access keys and a security token) to any IAM user to\nenable them to access your AWS services and resources. You can also manage users in your system\noutside AWS. These are referred to as federated users. Additionally, users can be applications that\nyou create to access your AWS resources.\nIAM provides the AWS Security Token Service API for you to request temporary security credentials.\nYou can use either the AWS STS API or the AWS SDK to request these credentials. The API returns\ntemporary security credentials (access key ID and secret access key), and a security token. These\ncredentials are valid only for the duration you specify when you request them. You use the access\nkey ID and secret key the same way you use them when sending requests using your AWS account\nor IAM user access keys. In addition, you must include the token in each request you send to\nAmazon S3.\nAn IAM user can request these temporary security credentials for their own use or hand them\nout to federated users or applications. When requesting temporary security credentials for\nfederated users, you must provide a user name and an IAM policy defining the permissions you\nwant to associate with these temporary security credentials. The federated user cannot get more\npermissions than the parent IAM user who requested the temporary credentials.\nYou can use these temporary security credentials in making requests to Amazon S3. The API\nlibraries compute the necessary signature value using those credentials to authenticate your\nrequest. If you send requests using expired credentials, Amazon S3 denies the request.\nFor information on signing requests using temporary security credentials in your REST API\nrequests, see Signing and authenticating REST requests (AWS signature version 2). For information\nabout sending requests using AWS SDKs, see Making requests using the AWS SDKs.\nFor more information about IAM support for temporary security credentials, see Temporary\nSecurity Credentials in the IAM User Guide.\nFor added security, you can require multifactor authentication (MFA) when accessing your Amazon\nS3 resources by configuring a bucket policy. For information, see Example bucket policies:\nRequiring MFA . After you require MFA to access your Amazon S3 resources, the only way you can\naccess these resources is by providing temporary credentials that are created with an MFA key.\nFor more information, see the AWS Multi-Factor Authentication detail page and Configuring MFA-\nProtected API Access in the IAM User Guide.\nAbout access keys API Version 2006-03-01 1604",
      "start_idx": 1691847,
      "end_idx": 1694615,
      "metadata": {
        "num_sentences": 24,
        "num_words": 438,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1610",
      "text": "Amazon Simple Storage Service API Reference\nRequest endpoints\nYou send REST requests to the service's predefined endpoint. For a list of all AWS services and their\ncorresponding endpoints, go to Regions and Endpoints in the AWS General Reference.\nMaking requests to Amazon S3 over IPv6\nAmazon Simple Storage Service (Amazon S3) supports the ability to access S3 buckets using\nthe Internet Protocol version 6 (IPv6), in addition to the IPv4 protocol. Amazon S3 dual-stack\nendpoints support requests to S3 buckets over IPv6 and IPv4. There are no additional charges for\naccessing Amazon S3 over IPv6. For more information about pricing, see Amazon S3 Pricing.\nTopics\n\u2022 Getting started making requests over IPv6\n\u2022 Using IPv6 addresses in IAM policies\n\u2022 Testing IP address compatibility\n\u2022 Using Amazon S3 dual-stack endpoints\nGetting started making requests over IPv6\nTo make a request to an S3 bucket over IPv6, you need to use a dual-stack endpoint. The next\nsection describes how to make requests over IPv6 by using dual-stack endpoints.\nThe following are some things you should know before trying to access a bucket over IPv6:\n\u2022 The client and the network accessing the bucket must be enabled to use IPv6.\n\u2022 Both virtual hosted-style and path style requests are supported for IPv6 access. For more\ninformation, see Amazon S3 dual-stack endpoints.\n\u2022 If you use source IP address filtering in your AWS Identity and Access Management (IAM) user\nor bucket policies, you need to update the policies to include IPv6 address ranges. For more\ninformation, see Using IPv6 addresses in IAM policies.\n\u2022 When using IPv6, server access log files output IP addresses in an IPv6 format. You need to\nupdate existing tools, scripts, and software that you use to parse Amazon S3 log files so that\nthey can parse the IPv6 formatted Remote IP addresses. For more information, see Logging\nrequests with server access logging .\nRequest endpoints API Version 2006-03-01 1605",
      "start_idx": 1694617,
      "end_idx": 1696568,
      "metadata": {
        "num_sentences": 17,
        "num_words": 321,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1611",
      "text": "Amazon Simple Storage Service API Reference\nNote\nIf you experience issues related to the presence of IPv6 addresses in log files, contact\nAWS Support.\nMaking requests over IPv6 by using dual-stack endpoints\nYou make requests with Amazon S3 API calls over IPv6 by using dual-stack endpoints. The Amazon\nS3 API operations work the same way whether you're accessing Amazon S3 over IPv6 or over IPv4.\nPerformance should be the same too.\nWhen using the REST API, you access a dual-stack endpoint directly. For more information, see\nDual-stack endpoints.\nWhen using the AWS Command Line Interface (AWS CLI) and AWS SDKs, you can use a parameter\nor flag to change to a dual-stack endpoint. You can also specify the dual-stack endpoint directly as\nan override of the Amazon S3 endpoint in the config file.\nYou can use a dual-stack endpoint to access a bucket over IPv6 from any of the following:\n\u2022 The AWS CLI, see Using dual-stack endpoints from the AWS CLI.\n\u2022 The AWS SDKs, see Using dual-stack endpoints from the AWS SDKs.\n\u2022 The REST API, see Making requests to dual-stack endpoints by using the REST API.\nFeatures not available over IPv6\nThe following feature is currently not supported when accessing an S3 bucket over IPv6: Static\nwebsite hosting from an S3 bucket.\nUsing IPv6 addresses in IAM policies\nBefore trying to access a bucket using IPv6, you must ensure that any IAM user or S3 bucket\npolices that are used for IP address filtering are updated to include IPv6 address ranges. IP address\nfiltering policies that are not updated to handle IPv6 addresses may result in clients incorrectly\nlosing or gaining access to the bucket when they start using IPv6. For more information about\nmanaging access permissions with IAM, see Identity and Access Management for Amazon S3 .\nMaking requests over IPv6 API Version 2006-03-01 1606",
      "start_idx": 1696570,
      "end_idx": 1698400,
      "metadata": {
        "num_sentences": 16,
        "num_words": 309,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1612",
      "text": "Amazon Simple Storage Service API Reference\nIAM policies that filter IP addresses use IP Address Condition Operators. The following\nbucket policy identifies the 54.240.143.* range of allowed IPv4 addresses by using IP address\ncondition operators. Any IP addresses outside of this range will be denied access to the bucket\n(examplebucket). Since all IPv6 addresses are outside of the allowed range, this policy prevents\nIPv6 addresses from being able to access examplebucket.\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"IPAllow\",\n\"Effect\": \"Allow\",\n\"Principal\": \"*\",\n\"Action\": \"s3:*\",\n\"Resource\": \"arn:aws:s3:::examplebucket/*\",\n\"Condition\": {\n\"IpAddress\": {\"aws:SourceIp\": \"54.240.143.0/24\"}\n}\n}\n]\n}\nYou can modify the bucket policy's Condition element to allow both IPv4 (54.240.143.0/24)\nand IPv6 (2001:DB8:1234:5678::/64) address ranges as shown in the following example. You\ncan use the same type of Condition block shown in the example to update both your IAM user\nand bucket policies.\n\"Condition\": {\n\"IpAddress\": {\n\"aws:SourceIp\": [\n\"54.240.143.0/24\",\n\"2001:DB8:1234:5678::/64\"\n]\n}\n}\nBefore using IPv6 you must update all relevant IAM user and bucket policies that use IP address\nfiltering. We do not recommend using IP address filterig in bucket policies.\nMaking requests over IPv6 API Version 2006-03-01 1607",
      "start_idx": 1698402,
      "end_idx": 1699726,
      "metadata": {
        "num_sentences": 10,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1613",
      "text": "Amazon Simple Storage Service API Reference\nYou can review your IAM user policies using the IAM console at https://console.aws.amazon.com/\niam/. For more information about IAM, see the IAM User Guide. For information about editing S3\nbucket policies, see Adding a bucket policy.\nTesting IP address compatibility\nIf you are using use Linux/Unix or Mac OS X, you can test whether you can access a dual-stack\nendpoint over IPv6 by using the curl command as shown in the following example:\nExample\ncurl -v http://s3.dualstack.us-west-2.amazonaws.com/\nYou get back information similar to the following example. If you are connected over IPv6 the\nconnected IP address will be an IPv6 address.\n* About to connect() to s3-us-west-2.amazonaws.com port 80 (#0)\n* Trying IPv6 address... connected\n* Connected to s3.dualstack.us-west-2.amazonaws.com (IPv6 address) port 80 (#0)\n> GET / HTTP/1.1\n> User-Agent: curl/7.18.1 (x86_64-unknown-linux-gnu) libcurl/7.18.1 OpenSSL/1.0.1t\nzlib/1.2.3\n> Host: s3.dualstack.us-west-2.amazonaws.com\nIf you are using Microsoft Windows 7 or Windows 10, you can test whether you can access a dual-\nstack endpoint over IPv6 or IPv4 by using the ping command as shown in the following example.\nping ipv6.s3.dualstack.us-west-2.amazonaws.com\nUsing Amazon S3 dual-stack endpoints\nAmazon S3 dual-stack endpoints support requests to S3 buckets over IPv6 and IPv4. This section\ndescribes how to use dual-stack endpoints.\nTopics\n\u2022 Amazon S3 dual-stack endpoints\n\u2022 Using dual-stack endpoints from the AWS CLI\nMaking requests over IPv6 API Version 2006-03-01 1608",
      "start_idx": 1699728,
      "end_idx": 1701301,
      "metadata": {
        "num_sentences": 9,
        "num_words": 230,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1614",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Using dual-stack endpoints from the AWS SDKs\n\u2022 Using dual-stack endpoints from the REST API\nAmazon S3 dual-stack endpoints\nWhen you make a request to a dual-stack endpoint, the bucket URL resolves to an IPv6 or an IPv4\naddress. For more information about accessing a bucket over IPv6, see Making requests to Amazon\nS3 over IPv6.\nWhen using the REST API, you directly access an Amazon S3 endpoint by using the endpoint name\n(URI). You can access an S3 bucket through a dual-stack endpoint by using a virtual hosted-style or\na path-style endpoint name. Amazon S3 supports only regional dual-stack endpoint names, which\nmeans that you must specify the region as part of the name.\nUse the following naming conventions for the dual-stack virtual hosted-style and path-style\nendpoint names:\n\u2022 Virtual hosted-style dual-stack endpoint:\nbucketname.s3.dualstack.aws-region.amazonaws.com\n\u2022 Path-style dual-stack endpoint:\ns3.dualstack.aws-region.amazonaws.com/bucketname\nFor more information, about endpoint name style, see Accessing and listing an Amazon S3 bucket .\nFor a list of Amazon S3 endpoints, see Regions and Endpoints in the AWS General Reference.\nImportant\nYou can use transfer acceleration with dual-stack endpoints. For more information, see\nGetting started with Amazon S3 Transfer Acceleration .\nMaking requests over IPv6 API Version 2006-03-01 1609",
      "start_idx": 1701303,
      "end_idx": 1702703,
      "metadata": {
        "num_sentences": 10,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1615",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThe two types of VPC endpoints to access Amazon S3 (Interface VPC endpoints and\nGateway VPC endpoints) don't have dual-stack support. For more information about VPC\nendpoints for Amazon S3, see AWS PrivateLink for Amazon S3 .\nWhen using the AWS Command Line Interface (AWS CLI) and AWS SDKs, you can use a parameter\nor flag to change to a dual-stack endpoint. You can also specify the dual-stack endpoint directly as\nan override of the Amazon S3 endpoint in the config file. The following sections describe how to\nuse dual-stack endpoints from the AWS CLI and the AWS SDKs.\nUsing dual-stack endpoints from the AWS CLI\nThis section provides examples of AWS CLI commands used to make requests to a dual-stack\nendpoint. For instructions on setting up the AWS CLI, see Developing with Amazon S3 using the\nAWS CLI.\nYou set the configuration value use_dualstack_endpoint to true in a profile in your AWS\nConfig file to direct all Amazon S3 requests made by the s3 and s3api AWS CLI commands to\nthe dual-stack endpoint for the specified region. You specify the region in the config file or in a\ncommand using the --region option.\nWhen using dual-stack endpoints with the AWS CLI, both path and virtual addressing styles\nare supported. The addressing style, set in the config file, controls if the bucket name is in the\nhostname or part of the URL. By default, the CLI will attempt to use virtual style where possible,\nbut will fall back to path style if necessary. For more information, see AWS CLI Amazon S3\nConfiguration.\nYou can also make configuration changes by using a command, as shown in the following example,\nwhich sets use_dualstack_endpoint to true and addressing_style to virtual in the\ndefault profile.\n$ aws configure set default.s3.use_dualstack_endpoint true\n$ aws configure set default.s3.addressing_style virtual\nIf you want to use a dual-stack endpoint for specified AWS CLI commands only (not all commands),\nyou can use either of the following methods:\nMaking requests over IPv6 API Version 2006-03-01 1610",
      "start_idx": 1702705,
      "end_idx": 1704774,
      "metadata": {
        "num_sentences": 15,
        "num_words": 343,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1616",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 You can use the dual-stack endpoint per command by setting the --endpoint-url\nparameter to https://s3.dualstack.aws-region.amazonaws.com or http://\ns3.dualstack.aws-region.amazonaws.com for any s3 or s3api command.\n$ aws s3api list-objects --bucket bucketname --endpoint-url https://s3.dualstack.aws-\nregion.amazonaws.com\n\u2022 You can set up separate profiles in your AWS Config file. For example, create one\nprofile that sets use_dualstack_endpoint to true and a profile that does not set\nuse_dualstack_endpoint. When you run a command, specify which profile you want to use,\ndepending upon whether or not you want to use the dual-stack endpoint.\nNote\nWhen using the AWS CLI you currently cannot use transfer acceleration with dual-stack\nendpoints. However, support for the AWS CLI is coming soon. For more information, see\nEnabling and using S3 Transfer Acceleration .\nUsing dual-stack endpoints from the AWS SDKs\nThis section provides examples of how to access a dual-stack endpoint by using the AWS SDKs.\nAWS SDK for Java dual-stack endpoint example\nThe following example shows how to enable dual-stack endpoints when creating an Amazon S3\nclient using the AWS SDK for Java.\nFor instructions on creating and testing a working Java sample, see Getting Started in the AWS SDK\nfor Java Developer Guide.\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.regions.Regions;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\npublic class DualStackEndpoints {\nMaking requests over IPv6 API Version 2006-03-01 1611",
      "start_idx": 1704776,
      "end_idx": 1706495,
      "metadata": {
        "num_sentences": 11,
        "num_words": 225,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1619",
      "text": "Amazon Simple Storage Service API Reference\n} while (response.IsTruncated == true);\n}\ncatch (AmazonS3Exception amazonS3Exception)\n{\nConsole.WriteLine(\"An AmazonS3Exception was thrown. Exception: \" +\namazonS3Exception.ToString());\n}\ncatch (Exception e)\n{\nConsole.WriteLine(\"Exception: \" + e.ToString());\n}\n}\n}\n}\nFor information about setting up and running the code examples, see Getting Started with the\nAWS SDK for .NET in the AWS SDK for .NET Developer Guide.\nUsing dual-stack endpoints from the REST API\nFor information about making requests to dual-stack endpoints by using the REST API, see Making\nrequests to dual-stack endpoints by using the REST API.\nMaking requests over IPv6 API Version 2006-03-01 1614",
      "start_idx": 1708937,
      "end_idx": 1709649,
      "metadata": {
        "num_sentences": 4,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1620",
      "text": "Amazon Simple Storage Service API Reference\nMaking requests using the AWS SDKs\nTopics\n\u2022 Making requests using AWS account or IAM user credentials\n\u2022 Making requests using IAM user temporary credentials\n\u2022 Making requests using federated user temporary credentials\nYou can send authenticated requests to Amazon S3 using either the AWS SDK or by making the\nREST API calls directly in your application. The AWS SDK API uses the credentials that you provide\nto compute the signature for authentication. If you use the REST API directly in your applications,\nyou must write the necessary code to compute the signature for authenticating your request. For a\nlist of available AWS SDKs go to, Sample Code and Libraries.\nMaking requests using AWS account or IAM user credentials\nYou can use your AWS account or IAM user security credentials to send authenticated requests to\nAmazon S3. This section provides examples of how you can send authenticated requests using the\nAWS SDK for Java, AWS SDK for .NET, and AWS SDK for PHP. For a list of available AWS SDKs, go to\nSample Code and Libraries.\nEach of these AWS SDKs uses an SDK-specific credentials provider chain to find and use credentials\nand perform actions on behalf of the credentials owner. What all these credentials provider chains\nhave in common is that they all look for your local AWS credentials file.\nFor more information, see the topics below:\nTopics\n\u2022 To create a local AWS credentials file\n\u2022 Sending authenticated requests using the AWS SDKs\nTo create a local AWS credentials file\nThe easiest way to configure credentials for your AWS SDKs is to use an AWS credentials file. If you\nuse the AWS Command Line Interface (AWS CLI), you may already have a local AWS credentials file\nconfigured. Otherwise, use the following procedure to set up a credentials file:\n1. Sign in to the AWS Management Console and open the IAM console at https://\nconsole.aws.amazon.com/iam/.\nMaking requests using the AWS SDKs API Version 2006-03-01 1615",
      "start_idx": 1709651,
      "end_idx": 1711637,
      "metadata": {
        "num_sentences": 14,
        "num_words": 332,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1621",
      "text": "Amazon Simple Storage Service API Reference\n2. Create a new user with permissions limited to the services and actions that you want your code\nto have access to. For more information about creating a new user, see Creating IAM users\n(Console), and follow the instructions through step 8.\n3. Choose Download .csv to save a local copy of your AWS credentials.\n4. On your computer, navigate to your home directory, and create an .aws directory. On Unix-\nbased systems, such as Linux or OS X, this is in the following location:\n~/.aws\nOn Windows, this is in the following location:\n%HOMEPATH%\\.aws\n5. In the .aws directory, create a new file named credentials.\n6. Open the credentials .csv file that you downloaded from the IAM console, and copy its\ncontents into the credentials file using the following format:\n[default]\naws_access_key_id = your_access_key_id\naws_secret_access_key = your_secret_access_key\n7. Save the credentials file, and delete the .csv file that you downloaded in step 3.\nYour shared credentials file is now configured on your local computer, and it's ready to be used with\nthe AWS SDKs.\nSending authenticated requests using the AWS SDKs\nUse the AWS SDKs to send authenticated requests. For more information about sending\nauthenticated requests, see AWS security credentials or IAM Identity Center Authentication.\nJava\nTo send authenticated requests to Amazon S3 using your AWS account or IAM user credentials,\ndo the following:\n\u2022 Use the AmazonS3ClientBuilder class to create an AmazonS3Client instance.\nMaking requests using the AWS SDKs API Version 2006-03-01 1616",
      "start_idx": 1711639,
      "end_idx": 1713224,
      "metadata": {
        "num_sentences": 17,
        "num_words": 251,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1622",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Run one of the AmazonS3Client methods to send requests to Amazon S3. The client\ngenerates the necessary signature from the credentials that you provide and includes it in the\nrequest.\nThe following example performs the preceding tasks. For information on creating and testing a\nworking sample, see Getting Started in the AWS SDK for Java Developer Guide.\nExample\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.regions.Regions;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\nimport com.amazonaws.services.s3.model.ListObjectsRequest;\nimport com.amazonaws.services.s3.model.ObjectListing;\nimport com.amazonaws.services.s3.model.S3ObjectSummary;\nimport java.io.IOException;\nimport java.util.List;\npublic class MakingRequests {\npublic static void main(String[] args) throws IOException {\nRegions clientRegion = Regions.DEFAULT_REGION;\nString bucketName = \"*** Bucket name ***\";\ntry {\nAmazonS3 s3Client = AmazonS3ClientBuilder.standard()\n.withCredentials(new ProfileCredentialsProvider())\n.withRegion(clientRegion)\n.build();\n// Get a list of objects in the bucket, two at a time, and\n// print the name and size of each object.\nListObjectsRequest listRequest = new\nListObjectsRequest().withBucketName(bucketName).withMaxKeys(2);\nObjectListing objects = s3Client.listObjects(listRequest);\nwhile (true) {\nList<S3ObjectSummary> summaries = objects.getObjectSummaries();\nMaking requests using the AWS SDKs API Version 2006-03-01 1617",
      "start_idx": 1713226,
      "end_idx": 1714869,
      "metadata": {
        "num_sentences": 6,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1623",
      "text": "Amazon Simple Storage Service API Reference\nfor (S3ObjectSummary summary : summaries) {\nSystem.out.printf(\"Object \\\"%s\\\" retrieved with size %d\\n\",\nsummary.getKey(), summary.getSize());\n}\nif (objects.isTruncated()) {\nobjects = s3Client.listNextBatchOfObjects(objects);\n} else {\nbreak;\n}\n}\n} catch (AmazonServiceException e) {\n// The call was transmitted successfully, but Amazon S3 couldn't process\n// it, so it returned an error response.\ne.printStackTrace();\n} catch (SdkClientException e) {\n// Amazon S3 couldn't be contacted for a response, or the client\n// couldn't parse the response from Amazon S3.\ne.printStackTrace();\n}\n}\n}\n.NET\nTo send authenticated requests using your AWS account or IAM user credentials:\n\u2022 Create an instance of the AmazonS3Client class.\n\u2022 Run one of the AmazonS3Client methods to send requests to Amazon S3. The client\ngenerates the necessary signature from the credentials that you provide and includes it in the\nrequest it sends to Amazon S3.\nFor more information, see Making requests using AWS account or IAM user credentials >.\nNote\n\u2022 You can create the AmazonS3Client client without providing your security\ncredentials. Requests sent using this client are anonymous requests, without a\nsignature. Amazon S3 returns an error if you send anonymous requests for a resource\nthat is not publicly available.\nMaking requests using the AWS SDKs API Version 2006-03-01 1618",
      "start_idx": 1714871,
      "end_idx": 1716270,
      "metadata": {
        "num_sentences": 10,
        "num_words": 210,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1624",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 You can create an AWS account and create the required users. You can also manage\ncredentials for those users. You need these credentials to perform the task in the\nfollowing example. For more information, see Configure AWS credentials in the AWS\nSDK for .NET Developer Guide.\nYou can then also configure your application to actively retrieve profiles and\ncredentials, and then explicitly use those credentials when creating an AWS service\nclient. For more information, see Accessing credentials and profiles in an application\nin the AWS SDK for .NET Developer Guide.\nThe following C# example shows how to perform the preceding tasks. For information about\nsetting up and running the code examples, see Getting Started with the AWS SDK for .NET in\nthe AWS SDK for .NET Developer Guide.\nExample\nusing Amazon;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing System;\nusing System.Threading.Tasks;\nnamespace Amazon.DocSamples.S3\n{\nclass MakeS3RequestTest\n{\nprivate const string bucketName = \"*** bucket name ***\";\n// Specify your bucket region (an example region is shown).\nprivate static readonly RegionEndpoint bucketRegion =\nRegionEndpoint.USWest2;\nprivate static IAmazonS3 client;\npublic static void Main()\n{\nusing (client = new AmazonS3Client(bucketRegion))\n{\nConsole.WriteLine(\"Listing objects stored in a bucket\");\nListingObjectsAsync().Wait();\n}\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1619",
      "start_idx": 1716272,
      "end_idx": 1717729,
      "metadata": {
        "num_sentences": 10,
        "num_words": 212,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1625",
      "text": "Amazon Simple Storage Service API Reference\nstatic async Task ListingObjectsAsync()\n{\ntry\n{\nListObjectsRequest request = new ListObjectsRequest\n{\nBucketName = bucketName,\nMaxKeys = 2\n};\ndo\n{\nListObjectsResponse response = await\nclient.ListObjectsAsync(request);\n// Process the response.\nforeach (S3Object entry in response.S3Objects)\n{\nConsole.WriteLine(\"key = {0} size = {1}\",\nentry.Key, entry.Size);\n}\n// If the response is truncated, set the marker to get the next\n// set of keys.\nif (response.IsTruncated)\n{\nrequest.Marker = response.NextMarker;\n}\nelse\n{\nrequest = null;\n}\n} while (request != null);\n}\ncatch (AmazonS3Exception e)\n{\nConsole.WriteLine(\"Error encountered on server. Message:'{0}' when\nwriting an object\", e.Message);\n}\ncatch (Exception e)\n{\nConsole.WriteLine(\"Unknown encountered on server. Message:'{0}' when\nwriting an object\", e.Message);\n}\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1620",
      "start_idx": 1717731,
      "end_idx": 1718657,
      "metadata": {
        "num_sentences": 5,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1626",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\nPHP\nThe following PHP example shows how the client makes a request using your security\ncredentials to list all of the buckets for your account.\nExample\nrequire 'vendor/autoload.php';\nuse Aws\\S3\\Exception\\S3Exception;\nuse Aws\\S3\\S3Client;\n$bucket = '*** Your Bucket Name ***';\n$s3 = new S3Client([\n'region' => 'us-east-1',\n'version' => 'latest',\n]);\n// Retrieve the list of buckets.\n$result = $s3->listBuckets();\ntry {\n// Retrieve a paginator for listing objects.\n$objects = $s3->getPaginator('ListObjects', [\n'Bucket' => $bucket\n]);\necho \"Keys retrieved!\" . PHP_EOL;\n// Print the list of objects to the page.\nforeach ($objects as $object) {\necho $object['Key'] . PHP_EOL;\n}\n} catch (S3Exception $e) {\necho $e->getMessage() . PHP_EOL;\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1621",
      "start_idx": 1718659,
      "end_idx": 1719505,
      "metadata": {
        "num_sentences": 9,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1627",
      "text": "Amazon Simple Storage Service API Reference\nNote\nYou can create the S3Client client without providing your security credentials.\nRequests sent using this client are anonymous requests, without a signature. Amazon\nS3 returns an error if you send anonymous requests for a resource that is not publicly\navailable. For more information, see Creating Anonymous Clients in the AWS SDK for\nPHP Documentation.\nRuby\nBefore you can use version 3 of the AWS SDK for Ruby to make calls to Amazon S3, you must\nset the AWS access credentials that the SDK uses to verify your access to your buckets and\nobjects. If you have shared credentials set up in the AWS credentials profile on your local\nsystem, version 3 of the SDK for Ruby can use those credentials without your having to declare\nthem in your code. For more information about setting up shared credentials, see Making\nrequests using AWS account or IAM user credentials .\nThe following Ruby code snippet uses the credentials in a shared AWS credentials file on a local\ncomputer to authenticate a request to get all of the object key names in a specific bucket. It\ndoes the following:\n1. Creates an instance of the Aws::S3::Client class.\n2. Makes a request to Amazon S3 by enumerating objects in a bucket using the\nlist_objects_v2 method of Aws::S3::Client. The client generates the necessary\nsignature value from the credentials in the AWS credentials file on your computer, and\nincludes it in the request it sends to Amazon S3.\n3. Prints the array of object key names to the terminal.\nExample\n# Prerequisites:\n# - An existing Amazon S3 bucket.\nrequire 'aws-sdk-s3'\n# @param s3_client [Aws::S3::Client] An initialized Amazon S3 client.\nMaking requests using the AWS SDKs API Version 2006-03-01 1622",
      "start_idx": 1719507,
      "end_idx": 1721249,
      "metadata": {
        "num_sentences": 18,
        "num_words": 291,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1628",
      "text": "Amazon Simple Storage Service API Reference\n# @param bucket_name [String] The bucket's name.\n# @return [Boolean] true if all operations succeed; otherwise, false.\n# @example\n# s3_client = Aws::S3::Client.new(region: 'us-west-2')\n# exit 1 unless list_bucket_objects?(s3_client, 'amzn-s3-demo-bucket')\ndef list_bucket_objects?(s3_client, bucket_name)\nputs \"Accessing the bucket named '#{bucket_name}'...\"\nobjects = s3_client.list_objects_v2(\nbucket: bucket_name,\nmax_keys: 50\n)\nif objects.count.positive?\nputs 'The object keys in this bucket are (first 50 objects):'\nobjects.contents.each do |object|\nputs object.key\nend\nelse\nputs 'No objects found in this bucket.'\nend\ntrue\nrescue StandardError => e\nputs \"Error while accessing the bucket named '#{bucket_name}': #{e.message}\"\nfalse\nend\n# Example usage:\ndef run_me\nregion = 'us-west-2'\nbucket_name = 'BUCKET_NAME'\ns3_client = Aws::S3::Client.new(region: region)\nexit 1 unless list_bucket_objects?(s3_client, bucket_name)\nend\nrun_me if $PROGRAM_NAME == __FILE__\nIf you don't have a local AWS credentials file, you can still create the Aws::S3::Client\nresource and run code against Amazon S3 buckets and objects. Requests that are sent using\nversion 3 of the SDK for Ruby are anonymous, with no signature by default. Amazon S3 returns\nan error if you send anonymous requests for a resource that's not publicly available.\nMaking requests using the AWS SDKs API Version 2006-03-01 1623",
      "start_idx": 1721251,
      "end_idx": 1722681,
      "metadata": {
        "num_sentences": 11,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1630",
      "text": "Amazon Simple Storage Service API Reference\nexit 1 unless list_bucket_objects?(s3_client, bucket_name)\nend\nrun_me if $PROGRAM_NAME == __FILE__\nGo\nExample\nThe following example uses AWS credentials automatically loaded by the SDK for Go from the\nshared credentials file.\npackage main\nimport (\n\"context\"\n\"fmt\"\n\"github.com/aws/aws-sdk-go-v2/config\"\n\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n// main uses the AWS SDK for Go V2 to create an Amazon Simple Storage Service\n// (Amazon S3) client and list up to 10 buckets in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\nctx := context.Background()\nsdkConfig, err := config.LoadDefaultConfig(ctx)\nif err != nil {\nfmt.Println(\"Couldn't load default configuration. Have you set up your AWS\naccount?\")\nfmt.Println(err)\nreturn\n}\ns3Client := s3.NewFromConfig(sdkConfig)\ncount := 10\nfmt.Printf(\"Let's list up to %v buckets for your account.\\n\", count)\nresult, err := s3Client.ListBuckets(ctx, &s3.ListBucketsInput{})\nif err != nil {\nfmt.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err)\nreturn\nMaking requests using the AWS SDKs API Version 2006-03-01 1625",
      "start_idx": 1723921,
      "end_idx": 1725119,
      "metadata": {
        "num_sentences": 8,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1632",
      "text": "Amazon Simple Storage Service API Reference\nMaking requests using IAM user temporary credentials\nAn AWS account or an IAM user can request temporary security credentials and use them to send\nauthenticated requests to Amazon S3. This section provides examples of how to use the AWS SDK\nfor Java, .NET, and PHP to obtain temporary security credentials and use them to authenticate your\nrequests to Amazon S3.\nJava\nAn IAM user or an AWS account can request temporary security credentials (see Making\nrequests) using the AWS SDK for Java and use them to access Amazon S3. These credentials\nexpire after the specified session duration.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the\nduration when requesting the temporary security credentials from 15 minutes to the maximum\nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide. For more information about making\nrequests, see Making requests.\nTo get temporary security credentials and access Amazon S3\n1. Create an instance of the AWSSecurityTokenService class.\n2. Retrieve the temporary security credentials for the desired role by calling the\nassumeRole() method of the Security Token Service (STS) client.\n3. Package the temporary security credentials into a BasicSessionCredentials object.\nYou use this object to provide the temporary security credentials to your Amazon S3 client.\n4. Create an instance of the AmazonS3Client class using the temporary security credentials.\nYou send requests to Amazon S3 using this client. If you send requests using expired\ncredentials, Amazon S3 will return an error.\nNote\nThe following example lists a set of object keys in the specified bucket. The example obtains\ntemporary security credentials for a session and uses them to send an authenticated request to\nAmazon S3.\nMaking requests using the AWS SDKs API Version 2006-03-01 1627",
      "start_idx": 1725465,
      "end_idx": 1727431,
      "metadata": {
        "num_sentences": 22,
        "num_words": 307,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1633",
      "text": "Amazon Simple Storage Service API Reference\nIf you want to test the sample by using IAM user credentials, you must create an IAM user under\nyour AWS account. For more information about how to create an IAM user, see Creating Your\nFirst IAM user and Administrators Group in the IAM User Guide.\nFor instructions on creating and testing a working sample, see Getting Started in the AWS SDK\nfor Java Developer Guide.\nimport com.amazonaws.AmazonServiceException;\nimport com.amazonaws.SdkClientException;\nimport com.amazonaws.auth.AWSStaticCredentialsProvider;\nimport com.amazonaws.auth.BasicSessionCredentials;\nimport com.amazonaws.auth.profile.ProfileCredentialsProvider;\nimport com.amazonaws.services.s3.AmazonS3;\nimport com.amazonaws.services.s3.AmazonS3ClientBuilder;\nimport com.amazonaws.services.s3.model.ObjectListing;\nimport com.amazonaws.services.securitytoken.AWSSecurityTokenService;\nimport com.amazonaws.services.securitytoken.AWSSecurityTokenServiceClientBuilder;\nimport com.amazonaws.services.securitytoken.model.AssumeRoleRequest;\nimport com.amazonaws.services.securitytoken.model.AssumeRoleResult;\nimport com.amazonaws.services.securitytoken.model.Credentials;\npublic class MakingRequestsWithIAMTempCredentials {\npublic static void main(String[] args) {\nString clientRegion = \"*** Client region ***\";\nString roleARN = \"*** ARN for role to be assumed ***\";\nString roleSessionName = \"*** Role session name ***\";\nString bucketName = \"*** Bucket name ***\";\ntry {\n// Creating the STS client is part of your trusted code. It has\n// the security credentials you use to obtain temporary security\ncredentials.\nAWSSecurityTokenService stsClient =\nAWSSecurityTokenServiceClientBuilder.standard()\n.withCredentials(new ProfileCredentialsProvider())\n.withRegion(clientRegion)\n.build();\n// Obtain credentials for the IAM role. Note that you cannot assume the\nrole of\n// an AWS root account;\nMaking requests using the AWS SDKs API Version 2006-03-01 1628",
      "start_idx": 1727433,
      "end_idx": 1729382,
      "metadata": {
        "num_sentences": 7,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1634",
      "text": "Amazon Simple Storage Service API Reference\n// Amazon S3 will deny access. You must use credentials for an IAM user\nor an\n// IAM role.\nAssumeRoleRequest roleRequest = new AssumeRoleRequest()\n.withRoleArn(roleARN)\n.withRoleSessionName(roleSessionName);\nAssumeRoleResult roleResponse = stsClient.assumeRole(roleRequest);\nCredentials sessionCredentials = roleResponse.getCredentials();\n// Create a BasicSessionCredentials object that contains the credentials\nyou\n// just retrieved.\nBasicSessionCredentials awsCredentials = new BasicSessionCredentials(\nsessionCredentials.getAccessKeyId(),\nsessionCredentials.getSecretAccessKey(),\nsessionCredentials.getSessionToken());\n// Provide temporary security credentials so that the Amazon S3 client\n// can send authenticated requests to Amazon S3. You create the client\n// using the sessionCredentials object.\nAmazonS3 s3Client = AmazonS3ClientBuilder.standard()\n.withCredentials(new\nAWSStaticCredentialsProvider(awsCredentials))\n.withRegion(clientRegion)\n.build();\n// Verify that assuming the role worked and the permissions are set\ncorrectly\n// by getting a set of object keys from the bucket.\nObjectListing objects = s3Client.listObjects(bucketName);\nSystem.out.println(\"No. of Objects: \" +\nobjects.getObjectSummaries().size());\n} catch (AmazonServiceException e) {\n// The call was transmitted successfully, but Amazon S3 couldn't process\n// it, so it returned an error response.\ne.printStackTrace();\n} catch (SdkClientException e) {\n// Amazon S3 couldn't be contacted for a response, or the client\n// couldn't parse the response from Amazon S3.\ne.printStackTrace();\n}\n}\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1629",
      "start_idx": 1729384,
      "end_idx": 1731060,
      "metadata": {
        "num_sentences": 10,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1635",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAn IAM user or an AWS account can request temporary security credentials using the AWS SDK\nfor .NET and use them to access Amazon S3. These credentials expire after the session duration.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the\nduration when requesting the temporary security credentials from 15 minutes to the maximum\nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide. For more information about making\nrequests, see Making requests.\nTo get temporary security credentials and access Amazon S3\n1. Create an instance of the AWS Security Token Service client,\nAmazonSecurityTokenServiceClient.\n2. Start a session by calling the GetSessionToken method of the STS client you\ncreated in the preceding step. You provide session information to this method using a\nGetSessionTokenRequest object.\nThe method returns your temporary security credentials.\n3. Package the temporary security credentials in an instance of the\nSessionAWSCredentials object. You use this object to provide the temporary security\ncredentials to your Amazon S3 client.\n4. Create an instance of the AmazonS3Client class by passing in the temporary security\ncredentials. You send requests to Amazon S3 using this client. If you send requests using\nexpired credentials, Amazon S3 returns an error.\nNote\nThe following C# example lists object keys in the specified bucket. For illustration, the example\nobtains temporary security credentials for a default one-hour session and uses them to send\nauthenticated request to Amazon S3.\nMaking requests using the AWS SDKs API Version 2006-03-01 1630",
      "start_idx": 1731062,
      "end_idx": 1732819,
      "metadata": {
        "num_sentences": 22,
        "num_words": 267,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1636",
      "text": "Amazon Simple Storage Service API Reference\nIf you want to test the sample by using IAM user credentials, you must create an IAM user under\nyour AWS account. For more information about how to create an IAM user, see Creating Your\nFirst IAM user and Administrators Group in the IAM User Guide. For more information about\nmaking requests, see Making requests.\nFor information about setting up and running the code examples, see Getting Started with the\nAWS SDK for .NET in the AWS SDK for .NET Developer Guide.\nusing Amazon;\nusing Amazon.Runtime;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Amazon.SecurityToken;\nusing Amazon.SecurityToken.Model;\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nnamespace Amazon.DocSamples.S3\n{\nclass TempCredExplicitSessionStartTest\n{\nprivate const string bucketName = \"*** bucket name ***\";\n// Specify your bucket region (an example region is shown).\nprivate static readonly RegionEndpoint bucketRegion =\nRegionEndpoint.USWest2;\nprivate static IAmazonS3 s3Client;\npublic static void Main()\n{\nListObjectsAsync().Wait();\n}\nprivate static async Task ListObjectsAsync()\n{\ntry\n{\n// Credentials use the default AWS SDK for .NET credential search\nchain.\n// On local development machines, this is your default profile.\nConsole.WriteLine(\"Listing objects stored in a bucket\");\nSessionAWSCredentials tempCredentials = await\nGetTemporaryCredentialsAsync();\nMaking requests using the AWS SDKs API Version 2006-03-01 1631",
      "start_idx": 1732821,
      "end_idx": 1734294,
      "metadata": {
        "num_sentences": 8,
        "num_words": 200,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1638",
      "text": "Amazon Simple Storage Service API Reference\ncredentials.SessionToken);\nreturn sessionCredentials;\n}\n}\n}\n}\nPHP\nFor more information about the AWS SDK for Ruby API, go to AWS SDK for Ruby - Version 2.\nAn IAM user or an AWS account can request temporary security credentials using version 3\nof the AWS SDK for PHP. It can then use the temporary credentials to access Amazon S3. The\ncredentials expire when the session duration expires.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the\nduration when requesting the temporary security credentials from 15 minutes to the maximum\nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide. For more information about making\nrequests, see Making requests.\nNote\nExample\nThe following PHP example lists object keys in the specified bucket using temporary security\ncredentials. The example obtains temporary security credentials for a default one-hour session,\nand uses them to send authenticated request to Amazon S3. For more information about the\nAWS SDK for Ruby API, go to AWS SDK for Ruby - Version 2.\nIf you want to test the example by using IAM user credentials, you must create an IAM user\nunder your AWS account. For information about how to create an IAM user, see Creating Your\nFirst IAM user and Administrators Group in the IAM User Guide. For examples of setting the\nsession duration when using IAM user credentials to request a session, see Making requests\nusing IAM user temporary credentials .\nrequire 'vendor/autoload.php';\nuse Aws\\S3\\Exception\\S3Exception;\nMaking requests using the AWS SDKs API Version 2006-03-01 1633",
      "start_idx": 1735592,
      "end_idx": 1737307,
      "metadata": {
        "num_sentences": 15,
        "num_words": 275,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1639",
      "text": "Amazon Simple Storage Service API Reference\nuse Aws\\S3\\S3Client;\nuse Aws\\Sts\\StsClient;\n$bucket = '*** Your Bucket Name ***';\n$sts = new StsClient([\n'version' => 'latest',\n'region' => 'us-east-1'\n]);\n$sessionToken = $sts->getSessionToken();\n$s3 = new S3Client([\n'region' => 'us-east-1',\n'version' => 'latest',\n'credentials' => [\n'key' => $sessionToken['Credentials']['AccessKeyId'],\n'secret' => $sessionToken['Credentials']['SecretAccessKey'],\n'token' => $sessionToken['Credentials']['SessionToken']\n]\n]);\n$result = $s3->listBuckets();\ntry {\n// Retrieve a paginator for listing objects.\n$objects = $s3->getPaginator('ListObjects', [\n'Bucket' => $bucket\n]);\necho \"Keys retrieved!\" . PHP_EOL;\n// List objects\nforeach ($objects as $object) {\necho $object['Key'] . PHP_EOL;\n}\n} catch (S3Exception $e) {\necho $e->getMessage() . PHP_EOL;\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1634",
      "start_idx": 1737309,
      "end_idx": 1738205,
      "metadata": {
        "num_sentences": 6,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1640",
      "text": "Amazon Simple Storage Service API Reference\nRuby\nAn IAM user or an AWS account can request temporary security credentials using AWS SDK for\nRuby and use them to access Amazon S3. These credentials expire after the session duration.\nBy default, the session duration is one hour. If you use IAM user credentials, you can specify the\nduration when requesting the temporary security credentials from 15 minutes to the maximum\nsession duration for the role. For more information about temporary security credentials, see\nTemporary Security Credentials in the IAM User Guide. For more information about making\nrequests, see Making requests.\nNote\nThe following Ruby example creates a temporary user to list the items in a specified bucket\nfor one hour. To use this example, you must have AWS credentials that have the necessary\npermissions to create new AWS Security Token Service (AWS STS) clients, and list Amazon S3\nbuckets.\n# Prerequisites:\n# - A user in AWS Identity and Access Management (IAM). This user must\n# be able to assume the following IAM role. You must run this code example\n# within the context of this user.\n# - An existing role in IAM that allows all of the Amazon S3 actions for all of the\n# resources in this code example. This role must also trust the preceding IAM\nuser.\n# - An existing S3 bucket.\nrequire 'aws-sdk-core'\nrequire 'aws-sdk-s3'\nrequire 'aws-sdk-iam'\n# Checks whether a user exists in IAM.\n#\n# @param iam [Aws::IAM::Client] An initialized IAM client.\n# @param user_name [String] The user's name.\n# @return [Boolean] true if the user exists; otherwise, false.\n# @example\n# iam_client = Aws::IAM::Client.new(region: 'us-west-2')\n# exit 1 unless user_exists?(iam_client, 'my-user')\nMaking requests using the AWS SDKs API Version 2006-03-01 1635",
      "start_idx": 1738207,
      "end_idx": 1739977,
      "metadata": {
        "num_sentences": 20,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1645",
      "text": "Amazon Simple Storage Service API Reference\nMaking requests using federated user temporary credentials\nYou can request temporary security credentials and provide them to your federated users or\napplications who need to access your AWS resources. This section provides examples of how\nyou can use the AWS SDK to obtain temporary security credentials for your federated users or\napplications and send authenticated requests to Amazon S3 using those credentials. For a list of\navailable AWS SDKs, see Sample Code and Libraries.\nNote\nBoth the AWS account and an IAM user can request temporary security credentials\nfor federated users. However, for added security, only an IAM user with the necessary\npermissions should request these temporary credentials to ensure that the federated user\ngets at most the permissions of the requesting IAM user. In some applications, you might\nfind it suitable to create an IAM user with specific permissions for the sole purpose of\ngranting temporary security credentials to your federated users and applications.\nJava\nYou can provide temporary security credentials for your federated users and applications so\nthat they can send authenticated requests to access your AWS resources. When requesting these\ntemporary credentials, you must provide a user name and an IAM policy that describes the\nresource permissions that you want to grant. By default, the session duration is one hour. You\ncan explicitly set a different duration value when requesting the temporary security credentials\nfor federated users and applications.\nNote\nFor added security when requesting temporary security credentials for federated\nusers and applications, we recommend that you use a dedicated IAM user with only\nthe necessary access permissions. The temporary user you create can never get more\npermissions than the IAM user who requested the temporary security credentials. For\nmore information, see AWS Identity and Access Management FAQs .\nTo provide security credentials and send authenticated request to access resources, do the\nfollowing:\nMaking requests using the AWS SDKs API Version 2006-03-01 1640",
      "start_idx": 1744896,
      "end_idx": 1747012,
      "metadata": {
        "num_sentences": 14,
        "num_words": 322,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1646",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Create an instance of the AWSSecurityTokenServiceClient class.\n\u2022 Start a session by calling the getFederationToken() method of the Security Token Service\n(STS) client. Provide session information, including the user name and an IAM policy, that you\nwant to attach to the temporary credentials. You can provide an optional session duration.\nThis method returns your temporary security credentials.\n\u2022 Package the temporary security credentials in an instance of the\nBasicSessionCredentials object. You use this object to provide the temporary security\ncredentials to your Amazon S3 client.\n\u2022 Create an instance of the AmazonS3Client class using the temporary security credentials.\nYou send requests to Amazon S3 using this client. If you send requests using expired\ncredentials, Amazon S3 returns an error.\nExample\nThe example lists keys in the specified S3 bucket. In the example, you obtain temporary security\ncredentials for a two-hour session for your federated user and use the credentials to send\nauthenticated requests to Amazon S3. To run the example, you need to create an IAM user with\nan attached policy that allows the user to request temporary security credentials and list your\nAWS resources. The following policy accomplishes this:\n{\n\"Statement\":[{\n\"Action\":[\"s3:ListBucket\",\n\"sts:GetFederationToken*\"\n],\n\"Effect\":\"Allow\",\n\"Resource\":\"*\"\n}\n]\n}\nFor more information about how to create an IAM user, see Creating Your First IAM user and\nAdministrators Group in the IAM User Guide.\nAfter creating an IAM user and attaching the preceding policy, you can run the following\nexample. For instructions on creating and testing a working sample, see Getting Started in the\nAWS SDK for Java Developer Guide.\nMaking requests using the AWS SDKs API Version 2006-03-01 1641",
      "start_idx": 1747014,
      "end_idx": 1748832,
      "metadata": {
        "num_sentences": 17,
        "num_words": 277,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1648",
      "text": "Amazon Simple Storage Service API Reference\n// Define the policy and add it to the request.\nPolicy policy = new Policy();\npolicy.withStatements(new Statement(Effect.Allow)\n.withActions(S3Actions.ListObjects)\n.withResources(new Resource(resourceARN)));\ngetFederationTokenRequest.setPolicy(policy.toJson());\n// Get the temporary security credentials.\nGetFederationTokenResult federationTokenResult =\nstsClient.getFederationToken(getFederationTokenRequest);\nCredentials sessionCredentials = federationTokenResult.getCredentials();\n// Package the session credentials as a BasicSessionCredentials\n// object for an Amazon S3 client object to use.\nBasicSessionCredentials basicSessionCredentials = new\nBasicSessionCredentials(\nsessionCredentials.getAccessKeyId(),\nsessionCredentials.getSecretAccessKey(),\nsessionCredentials.getSessionToken());\nAmazonS3 s3Client = AmazonS3ClientBuilder.standard()\n.withCredentials(new\nAWSStaticCredentialsProvider(basicSessionCredentials))\n.withRegion(clientRegion)\n.build();\n// To verify that the client works, send a listObjects request using\n// the temporary security credentials.\nObjectListing objects = s3Client.listObjects(bucketName);\nSystem.out.println(\"No. of Objects = \" +\nobjects.getObjectSummaries().size());\n} catch (AmazonServiceException e) {\n// The call was transmitted successfully, but Amazon S3 couldn't process\n// it, so it returned an error response.\ne.printStackTrace();\n} catch (SdkClientException e) {\n// Amazon S3 couldn't be contacted for a response, or the client\n// couldn't parse the response from Amazon S3.\ne.printStackTrace();\n}\n}\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1643",
      "start_idx": 1750702,
      "end_idx": 1752355,
      "metadata": {
        "num_sentences": 8,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1649",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nYou can provide temporary security credentials for your federated users and applications so\nthat they can send authenticated requests to access your AWS resources. When requesting\nthese temporary credentials, you must provide a user name and an IAM policy that describes\nthe resource permissions that you want to grant. By default, the duration of a session is one\nhour. You can explicitly set a different duration value when requesting the temporary security\ncredentials for federated users and applications. For information about sending authenticated\nrequests, see Making requests.\nNote\nWhen requesting temporary security credentials for federated users and applications,\nfor added security, we suggest that you use a dedicated IAM user with only the\nnecessary access permissions. The temporary user you create can never get more\npermissions than the IAM user who requested the temporary security credentials. For\nmore information, see AWS Identity and Access Management FAQs .\nYou do the following:\n\u2022 Create an instance of the AWS Security Token Service client,\nAmazonSecurityTokenServiceClient class.\n\u2022 Start a session by calling the GetFederationToken method of the STS client. You need\nto provide session information, including the user name and an IAM policy that you want\nto attach to the temporary credentials. Optionally, you can provide a session duration. This\nmethod returns your temporary security credentials.\n\u2022 Package the temporary security credentials in an instance of the SessionAWSCredentials\nobject. You use this object to provide the temporary security credentials to your Amazon S3\nclient.\n\u2022 Create an instance of the AmazonS3Client class by passing the temporary security\ncredentials. You use this client to send requests to Amazon S3. If you send requests using\nexpired credentials, Amazon S3 returns an error.\nMaking requests using the AWS SDKs API Version 2006-03-01 1644",
      "start_idx": 1752357,
      "end_idx": 1754306,
      "metadata": {
        "num_sentences": 19,
        "num_words": 295,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1650",
      "text": "Amazon Simple Storage Service API Reference\nExample\nThe following C# example lists the keys in the specified bucket. In the example, you obtain\ntemporary security credentials for a two-hour session for your federated user (User1), and use\nthe credentials to send authenticated requests to Amazon S3.\n\u2022 For this exercise, you create an IAM user with minimal permissions. Using the credentials\nof this IAM user, you request temporary credentials for others. This example lists only the\nobjects in a specific bucket. Create an IAM user with the following policy attached:\n{\n\"Statement\":[{\n\"Action\":[\"s3:ListBucket\",\n\"sts:GetFederationToken*\"\n],\n\"Effect\":\"Allow\",\n\"Resource\":\"*\"\n}\n]\n}\nThe policy allows the IAM user to request temporary security credentials and access\npermission only to list your AWS resources. For more information about how to create an IAM\nuser, see Creating Your IAM user User and Administrators Group in the IAM User Guide.\n\u2022 Use the IAM user security credentials to test the following example. The example sends\nauthenticated request to Amazon S3 using temporary security credentials. The example\nspecifies the following policy when requesting temporary security credentials for the\nfederated user (User1), which restricts access to listing objects in a specific bucket\n(YourBucketName). You must update the policy and provide your own existing bucket name.\n{\n\"Statement\":[\n{\n\"Sid\":\"1\",\n\"Action\":[\"s3:ListBucket\"],\n\"Effect\":\"Allow\",\n\"Resource\":\"arn:aws:s3:::YourBucketName\"\n}\n]\n}\nMaking requests using the AWS SDKs API Version 2006-03-01 1645",
      "start_idx": 1754308,
      "end_idx": 1755870,
      "metadata": {
        "num_sentences": 12,
        "num_words": 227,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1651",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Example\nUpdate the following sample and provide the bucket name that you specified in the\npreceding federated user access policy. For information about setting up and running the\ncode examples, see Getting Started with the AWS SDK for .NET in the AWS SDK for .NET\nDeveloper Guide.\nusing Amazon;\nusing Amazon.Runtime;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Amazon.SecurityToken;\nusing Amazon.SecurityToken.Model;\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nnamespace Amazon.DocSamples.S3\n{\nclass TempFederatedCredentialsTest\n{\nprivate const string bucketName = \"*** bucket name ***\";\n// Specify your bucket region (an example region is shown).\nprivate static readonly RegionEndpoint bucketRegion =\nRegionEndpoint.USWest2;\nprivate static IAmazonS3 client;\npublic static void Main()\n{\nListObjectsAsync().Wait();\n}\nprivate static async Task ListObjectsAsync()\n{\ntry\n{\nConsole.WriteLine(\"Listing objects stored in a bucket\");\n// Credentials use the default AWS SDK for .NET credential search\nchain.\n// On local development machines, this is your default profile.\nSessionAWSCredentials tempCredentials =\nawait GetTemporaryFederatedCredentialsAsync();\nMaking requests using the AWS SDKs API Version 2006-03-01 1646",
      "start_idx": 1755872,
      "end_idx": 1757166,
      "metadata": {
        "num_sentences": 6,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1652",
      "text": "Amazon Simple Storage Service API Reference\n// Create a client by providing temporary security credentials.\nusing (client = new AmazonS3Client(bucketRegion))\n{\nListObjectsRequest listObjectRequest = new\nListObjectsRequest();\nlistObjectRequest.BucketName = bucketName;\nListObjectsResponse response = await\nclient.ListObjectsAsync(listObjectRequest);\nList<S3Object> objects = response.S3Objects;\nConsole.WriteLine(\"Object count = {0}\", objects.Count);\nConsole.WriteLine(\"Press any key to continue...\");\nConsole.ReadKey();\n}\n}\ncatch (AmazonS3Exception e)\n{\nConsole.WriteLine(\"Error encountered ***. Message:'{0}' when\nwriting an object\", e.Message);\n}\ncatch (Exception e)\n{\nConsole.WriteLine(\"Unknown encountered on server. Message:'{0}'\nwhen writing an object\", e.Message);\n}\n}\nprivate static async Task<SessionAWSCredentials>\nGetTemporaryFederatedCredentialsAsync()\n{\nAmazonSecurityTokenServiceConfig config = new\nAmazonSecurityTokenServiceConfig();\nAmazonSecurityTokenServiceClient stsClient =\nnew AmazonSecurityTokenServiceClient(\nconfig);\nGetFederationTokenRequest federationTokenRequest =\nnew GetFederationTokenRequest();\nfederationTokenRequest.DurationSeconds = 7200;\nfederationTokenRequest.Name = \"User1\";\nfederationTokenRequest.Policy = @\"{\n\"\"Statement\"\":\n[\nMaking requests using the AWS SDKs API Version 2006-03-01 1647",
      "start_idx": 1757168,
      "end_idx": 1758494,
      "metadata": {
        "num_sentences": 4,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1653",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"\"Sid\"\":\"\"Stmt1311212314284\"\",\n\"\"Action\"\":[\"\"s3:ListBucket\"\"],\n\"\"Effect\"\":\"\"Allow\"\",\n\"\"Resource\"\":\"\"arn:aws:s3:::\" + bucketName + @\"\"\"\n}\n]\n}\n\";\nGetFederationTokenResponse federationTokenResponse =\nawait\nstsClient.GetFederationTokenAsync(federationTokenRequest);\nCredentials credentials = federationTokenResponse.Credentials;\nSessionAWSCredentials sessionCredentials =\nnew SessionAWSCredentials(credentials.AccessKeyId,\ncredentials.SecretAccessKey,\ncredentials.SessionToken);\nreturn sessionCredentials;\n}\n}\n}\nPHP\nThis topic explains how to use classes from version 3 of the AWS SDK for PHP to request\ntemporary security credentials for federated users and applications and use them to access\nresources stored in Amazon S3. For more information about the AWS SDK for Ruby API, go to\nAWS SDK for Ruby - Version 2.\nYou can provide temporary security credentials to your federated users and applications so\nthey can send authenticated requests to access your AWS resources. When requesting these\ntemporary credentials, you must provide a user name and an IAM policy that describes the\nresource permissions that you want to grant. These credentials expire when the session duration\nexpires. By default, the session duration is one hour. You can explicitly set a different value\nfor the duration when requesting the temporary security credentials for federated users and\napplications. For more information about temporary security credentials, see Temporary\nSecurity Credentials in the IAM User Guide. For information about providing temporary security\ncredentials to your federated users and applications, see Making requests.\nMaking requests using the AWS SDKs API Version 2006-03-01 1648",
      "start_idx": 1758496,
      "end_idx": 1760225,
      "metadata": {
        "num_sentences": 10,
        "num_words": 223,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1654",
      "text": "Amazon Simple Storage Service API Reference\nFor added security when requesting temporary security credentials for federated users and\napplications, we recommend using a dedicated IAM user with only the necessary access\npermissions. The temporary user you create can never get more permissions than the IAM user\nwho requested the temporary security credentials. For information about identity federation,\nsee AWS Identity and Access Management FAQs.\nFor more information about the AWS SDK for Ruby API, go to AWS SDK for Ruby - Version 2.\nExample\nThe following PHP example lists keys in the specified bucket. In the example, you obtain\ntemporary security credentials for an hour session for your federated user (User1). Then you use\nthe temporary security credentials to send authenticated requests to Amazon S3.\nFor added security when requesting temporary credentials for others, you use the security\ncredentials of an IAM user who has permissions to request temporary security credentials.\nTo ensure that the IAM user grants only the minimum application-specific permissions to the\nfederated user, you can also limit the access permissions of this IAM user. This example lists only\nobjects in a specific bucket. Create an IAM user with the following policy attached:\n{\n\"Statement\":[{\n\"Action\":[\"s3:ListBucket\",\n\"sts:GetFederationToken*\"\n],\n\"Effect\":\"Allow\",\n\"Resource\":\"*\"\n}\n]\n}\nThe policy allows the IAM user to request temporary security credentials and access permission\nonly to list your AWS resources. For more information about how to create an IAM user, see\nCreating Your First IAM user and Administrators Group in the IAM User Guide.\nYou can now use the IAM user security credentials to test the following example. The example\nsends an authenticated request to Amazon S3 using temporary security credentials. When\nrequesting temporary security credentials for the federated user (User1), the example specifies\nthe following policy, which restricts access to list objects in a specific bucket. Update the policy\nwith your bucket name.\nMaking requests using the AWS SDKs API Version 2006-03-01 1649",
      "start_idx": 1760227,
      "end_idx": 1762333,
      "metadata": {
        "num_sentences": 17,
        "num_words": 320,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1655",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"Statement\":[\n{\n\"Sid\":\"1\",\n\"Action\":[\"s3:ListBucket\"],\n\"Effect\":\"Allow\",\n\"Resource\":\"arn:aws:s3:::YourBucketName\"\n}\n]\n}\nIn the following example, when specifying the policy resource, replace YourBucketName with\nthe name of your bucket.:\nrequire 'vendor/autoload.php';\nuse Aws\\S3\\Exception\\S3Exception;\nuse Aws\\S3\\S3Client;\nuse Aws\\Sts\\StsClient;\n$bucket = '*** Your Bucket Name ***';\n// In real applications, the following code is part of your trusted code. It has\n// the security credentials that you use to obtain temporary security credentials.\n$sts = new StsClient([\n'version' => 'latest',\n'region' => 'us-east-1'\n]);\n// Fetch the federated credentials.\n$sessionToken = $sts->getFederationToken([\n'Name' => 'User1',\n'DurationSeconds' => '3600',\n'Policy' => json_encode([\n'Statement' => [\n'Sid' => 'randomstatementid' . time(),\n'Action' => ['s3:ListBucket'],\n'Effect' => 'Allow',\n'Resource' => 'arn:aws:s3:::' . $bucket\n]\n])\n]);\nMaking requests using the AWS SDKs API Version 2006-03-01 1650",
      "start_idx": 1762335,
      "end_idx": 1763375,
      "metadata": {
        "num_sentences": 7,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1656",
      "text": "Amazon Simple Storage Service API Reference\n// The following will be part of your less trusted code. You provide temporary\n// security credentials so the code can send authenticated requests to Amazon S3.\n$s3 = new S3Client([\n'region' => 'us-east-1',\n'version' => 'latest',\n'credentials' => [\n'key' => $sessionToken['Credentials']['AccessKeyId'],\n'secret' => $sessionToken['Credentials']['SecretAccessKey'],\n'token' => $sessionToken['Credentials']['SessionToken']\n]\n]);\ntry {\n$result = $s3->listObjects([\n'Bucket' => $bucket\n]);\n} catch (S3Exception $e) {\necho $e->getMessage() . PHP_EOL;\n}\nRuby\nYou can provide temporary security credentials for your federated users and applications so\nthat they can send authenticated requests to access your AWS resources. When requesting\ntemporary credentials from the IAM service, you must provide a user name and an IAM policy\nthat describes the resource permissions that you want to grant. By default, the session duration\nis one hour. However, if you are requesting temporary credentials using IAM user credentials,\nyou can explicitly set a different duration value when requesting the temporary security\ncredentials for federated users and applications. For information about temporary security\ncredentials for your federated users and applications, see Making requests.\nNote\nFor added security when you request temporary security credentials for federated users\nand applications, you might want to use a dedicated IAM user with only the necessary\naccess permissions. The temporary user you create can never get more permissions than\nthe IAM user who requested the temporary security credentials. For more information,\nsee AWS Identity and Access Management FAQs .\nMaking requests using the AWS SDKs API Version 2006-03-01 1651",
      "start_idx": 1763377,
      "end_idx": 1765147,
      "metadata": {
        "num_sentences": 12,
        "num_words": 253,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1657",
      "text": "Amazon Simple Storage Service API Reference\nExample\nThe following Ruby code example allows a federated user with a limited set of permissions to\nlists keys in the specified bucket.\n# Prerequisites:\n# - An existing Amazon S3 bucket.\nrequire 'aws-sdk-s3'\nrequire 'aws-sdk-iam'\nrequire 'json'\n# Checks to see whether a user exists in IAM; otherwise,\n# creates the user.\n#\n# @param iam [Aws::IAM::Client] An initialized IAM client.\n# @param user_name [String] The user's name.\n# @return [Aws::IAM::Types::User] The existing or new user.\n# @example\n# iam = Aws::IAM::Client.new(region: 'us-west-2')\n# user = get_user(iam, 'my-user')\n# exit 1 unless user.user_name\n# puts \"User's name: #{user.user_name}\"\ndef get_user(iam, user_name)\nputs \"Checking for a user with the name '#{user_name}'...\"\nresponse = iam.get_user(user_name: user_name)\nputs \"A user with the name '#{user_name}' already exists.\"\nresponse.user\n# If the user doesn't exist, create them.\nrescue Aws::IAM::Errors::NoSuchEntity\nputs \"A user with the name '#{user_name}' doesn't exist. Creating this user...\"\nresponse = iam.create_user(user_name: user_name)\niam.wait_until(:user_exists, user_name: user_name)\nputs \"Created user with the name '#{user_name}'.\"\nresponse.user\nrescue StandardError => e\nputs \"Error while accessing or creating the user named '#{user_name}':\n#{e.message}\"\nend\n# Gets temporary AWS credentials for an IAM user with the specified permissions.\n#\n# @param sts [Aws::STS::Client] An initialized AWS STS client.\n# @param duration_seconds [Integer] The number of seconds for valid credentials.\nMaking requests using the AWS SDKs API Version 2006-03-01 1652",
      "start_idx": 1765149,
      "end_idx": 1766783,
      "metadata": {
        "num_sentences": 14,
        "num_words": 228,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1660",
      "text": "Amazon Simple Storage Service API Reference\nexit 1 unless credentials.access_key_id\nputs \"Access key ID: #{credentials.access_key_id}\"\ns3_client = Aws::S3::Client.new(region: region, credentials: credentials)\nexit 1 unless list_objects_in_bucket?(s3_client, bucket_name)\nend\nrun_me if $PROGRAM_NAME == __FILE__\nMaking requests using the REST API\nThis section contains information on how to make requests to Amazon S3 endpoints by using\nthe REST API. For a list of Amazon S3 endpoints, see Regions and Endpoints in the AWS General\nReference.\nConstructing S3 hostnames for REST API requests\nAmazon S3 endpoints follow the structure shown below:\ns3.Region.amazonaws.com\nAmazon S3 access points endpoints and dual-stack endpoints also follow the standard structure:\n\u2022 Amazon S3 access points \u2010s3-accesspoint.Region.amazonaws.com\n\u2022 Dual-stack \u2010 s3.dualstack.Region.amazonaws.com\nFor a complete list of Amazon S3 Regions and endpoints, see Amazon S3 endpoints and quotas in\nthe Amazon Web Services General Reference.\nVirtual hosted\u2010style and path\u2010style requests\nWhen making requests by using the REST API, you can use virtual hosted\u2013style or path-style URIs\nfor the Amazon S3 endpoints. For more information, see Path-style requests .\nMaking requests using the REST API API Version 2006-03-01 1655",
      "start_idx": 1769490,
      "end_idx": 1770781,
      "metadata": {
        "num_sentences": 7,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1661",
      "text": "Amazon Simple Storage Service API Reference\nExample Virtual hosted\u2013Style request\nFollowing is an example of a virtual hosted\u2013style request to delete the puppy.jpg file from the\nbucket named examplebucket in the US West (Oregon) Region. For more information about\nvirtual hosted-style requests, see Path-style requests .\nDELETE /puppy.jpg HTTP/1.1\nHost: examplebucket.s3.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nExample Path-style request\nFollowing is an example of a path-style version of the same request.\nDELETE /examplebucket/puppy.jpg HTTP/1.1\nHost: s3.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nYou will receive an HTTP response code 307 Temporary Redirect error and a message indicating\nwhat the correct URI is for your resource if you try to access a bucket outside the US East (N.\nVirginia) region with path-style syntax that uses either of the following:\nFor more information about path-style requests, see Path-style requests .\nImportant\nUpdate (September 23, 2020) \u2013 To make sure that customers have the time that they need\nto transition to virtual-hosted\u2013style URLs, we have decided to delay the deprecation of\npath-style URLs. For more information, see Amazon S3 Path Deprecation Plan \u2013 The Rest of\nthe Story in the AWS News Blog.\nMaking requests to dual-stack endpoints by using the REST API\nWhen using the REST API, you can directly access a dual-stack endpoint by using a virtual hosted\u2013\nstyle or a path style endpoint name (URI). All Amazon S3 dual-stack endpoint names include the\nMaking requests using the REST API API Version 2006-03-01 1656",
      "start_idx": 1770783,
      "end_idx": 1772536,
      "metadata": {
        "num_sentences": 8,
        "num_words": 266,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1662",
      "text": "Amazon Simple Storage Service API Reference\nregion in the name. Unlike the standard IPv4-only endpoints, both virtual hosted\u2013style and a path-\nstyle endpoints use region-specific endpoint names.\nExample Virtual hosted\u2013Style dual-stack endpoint request\nYou can use a virtual hosted\u2013style endpoint in your REST request as shown in the following\nexample that retrieves the puppy.jpg object from the bucket named examplebucket in the US\nWest (Oregon) Region.\nGET /puppy.jpg HTTP/1.1\nHost: examplebucket.s3.dualstack.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nExample Path-style dual-stack endpoint request\nOr you can use a path-style endpoint in your request as shown in the following example.\nGET /examplebucket/puppy.jpg HTTP/1.1\nHost: s3.dualstack.us-west-2.amazonaws.com\nDate: Mon, 11 Apr 2016 12:00:00 GMT\nx-amz-date: Mon, 11 Apr 2016 12:00:00 GMT\nAuthorization: authorization string\nFor more information about dual-stack endpoints, see Using Amazon S3 dual-stack endpoints.\nFor more information about making requests using the REST API, see the topics beldow.\nTopics\n\u2022 Request redirection and the REST API\n\u2022 Request routing\nRequest redirection and the REST API\nTopics\n\u2022 Redirects and HTTP user-agents\n\u2022 Redirects and 100-Continue\n\u2022 Redirect example\nMaking requests using the REST API API Version 2006-03-01 1657",
      "start_idx": 1772538,
      "end_idx": 1773946,
      "metadata": {
        "num_sentences": 7,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1663",
      "text": "Amazon Simple Storage Service API Reference\nThis section describes how to handle HTTP redirects by using the Amazon S3 REST API. For general\ninformation about Amazon S3 redirects, see Making requests in the Amazon Simple Storage\nService API Reference.\nRedirects and HTTP user-agents\nPrograms that use the Amazon S3 REST API should handle redirects either at the application\nlayer or the HTTP layer. Many HTTP client libraries and user agents can be configured to correctly\nhandle redirects automatically; however, many others have incorrect or incomplete redirect\nimplementations.\nBefore you rely on a library to fulfill the redirect requirement, test the following cases:\n\u2022 Verify all HTTP request headers are correctly included in the redirected request (the second\nrequest after receiving a redirect) including HTTP standards such as Authorization and Date.\n\u2022 Verify non-GET redirects, such as PUT and DELETE, work correctly.\n\u2022 Verify large PUT requests follow redirects correctly.\n\u2022 Verify PUT requests follow redirects correctly if the 100-continue response takes a long time to\narrive.\nHTTP user-agents that strictly conform to RFC 2616 might require explicit confirmation before\nfollowing a redirect when the HTTP request method is not GET or HEAD. It is generally safe to\nfollow redirects generated by Amazon S3 automatically, as the system will issue redirects only to\nhosts within the amazonaws.com domain and the effect of the redirected request will be the same\nas that of the original request.\nRedirects and 100-Continue\nTo simplify redirect handling, improve efficiencies, and avoid the costs associated with sending a\nredirected request body twice, configure your application to use 100-continues for PUT operations.\nWhen your application uses 100-continue, it does not send the request body until it receives an\nacknowledgement. If the message is rejected based on the headers, the body of the message is not\nsent. For more information about 100-continue, go to RFC 2616 Section 8.2.3\nNote\nAccording to RFC 2616, when using Expect: Continue with an unknown HTTP server,\nyou should not wait an indefinite period before sending the request body. This is because\nMaking requests using the REST API API Version 2006-03-01 1658",
      "start_idx": 1773948,
      "end_idx": 1776186,
      "metadata": {
        "num_sentences": 15,
        "num_words": 348,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1664",
      "text": "Amazon Simple Storage Service API Reference\nsome HTTP servers do not recognize 100-continue. However, Amazon S3 does recognize\nif your request contains an Expect: Continue and will respond with a provisional\n100-continue status or a final status code. Additionally, no redirect error will occur after\nreceiving the provisional 100 continue go-ahead. This will help you avoid receiving a\nredirect response while you are still writing the request body.\nRedirect example\nThis section provides an example of client-server interaction using HTTP redirects and 100-\ncontinue.\nFollowing is a sample PUT to the quotes.s3.amazonaws.com bucket.\nPUT /nelson.txt HTTP/1.1\nHost: quotes.s3.amazonaws.com\nDate: Mon, 15 Oct 2007 22:18:46 +0000\nContent-Length: 6\nExpect: 100-continue\nAmazon S3 returns the following:\nHTTP/1.1 307 Temporary Redirect\nLocation: http://quotes.s3-4c25d83b.amazonaws.com/nelson.txt?rk=8d47490b\nContent-Type: application/xml\nTransfer-Encoding: chunked\nDate: Mon, 15 Oct 2007 22:18:46 GMT\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error>\n<Code>TemporaryRedirect</Code>\n<Message>Please re-send this request to the\nspecified temporary endpoint. Continue to use the\noriginal request endpoint for future requests.\n</Message>\n<Endpoint>quotes.s3-4c25d83b.amazonaws.com</Endpoint>\n<Bucket>quotes</Bucket>\nMaking requests using the REST API API Version 2006-03-01 1659",
      "start_idx": 1776188,
      "end_idx": 1777573,
      "metadata": {
        "num_sentences": 9,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1665",
      "text": "Amazon Simple Storage Service API Reference\n</Error>\nThe client follows the redirect response and issues a new request to the\nquotes.s3-4c25d83b.amazonaws.com temporary endpoint.\nPUT /nelson.txt?rk=8d47490b HTTP/1.1\nHost: quotes.s3-4c25d83b.amazonaws.com\nDate: Mon, 15 Oct 2007 22:18:46 +0000\nContent-Length: 6\nExpect: 100-continue\nAmazon S3 returns a 100-continue indicating the client should proceed with sending the request\nbody.\nHTTP/1.1 100 Continue\nThe client sends the request body.\nha ha\\n\nAmazon S3 returns the final response.\nHTTP/1.1 200 OK\nDate: Mon, 15 Oct 2007 22:18:48 GMT\nETag: \"a2c8d6b872054293afd41061e93bc289\"\nContent-Length: 0\nServer: AmazonS3\nRequest routing\nPrograms that make requests against buckets created using the CreateBucket API that include a\nCreateBucketConfiguration must support redirects. Additionally, some clients that do not respect\nDNS TTLs might encounter issues.\nThis section describes routing and DNS issues to consider when designing your service or\napplication for use with Amazon S3.\nMaking requests using the REST API API Version 2006-03-01 1660",
      "start_idx": 1777575,
      "end_idx": 1778666,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1666",
      "text": "Amazon Simple Storage Service API Reference\nRequest redirection and the REST API\nAmazon S3 uses the Domain Name System (DNS) to route requests to facilities that can process\nthem. This system works effectively, but temporary routing errors can occur. If a request arrives\nat the wrong Amazon S3 location, Amazon S3 responds with a temporary redirect that tells the\nrequester to resend the request to a new endpoint. If a request is incorrectly formed, Amazon S3\nuses permanent redirects to provide direction on how to perform the request correctly.\nImportant\nTo use this feature, you must have an application that can handle Amazon S3 redirect\nresponses. The only exception is for applications that work exclusively with buckets that\nwere created without <CreateBucketConfiguration>. For more information about\nlocation constraints, see Accessing and listing an Amazon S3 bucket .\nFor all Regions that launched after March 20, 2019, if a request arrives at the wrong\nAmazon S3 location, Amazon S3 returns an HTTP 400 Bad Request error.\nFor more information about enabling or disabling an AWS Region, see AWS Regions and\nEndpoints in the AWS General Reference.\nTopics\n\u2022 DNS routing\n\u2022 Temporary request redirection\n\u2022 Permanent request redirection\n\u2022 Request redirection examples\nDNS routing\nDNS routing routes requests to appropriate Amazon S3 facilities. The following figure and\nprocedure show an example of DNS routing.\nMaking requests using the REST API API Version 2006-03-01 1661",
      "start_idx": 1778668,
      "end_idx": 1780150,
      "metadata": {
        "num_sentences": 12,
        "num_words": 233,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1667",
      "text": "Amazon Simple Storage Service API Reference\nDNS routing request steps\n1. The client makes a DNS request to get an object stored on Amazon S3.\nMaking requests using the REST API API Version 2006-03-01 1662",
      "start_idx": 1780152,
      "end_idx": 1780356,
      "metadata": {
        "num_sentences": 3,
        "num_words": 35,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1668",
      "text": "Amazon Simple Storage Service API Reference\n2. The client receives one or more IP addresses for facilities that can process the request. In this\nexample, the IP address is for Facility B.\n3. The client makes a request to Amazon S3 Facility B.\n4. Facility B returns a copy of the object to the client.\nTemporary request redirection\nA temporary redirect is a type of error response that signals to the requester that they should\nresend the request to a different endpoint. Due to the distributed nature of Amazon S3, requests\ncan be temporarily routed to the wrong facility. This is most likely to occur immediately after\nbuckets are created or deleted.\nFor example, if you create a new bucket and immediately make a request to the bucket, you might\nreceive a temporary redirect, depending on the location constraint of the bucket. If you created the\nbucket in the US East (N. Virginia) AWS Region, you will not see the redirect because this is also the\ndefault Amazon S3 endpoint.\nHowever, if the bucket is created in any other Region, any requests for the bucket go to the default\nendpoint while the bucket's DNS entry is propagated. The default endpoint redirects the request to\nthe correct endpoint with an HTTP 302 response. Temporary redirects contain a URI to the correct\nfacility, which you can use to immediately resend the request.\nImportant\nDon't reuse an endpoint provided by a previous redirect response. It might appear to\nwork (even for long periods of time), but it might provide unpredictable results and will\neventually fail without notice.\nThe following figure and procedure shows an example of a temporary redirect.\nMaking requests using the REST API API Version 2006-03-01 1663",
      "start_idx": 1780358,
      "end_idx": 1782054,
      "metadata": {
        "num_sentences": 19,
        "num_words": 286,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1669",
      "text": "Amazon Simple Storage Service API Reference\nTemporary request redirection steps\n1. The client makes a DNS request to get an object stored on Amazon S3.\n2. The client receives one or more IP addresses for facilities that can process the request.\nMaking requests using the REST API API Version 2006-03-01 1664",
      "start_idx": 1782056,
      "end_idx": 1782363,
      "metadata": {
        "num_sentences": 5,
        "num_words": 51,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1670",
      "text": "Amazon Simple Storage Service API Reference\n3. The client makes a request to Amazon S3 Facility B.\n4. Facility B returns a redirect indicating the object is available from Location C.\n5. The client resends the request to Facility C.\n6. Facility C returns a copy of the object.\nPermanent request redirection\nA permanent redirect indicates that your request addressed a resource inappropriately. For\nexample, permanent redirects occur if you use a path-style request to access a bucket that was\ncreated using <CreateBucketConfiguration>. For more information, see Accessing and listing\nan Amazon S3 bucket .\nTo help you find these errors during development, this type of redirect does not contain a Location\nHTTP header that allows you to automatically follow the request to the correct location. Consult\nthe resulting XML error document for help using the correct Amazon S3 endpoint.\nRequest redirection examples\nThe following are examples of temporary request redirection responses.\nREST API temporary redirect response\nHTTP/1.1 307 Temporary Redirect\nLocation: http://awsexamplebucket1.s3-gztb4pa9sq.amazonaws.com/photos/puppy.jpg?\nrk=e2c69a31\nContent-Type: application/xml\nTransfer-Encoding: chunked\nDate: Fri, 12 Oct 2007 01:12:56 GMT\nServer: AmazonS3\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error>\n<Code>TemporaryRedirect</Code>\n<Message>Please re-send this request to the specified temporary endpoint.\nContinue to use the original request endpoint for future requests.</Message>\n<Endpoint>awsexamplebucket1.s3-gztb4pa9sq.amazonaws.com</Endpoint>\n</Error>\nMaking requests using the REST API API Version 2006-03-01 1665",
      "start_idx": 1782365,
      "end_idx": 1783987,
      "metadata": {
        "num_sentences": 15,
        "num_words": 213,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1671",
      "text": "Amazon Simple Storage Service API Reference\nSOAP API temporary redirect response\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\n<soapenv:Body>\n<soapenv:Fault>\n<Faultcode>soapenv:Client.TemporaryRedirect</Faultcode>\n<Faultstring>Please re-send this request to the specified temporary endpoint.\nContinue to use the original request endpoint for future requests.</Faultstring>\n<Detail>\n<Bucket>images</Bucket>\n<Endpoint>s3-gztb4pa9sq.amazonaws.com</Endpoint>\n</Detail>\n</soapenv:Fault>\n</soapenv:Body>\nDNS considerations\nOne of the design requirements of Amazon S3 is extremely high availability. One of the ways we\nmeet this requirement is by updating the IP addresses associated with the Amazon S3 endpoint in\nDNS as needed. These changes are automatically reflected in short-lived clients, but not in some\nlong-lived clients. Long-lived clients will need to take special action to re-resolve the Amazon S3\nendpoint periodically to benefit from these changes. For more information about virtual machines\n(VMs), refer to the following:\n\u2022 For Java, Sun's JVM caches DNS lookups forever by default; go to the \"InetAddress Caching\"\nsection of the InetAddress documentation for information on how to change this behavior.\n\u2022 For PHP, the persistent PHP VM that runs in the most popular deployment configurations caches\nDNS lookups until the VM is restarted. Go to the getHostByName PHP docs.\nMaking requests using the REST API API Version 2006-03-01 1666",
      "start_idx": 1783989,
      "end_idx": 1785588,
      "metadata": {
        "num_sentences": 12,
        "num_words": 227,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1672",
      "text": "Amazon Simple Storage Service API Reference\nDeveloping with Amazon S3 using the AWS CLI\nThe Amazon S3 AWS CLI commands are organized into different sets in AWS CLI Command\nReference and each has it\u2019s own available commands. If you don't find the command that you're\nlooking for in one set, check one of the other sets. The different sets are as follows:\n\u2022 s3 \u2013 Describes high-level commands for working with objects and buckets. These include\ncopy, list and move actions. For a complete list of commands in this set, see s3 in the AWS CLI\nCommand Reference.\n\u2022 s3api \u2013 Describes low-level commands that manage S3 resources such as buckets, objects,\nsessions and multipart uploads. These commands correspond to the Amazon S3 API operations.\nFor a complete list of CLI commands in this set, see s3api in the AWS CLI Command Reference.\n\u2022 s3control \u2013 Describes low-level commands that manage all other S3 resources such as Access\nGrants, Storage Lens groups, and Amazon S3 on Outposts buckets. These commands correspond\nto the Amazon S3 Control API operations. For a complete list of CLI commands in this set, see\ns3control in the AWS CLI Command Reference.\nNote\nServices in AWS, such as Amazon S3, require that you provide credentials when you\naccess them. The service can then determine whether you have permissions to access the\nresources that it owns. The console requires your password. You can create access keys for\nyour AWS account to access the AWS CLI or API. However, we don't recommend that you\naccess AWS using the credentials for your AWS account. Instead, we recommend that you\nuse AWS Identity and Access Management (IAM). Create an IAM user, add the user to an IAM\ngroup with administrative permissions, and then grant administrative permissions to the\nIAM user that you created. You can then access AWS using a special URL and the credentials\nof that IAM user. For instructions, go to Creating Your First IAM user and Administrators\nGroup in the IAM User Guide.\nLearn more about the AWS CLI\nTo learn more about the AWS, see the following resources:\n\u2022 AWS Command Line Interface\nUsing the AWS CLI API Version 2006-03-01 1667",
      "start_idx": 1785590,
      "end_idx": 1787726,
      "metadata": {
        "num_sentences": 21,
        "num_words": 365,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1673",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 AWS Command Line Interface User Guide for Version 2\nDeveloping with Amazon S3 using the AWS SDKs\nAWS software development kits (SDKs) are available for many popular programming languages.\nEach SDK provides an API, code examples, and documentation that make it easier for developers to\nbuild applications in their preferred language.\nNote\nYou can use AWS Amplify for end-to-end fullstack development of web and mobile apps.\nAmplify Storage seamlessly integrates file storage and management capabilities into\nfrontend web and mobile apps, built on top of Amazon S3. For more information, see\nStorage in the Amplify user guide.\nSDK documentation Code examples\nAWS SDK for C++ AWS SDK for C++ code examples\nAWS CLI AWS CLI code examples\nAWS SDK for Go AWS SDK for Go code examples\nAWS SDK for Java AWS SDK for Java code examples\nAWS SDK for JavaScript AWS SDK for JavaScript code examples\nAWS SDK for Kotlin AWS SDK for Kotlin code examples\nAWS SDK for .NET AWS SDK for .NET code examples\nAWS SDK for PHP AWS SDK for PHP code examples\nAWS Tools for PowerShell Tools for PowerShell code examples\nAWS SDK for Python (Boto3) AWS SDK for Python (Boto3) code examples\nAWS SDK for Ruby AWS SDK for Ruby code examples\nDeveloping with AWS SDKs API Version 2006-03-01 1668",
      "start_idx": 1787728,
      "end_idx": 1789033,
      "metadata": {
        "num_sentences": 6,
        "num_words": 223,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1674",
      "text": "Amazon Simple Storage Service API Reference\nSDK documentation Code examples\nAWS SDK for Rust AWS SDK for Rust code examples\nAWS SDK for SAP ABAP AWS SDK for SAP ABAP code examples\nAWS SDK for Swift AWS SDK for Swift code examples\nFor specific examples, see Code examples for Amazon S3 using AWS SDKs.\nSDK Programming interfaces\nEach AWS SDK provides one or more programmatic interfaces for working with Amazon S3.\nEach SDK provides a low-level interface for Amazon S3, with methods that closely resemble API\noperations. Some SDKs provide high-level interfaces for Amazon S3, that are abstractions intended\nto simplify common use cases.\nFor example, when you perform a multipart upload by using the low-level API operations, you\nuse an operation to initiate the upload, another operation to upload parts, and a final operation\nto complete the upload. A high-level multipart upload API operation lets you to do all of the\noperations required for upload in a single API call. For examples, see Uploading an object using\nmultipart upload in the Amazon S3 User Guide.\nLow-level API operations allow greater control over the upload. We recommend that you use\nthe low-level API operations if you need to pause and resume uploads, vary part sizes during the\nupload, or begin uploads when you don't know the size of the data in advance.\nSpecifying the Signature Version in Request Authentication\nAmazon S3 supports only AWS Signature Version 4 in most AWS Regions. In some of the older\nAWS Regions, Amazon S3 supports both Signature Version 4 and Signature Version 2. However,\nSignature Version 2 is being turned off (deprecated). For more information about the end of\nsupport for Signature Version 2, see AWS Signature Version 2 Turned Off (Deprecated) for Amazon\nS3.\nFor a list of all the Amazon S3 Regions and the signature versions they support, see Regions and\nEndpoints in the AWS General Reference.\nSDK Programming interfaces API Version 2006-03-01 1669",
      "start_idx": 1789035,
      "end_idx": 1790986,
      "metadata": {
        "num_sentences": 15,
        "num_words": 322,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1675",
      "text": "Amazon Simple Storage Service API Reference\nFor all AWS Regions, AWS SDKs use Signature Version 4 by default to authenticate requests. When\nusing AWS SDKs that were released before May 2016, you might be required to request Signature\nVersion 4, as shown in the following table.\nSDK Requesting Signature Version 4 for Request Authentication\nAWS CLI For the default profile, run the following command:\n$ aws configure set default.s3.signature_version\ns3v4\nFor a custom profile, run the following command:\n$ aws configure set profile.your_profile_name.s\n3.signature_version s3v4\nJava SDK Add the following in your code:\nSystem.setProperty(SDKGlobalConfiguration.ENA\nBLE_S3_SIGV4_SYSTEM_PROPERTY, \"true\");\nOr, on the command line, specify the following:\n-Dcom.amazonaws.services.s3.enableV4\nJavaScript SDK Set the signatureVersion parameter to v4 when construct\ning the client:\nvar s3 = new AWS.S3({signatureVersion: 'v4'});\nPHP SDK Set the signature parameter to v4 when constructing the\nAmazon S3 service client for PHP SDK v2:\n<?php\n$client = S3Client::factory([\n'region' => 'YOUR-REGION',\n'version' => 'latest',\n'signature' => 'v4'\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1670",
      "start_idx": 1790988,
      "end_idx": 1792206,
      "metadata": {
        "num_sentences": 3,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1677",
      "text": "Amazon Simple Storage Service API Reference\nSDK Requesting Signature Version 4 for Request Authentication\n.NET SDK Add the following to the code before creating the Amazon S3\nclient:\nAWSConfigsS3.UseSignatureVersion4 = true;\nOr, add the following to the config file:\n<appSettings>\n<add key=\"AWS.S3.UseSignatureVersion4\" value=\"tr\nue\" />\n</appSettings>\nAWS Signature Version 2 Turned Off (Deprecated) for Amazon S3\nSignature Version 2 is being turned off (deprecated) in Amazon S3. Amazon S3 will then only\naccept API requests that are signed using Signature Version 4.\nThis section provides answers to common questions regarding the end of support for Signature\nVersion 2.\nWhat is Signature Version 2/4, and What Does It Mean to Sign Requests?\nThe Signature Version 2 or Signature Version 4 signing process is used to authenticate your\nAmazon S3 API requests. Signing requests enables Amazon S3 to identify who is sending the\nrequest and protects your requests from bad actors.\nFor more information about signing AWS requests, see Signing AWS API Requests in the AWS\nGeneral Reference.\nWhat Update Are You Making?\nWe currently support Amazon S3 API requests that are signed using Signature Version 2 and\nSignature Version 4 processes. After that, Amazon S3 will only accept requests that are signed\nusing Signature Version 4.\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1672",
      "start_idx": 1793048,
      "end_idx": 1794460,
      "metadata": {
        "num_sentences": 11,
        "num_words": 216,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1678",
      "text": "Amazon Simple Storage Service API Reference\nFor more information about signing AWS requests, see Changes in Signature Version 4 in the AWS\nGeneral Reference.\nWhy Are You Making the Update?\nSignature Version 4 provides improved security by using a signing key instead of your secret access\nkey. Signature Version 4 is currently supported in all AWS Regions, whereas Signature Version 2\nis only supported in Regions that were launched before January 2014. This update allows us to\nprovide a more consistent experience across all Regions.\nHow Do I Ensure That I'm Using Signature Version 4, and What Updates Do I Need?\nThe signature version that is used to sign your requests is usually set by the tool or the SDK on the\nclient side. By default, the latest versions of our AWS SDKs use Signature Version 4. For third-party\nsoftware, contact the appropriate support team for your software to confirm what version you\nneed. If you are sending direct REST calls to Amazon S3, you must modify your application to use\nthe Signature Version 4 signing process.\nFor information about which version of the AWS SDKs to use when moving to Signature Version 4,\nsee Moving from Signature Version 2 to Signature Version 4.\nFor information about using Signature Version 4 with the Amazon S3 REST API, see Authenticating\nRequests (AWS Signature Version 4) in the Amazon Simple Storage Service API Reference.\nWhat Happens if I Don't Make Updates?\nRequests signed with Signature Version 2 that are made after that will fail to authenticate with\nAmazon S3. Requesters will see errors stating that the request must be signed with Signature\nVersion 4.\nShould I Make Changes Even if I\u2019m Using a Presigned URL That Requires Me to Sign for More\nthan 7 Days?\nIf you are using a presigned URL that requires you to sign for more than 7 days, no action is\ncurrently needed. You can continue to use AWS Signature Version 2 to sign and authenticate the\npresigned URL. We will follow up and provide more details on how to migrate to Signature Version\n4 for a presigned URL scenario.\nMore Info\n\u2022 For more information about using Signature Version 4, see Signing AWS API Requests.\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1673",
      "start_idx": 1794462,
      "end_idx": 1796693,
      "metadata": {
        "num_sentences": 21,
        "num_words": 379,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1679",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 View the list of changes between Signature Version 2 and Signature Version 4 in Changes in\nSignature Version 4.\n\u2022 View the post AWS Signature Version 4 to replace AWS Signature Version 2 for signing Amazon\nS3 API requests in the AWS forums.\n\u2022 If you have any questions or concerns, contact AWS Support.\nMoving from Signature Version 2 to Signature Version 4\nIf you currently use Signature Version 2 for Amazon S3 API request authentication, you should\nmove to using Signature Version 4. Support is ending for Signature Version 2, as described in AWS\nSignature Version 2 Turned Off (Deprecated) for Amazon S3.\nFor information about using Signature Version 4 with the Amazon S3 REST API, see Authenticating\nRequests (AWS Signature Version 4) in the Amazon Simple Storage Service API Reference.\nThe following table lists the SDKs with the necessary minimum version to use Signature Version\n4 (SigV4). If you are using presigned URLs with the AWS Java, JavaScript (Node.js), or Python\n(Boto/CLI) SDKs, you must set the correct AWS Region and set Signature Version 4 in the client\nconfiguration. For information about setting SigV4 in the client configuration, see Specifying the\nSignature Version in Request Authentication.\nIf you use Upgrade Code change Link to SDK documentation\nthis SDK/ to this SDK needed to\nProduct version the client to\nuse Sigv4?\nAWS SDK for Upgrade Yes Specifying the Signature Version in Request\nJava v1 to Java Authentication\n1.11.201+ or\nv2.\nAWS SDK for No SDK No AWS SDK for Java\nJava v2 upgrade is\nneeded.\nSpecifying the Signature Version in Request Authentication API Version 2006-03-01 1674",
      "start_idx": 1796695,
      "end_idx": 1798359,
      "metadata": {
        "num_sentences": 13,
        "num_words": 274,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1683",
      "text": "Amazon Simple Storage Service API Reference\nIf you use Upgrade Code change Link to SDK documentation\nthis SDK/ to this SDK needed to\nProduct version the client to\nuse Sigv4?\nC++ No SDK No AWS SDK for C++\nupgrade is\nneeded.\nAWS Tools for Windows PowerShell or AWS Tools for PowerShell Core\nIf you are using module versions earlier than 3.3.0.0, you must upgrade to 3.3.0.0.\nTo get the version information, use the Get-Module cmdlet:\nGet-Module \u2013Name AWSPowershell\nGet-Module \u2013Name AWSPowershell.NetCore\nTo update the 3.3.0.0 version, use the Update-Module cmdlet:\nUpdate-Module \u2013Name AWSPowershell\nUpdate-Module \u2013Name AWSPowershell.NetCore\nYou can use presigned URLs that are valid for more than 7 days that you will send Signature\nVersion 2 traffic on.\nGetting Amazon S3 request IDs for AWS Support\nWhenever you contact AWS Support because you've encountered errors or unexpected behavior in\nAmazon S3, you must provide the request IDs associated with the failed action. AWS Support uses\nthese request IDs to help resolve the problems that you're experiencing.\nRequest IDs come in pairs, are returned in every response that Amazon S3 processes (even the\nerroneous ones), and can be accessed through verbose logs. There are a number of common\nGet Amazon S3 request IDs for AWS Support API Version 2006-03-01 1678",
      "start_idx": 1800603,
      "end_idx": 1801914,
      "metadata": {
        "num_sentences": 8,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1684",
      "text": "Amazon Simple Storage Service API Reference\nmethods for getting your request IDs, including S3 access logs and AWS CloudTrail events or data\nevents.\nAfter you've recovered these logs, copy and retain those two values, because you'll need them\nwhen you contact AWS Support. For information about contacting AWS Support, see Contact AWS\nor the AWS Support Documentation.\nUsing HTTP to obtain request IDs\nYou can obtain your request IDs, x-amz-request-id and x-amz-id-2 by logging the bits of an\nHTTP request before it reaches the target application. There are a variety of third-party tools that\ncan be used to recover verbose logs for HTTP requests. Choose one that you trust, and then run the\ntool to listen on the port that your Amazon S3 traffic travels on, as you send out another Amazon\nS3 HTTP request.\nFor HTTP requests, the pair of request IDs will look like the following:\nx-amz-request-id: 79104EXAMPLEB723\nx-amz-id-2: IOWQ4fDEXAMPLEQM+ey7N9WgVhSnQ6JEXAMPLEZb7hSQDASK+Jd1vEXAMPLEa3Km\nNote\nHTTPS requests are encrypted and hidden in most packet captures.\nUsing a web browser to obtain request IDs\nMost web browsers have developer tools that you can use to view request headers.\nFor web browser-based requests that return an error, the pair of requests IDs will look like the\nfollowing examples.\n<Error><Code>AccessDenied</Code><Message>Access Denied</Message>\n<RequestId>79104EXAMPLEB723</RequestId><HostId>IOWQ4fDEXAMPLEQM\n+ey7N9WgVhSnQ6JEXAMPLEZb7hSQDASK+Jd1vEXAMPLEa3Km</HostId></Error>\nTo obtain the request ID pair from successful requests, use your browser's developer tools to look\nat the HTTP response headers. For information about developer tools for specific browsers, see\nAmazon S3 Troubleshooting - How to recover your S3 request IDs in AWS re:Post.\nUsing HTTP to obtain request IDs API Version 2006-03-01 1679",
      "start_idx": 1801916,
      "end_idx": 1803747,
      "metadata": {
        "num_sentences": 12,
        "num_words": 262,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1685",
      "text": "Amazon Simple Storage Service API Reference\nUsing the AWS SDKs to obtain request IDs\nThe following sections include information for configuring logging by using an AWS SDK. Although\nyou can enable verbose logging on every request and response, we don't recommend enabling\nlogging in production systems, because large requests or responses can significantly slow down an\napplication.\nFor AWS SDK requests, the pair of request IDs will look like the following examples.\nStatus Code: 403, AWS Service: Amazon S3, AWS Request ID: 79104EXAMPLEB723\nAWS Error Code: AccessDenied AWS Error Message: Access Denied\nS3 Extended Request ID: IOWQ4fDEXAMPLEQM+ey7N9WgVhSnQ6JEXAMPLEZb7hSQDASK\n+Jd1vEXAMPLEa3Km\nUsing the SDK for Go to obtain request IDs\nYou can configure logging by using SDK for Go. For more information, see Response metadata in\nthe SDK for Go V2 Developer Guide.\nUsing the SDK for PHP to obtain request IDs\nYou can configure logging by using PHP. For more information, see How can I see what data is sent\nover the wire? in the AWS SDK for PHP Developer Guide.\nUsing the SDK for Java to obtain request IDs\nYou can enable logging for specific requests or responses to catch and return only the relevant\nheaders. To do this, import the com.amazonaws.services.s3.S3ResponseMetadata class.\nAfterward, you can store the request in a variable before performing the actual request. To get the\nlogged request or response, call getCachedResponseMetadata(AmazonWebServiceRequest\nrequest).getRequestID().\nExample\nPutObjectRequest req = new PutObjectRequest(bucketName, key, createSampleFile());\ns3.putObject(req);\nS3ResponseMetadata md = s3.getCachedResponseMetadata(req);\nSystem.out.println(\"Host ID: \" + md.getHostId() + \" RequestID: \" + md.getRequestId());\nAlternatively, you can use verbose logging of every Java request and response. For more\ninformation, see Verbose Wire Logging in the AWS SDK for Java Developer Guide.\nUsing the AWS SDKs to obtain request IDs API Version 2006-03-01 1680",
      "start_idx": 1803749,
      "end_idx": 1805736,
      "metadata": {
        "num_sentences": 15,
        "num_words": 289,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1686",
      "text": "Amazon Simple Storage Service API Reference\nUsing the AWS SDK for .NET to obtain request IDs\nYou can configure logging with the AWS SDK for .NET by using the built-in System.Diagnostics\nlogging tool. For more information, see the Logging with the AWS SDK for .NET AWS Developer\nBlog post.\nNote\nBy default, the returned log contains only error information. To get the request IDs, the\nconfig file must have AWSLogMetrics (and optionally, AWSResponseLogging) added.\nUsing the SDK for Python (Boto3) to obtain request IDs\nWith the AWS SDK for Python (Boto3), you can log specific responses. You can use this feature to\ncapture only the relevant headers. The following code shows how to log parts of the response to a\nfile:\nimport logging\nimport boto3\nlogging.basicConfig(filename='logfile.txt', level=logging.INFO)\nlogger = logging.getLogger(__name__)\ns3 = boto3.resource('s3')\nresponse = s3.Bucket(bucket_name).Object(object_key).put()\nlogger.info(\"HTTPStatusCode: %s\", response['ResponseMetadata']['HTTPStatusCode'])\nlogger.info(\"RequestId: %s\", response['ResponseMetadata']['RequestId'])\nlogger.info(\"HostId: %s\", response['ResponseMetadata']['HostId'])\nlogger.info(\"Date: %s\", response['ResponseMetadata']['HTTPHeaders']['date'])\nYou can also catch exceptions and log relevant information when an exception is raised. For more\ninformation, see Discerning useful information from error responses in the AWS SDK for Python\n(Boto) API Reference.\nAdditionally, you can configure Boto3 to output verbose debugging logs by using the following\ncode:\nimport boto3\nboto3.set_stream_logger('', logging.DEBUG)\nFor more information, see set_stream_logger in the AWS SDK for Python (Boto) API Reference.\nUsing the AWS SDKs to obtain request IDs API Version 2006-03-01 1681",
      "start_idx": 1805738,
      "end_idx": 1807498,
      "metadata": {
        "num_sentences": 10,
        "num_words": 226,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1687",
      "text": "Amazon Simple Storage Service API Reference\nUsing the SDK for Ruby to obtain request IDs\nYou can get your request IDs using the SDK for Ruby Versions 1, 2, or 3.\n\u2022 Using the SDK for Ruby - Version 1\u2013 You can enable HTTP wire logging globally with the\nfollowing line of code.\ns3 = AWS::S3.new(:logger => Logger.new($stdout), :http_wire_trace => true)\n\u2022 Using the SDK for Ruby - Version 2 or Version 3\u2013 You can enable HTTP wire logging globally\nwith the following line of code.\ns3 = Aws::S3::Client.new(:logger => Logger.new($stdout), :http_wire_trace => true)\nFor tips on getting wire information from an AWS client, see Debugging tip: Getting wire trace\ninformation from a client.\nUsing the AWS CLI to obtain request IDs\nTo get your request IDs when using the AWS Command Line Interface (AWS CLI), add --debug to\nyour command.\nUsing Windows PowerShell to obtain request IDs\nFor information on recovering logs with Windows PowerShell, see the Response Logging in AWS\nTools for Windows PowerShell .NET Development blog post.\nUsing AWS CloudTrail data events to obtain request IDs\nAn Amazon S3 bucket that is configured with CloudTrail data events to log S3 object-level API\noperations provides detailed information about actions that are taken by a user, role, or an AWS\nservice in Amazon S3. You can identify S3 request IDs by querying CloudTrail events with Athena.\nUsing S3 server access logging to obtain request IDs\nAn Amazon S3 bucket configured for S3 server access logging provides detailed records for each\nrequest that is made to the bucket. You can identify S3 request IDs by querying the server access\nlogs using Athena.\nUsing the AWS CLI to obtain request IDs API Version 2006-03-01 1682",
      "start_idx": 1807500,
      "end_idx": 1809198,
      "metadata": {
        "num_sentences": 11,
        "num_words": 284,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1688",
      "text": "Amazon Simple Storage Service API Reference\nCode examples for Amazon S3 using AWS SDKs\nThe following code examples show how to use Amazon S3 with an AWS software development kit\n(SDK).\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nCode examples\n\u2022 Code examples for Amazon S3 using AWS SDKs\n\u2022 Basic examples for Amazon S3 using AWS SDKs\n\u2022 Hello Amazon S3\n\u2022 Learn the basics of Amazon S3 with an AWS SDK\n\u2022 Actions for Amazon S3 using AWS SDKs\n\u2022 Use AbortMultipartUpload with an AWS SDK or CLI\n\u2022 Use AbortMultipartUploads with an AWS SDK\n\u2022 Use CompleteMultipartUpload with an AWS SDK or CLI\n\u2022 Use CopyObject with an AWS SDK or CLI\n\u2022 Use CreateBucket with an AWS SDK or CLI\n\u2022 Use CreateMultiRegionAccessPoint with an AWS SDK\n\u2022 Use CreateMultipartUpload with an AWS SDK or CLI\n\u2022 Use DeleteBucket with an AWS SDK or CLI\n\u2022 Use DeleteBucketAnalyticsConfiguration with a CLI\n\u2022 Use DeleteBucketCors with an AWS SDK or CLI\n\u2022 Use DeleteBucketEncryption with a CLI\n\u2022 Use DeleteBucketInventoryConfiguration with a CLI\n\u2022 Use DeleteBucketLifecycle with an AWS SDK or CLI\n\u2022 Use DeleteBucketMetricsConfiguration with a CLI\n\u2022 Use DeleteBucketPolicy with an AWS SDK or CLI\n\u2022 Use DeleteBucketReplication with a CLI\n\u2022 Use DeleteBucketTagging with a CLI API Version 2006-03-01 1683",
      "start_idx": 1809200,
      "end_idx": 1810629,
      "metadata": {
        "num_sentences": 4,
        "num_words": 244,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1693",
      "text": "Amazon Simple Storage Service API Reference\nActions are code excerpts from larger programs and must be run in context. While actions show you\nhow to call individual service functions, you can see actions in context in their related scenarios.\nScenarios are code examples that show you how to accomplish specific tasks by calling multiple\nfunctions within a service or combined with other AWS services.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nGet started\nHello Amazon S3\nThe following code examples show how to get started using Amazon S3.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCode for the CMakeLists.txt CMake file.\n# Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS s3)\n# Set this project's name.\nproject(\"hello_s3\")\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n# Use the MSVC variable to determine if this is a Windows build.\nAmazon S3 API Version 2006-03-01 1688",
      "start_idx": 1816996,
      "end_idx": 1818356,
      "metadata": {
        "num_sentences": 16,
        "num_words": 225,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1695",
      "text": "Amazon Simple Storage Service API Reference\n* and lists the Amazon S3 buckets in the selected region.\n*\n* main function\n*\n* Usage: 'hello_s3'\n*\n*/\nint main(int argc, char **argv) {\nAws::SDKOptions options;\n// Optionally change the log level for debugging.\n// options.loggingOptions.logLevel = Utils::Logging::LogLevel::Debug;\nAws::InitAPI(options); // Should only be called once.\nint result = 0;\n{\nAws::Client::ClientConfiguration clientConfig;\n// Optional: Set to the AWS Region (overrides config file).\n// clientConfig.region = \"us-east-1\";\n// You don't normally have to test that you are authenticated. But the\nS3 service permits anonymous requests, thus the s3Client will return \"success\"\nand 0 buckets even if you are unauthenticated, which can be confusing to a new\nuser.\nauto provider =\nAws::MakeShared<DefaultAWSCredentialsProviderChain>(\"alloc-tag\");\nauto creds = provider->GetAWSCredentials();\nif (creds.IsEmpty()) {\nstd::cerr << \"Failed authentication\" << std::endl;\n}\nAws::S3::S3Client s3Client(clientConfig);\nauto outcome = s3Client.ListBuckets();\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Failed with error: \" << outcome.GetError() <<\nstd::endl;\nresult = 1;\n} else {\nstd::cout << \"Found \" << outcome.GetResult().GetBuckets().size()\n<< \" buckets\\n\";\nfor (auto &bucket: outcome.GetResult().GetBuckets()) {\nstd::cout << bucket.GetName() << std::endl;\n}\n}\nAmazon S3 API Version 2006-03-01 1690",
      "start_idx": 1819685,
      "end_idx": 1821088,
      "metadata": {
        "num_sentences": 7,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1696",
      "text": "Amazon Simple Storage Service API Reference\n}\nAws::ShutdownAPI(options); // Should only be called once.\nreturn result;\n}\n\u2022 For API details, see ListBuckets in AWS SDK for C++ API Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npackage main\nimport (\n\"context\"\n\"fmt\"\n\"github.com/aws/aws-sdk-go-v2/config\"\n\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n// main uses the AWS SDK for Go V2 to create an Amazon Simple Storage Service\n// (Amazon S3) client and list up to 10 buckets in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\nctx := context.Background()\nsdkConfig, err := config.LoadDefaultConfig(ctx)\nif err != nil {\nfmt.Println(\"Couldn't load default configuration. Have you set up your AWS\naccount?\")\nfmt.Println(err)\nreturn\nAmazon S3 API Version 2006-03-01 1691",
      "start_idx": 1821090,
      "end_idx": 1822037,
      "metadata": {
        "num_sentences": 9,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1697",
      "text": "Amazon Simple Storage Service API Reference\n}\ns3Client := s3.NewFromConfig(sdkConfig)\ncount := 10\nfmt.Printf(\"Let's list up to %v buckets for your account.\\n\", count)\nresult, err := s3Client.ListBuckets(ctx, &s3.ListBucketsInput{})\nif err != nil {\nfmt.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err)\nreturn\n}\nif len(result.Buckets) == 0 {\nfmt.Println(\"You don't have any buckets!\")\n} else {\nif count > len(result.Buckets) {\ncount = len(result.Buckets)\n}\nfor _, bucket := range result.Buckets[:count] {\nfmt.Printf(\"\\t%v\\n\", *bucket.Name)\n}\n}\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.Bucket;\nimport software.amazon.awssdk.services.s3.model.ListBucketsResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.List;\nAmazon S3 API Version 2006-03-01 1692",
      "start_idx": 1822039,
      "end_idx": 1823164,
      "metadata": {
        "num_sentences": 6,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1699",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport {\npaginateListBuckets,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* List the S3 buckets in your configured AWS account.\n*/\nexport const helloS3 = async () => {\n// When no region or credentials are provided, the SDK will use the\n// region and credentials from the local AWS config.\nconst client = new S3Client({});\ntry {\n/**\n* @type { import(\"@aws-sdk/client-s3\").Bucket[] }\n*/\nconst buckets = [];\nfor await (const page of paginateListBuckets({ client }, {})) {\nbuckets.push(...page.Buckets);\n}\nconsole.log(\"Buckets: \");\nconsole.log(buckets.map((bucket) => bucket.Name).join(\"\\n\"));\nreturn buckets;\n} catch (caught) {\n// ListBuckets does not throw any modeled errors. Any error caught\n// here will be something generic like `AccessDenied`.\nif (caught instanceof S3ServiceException) {\nconsole.error(`${caught.name}: ${caught.message}`);\n} else {\nAmazon S3 API Version 2006-03-01 1694",
      "start_idx": 1824270,
      "end_idx": 1825381,
      "metadata": {
        "num_sentences": 7,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1700",
      "text": "Amazon Simple Storage Service API Reference\n// Something besides S3 failed.\nthrow caught;\n}\n}\n};\n\u2022 For API details, see ListBuckets in AWS SDK for JavaScript API Reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nuse Aws\\S3\\S3Client;\n$client = new S3Client(['region' => 'us-west-2']);\n$results = $client->listBuckets();\nvar_dump($results);\n\u2022 For API details, see ListBuckets in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport boto3\nAmazon S3 API Version 2006-03-01 1695",
      "start_idx": 1825383,
      "end_idx": 1826096,
      "metadata": {
        "num_sentences": 8,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1701",
      "text": "Amazon Simple Storage Service API Reference\ndef hello_s3():\n\"\"\"\nUse the AWS SDK for Python (Boto3) to create an Amazon Simple Storage Service\n(Amazon S3) resource and list the buckets in your account.\nThis example uses the default settings specified in your shared credentials\nand config files.\n\"\"\"\ns3_resource = boto3.resource(\"s3\")\nprint(\"Hello, Amazon S3! Let's list your buckets:\")\nfor bucket in s3_resource.buckets.all():\nprint(f\"\\t{bucket.name}\")\nif __name__ == \"__main__\":\nhello_s3()\n\u2022 For API details, see ListBuckets in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# frozen_string_literal: true\n# S3Manager is a class responsible for managing S3 operations\n# such as listing all S3 buckets in the current AWS account.\nclass S3Manager\ndef initialize(client)\n@client = client\n@logger = Logger.new($stdout)\nend\nAmazon S3 API Version 2006-03-01 1696",
      "start_idx": 1826098,
      "end_idx": 1827091,
      "metadata": {
        "num_sentences": 8,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1702",
      "text": "Amazon Simple Storage Service API Reference\n# Lists and prints all S3 buckets in the current AWS account.\ndef list_buckets\n@logger.info('Here are the buckets in your account:')\nresponse = @client.list_buckets\nif response.buckets.empty?\n@logger.info(\"You don't have any S3 buckets yet.\")\nelse\nresponse.buckets.each do |bucket|\n@logger.info(\"- #{bucket.name}\")\nend\nend\nrescue Aws::Errors::ServiceError => e\n@logger.error(\"Encountered an error while listing buckets: #{e.message}\")\nend\nend\nif $PROGRAM_NAME == __FILE__\ns3_client = Aws::S3::Client.new\nmanager = S3Manager.new(s3_client)\nmanager.list_buckets\nend\n\u2022 For API details, see ListBuckets in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// S3 Hello World Example using the AWS SDK for Rust.\n///\n/// This example lists the objects in a bucket, uploads an object to that bucket,\nAmazon S3 API Version 2006-03-01 1697",
      "start_idx": 1827093,
      "end_idx": 1828091,
      "metadata": {
        "num_sentences": 8,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1703",
      "text": "Amazon Simple Storage Service API Reference\n/// and then retrieves the object and prints some S3 information about the\nobject.\n/// This shows a number of S3 features, including how to use built-in paginators\n/// for large data sets.\n///\n/// # Arguments\n///\n/// * `client` - an S3 client configured appropriately for the environment.\n/// * `bucket` - the bucket name that the object will be uploaded to. Must be\npresent in the region the `client` is configured to use.\n/// * `filename` - a reference to a path that will be read and uploaded to S3.\n/// * `key` - the string key that the object will be uploaded as inside the\nbucket.\nasync fn list_bucket_and_upload_object(\nclient: &aws_sdk_s3::Client,\nbucket: &str,\nfilepath: &Path,\nkey: &str,\n) -> Result<(), S3ExampleError> {\n// List the buckets in this account\nlet mut objects = client\n.list_objects_v2()\n.bucket(bucket)\n.into_paginator()\n.send();\nprintln!(\"key\\tetag\\tlast_modified\\tstorage_class\");\nwhile let Some(Ok(object)) = objects.next().await {\nfor item in object.contents() {\nprintln!(\n\"{}\\t{}\\t{}\\t{}\",\nitem.key().unwrap_or_default(),\nitem.e_tag().unwrap_or_default(),\nitem.last_modified()\n.map(|lm| format!(\"{lm}\"))\n.unwrap_or_default(),\nitem.storage_class()\n.map(|sc| format!(\"{sc}\"))\n.unwrap_or_default()\n);\n}\n}\nAmazon S3 API Version 2006-03-01 1698",
      "start_idx": 1828093,
      "end_idx": 1829406,
      "metadata": {
        "num_sentences": 12,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1704",
      "text": "Amazon Simple Storage Service API Reference\n// Prepare a ByteStream around the file, and upload the object using that\nByteStream.\nlet body = aws_sdk_s3::primitives::ByteStream::from_path(filepath)\n.await\n.map_err(|err| {\nS3ExampleError::new(format!(\n\"Failed to create bytestream for {filepath:?} ({err:?})\"\n))\n})?;\nlet resp = client\n.put_object()\n.bucket(bucket)\n.key(key)\n.body(body)\n.send()\n.await?;\nprintln!(\n\"Upload success. Version: {:?}\",\nresp.version_id()\n.expect(\"S3 Object upload missing version ID\")\n);\n// Retrieve the just-uploaded object.\nlet resp = client.get_object().bucket(bucket).key(key).send().await?;\nprintln!(\"etag: {}\", resp.e_tag().unwrap_or(\"(missing)\"));\nprintln!(\"version: {}\", resp.version_id().unwrap_or(\"(missing)\"));\nOk(())\n}\nS3ExampleError utilities\n/// S3ExampleError provides a From<T: ProvideErrorMetadata> impl to extract\n/// client-specific error details. This serves as a consistent backup to handling\n/// specific service errors, depending on what is needed by the scenario.\n/// It is used throughout the code examples for the AWS SDK for Rust.\n#[derive(Debug)]\npub struct S3ExampleError(String);\nimpl S3ExampleError {\npub fn new(value: impl Into<String>) -> Self {\nS3ExampleError(value.into())\nAmazon S3 API Version 2006-03-01 1699",
      "start_idx": 1829408,
      "end_idx": 1830678,
      "metadata": {
        "num_sentences": 17,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1713",
      "text": "Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCode for the CMakeLists.txt CMake file.\n# Set the minimum required version of CMake for this project.\ncmake_minimum_required(VERSION 3.13)\n# Set the AWS service components used by this project.\nset(SERVICE_COMPONENTS s3)\n# Set this project's name.\nproject(\"hello_s3\")\n# Set the C++ standard to use to build this target.\n# At least C++ 11 is required for the AWS SDK for C++.\nset(CMAKE_CXX_STANDARD 11)\n# Use the MSVC variable to determine if this is a Windows build.\nset(WINDOWS_BUILD ${MSVC})\nif (WINDOWS_BUILD) # Set the location where CMake can find the installed\nlibraries for the AWS SDK.\nstring(REPLACE \";\" \"/aws-cpp-sdk-all;\" SYSTEM_MODULE_PATH\n\"${CMAKE_SYSTEM_PREFIX_PATH}/aws-cpp-sdk-all\")\nlist(APPEND CMAKE_PREFIX_PATH ${SYSTEM_MODULE_PATH})\nendif ()\n# Find the AWS SDK for C++ package.\nfind_package(AWSSDK REQUIRED COMPONENTS ${SERVICE_COMPONENTS})\nif (WINDOWS_BUILD AND AWSSDK_INSTALL_AS_SHARED_LIBS)\n# Copy relevant AWS SDK for C++ libraries into the current binary directory\nfor running and debugging.\nBasics API Version 2006-03-01 1708",
      "start_idx": 1842163,
      "end_idx": 1843397,
      "metadata": {
        "num_sentences": 13,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1715",
      "text": "Amazon Simple Storage Service API Reference\n// Optional: Set to the AWS Region (overrides config file).\n// clientConfig.region = \"us-east-1\";\n// You don't normally have to test that you are authenticated. But the\nS3 service permits anonymous requests, thus the s3Client will return \"success\"\nand 0 buckets even if you are unauthenticated, which can be confusing to a new\nuser.\nauto provider =\nAws::MakeShared<DefaultAWSCredentialsProviderChain>(\"alloc-tag\");\nauto creds = provider->GetAWSCredentials();\nif (creds.IsEmpty()) {\nstd::cerr << \"Failed authentication\" << std::endl;\n}\nAws::S3::S3Client s3Client(clientConfig);\nauto outcome = s3Client.ListBuckets();\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Failed with error: \" << outcome.GetError() <<\nstd::endl;\nresult = 1;\n} else {\nstd::cout << \"Found \" << outcome.GetResult().GetBuckets().size()\n<< \" buckets\\n\";\nfor (auto &bucket: outcome.GetResult().GetBuckets()) {\nstd::cout << bucket.GetName() << std::endl;\n}\n}\n}\nAws::ShutdownAPI(options); // Should only be called once.\nreturn result;\n}\n\u2022 For API details, see ListBuckets in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 1710",
      "start_idx": 1844575,
      "end_idx": 1845720,
      "metadata": {
        "num_sentences": 6,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1716",
      "text": "Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npackage main\nimport (\n\"context\"\n\"fmt\"\n\"github.com/aws/aws-sdk-go-v2/config\"\n\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\n// main uses the AWS SDK for Go V2 to create an Amazon Simple Storage Service\n// (Amazon S3) client and list up to 10 buckets in your account.\n// This example uses the default settings specified in your shared credentials\n// and config files.\nfunc main() {\nctx := context.Background()\nsdkConfig, err := config.LoadDefaultConfig(ctx)\nif err != nil {\nfmt.Println(\"Couldn't load default configuration. Have you set up your AWS\naccount?\")\nfmt.Println(err)\nreturn\n}\ns3Client := s3.NewFromConfig(sdkConfig)\ncount := 10\nfmt.Printf(\"Let's list up to %v buckets for your account.\\n\", count)\nresult, err := s3Client.ListBuckets(ctx, &s3.ListBucketsInput{})\nif err != nil {\nfmt.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err)\nreturn\n}\nBasics API Version 2006-03-01 1711",
      "start_idx": 1845722,
      "end_idx": 1846809,
      "metadata": {
        "num_sentences": 8,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1717",
      "text": "Amazon Simple Storage Service API Reference\nif len(result.Buckets) == 0 {\nfmt.Println(\"You don't have any buckets!\")\n} else {\nif count > len(result.Buckets) {\ncount = len(result.Buckets)\n}\nfor _, bucket := range result.Buckets[:count] {\nfmt.Printf(\"\\t%v\\n\", *bucket.Name)\n}\n}\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.Bucket;\nimport software.amazon.awssdk.services.s3.model.ListBucketsResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.List;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n* <p>\n* For more information, see the following documentation topic:\n* <p>\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\nBasics API Version 2006-03-01 1712",
      "start_idx": 1846811,
      "end_idx": 1847918,
      "metadata": {
        "num_sentences": 6,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1718",
      "text": "Amazon Simple Storage Service API Reference\n*/\npublic class HelloS3 {\npublic static void main(String[] args) {\nRegion region = Region.US_EAST_1;\nS3Client s3 = S3Client.builder()\n.region(region)\n.build();\nlistBuckets(s3);\n}\n/**\n* Lists all the S3 buckets associated with the provided AWS S3 client.\n*\n* @param s3 the S3Client instance used to interact with the AWS S3 service\n*/\npublic static void listBuckets(S3Client s3) {\ntry {\nListBucketsResponse response = s3.listBuckets();\nList<Bucket> bucketList = response.buckets();\nbucketList.forEach(bucket -> {\nSystem.out.println(\"Bucket Name: \" + bucket.name());\n});\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1713",
      "start_idx": 1847920,
      "end_idx": 1848904,
      "metadata": {
        "num_sentences": 5,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1719",
      "text": "Amazon Simple Storage Service API Reference\nimport {\npaginateListBuckets,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* List the S3 buckets in your configured AWS account.\n*/\nexport const helloS3 = async () => {\n// When no region or credentials are provided, the SDK will use the\n// region and credentials from the local AWS config.\nconst client = new S3Client({});\ntry {\n/**\n* @type { import(\"@aws-sdk/client-s3\").Bucket[] }\n*/\nconst buckets = [];\nfor await (const page of paginateListBuckets({ client }, {})) {\nbuckets.push(...page.Buckets);\n}\nconsole.log(\"Buckets: \");\nconsole.log(buckets.map((bucket) => bucket.Name).join(\"\\n\"));\nreturn buckets;\n} catch (caught) {\n// ListBuckets does not throw any modeled errors. Any error caught\n// here will be something generic like `AccessDenied`.\nif (caught instanceof S3ServiceException) {\nconsole.error(`${caught.name}: ${caught.message}`);\n} else {\n// Something besides S3 failed.\nthrow caught;\n}\n}\n};\n\u2022 For API details, see ListBuckets in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1714",
      "start_idx": 1848906,
      "end_idx": 1849984,
      "metadata": {
        "num_sentences": 7,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1720",
      "text": "Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nuse Aws\\S3\\S3Client;\n$client = new S3Client(['region' => 'us-west-2']);\n$results = $client->listBuckets();\nvar_dump($results);\n\u2022 For API details, see ListBuckets in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport boto3\ndef hello_s3():\n\"\"\"\nUse the AWS SDK for Python (Boto3) to create an Amazon Simple Storage Service\n(Amazon S3) resource and list the buckets in your account.\nThis example uses the default settings specified in your shared credentials\nand config files.\n\"\"\"\ns3_resource = boto3.resource(\"s3\")\nBasics API Version 2006-03-01 1715",
      "start_idx": 1849986,
      "end_idx": 1850857,
      "metadata": {
        "num_sentences": 8,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1721",
      "text": "Amazon Simple Storage Service API Reference\nprint(\"Hello, Amazon S3! Let's list your buckets:\")\nfor bucket in s3_resource.buckets.all():\nprint(f\"\\t{bucket.name}\")\nif __name__ == \"__main__\":\nhello_s3()\n\u2022 For API details, see ListBuckets in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# frozen_string_literal: true\n# S3Manager is a class responsible for managing S3 operations\n# such as listing all S3 buckets in the current AWS account.\nclass S3Manager\ndef initialize(client)\n@client = client\n@logger = Logger.new($stdout)\nend\n# Lists and prints all S3 buckets in the current AWS account.\ndef list_buckets\n@logger.info('Here are the buckets in your account:')\nresponse = @client.list_buckets\nif response.buckets.empty?\n@logger.info(\"You don't have any S3 buckets yet.\")\nelse\nresponse.buckets.each do |bucket|\nBasics API Version 2006-03-01 1716",
      "start_idx": 1850859,
      "end_idx": 1851841,
      "metadata": {
        "num_sentences": 9,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1722",
      "text": "Amazon Simple Storage Service API Reference\n@logger.info(\"- #{bucket.name}\")\nend\nend\nrescue Aws::Errors::ServiceError => e\n@logger.error(\"Encountered an error while listing buckets: #{e.message}\")\nend\nend\nif $PROGRAM_NAME == __FILE__\ns3_client = Aws::S3::Client.new\nmanager = S3Manager.new(s3_client)\nmanager.list_buckets\nend\n\u2022 For API details, see ListBuckets in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// S3 Hello World Example using the AWS SDK for Rust.\n///\n/// This example lists the objects in a bucket, uploads an object to that bucket,\n/// and then retrieves the object and prints some S3 information about the\nobject.\n/// This shows a number of S3 features, including how to use built-in paginators\n/// for large data sets.\n///\n/// # Arguments\n///\n/// * `client` - an S3 client configured appropriately for the environment.\n/// * `bucket` - the bucket name that the object will be uploaded to. Must be\npresent in the region the `client` is configured to use.\n/// * `filename` - a reference to a path that will be read and uploaded to S3.\nBasics API Version 2006-03-01 1717",
      "start_idx": 1851843,
      "end_idx": 1853059,
      "metadata": {
        "num_sentences": 11,
        "num_words": 200,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1724",
      "text": "Amazon Simple Storage Service API Reference\n.key(key)\n.body(body)\n.send()\n.await?;\nprintln!(\n\"Upload success. Version: {:?}\",\nresp.version_id()\n.expect(\"S3 Object upload missing version ID\")\n);\n// Retrieve the just-uploaded object.\nlet resp = client.get_object().bucket(bucket).key(key).send().await?;\nprintln!(\"etag: {}\", resp.e_tag().unwrap_or(\"(missing)\"));\nprintln!(\"version: {}\", resp.version_id().unwrap_or(\"(missing)\"));\nOk(())\n}\nS3ExampleError utilities\n/// S3ExampleError provides a From<T: ProvideErrorMetadata> impl to extract\n/// client-specific error details. This serves as a consistent backup to handling\n/// specific service errors, depending on what is needed by the scenario.\n/// It is used throughout the code examples for the AWS SDK for Rust.\n#[derive(Debug)]\npub struct S3ExampleError(String);\nimpl S3ExampleError {\npub fn new(value: impl Into<String>) -> Self {\nS3ExampleError(value.into())\n}\npub fn add_message(self, message: impl Into<String>) -> Self {\nS3ExampleError(format!(\"{}: {}\", message.into(), self.0))\n}\n}\nimpl<T: aws_sdk_s3::error::ProvideErrorMetadata> From<T> for S3ExampleError {\nfn from(value: T) -> Self {\nS3ExampleError(format!(\n\"{}: {}\",\nvalue\nBasics API Version 2006-03-01 1719",
      "start_idx": 1854189,
      "end_idx": 1855410,
      "metadata": {
        "num_sentences": 14,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1725",
      "text": "Amazon Simple Storage Service API Reference\n.code()\n.map(String::from)\n.unwrap_or(\"unknown code\".into()),\nvalue\n.message()\n.map(String::from)\n.unwrap_or(\"missing reason\".into()),\n))\n}\n}\nimpl std::error::Error for S3ExampleError {}\nimpl std::fmt::Display for S3ExampleError {\nfn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {\nwrite!(f, \"{}\", self.0)\n}\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nLearn the basics of Amazon S3 with an AWS SDK\nThe following code examples show how to:\n\u2022 Create a bucket and upload a file to it.\n\u2022 Download an object from a bucket.\n\u2022 Copy an object to a subfolder in a bucket.\n\u2022 List the objects in a bucket.\n\u2022 Delete the bucket objects and the bucket.\nBasics API Version 2006-03-01 1720",
      "start_idx": 1855412,
      "end_idx": 1856392,
      "metadata": {
        "num_sentences": 10,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1726",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npublic class S3_Basics\n{\npublic static async Task Main()\n{\n// Create an Amazon S3 client object. The constructor uses the\n// default user installed on the system. To work with Amazon S3\n// features in a different AWS Region, pass the AWS Region as a\n// parameter to the client constructor.\nIAmazonS3 client = new AmazonS3Client();\nstring bucketName = string.Empty;\nstring filePath = string.Empty;\nstring keyName = string.Empty;\nvar sepBar = new string('-', Console.WindowWidth);\nConsole.WriteLine(sepBar);\nConsole.WriteLine(\"Amazon Simple Storage Service (Amazon S3) basic\");\nConsole.WriteLine(\"procedures. This application will:\");\nConsole.WriteLine(\"\\n\\t1. Create a bucket\");\nConsole.WriteLine(\"\\n\\t2. Upload an object to the new bucket\");\nConsole.WriteLine(\"\\n\\t3. Copy the uploaded object to a folder in the\nbucket\");\nConsole.WriteLine(\"\\n\\t4. List the items in the new bucket\");\nConsole.WriteLine(\"\\n\\t5. Delete all the items in the bucket\");\nConsole.WriteLine(\"\\n\\t6. Delete the bucket\");\nConsole.WriteLine(sepBar);\n// Create a bucket.\nConsole.WriteLine($\"\\n{sepBar}\");\nConsole.WriteLine(\"\\nCreate a new Amazon S3 bucket.\\n\");\nConsole.WriteLine(sepBar);\nBasics API Version 2006-03-01 1721",
      "start_idx": 1856394,
      "end_idx": 1857778,
      "metadata": {
        "num_sentences": 14,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1727",
      "text": "Amazon Simple Storage Service API Reference\nConsole.Write(\"Please enter a name for the new bucket: \");\nbucketName = Console.ReadLine();\nvar success = await S3Bucket.CreateBucketAsync(client, bucketName);\nif (success)\n{\nConsole.WriteLine($\"Successfully created bucket: {bucketName}.\n\\n\");\n}\nelse\n{\nConsole.WriteLine($\"Could not create bucket: {bucketName}.\\n\");\n}\nConsole.WriteLine(sepBar);\nConsole.WriteLine(\"Upload a file to the new bucket.\");\nConsole.WriteLine(sepBar);\n// Get the local path and filename for the file to upload.\nwhile (string.IsNullOrEmpty(filePath))\n{\nConsole.Write(\"Please enter the path and filename of the file to\nupload: \");\nfilePath = Console.ReadLine();\n// Confirm that the file exists on the local computer.\nif (!File.Exists(filePath))\n{\nConsole.WriteLine($\"Couldn't find {filePath}. Try again.\\n\");\nfilePath = string.Empty;\n}\n}\n// Get the file name from the full path.\nkeyName = Path.GetFileName(filePath);\nsuccess = await S3Bucket.UploadFileAsync(client, bucketName, keyName,\nfilePath);\nif (success)\n{\nConsole.WriteLine($\"Successfully uploaded {keyName} from\n{filePath} to {bucketName}.\\n\");\n}\nBasics API Version 2006-03-01 1722",
      "start_idx": 1857780,
      "end_idx": 1858937,
      "metadata": {
        "num_sentences": 7,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1729",
      "text": "Amazon Simple Storage Service API Reference\nConsole.Write(\"Please enter the name of the folder to copy your\nobject to: \");\nfolderName = Console.ReadLine();\n}\nwhile (string.IsNullOrEmpty(keyName))\n{\n// Get the name to give to the object once uploaded.\nConsole.Write(\"Enter the name of the object to copy: \");\nkeyName = Console.ReadLine();\n}\nawait S3Bucket.CopyObjectInBucketAsync(client, bucketName, keyName,\nfolderName);\n// List the objects in the bucket.\nawait S3Bucket.ListBucketContentsAsync(client, bucketName);\n// Delete the contents of the bucket.\nawait S3Bucket.DeleteBucketContentsAsync(client, bucketName);\n// Deleting the bucket too quickly after deleting its contents will\n// cause an error that the bucket isn't empty. So...\nConsole.WriteLine(\"Press <Enter> when you are ready to delete the\nbucket.\");\n_ = Console.ReadLine();\n// Delete the bucket.\nawait S3Bucket.DeleteBucketAsync(client, bucketName);\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\nBasics API Version 2006-03-01 1724",
      "start_idx": 1860089,
      "end_idx": 1861207,
      "metadata": {
        "num_sentences": 8,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1730",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 PutObject\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function s3_getting_started\n#\n# This function creates, copies, and deletes S3 buckets and objects.\n#\n# Returns:\n# 0 - If successful.\n# 1 - If an error occurred.\n###############################################################################\nfunction s3_getting_started() {\n{\nif [ \"$BUCKET_OPERATIONS_SOURCED\" != \"True\" ]; then\ncd bucket-lifecycle-operations || exit\nsource ./bucket_operations.sh\ncd ..\nfi\n}\necho_repeat \"*\" 88\necho \"Welcome to the Amazon S3 getting started demo.\"\necho_repeat \"*\" 88\necho \"A unique bucket will be created by appending a Universally Unique\nIdentifier to a bucket name prefix.\"\necho -n \"Enter a prefix for the S3 bucket that will be used in this demo: \"\nget_input\nbucket_name_prefix=$get_input_result\nlocal bucket_name\nbucket_name=$(generate_random_name \"$bucket_name_prefix\")\nBasics API Version 2006-03-01 1725",
      "start_idx": 1861209,
      "end_idx": 1862342,
      "metadata": {
        "num_sentences": 8,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1731",
      "text": "Amazon Simple Storage Service API Reference\nlocal region_code\nregion_code=$(aws configure get region)\nif create_bucket -b \"$bucket_name\" -r \"$region_code\"; then\necho \"Created demo bucket named $bucket_name\"\nelse\nerrecho \"The bucket failed to create. This demo will exit.\"\nreturn 1\nfi\nlocal file_name\nwhile [ -z \"$file_name\" ]; do\necho -n \"Enter a file you want to upload to your bucket: \"\nget_input\nfile_name=$get_input_result\nif [ ! -f \"$file_name\" ]; then\necho \"Could not find file $file_name. Are you sure it exists?\"\nfile_name=\"\"\nfi\ndone\nlocal key\nkey=\"$(basename \"$file_name\")\"\nlocal result=0\nif copy_file_to_bucket \"$bucket_name\" \"$file_name\" \"$key\"; then\necho \"Uploaded file $file_name into bucket $bucket_name with key $key.\"\nelse\nresult=1\nfi\nlocal destination_file\ndestination_file=\"$file_name.download\"\nif yes_no_input \"Would you like to download $key to the file $destination_file?\n(y/n) \"; then\nif download_object_from_bucket \"$bucket_name\" \"$destination_file\" \"$key\";\nthen\necho \"Downloaded $key in the bucket $bucket_name to the file\n$destination_file.\"\nelse\nresult=1\nfi\nBasics API Version 2006-03-01 1726",
      "start_idx": 1862344,
      "end_idx": 1863462,
      "metadata": {
        "num_sentences": 9,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1733",
      "text": "Amazon Simple Storage Service API Reference\n}\nThe Amazon S3 functions used in this scenario.\n###############################################################################\n# function create-bucket\n#\n# This function creates the specified bucket in the specified AWS Region, unless\n# it already exists.\n#\n# Parameters:\n# -b bucket_name -- The name of the bucket to create.\n# -r region_code -- The code for an AWS Region in which to\n# create the bucket.\n#\n# Returns:\n# The URL of the bucket that was created.\n# And:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction create_bucket() {\nlocal bucket_name region_code response\nlocal option OPTARG # Required to use getopts command in a function.\n# bashsupport disable=BP5008\nfunction usage() {\necho \"function create_bucket\"\necho \"Creates an Amazon S3 bucket. You must supply a bucket name:\"\necho \" -b bucket_name The name of the bucket. It must be globally\nunique.\"\necho \" [-r region_code] The code for an AWS Region in which the bucket is\ncreated.\"\necho \"\"\n}\n# Retrieve the calling parameters.\nwhile getopts \"b:r:h\" option; do\ncase \"${option}\" in\nb) bucket_name=\"${OPTARG}\" ;;\nr) region_code=\"${OPTARG}\" ;;\nh)\nBasics API Version 2006-03-01 1728",
      "start_idx": 1864466,
      "end_idx": 1865734,
      "metadata": {
        "num_sentences": 14,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1734",
      "text": "Amazon Simple Storage Service API Reference\nusage\nreturn 0\n;;\n\\?)\necho \"Invalid parameter\"\nusage\nreturn 1\n;;\nesac\ndone\nif [[ -z \"$bucket_name\" ]]; then\nerrecho \"ERROR: You must provide a bucket name with the -b parameter.\"\nusage\nreturn 1\nfi\nlocal bucket_config_arg\n# A location constraint for \"us-east-1\" returns an error.\nif [[ -n \"$region_code\" ]] && [[ \"$region_code\" != \"us-east-1\" ]]; then\nbucket_config_arg=\"--create-bucket-configuration LocationConstraint=\n$region_code\"\nfi\niecho \"Parameters:\\n\"\niecho \" Bucket name: $bucket_name\"\niecho \" Region code: $region_code\"\niecho \"\"\n# If the bucket already exists, we don't want to try to create it.\nif (bucket_exists \"$bucket_name\"); then\nerrecho \"ERROR: A bucket with that name already exists. Try again.\"\nreturn 1\nfi\n# shellcheck disable=SC2086\nresponse=$(aws s3api create-bucket \\\n--bucket \"$bucket_name\" \\\n$bucket_config_arg)\n# shellcheck disable=SC2181\nif [[ ${?} -ne 0 ]]; then\nerrecho \"ERROR: AWS reports create-bucket operation failed.\\n$response\"\nreturn 1\nBasics API Version 2006-03-01 1729",
      "start_idx": 1865736,
      "end_idx": 1866785,
      "metadata": {
        "num_sentences": 8,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1737",
      "text": "Amazon Simple Storage Service API Reference\n--bucket \"$bucket_name\" \\\n--copy-source \"$bucket_name/$source_key\" \\\n--key \"$destination_key\")\n# shellcheck disable=SC2181\nif [[ $? -ne 0 ]]; then\nerrecho \"ERROR: AWS reports s3api copy-object operation failed.\\n$response\"\nreturn 1\nfi\n}\n###############################################################################\n# function list_items_in_bucket\n#\n# This function displays a list of the files in the bucket with each file's\n# size. The function uses the --query parameter to retrieve only the key and\n# size fields from the Contents collection.\n#\n# Parameters:\n# $1 - The name of the bucket.\n#\n# Returns:\n# The list of files in text format.\n# And:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction list_items_in_bucket() {\nlocal bucket_name=$1\nlocal response\nresponse=$(aws s3api list-objects \\\n--bucket \"$bucket_name\" \\\n--output text \\\n--query 'Contents[].{Key: Key, Size: Size}')\n# shellcheck disable=SC2181\nif [[ ${?} -eq 0 ]]; then\necho \"$response\"\nelse\nerrecho \"ERROR: AWS reports s3api list-objects operation failed.\\n$response\"\nreturn 1\nfi\n}\nBasics API Version 2006-03-01 1732",
      "start_idx": 1869363,
      "end_idx": 1870572,
      "metadata": {
        "num_sentences": 10,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1740",
      "text": "Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n#include <iostream>\n#include <aws/core/Aws.h>\n#include <aws/s3/S3Client.h>\n#include <aws/s3/model/CopyObjectRequest.h>\n#include <aws/s3/model/CreateBucketRequest.h>\n#include <aws/s3/model/DeleteBucketRequest.h>\n#include <aws/s3/model/DeleteObjectRequest.h>\n#include <aws/s3/model/GetObjectRequest.h>\n#include <aws/s3/model/ListObjectsV2Request.h>\n#include <aws/s3/model/PutObjectRequest.h>\n#include <aws/s3/model/BucketLocationConstraint.h>\n#include <aws/s3/model/CreateBucketConfiguration.h>\n#include <aws/core/utils/UUID.h>\n#include <aws/core/utils/StringUtils.h>\n#include <aws/core/utils/memory/stl/AWSAllocator.h>\n#include <fstream>\n#include \"s3_examples.h\"\nnamespace AwsDoc {\nnamespace S3 {\n//! Delete an S3 bucket.\n/*!\n\\param bucketName: The S3 bucket's name.\n\\param client: An S3 client.\n\\return bool: Function succeeded.\n*/\nstatic bool\ndeleteBucket(const Aws::String &bucketName, Aws::S3::S3Client &client);\n//! Delete an object in an S3 bucket.\n/*!\nBasics API Version 2006-03-01 1735",
      "start_idx": 1872492,
      "end_idx": 1873668,
      "metadata": {
        "num_sentences": 12,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1741",
      "text": "Amazon Simple Storage Service API Reference\n\\param bucketName: The S3 bucket's name.\n\\param key: The key for the object in the S3 bucket.\n\\param client: An S3 client.\n\\return bool: Function succeeded.\n*/\nstatic bool\ndeleteObjectFromBucket(const Aws::String &bucketName, const Aws::String\n&key,\nAws::S3::S3Client &client);\n}\n}\n//! Scenario to create, copy, and delete S3 buckets and objects.\n/*!\n\\param bucketNamePrefix: A prefix for a bucket name.\n\\param uploadFilePath: Path to file to upload to an Amazon S3 bucket.\n\\param saveFilePath: Path for saving a downloaded S3 object.\n\\param clientConfig: Aws client configuration.\n\\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::S3_GettingStartedScenario(const Aws::String &bucketNamePrefix,\nconst Aws::String &uploadFilePath,\nconst Aws::String &saveFilePath,\nconst Aws::Client::ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client client(clientConfig);\n// Create a unique bucket name which is only temporary and will be deleted.\n// Format: <bucketNamePrefix> + \"-\" + lowercase UUID.\nAws::String uuid = Aws::Utils::UUID::RandomUUID();\nAws::String bucketName = bucketNamePrefix +\nAws::Utils::StringUtils::ToLower(uuid.c_str());\n// 1. Create a bucket.\n{\nAws::S3::Model::CreateBucketRequest request;\nrequest.SetBucket(bucketName);\nif (clientConfig.region != Aws::Region::US_EAST_1) {\nAws::S3::Model::CreateBucketConfiguration createBucketConfiguration;\ncreateBucketConfiguration.WithLocationConstraint(\nBasics API Version 2006-03-01 1736",
      "start_idx": 1873670,
      "end_idx": 1875157,
      "metadata": {
        "num_sentences": 17,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1742",
      "text": "Amazon Simple Storage Service API Reference\nAws::S3::Model::BucketLocationConstraintMapper::GetBucketLocationConstraintForName(\nclientConfig.region));\nrequest.WithCreateBucketConfiguration(createBucketConfiguration);\n}\nAws::S3::Model::CreateBucketOutcome outcome =\nclient.CreateBucket(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: createBucket: \" <<\nerr.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\nreturn false;\n} else {\nstd::cout << \"Created the bucket, '\" << bucketName <<\n\"', in the region, '\" << clientConfig.region << \"'.\" <<\nstd::endl;\n}\n}\n// 2. Upload a local file to the bucket.\nAws::String key = \"key-for-test\";\n{\nAws::S3::Model::PutObjectRequest request;\nrequest.SetBucket(bucketName);\nrequest.SetKey(key);\nstd::shared_ptr<Aws::FStream> input_data =\nAws::MakeShared<Aws::FStream>(\"SampleAllocationTag\",\nuploadFilePath,\nstd::ios_base::in |\nstd::ios_base::binary);\nif (!input_data->is_open()) {\nstd::cerr << \"Error: unable to open file, '\" << uploadFilePath <<\n\"'.\"\n<< std::endl;\nAwsDoc::S3::deleteBucket(bucketName, client);\nreturn false;\n}\nrequest.SetBody(input_data);\nBasics API Version 2006-03-01 1737",
      "start_idx": 1875159,
      "end_idx": 1876352,
      "metadata": {
        "num_sentences": 5,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1743",
      "text": "Amazon Simple Storage Service API Reference\nAws::S3::Model::PutObjectOutcome outcome =\nclient.PutObject(request);\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Error: putObject: \" <<\noutcome.GetError().GetMessage() << std::endl;\nAwsDoc::S3::deleteObjectFromBucket(bucketName, key, client);\nAwsDoc::S3::deleteBucket(bucketName, client);\nreturn false;\n} else {\nstd::cout << \"Added the object with the key, '\" << key\n<< \"', to the bucket, '\"\n<< bucketName << \"'.\" << std::endl;\n}\n}\n// 3. Download the object to a local file.\n{\nAws::S3::Model::GetObjectRequest request;\nrequest.SetBucket(bucketName);\nrequest.SetKey(key);\nAws::S3::Model::GetObjectOutcome outcome =\nclient.GetObject(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: getObject: \" <<\nerr.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nstd::cout << \"Downloaded the object with the key, '\" << key\n<< \"', in the bucket, '\"\n<< bucketName << \"'.\" << std::endl;\nAws::IOStream &ioStream = outcome.GetResultWithOwnership().\nGetBody();\nAws::OFStream outStream(saveFilePath,\nstd::ios_base::out | std::ios_base::binary);\nif (!outStream.is_open()) {\nstd::cout << \"Error: unable to open file, '\" << saveFilePath <<\n\"'.\"\n<< std::endl;\nBasics API Version 2006-03-01 1738",
      "start_idx": 1876354,
      "end_idx": 1877647,
      "metadata": {
        "num_sentences": 7,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1744",
      "text": "Amazon Simple Storage Service API Reference\n} else {\noutStream << ioStream.rdbuf();\nstd::cout << \"Wrote the downloaded object to the file '\"\n<< saveFilePath << \"'.\" << std::endl;\n}\n}\n}\n// 4. Copy the object to a different \"folder\" in the bucket.\nAws::String copiedToKey = \"test-folder/\" + key;\n{\nAws::S3::Model::CopyObjectRequest request;\nrequest.WithBucket(bucketName)\n.WithKey(copiedToKey)\n.WithCopySource(bucketName + \"/\" + key);\nAws::S3::Model::CopyObjectOutcome outcome =\nclient.CopyObject(request);\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Error: copyObject: \" <<\noutcome.GetError().GetMessage() << std::endl;\n} else {\nstd::cout << \"Copied the object with the key, '\" << key\n<< \"', to the key, '\" << copiedToKey\n<< \", in the bucket, '\" << bucketName << \"'.\" << std::endl;\n}\n}\n// 5. List objects in the bucket.\n{\nAws::S3::Model::ListObjectsV2Request request;\nrequest.WithBucket(bucketName);\nAws::String continuationToken;\nAws::Vector<Aws::S3::Model::Object> allObjects;\ndo {\nif (!continuationToken.empty()) {\nrequest.SetContinuationToken(continuationToken);\n}\nAws::S3::Model::ListObjectsV2Outcome outcome = client.ListObjectsV2(\nrequest);\nif (!outcome.IsSuccess()) {\nBasics API Version 2006-03-01 1739",
      "start_idx": 1877649,
      "end_idx": 1878856,
      "metadata": {
        "num_sentences": 7,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1745",
      "text": "Amazon Simple Storage Service API Reference\nstd::cerr << \"Error: ListObjects: \" <<\noutcome.GetError().GetMessage() << std::endl;\nbreak;\n} else {\nAws::Vector<Aws::S3::Model::Object> objects =\noutcome.GetResult().GetContents();\nallObjects.insert(allObjects.end(), objects.begin(),\nobjects.end());\ncontinuationToken = outcome.GetResult().GetContinuationToken();\n}\n} while (!continuationToken.empty());\nstd::cout << allObjects.size() << \" objects in the bucket, '\" <<\nbucketName\n<< \"':\" << std::endl;\nfor (Aws::S3::Model::Object &object: allObjects) {\nstd::cout << \" '\" << object.GetKey() << \"'\" << std::endl;\n}\n}\n// 6. Delete all objects in the bucket.\n// All objects in the bucket must be deleted before deleting the bucket.\nAwsDoc::S3::deleteObjectFromBucket(bucketName, copiedToKey, client);\nAwsDoc::S3::deleteObjectFromBucket(bucketName, key, client);\n// 7. Delete the bucket.\nreturn AwsDoc::S3::deleteBucket(bucketName, client);\n}\nbool AwsDoc::S3::deleteObjectFromBucket(const Aws::String &bucketName,\nconst Aws::String &key,\nAws::S3::S3Client &client) {\nAws::S3::Model::DeleteObjectRequest request;\nrequest.SetBucket(bucketName);\nrequest.SetKey(key);\nAws::S3::Model::DeleteObjectOutcome outcome =\nclient.DeleteObject(request);\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Error: deleteObject: \" <<\noutcome.GetError().GetMessage() << std::endl;\n} else {\nBasics API Version 2006-03-01 1740",
      "start_idx": 1878858,
      "end_idx": 1880245,
      "metadata": {
        "num_sentences": 6,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1747",
      "text": "Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDefine a struct that wraps bucket and object actions used by the scenario.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// ListBuckets lists the buckets in the current account.\nfunc (basics BucketBasics) ListBuckets(ctx context.Context) ([]types.Bucket,\nerror) {\nresult, err := basics.S3Client.ListBuckets(ctx, &s3.ListBucketsInput{})\nvar buckets []types.Bucket\nif err != nil {\nlog.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err)\n} else {\nbuckets = result.Buckets\n}\nreturn buckets, err\n}\n// BucketExists checks whether a bucket exists in the current account.\nfunc (basics BucketBasics) BucketExists(ctx context.Context, bucketName string)\n(bool, error) {\nBasics API Version 2006-03-01 1742",
      "start_idx": 1881195,
      "end_idx": 1882312,
      "metadata": {
        "num_sentences": 9,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1748",
      "text": "Amazon Simple Storage Service API Reference\n_, err := basics.S3Client.HeadBucket(ctx, &s3.HeadBucketInput{\nBucket: aws.String(bucketName),\n})\nexists := true\nif err != nil {\nvar apiError smithy.APIError\nif errors.As(err, &apiError) {\nswitch apiError.(type) {\ncase *types.NotFound:\nlog.Printf(\"Bucket %v is available.\\n\", bucketName)\nexists = false\nerr = nil\ndefault:\nlog.Printf(\"Either you don't have access to bucket %v or another error\noccurred. \"+\n\"Here's what happened: %v\\n\", bucketName, err)\n}\n}\n} else {\nlog.Printf(\"Bucket %v exists and you already own it.\", bucketName)\n}\nreturn exists, err\n}\n// CreateBucket creates a bucket with the specified name in the specified Region.\nfunc (basics BucketBasics) CreateBucket(ctx context.Context, name string, region\nstring) error {\n_, err := basics.S3Client.CreateBucket(ctx, &s3.CreateBucketInput{\nBucket: aws.String(name),\nCreateBucketConfiguration: &types.CreateBucketConfiguration{\nLocationConstraint: types.BucketLocationConstraint(region),\n},\n})\nif err != nil {\nlog.Printf(\"Couldn't create bucket %v in Region %v. Here's why: %v\\n\",\nname, region, err)\n}\nreturn err\n}\nBasics API Version 2006-03-01 1743",
      "start_idx": 1882314,
      "end_idx": 1883468,
      "metadata": {
        "num_sentences": 6,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1749",
      "text": "Amazon Simple Storage Service API Reference\n// UploadFile reads from a file and puts the data into an object in a bucket.\nfunc (basics BucketBasics) UploadFile(ctx context.Context, bucketName string,\nobjectKey string, fileName string) error {\nfile, err := os.Open(fileName)\nif err != nil {\nlog.Printf(\"Couldn't open file %v to upload. Here's why: %v\\n\", fileName, err)\n} else {\ndefer file.Close()\n_, err = basics.S3Client.PutObject(ctx, &s3.PutObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\nBody: file,\n})\nif err != nil {\nlog.Printf(\"Couldn't upload file %v to %v:%v. Here's why: %v\\n\",\nfileName, bucketName, objectKey, err)\n}\n}\nreturn err\n}\n// UploadLargeObject uses an upload manager to upload data to an object in a\nbucket.\n// The upload manager breaks large data into parts and uploads the parts\nconcurrently.\nfunc (basics BucketBasics) UploadLargeObject(ctx context.Context, bucketName\nstring, objectKey string, largeObject []byte) error {\nlargeBuffer := bytes.NewReader(largeObject)\nvar partMiBs int64 = 10\nuploader := manager.NewUploader(basics.S3Client, func(u *manager.Uploader) {\nu.PartSize = partMiBs * 1024 * 1024\n})\n_, err := uploader.Upload(ctx, &s3.PutObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\nBody: largeBuffer,\n})\nif err != nil {\nlog.Printf(\"Couldn't upload large object to %v:%v. Here's why: %v\\n\",\nbucketName, objectKey, err)\n}\nBasics API Version 2006-03-01 1744",
      "start_idx": 1883470,
      "end_idx": 1884908,
      "metadata": {
        "num_sentences": 7,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1750",
      "text": "Amazon Simple Storage Service API Reference\nreturn err\n}\n// DownloadFile gets an object from a bucket and stores it in a local file.\nfunc (basics BucketBasics) DownloadFile(ctx context.Context, bucketName string,\nobjectKey string, fileName string) error {\nresult, err := basics.S3Client.GetObject(ctx, &s3.GetObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n})\nif err != nil {\nlog.Printf(\"Couldn't get object %v:%v. Here's why: %v\\n\", bucketName,\nobjectKey, err)\nreturn err\n}\ndefer result.Body.Close()\nfile, err := os.Create(fileName)\nif err != nil {\nlog.Printf(\"Couldn't create file %v. Here's why: %v\\n\", fileName, err)\nreturn err\n}\ndefer file.Close()\nbody, err := io.ReadAll(result.Body)\nif err != nil {\nlog.Printf(\"Couldn't read object body from %v. Here's why: %v\\n\", objectKey,\nerr)\n}\n_, err = file.Write(body)\nreturn err\n}\n// DownloadLargeObject uses a download manager to download an object from a\nbucket.\n// The download manager gets the data in parts and writes them to a buffer until\nall of\n// the data has been downloaded.\nfunc (basics BucketBasics) DownloadLargeObject(ctx context.Context, bucketName\nstring, objectKey string) ([]byte, error) {\nvar partMiBs int64 = 10\nBasics API Version 2006-03-01 1745",
      "start_idx": 1884910,
      "end_idx": 1886150,
      "metadata": {
        "num_sentences": 7,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1751",
      "text": "Amazon Simple Storage Service API Reference\ndownloader := manager.NewDownloader(basics.S3Client, func(d *manager.Downloader)\n{\nd.PartSize = partMiBs * 1024 * 1024\n})\nbuffer := manager.NewWriteAtBuffer([]byte{})\n_, err := downloader.Download(ctx, buffer, &s3.GetObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n})\nif err != nil {\nlog.Printf(\"Couldn't download large object from %v:%v. Here's why: %v\\n\",\nbucketName, objectKey, err)\n}\nreturn buffer.Bytes(), err\n}\n// CopyToFolder copies an object in a bucket to a subfolder in the same bucket.\nfunc (basics BucketBasics) CopyToFolder(ctx context.Context, bucketName string,\nobjectKey string, folderName string) error {\n_, err := basics.S3Client.CopyObject(ctx, &s3.CopyObjectInput{\nBucket: aws.String(bucketName),\nCopySource: aws.String(fmt.Sprintf(\"%v/%v\", bucketName, objectKey)),\nKey: aws.String(fmt.Sprintf(\"%v/%v\", folderName, objectKey)),\n})\nif err != nil {\nlog.Printf(\"Couldn't copy object from %v:%v to %v:%v/%v. Here's why: %v\\n\",\nbucketName, objectKey, bucketName, folderName, objectKey, err)\n}\nreturn err\n}\n// CopyToBucket copies an object in a bucket to another bucket.\nfunc (basics BucketBasics) CopyToBucket(ctx context.Context, sourceBucket string,\ndestinationBucket string, objectKey string) error {\n_, err := basics.S3Client.CopyObject(ctx, &s3.CopyObjectInput{\nBucket: aws.String(destinationBucket),\nCopySource: aws.String(fmt.Sprintf(\"%v/%v\", sourceBucket, objectKey)),\nKey: aws.String(objectKey),\n})\nif err != nil {\nBasics API Version 2006-03-01 1746",
      "start_idx": 1886152,
      "end_idx": 1887694,
      "metadata": {
        "num_sentences": 5,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1752",
      "text": "Amazon Simple Storage Service API Reference\nlog.Printf(\"Couldn't copy object from %v:%v to %v:%v. Here's why: %v\\n\",\nsourceBucket, objectKey, destinationBucket, objectKey, err)\n}\nreturn err\n}\n// ListObjects lists the objects in a bucket.\nfunc (basics BucketBasics) ListObjects(ctx context.Context, bucketName string)\n([]types.Object, error) {\nresult, err := basics.S3Client.ListObjectsV2(ctx, &s3.ListObjectsV2Input{\nBucket: aws.String(bucketName),\n})\nvar contents []types.Object\nif err != nil {\nlog.Printf(\"Couldn't list objects in bucket %v. Here's why: %v\\n\", bucketName,\nerr)\n} else {\ncontents = result.Contents\n}\nreturn contents, err\n}\n// DeleteObjects deletes a list of objects from a bucket.\nfunc (basics BucketBasics) DeleteObjects(ctx context.Context, bucketName string,\nobjectKeys []string) error {\nvar objectIds []types.ObjectIdentifier\nfor _, key := range objectKeys {\nobjectIds = append(objectIds, types.ObjectIdentifier{Key: aws.String(key)})\n}\noutput, err := basics.S3Client.DeleteObjects(ctx, &s3.DeleteObjectsInput{\nBucket: aws.String(bucketName),\nDelete: &types.Delete{Objects: objectIds},\n})\nif err != nil {\nlog.Printf(\"Couldn't delete objects from bucket %v. Here's why: %v\\n\",\nbucketName, err)\n} else {\nlog.Printf(\"Deleted %v objects.\\n\", len(output.Deleted))\n}\nreturn err\nBasics API Version 2006-03-01 1747",
      "start_idx": 1887696,
      "end_idx": 1889024,
      "metadata": {
        "num_sentences": 6,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1753",
      "text": "Amazon Simple Storage Service API Reference\n}\n// DeleteBucket deletes a bucket. The bucket must be empty or an error is\nreturned.\nfunc (basics BucketBasics) DeleteBucket(ctx context.Context, bucketName string)\nerror {\n_, err := basics.S3Client.DeleteBucket(ctx, &s3.DeleteBucketInput{\nBucket: aws.String(bucketName)})\nif err != nil {\nlog.Printf(\"Couldn't delete bucket %v. Here's why: %v\\n\", bucketName, err)\n}\nreturn err\n}\nRun an interactive scenario that shows you how work with S3 buckets and objects.\n// RunGetStartedScenario is an interactive example that shows you how to use\nAmazon\n// Simple Storage Service (Amazon S3) to create an S3 bucket and use it to store\nobjects.\n//\n// 1. Create a bucket.\n// 2. Upload a local file to the bucket.\n// 3. Upload a large object to the bucket by using an upload manager.\n// 4. Download an object to a local file.\n// 5. Download a large object by using a download manager.\n// 6. Copy an object to a different folder in the bucket.\n// 7. List objects in the bucket.\n// 8. Delete all objects in the bucket.\n// 9. Delete the bucket.\n//\n// This example creates an Amazon S3 service client from the specified sdkConfig\nso that\n// you can replace it with a mocked or stubbed config for unit testing.\n//\n// It uses a questioner from the `demotools` package to get input during the\nexample.\n// This package can be found in the ..\\..\\demotools folder of this repo.\nBasics API Version 2006-03-01 1748",
      "start_idx": 1889026,
      "end_idx": 1890460,
      "metadata": {
        "num_sentences": 27,
        "num_words": 245,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1754",
      "text": "Amazon Simple Storage Service API Reference\nfunc RunGetStartedScenario(ctx context.Context, sdkConfig aws.Config, questioner\ndemotools.IQuestioner) {\ndefer func() {\nif r := recover(); r != nil {\nfmt.Println(\"Something went wrong with the demo.\\n\", r)\n}\n}()\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Println(\"Welcome to the Amazon S3 getting started demo.\")\nlog.Println(strings.Repeat(\"-\", 88))\ns3Client := s3.NewFromConfig(sdkConfig)\nbucketBasics := actions.BucketBasics{S3Client: s3Client}\ncount := 10\nlog.Printf(\"Let's list up to %v buckets for your account:\", count)\nbuckets, err := bucketBasics.ListBuckets(ctx)\nif err != nil {\npanic(err)\n}\nif len(buckets) == 0 {\nlog.Println(\"You don't have any buckets!\")\n} else {\nif count > len(buckets) {\ncount = len(buckets)\n}\nfor _, bucket := range buckets[:count] {\nlog.Printf(\"\\t%v\\n\", *bucket.Name)\n}\n}\nbucketName := questioner.Ask(\"Let's create a bucket. Enter a name for your\nbucket:\",\ndemotools.NotEmpty{})\nbucketExists, err := bucketBasics.BucketExists(ctx, bucketName)\nif err != nil {\npanic(err)\n}\nif !bucketExists {\nerr = bucketBasics.CreateBucket(ctx, bucketName, sdkConfig.Region)\nif err != nil {\npanic(err)\n} else {\nBasics API Version 2006-03-01 1749",
      "start_idx": 1890462,
      "end_idx": 1891666,
      "metadata": {
        "num_sentences": 4,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1755",
      "text": "Amazon Simple Storage Service API Reference\nlog.Println(\"Bucket created.\")\n}\n}\nlog.Println(strings.Repeat(\"-\", 88))\nfmt.Println(\"Let's upload a file to your bucket.\")\nsmallFile := questioner.Ask(\"Enter the path to a file you want to upload:\",\ndemotools.NotEmpty{})\nconst smallKey = \"doc-example-key\"\nerr = bucketBasics.UploadFile(ctx, bucketName, smallKey, smallFile)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"Uploaded %v as %v.\\n\", smallFile, smallKey)\nlog.Println(strings.Repeat(\"-\", 88))\nmibs := 30\nlog.Printf(\"Let's create a slice of %v MiB of random bytes and upload it to your\nbucket. \", mibs)\nquestioner.Ask(\"Press Enter when you're ready.\")\nlargeBytes := make([]byte, 1024*1024*mibs)\n_, _ = rand.Read(largeBytes)\nlargeKey := \"doc-example-large\"\nlog.Println(\"Uploading...\")\nerr = bucketBasics.UploadLargeObject(ctx, bucketName, largeKey, largeBytes)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"Uploaded %v MiB object as %v\", mibs, largeKey)\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Printf(\"Let's download %v to a file.\", smallKey)\ndownloadFileName := questioner.Ask(\"Enter a name for the downloaded file:\",\ndemotools.NotEmpty{})\nerr = bucketBasics.DownloadFile(ctx, bucketName, smallKey, downloadFileName)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"File %v downloaded.\", downloadFileName)\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Printf(\"Let's download the %v MiB object.\", mibs)\nquestioner.Ask(\"Press Enter when you're ready.\")\nlog.Println(\"Downloading...\")\nBasics API Version 2006-03-01 1750",
      "start_idx": 1891668,
      "end_idx": 1893162,
      "metadata": {
        "num_sentences": 9,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1757",
      "text": "Amazon Simple Storage Service API Reference\nerr = os.Remove(downloadFileName)\nif err != nil {\npanic(err)\n}\n} else {\nlog.Println(\"Okay. Don't forget to delete objects from your bucket to avoid\ncharges.\")\n}\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Println(\"Thanks for watching!\")\nlog.Println(strings.Repeat(\"-\", 88))\n}\n\u2022 For API details, see the following topics in AWS SDK for Go API Reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nA scenario example.\nimport java.io.IOException;\nBasics API Version 2006-03-01 1752",
      "start_idx": 1894597,
      "end_idx": 1895318,
      "metadata": {
        "num_sentences": 8,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1758",
      "text": "Amazon Simple Storage Service API Reference\nimport java.util.Scanner;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n*\n* For more information, see the following documentation topic:\n*\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*\n* This Java code example performs the following tasks:\n*\n* 1. Creates an Amazon S3 bucket.\n* 2. Uploads an object to the bucket.\n* 3. Downloads the object to another local file.\n* 4. Uploads an object using multipart upload.\n* 5. List all objects located in the Amazon S3 bucket.\n* 6. Copies the object to another Amazon S3 bucket.\n* 7. Deletes the object from the Amazon S3 bucket.\n* 8. Deletes the Amazon S3 bucket.\n*/\npublic class S3Scenario {\npublic static Scanner scanner = new Scanner(System.in);\nstatic S3Actions s3Actions = new S3Actions();\npublic static final String DASHES = new String(new char[80]).replace(\"\\0\",\n\"-\");\nprivate static final Logger logger =\nLoggerFactory.getLogger(S3Scenario.class);\npublic static void main(String[] args) throws IOException {\nfinal String usage = \"\"\"\nUsage:\n<bucketName> <key> <objectPath> <savePath> <toBucket>\nWhere:\nbucketName - The name of the S3 bucket.\nBasics API Version 2006-03-01 1753",
      "start_idx": 1895320,
      "end_idx": 1896850,
      "metadata": {
        "num_sentences": 19,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1759",
      "text": "Amazon Simple Storage Service API Reference\nkey - The unique identifier for the object stored in the S3\nbucket.\nobjectPath - The full file path of the object within the S3\nbucket (e.g., \"documents/reports/annual_report.pdf\").\nsavePath - The local file path where the object will be\ndownloaded and saved (e.g., \"C:/Users/username/Downloads/annual_report.pdf\").\ntoBucket - The name of the S3 bucket to which the object will be\ncopied.\n\"\"\";\nif (args.length != 5) {\nlogger.info(usage);\nreturn;\n}\nString bucketName = args[0];\nString key = args[1];\nString objectPath = args[2];\nString savePath = args[3];\nString toBucket = args[4];\nlogger.info(DASHES);\nlogger.info(\"Welcome to the Amazon Simple Storage Service (S3) example\nscenario.\");\nlogger.info(\"\"\"\nAmazon S3 is a highly scalable and durable object storage\nservice provided by Amazon Web Services (AWS). It is designed to\nstore and retrieve\nany amount of data, from anywhere on the web, at any time.\nThe `S3AsyncClient` interface in the AWS SDK for Java 2.x provides a\nset of methods to\nprogrammatically interact with the Amazon S3 (Simple Storage Service)\nservice. This allows\ndevelopers to automate the management and manipulation of S3 buckets\nand objects as\npart of their application deployment pipelines. With S3, teams can\nfocus on building\nand deploying their applications without having to worry about the\nunderlying storage\ninfrastructure required to host and manage large amounts of data.\nThis scenario walks you through how to perform key operations for\nthis service.\nBasics API Version 2006-03-01 1754",
      "start_idx": 1896852,
      "end_idx": 1898413,
      "metadata": {
        "num_sentences": 12,
        "num_words": 236,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1760",
      "text": "Amazon Simple Storage Service API Reference\nLet's get started...\n\"\"\");\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\ntry {\n// Run the methods that belong to this scenario.\nrunScenario(bucketName, key, objectPath, savePath, toBucket);\n} catch (Throwable rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception kmsEx) {\nlogger.info(\"KMS error occurred: Error message: {}, Error code\n{}\", kmsEx.getMessage(), kmsEx.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\n}\n}\nprivate static void runScenario(String bucketName, String key, String\nobjectPath, String savePath, String toBucket) throws Throwable {\nlogger.info(DASHES);\nlogger.info(\"1. Create an Amazon S3 bucket.\");\ntry {\nCompletableFuture<Void> future =\ns3Actions.createBucketAsync(bucketName);\nfuture.join();\nwaitForInputToContinue(scanner);\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nlogger.info(DASHES);\nlogger.info(DASHES);\nBasics API Version 2006-03-01 1755",
      "start_idx": 1898415,
      "end_idx": 1899690,
      "metadata": {
        "num_sentences": 4,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1761",
      "text": "Amazon Simple Storage Service API Reference\nlogger.info(\"2. Upload a local file to the Amazon S3 bucket.\");\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<PutObjectResponse> future =\ns3Actions.uploadLocalFileAsync(bucketName, key, objectPath);\nfuture.join();\nlogger.info(\"File uploaded successfully to {}/{}\", bucketName, key);\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"3. Download the object to another local file.\");\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<Void> future =\ns3Actions.getObjectBytesAsync(bucketName, key, savePath);\nfuture.join();\nlogger.info(\"Successfully obtained bytes from S3 object and wrote to\nfile {}\", savePath);\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nBasics API Version 2006-03-01 1756",
      "start_idx": 1899692,
      "end_idx": 1901130,
      "metadata": {
        "num_sentences": 5,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1762",
      "text": "Amazon Simple Storage Service API Reference\nlogger.info(DASHES);\nlogger.info(\"4. Perform a multipart upload.\");\nwaitForInputToContinue(scanner);\nString multipartKey = \"multiPartKey\";\ntry {\n// Call the multipartUpload method\nCompletableFuture<Void> future =\ns3Actions.multipartUpload(bucketName, multipartKey);\nfuture.join();\nlogger.info(\"Multipart upload completed successfully for bucket '{}'\nand key '{}'\", bucketName, multipartKey);\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"5. List all objects located in the Amazon S3 bucket.\");\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<Void> future =\ns3Actions.listAllObjectsAsync(bucketName);\nfuture.join();\nlogger.info(\"Object listing completed successfully.\");\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\nBasics API Version 2006-03-01 1757",
      "start_idx": 1901132,
      "end_idx": 1902569,
      "metadata": {
        "num_sentences": 6,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1763",
      "text": "Amazon Simple Storage Service API Reference\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"6. Copy the object to another Amazon S3 bucket.\");\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<String> future =\ns3Actions.copyBucketObjectAsync(bucketName, key, toBucket);\nString result = future.join();\nlogger.info(\"Copy operation result: {}\", result);\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"7. Copy the object to another Amazon S3 bucket using multi\ncopy.\");\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<String> future =\ns3Actions.performMultiCopy(toBucket, bucketName, key);\nString result = future.join();\nlogger.info(\"Copy operation result: {}\", result);\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"KMS error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\nBasics API Version 2006-03-01 1758",
      "start_idx": 1902571,
      "end_idx": 1903995,
      "metadata": {
        "num_sentences": 5,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1764",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"8. Delete objects from the Amazon S3 bucket.\");\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<Void> future =\ns3Actions.deleteObjectFromBucketAsync(bucketName, key);\nfuture.join();\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\ntry {\nCompletableFuture<Void> future =\ns3Actions.deleteObjectFromBucketAsync(bucketName, \"multiPartKey\");\nfuture.join();\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"9. Delete the Amazon S3 bucket.\");\nBasics API Version 2006-03-01 1759",
      "start_idx": 1903997,
      "end_idx": 1905242,
      "metadata": {
        "num_sentences": 5,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1765",
      "text": "Amazon Simple Storage Service API Reference\nwaitForInputToContinue(scanner);\ntry {\nCompletableFuture<Void> future =\ns3Actions.deleteBucketAsync(bucketName);\nfuture.join();\n} catch (RuntimeException rt) {\nThrowable cause = rt.getCause();\nif (cause instanceof S3Exception s3Ex) {\nlogger.info(\"S3 error occurred: Error message: {}, Error code\n{}\", s3Ex.getMessage(), s3Ex.awsErrorDetails().errorCode());\n} else {\nlogger.info(\"An unexpected error occurred: \" + rt.getMessage());\n}\nthrow cause;\n}\nwaitForInputToContinue(scanner);\nlogger.info(DASHES);\nlogger.info(DASHES);\nlogger.info(\"You successfully completed the Amazon S3 scenario.\");\nlogger.info(DASHES);\n}\nprivate static void waitForInputToContinue(Scanner scanner) {\nwhile (true) {\nlogger.info(\"\");\nlogger.info(\"Enter 'c' followed by <ENTER> to continue:\");\nString input = scanner.nextLine();\nif (input.trim().equalsIgnoreCase(\"c\")) {\nlogger.info(\"Continuing with the program...\");\nlogger.info(\"\");\nbreak;\n} else {\n// Handle invalid input.\nlogger.info(\"Invalid input. Please try again.\");\n}\n}\n}\n}\nBasics API Version 2006-03-01 1760",
      "start_idx": 1905244,
      "end_idx": 1906327,
      "metadata": {
        "num_sentences": 5,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1776",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nFirst, import all the necessary modules.\n// Used to check if currently running file is this file.\nimport { fileURLToPath } from \"node:url\";\nimport { readdirSync, readFileSync, writeFileSync } from \"node:fs\";\n// Local helper utils.\nimport { dirnameFromMetaUrl } from \"@aws-doc-sdk-examples/lib/utils/util-fs.js\";\nimport { Prompter } from \"@aws-doc-sdk-examples/lib/prompter.js\";\nimport { wrapText } from \"@aws-doc-sdk-examples/lib/utils/util-string.js\";\nimport {\nS3Client,\nCreateBucketCommand,\nPutObjectCommand,\nListObjectsCommand,\nCopyObjectCommand,\nGetObjectCommand,\nDeleteObjectsCommand,\nDeleteBucketCommand,\n} from \"@aws-sdk/client-s3\";\nThe preceding imports reference some helper utilities. These utilities are local to the\nGitHub repository linked at the start of this section. For your reference, see the following\nimplementations of those utilities.\nexport const dirnameFromMetaUrl = (metaUrl) =>\nfileURLToPath(new URL(\".\", metaUrl));\nimport { select, input, confirm, checkbox } from \"@inquirer/prompts\";\nBasics API Version 2006-03-01 1771",
      "start_idx": 1919611,
      "end_idx": 1920860,
      "metadata": {
        "num_sentences": 10,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1778",
      "text": "Amazon Simple Storage Service API Reference\nconst rule = char.repeat(80);\nreturn `${rule}\\n ${text}\\n${rule}\\n`;\n};\nObjects in S3 are stored in 'buckets'. Let's define a function for creating a new bucket.\nexport const createBucket = async () => {\nconst bucketName = await prompter.input({\nmessage: \"Enter a bucket name. Bucket names must be globally unique:\",\n});\nconst command = new CreateBucketCommand({ Bucket: bucketName });\nawait s3Client.send(command);\nconsole.log(\"Bucket created successfully.\\n\");\nreturn bucketName;\n};\nBuckets contain 'objects'. This function uploads the contents of a directory to your bucket as\nobjects.\nexport const uploadFilesToBucket = async ({ bucketName, folderPath }) => {\nconsole.log(`Uploading files from ${folderPath}\\n`);\nconst keys = readdirSync(folderPath);\nconst files = keys.map((key) => {\nconst filePath = `${folderPath}/${key}`;\nconst fileContent = readFileSync(filePath);\nreturn {\nKey: key,\nBody: fileContent,\n};\n});\nfor (const file of files) {\nawait s3Client.send(\nnew PutObjectCommand({\nBucket: bucketName,\nBody: file.Body,\nKey: file.Key,\n}),\n);\nconsole.log(`${file.Key} uploaded successfully.`);\n}\nBasics API Version 2006-03-01 1773",
      "start_idx": 1921688,
      "end_idx": 1922869,
      "metadata": {
        "num_sentences": 6,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1779",
      "text": "Amazon Simple Storage Service API Reference\n};\nAfter uploading objects, check to confirm that they were uploaded correctly. You can use\nListObjects for that. You'll be using the 'Key' property, but there are other useful properties\nin the response also.\nexport const listFilesInBucket = async ({ bucketName }) => {\nconst command = new ListObjectsCommand({ Bucket: bucketName });\nconst { Contents } = await s3Client.send(command);\nconst contentsList = Contents.map((c) => ` \u2022 ${c.Key}`).join(\"\\n\");\nconsole.log(\"\\nHere's a list of files in the bucket:\");\nconsole.log(`${contentsList}\\n`);\n};\nSometimes you might want to copy an object from one bucket to another. Use the\nCopyObject command for that.\nexport const copyFileFromBucket = async ({ destinationBucket }) => {\nconst proceed = await prompter.confirm({\nmessage: \"Would you like to copy an object from another bucket?\",\n});\nif (!proceed) {\nreturn;\n}\nconst copy = async () => {\ntry {\nconst sourceBucket = await prompter.input({\nmessage: \"Enter source bucket name:\",\n});\nconst sourceKey = await prompter.input({\nmessage: \"Enter source key:\",\n});\nconst destinationKey = await prompter.input({\nmessage: \"Enter destination key:\",\n});\nconst command = new CopyObjectCommand({\nBucket: destinationBucket,\nCopySource: `${sourceBucket}/${sourceKey}`,\nBasics API Version 2006-03-01 1774",
      "start_idx": 1922871,
      "end_idx": 1924200,
      "metadata": {
        "num_sentences": 7,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1780",
      "text": "Amazon Simple Storage Service API Reference\nKey: destinationKey,\n});\nawait s3Client.send(command);\nawait copyFileFromBucket({ destinationBucket });\n} catch (err) {\nconsole.error(\"Copy error.\");\nconsole.error(err);\nconst retryAnswer = await prompter.confirm({ message: \"Try again?\" });\nif (retryAnswer) {\nawait copy();\n}\n}\n};\nawait copy();\n};\nThere's no SDK method for getting multiple objects from a bucket. Instead, you'll create a\nlist of objects to download and iterate over them.\nexport const downloadFilesFromBucket = async ({ bucketName }) => {\nconst { Contents } = await s3Client.send(\nnew ListObjectsCommand({ Bucket: bucketName }),\n);\nconst path = await prompter.input({\nmessage: \"Enter destination path for files:\",\n});\nfor (const content of Contents) {\nconst obj = await s3Client.send(\nnew GetObjectCommand({ Bucket: bucketName, Key: content.Key }),\n);\nwriteFileSync(\n`${path}/${content.Key}`,\nawait obj.Body.transformToByteArray(),\n);\n}\nconsole.log(\"Files downloaded successfully.\\n\");\n};\nIt's time to clean up your resources. A bucket must be empty before it can be deleted. These\ntwo functions empty and delete the bucket.\nBasics API Version 2006-03-01 1775",
      "start_idx": 1924202,
      "end_idx": 1925373,
      "metadata": {
        "num_sentences": 8,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1781",
      "text": "Amazon Simple Storage Service API Reference\nexport const emptyBucket = async ({ bucketName }) => {\nconst listObjectsCommand = new ListObjectsCommand({ Bucket: bucketName });\nconst { Contents } = await s3Client.send(listObjectsCommand);\nconst keys = Contents.map((c) => c.Key);\nconst deleteObjectsCommand = new DeleteObjectsCommand({\nBucket: bucketName,\nDelete: { Objects: keys.map((key) => ({ Key: key })) },\n});\nawait s3Client.send(deleteObjectsCommand);\nconsole.log(`${bucketName} emptied successfully.\\n`);\n};\nexport const deleteBucket = async ({ bucketName }) => {\nconst command = new DeleteBucketCommand({ Bucket: bucketName });\nawait s3Client.send(command);\nconsole.log(`${bucketName} deleted successfully.\\n`);\n};\nThe 'main' function pulls everything together. If you run this file directly the main function\nwill be called.\nconst main = async () => {\nconst OBJECT_DIRECTORY = `${dirnameFromMetaUrl(\nimport.meta.url,\n)}../../../../resources/sample_files/.sample_media`;\ntry {\nconsole.log(wrapText(\"Welcome to the Amazon S3 getting started example.\"));\nconsole.log(\"Let's create a bucket.\");\nconst bucketName = await createBucket();\nawait prompter.confirm({ message: continueMessage });\nconsole.log(wrapText(\"File upload.\"));\nconsole.log(\n\"I have some default files ready to go. You can edit the source code to\nprovide your own.\",\n);\nawait uploadFilesToBucket({\nbucketName,\nfolderPath: OBJECT_DIRECTORY,\n});\nBasics API Version 2006-03-01 1776",
      "start_idx": 1925375,
      "end_idx": 1926823,
      "metadata": {
        "num_sentences": 8,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1782",
      "text": "Amazon Simple Storage Service API Reference\nawait listFilesInBucket({ bucketName });\nawait prompter.confirm({ message: continueMessage });\nconsole.log(wrapText(\"Copy files.\"));\nawait copyFileFromBucket({ destinationBucket: bucketName });\nawait listFilesInBucket({ bucketName });\nawait prompter.confirm({ message: continueMessage });\nconsole.log(wrapText(\"Download files.\"));\nawait downloadFilesFromBucket({ bucketName });\nconsole.log(wrapText(\"Clean up.\"));\nawait emptyBucket({ bucketName });\nawait deleteBucket({ bucketName });\n} catch (err) {\nconsole.error(err);\n}\n};\n\u2022 For API details, see the following topics in AWS SDK for JavaScript API Reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1777",
      "start_idx": 1926825,
      "end_idx": 1927759,
      "metadata": {
        "num_sentences": 7,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1787",
      "text": "Amazon Simple Storage Service API Reference\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.deleteBucket(request)\nprintln(\"The $bucketName was successfully deleted!\")\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for Kotlin API reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\necho(\"\\n\");\necho(\"--------------------------------------\\n\");\nprint(\"Welcome to the Amazon S3 getting started demo using PHP!\\n\");\necho(\"--------------------------------------\\n\");\n$region = 'us-west-2';\n$this->s3client = new S3Client([\n'region' => $region,\n]);\n/* Inline declaration example\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\nBasics API Version 2006-03-01 1782",
      "start_idx": 1931609,
      "end_idx": 1932487,
      "metadata": {
        "num_sentences": 5,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1788",
      "text": "Amazon Simple Storage Service API Reference\n*/\n$this->bucketName = \"amzn-s3-demo-bucket-\" . uniqid();\ntry {\n$this->s3client->createBucket([\n'Bucket' => $this->bucketName,\n'CreateBucketConfiguration' => ['LocationConstraint' => $region],\n]);\necho \"Created bucket named: $this->bucketName \\n\";\n} catch (Exception $exception) {\necho \"Failed to create bucket $this->bucketName with error: \" .\n$exception->getMessage();\nexit(\"Please fix error with bucket creation before continuing.\");\n}\n$fileName = __DIR__ . \"/local-file-\" . uniqid();\ntry {\n$this->s3client->putObject([\n'Bucket' => $this->bucketName,\n'Key' => $fileName,\n'SourceFile' => __DIR__ . '/testfile.txt'\n]);\necho \"Uploaded $fileName to $this->bucketName.\\n\";\n} catch (Exception $exception) {\necho \"Failed to upload $fileName with error: \" . $exception-\n>getMessage();\nexit(\"Please fix error with file upload before continuing.\");\n}\ntry {\n$file = $this->s3client->getObject([\n'Bucket' => $this->bucketName,\n'Key' => $fileName,\n]);\n$body = $file->get('Body');\n$body->rewind();\necho \"Downloaded the file and it begins with: {$body->read(26)}.\\n\";\n} catch (Exception $exception) {\necho \"Failed to download $fileName from $this->bucketName with error:\n\" . $exception->getMessage();\nexit(\"Please fix error with file downloading before continuing.\");\n}\nBasics API Version 2006-03-01 1783",
      "start_idx": 1932489,
      "end_idx": 1933825,
      "metadata": {
        "num_sentences": 11,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1789",
      "text": "Amazon Simple Storage Service API Reference\ntry {\n$folder = \"copied-folder\";\n$this->s3client->copyObject([\n'Bucket' => $this->bucketName,\n'CopySource' => \"$this->bucketName/$fileName\",\n'Key' => \"$folder/$fileName-copy\",\n]);\necho \"Copied $fileName to $folder/$fileName-copy.\\n\";\n} catch (Exception $exception) {\necho \"Failed to copy $fileName with error: \" . $exception-\n>getMessage();\nexit(\"Please fix error with object copying before continuing.\");\n}\ntry {\n$contents = $this->s3client->listObjectsV2([\n'Bucket' => $this->bucketName,\n]);\necho \"The contents of your bucket are: \\n\";\nforeach ($contents['Contents'] as $content) {\necho $content['Key'] . \"\\n\";\n}\n} catch (Exception $exception) {\necho \"Failed to list objects in $this->bucketName with error: \" .\n$exception->getMessage();\nexit(\"Please fix error with listing objects before continuing.\");\n}\ntry {\n$objects = [];\nforeach ($contents['Contents'] as $content) {\n$objects[] = [\n'Key' => $content['Key'],\n];\n}\n$this->s3client->deleteObjects([\n'Bucket' => $this->bucketName,\n'Delete' => [\n'Objects' => $objects,\n],\n]);\n$check = $this->s3client->listObjectsV2([\n'Bucket' => $this->bucketName,\n]);\nBasics API Version 2006-03-01 1784",
      "start_idx": 1933827,
      "end_idx": 1935011,
      "metadata": {
        "num_sentences": 6,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1790",
      "text": "Amazon Simple Storage Service API Reference\nif (count($check) <= 0) {\nthrow new Exception(\"Bucket wasn't empty.\");\n}\necho \"Deleted all objects and folders from $this->bucketName.\\n\";\n} catch (Exception $exception) {\necho \"Failed to delete $fileName from $this->bucketName with error:\n\" . $exception->getMessage();\nexit(\"Please fix error with object deletion before continuing.\");\n}\ntry {\n$this->s3client->deleteBucket([\n'Bucket' => $this->bucketName,\n]);\necho \"Deleted bucket $this->bucketName.\\n\";\n} catch (Exception $exception) {\necho \"Failed to delete $this->bucketName with error: \" . $exception-\n>getMessage();\nexit(\"Please fix error with bucket deletion before continuing.\");\n}\necho \"Successfully ran the Amazon S3 with PHP demo.\\n\";\n\u2022 For API details, see the following topics in AWS SDK for PHP API Reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nBasics API Version 2006-03-01 1785",
      "start_idx": 1935013,
      "end_idx": 1935964,
      "metadata": {
        "num_sentences": 7,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1791",
      "text": "Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport io\nimport os\nimport uuid\nimport boto3\nfrom boto3.s3.transfer import S3UploadFailedError\nfrom botocore.exceptions import ClientError\ndef do_scenario(s3_resource):\nprint(\"-\" * 88)\nprint(\"Welcome to the Amazon S3 getting started demo!\")\nprint(\"-\" * 88)\nbucket_name = f\"amzn-s3-demo-bucket-{uuid.uuid4()}\"\nbucket = s3_resource.Bucket(bucket_name)\ntry:\nbucket.create(\nCreateBucketConfiguration={\n\"LocationConstraint\": s3_resource.meta.client.meta.region_name\n}\n)\nprint(f\"Created demo bucket named {bucket.name}.\")\nexcept ClientError as err:\nprint(f\"Tried and failed to create demo bucket {bucket_name}.\")\nprint(f\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\")\nprint(f\"\\nCan't continue the demo without a bucket!\")\nreturn\nfile_name = None\nwhile file_name is None:\nBasics API Version 2006-03-01 1786",
      "start_idx": 1935966,
      "end_idx": 1936988,
      "metadata": {
        "num_sentences": 7,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1792",
      "text": "Amazon Simple Storage Service API Reference\nfile_name = input(\"\\nEnter a file you want to upload to your bucket: \")\nif not os.path.exists(file_name):\nprint(f\"Couldn't find file {file_name}. Are you sure it exists?\")\nfile_name = None\nobj = bucket.Object(os.path.basename(file_name))\ntry:\nobj.upload_file(file_name)\nprint(\nf\"Uploaded file {file_name} into bucket {bucket.name} with key\n{obj.key}.\"\n)\nexcept S3UploadFailedError as err:\nprint(f\"Couldn't upload file {file_name} to {bucket.name}.\")\nprint(f\"\\t{err}\")\nanswer = input(f\"\\nDo you want to download {obj.key} into memory (y/n)? \")\nif answer.lower() == \"y\":\ndata = io.BytesIO()\ntry:\nobj.download_fileobj(data)\ndata.seek(0)\nprint(f\"Got your object. Here are the first 20 bytes:\\n\")\nprint(f\"\\t{data.read(20)}\")\nexcept ClientError as err:\nprint(f\"Couldn't download {obj.key}.\")\nprint(\nf\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\"\n)\nanswer = input(\nf\"\\nDo you want to copy {obj.key} to a subfolder in your bucket (y/n)? \"\n)\nif answer.lower() == \"y\":\ndest_obj = bucket.Object(f\"demo-folder/{obj.key}\")\ntry:\ndest_obj.copy({\"Bucket\": bucket.name, \"Key\": obj.key})\nprint(f\"Copied {obj.key} to {dest_obj.key}.\")\nexcept ClientError as err:\nprint(f\"Couldn't copy {obj.key} to {dest_obj.key}.\")\nprint(\nf\"\\t{err.response['Error']['Code']}:{err.response['Error']\n['Message']}\"\nBasics API Version 2006-03-01 1787",
      "start_idx": 1936990,
      "end_idx": 1938370,
      "metadata": {
        "num_sentences": 11,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1794",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 ListObjectsV2\n\u2022 PutObject\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps the getting started scenario actions.\nclass ScenarioGettingStarted\nattr_reader :s3_resource\n# @param s3_resource [Aws::S3::Resource] An Amazon S3 resource.\ndef initialize(s3_resource)\n@s3_resource = s3_resource\nend\n# Creates a bucket with a random name in the currently configured account and\n# AWS Region.\n#\n# @return [Aws::S3::Bucket] The newly created bucket.\ndef create_bucket\nbucket = @s3_resource.create_bucket(\nbucket: \"amzn-s3-demo-bucket-#{Random.uuid}\",\ncreate_bucket_configuration: {\nlocation_constraint: 'us-east-1' # NOTE: only certain regions permitted\n}\n)\nputs(\"Created demo bucket named #{bucket.name}.\")\nrescue Aws::Errors::ServiceError => e\nputs('Tried and failed to create demo bucket.')\nputs(\"\\t#{e.code}: #{e.message}\")\nputs(\"\\nCan't continue the demo without a bucket!\")\nraise\nBasics API Version 2006-03-01 1789",
      "start_idx": 1939385,
      "end_idx": 1940461,
      "metadata": {
        "num_sentences": 10,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1798",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCode for the binary crate which runs the scenario.\n#![allow(clippy::result_large_err)]\n//! Purpose\n//! Shows how to use the AWS SDK for Rust to get started using\n//! Amazon Simple Storage Service (Amazon S3). Create a bucket, move objects\ninto and out of it,\n//! and delete all resources at the end of the demo.\n//!\n//! This example follows the steps in \"Getting started with Amazon S3\" in the\nAmazon S3\n//! user guide.\n//! - https://docs.aws.amazon.com/AmazonS3/latest/userguide/\nGetStartedWithS3.html\nuse aws_config::meta::region::RegionProviderChain;\nuse aws_sdk_s3::{config::Region, Client};\nuse s3_code_examples::error::S3ExampleError;\nuse uuid::Uuid;\n#[tokio::main]\nasync fn main() -> Result<(), S3ExampleError> {\nBasics API Version 2006-03-01 1793",
      "start_idx": 1944365,
      "end_idx": 1945376,
      "metadata": {
        "num_sentences": 16,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1804",
      "text": "Amazon Simple Storage Service API Reference\n.as_service_error()\n.and_then(aws_sdk_s3::error::ProvideErrorMetadata::code)\n== Some(\"NoSuchBucket\")\n{\nOk(())\n} else {\nErr(S3ExampleError::from(err))\n}\n}\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for Rust API reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDATA(lo_session) = /aws1/cl_rt_session_aws=>create( cv_pfl ).\nDATA(lo_s3) = /aws1/cl_s3_factory=>create( lo_session ).\n\" Create an Amazon Simple Storage Service (Amazon S3) bucket. \"\nTRY.\nlo_s3->createbucket(\nBasics API Version 2006-03-01 1799",
      "start_idx": 1951007,
      "end_idx": 1951780,
      "metadata": {
        "num_sentences": 8,
        "num_words": 106,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1805",
      "text": "Amazon Simple Storage Service API Reference\niv_bucket = iv_bucket_name\n).\nMESSAGE 'S3 bucket created.' TYPE 'I'.\nCATCH /aws1/cx_s3_bucketalrdyexists.\nMESSAGE 'Bucket name already exists.' TYPE 'E'.\nCATCH /aws1/cx_s3_bktalrdyownedbyyou.\nMESSAGE 'Bucket already exists and is owned by you.' TYPE 'E'.\nENDTRY.\n\"Upload an object to an S3 bucket.\"\nTRY.\n\"Get contents of file from application server.\"\nDATA lv_file_content TYPE xstring.\nOPEN DATASET iv_key FOR INPUT IN BINARY MODE.\nREAD DATASET iv_key INTO lv_file_content.\nCLOSE DATASET iv_key.\nlo_s3->putobject(\niv_bucket = iv_bucket_name\niv_key = iv_key\niv_body = lv_file_content\n).\nMESSAGE 'Object uploaded to S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\n\" Get an object from a bucket. \"\nTRY.\nDATA(lo_result) = lo_s3->getobject(\niv_bucket = iv_bucket_name\niv_key = iv_key\n).\nDATA(lv_object_data) = lo_result->get_body( ).\nMESSAGE 'Object retrieved from S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nCATCH /aws1/cx_s3_nosuchkey.\nMESSAGE 'Object key does not exist.' TYPE 'E'.\nENDTRY.\n\" Copy an object to a subfolder in a bucket. \"\nTRY.\nBasics API Version 2006-03-01 1800",
      "start_idx": 1951782,
      "end_idx": 1953011,
      "metadata": {
        "num_sentences": 40,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1806",
      "text": "Amazon Simple Storage Service API Reference\nlo_s3->copyobject(\niv_bucket = iv_bucket_name\niv_key = |{ iv_copy_to_folder }/{ iv_key }|\niv_copysource = |{ iv_bucket_name }/{ iv_key }|\n).\nMESSAGE 'Object copied to a subfolder.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nCATCH /aws1/cx_s3_nosuchkey.\nMESSAGE 'Object key does not exist.' TYPE 'E'.\nENDTRY.\n\" List objects in the bucket. \"\nTRY.\nDATA(lo_list) = lo_s3->listobjects(\niv_bucket = iv_bucket_name\n).\nMESSAGE 'Retrieved list of objects in S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\nDATA text TYPE string VALUE 'Object List - '.\nDATA lv_object_key TYPE /aws1/s3_objectkey.\nLOOP AT lo_list->get_contents( ) INTO DATA(lo_object).\nlv_object_key = lo_object->get_key( ).\nCONCATENATE lv_object_key ', ' INTO text.\nENDLOOP.\nMESSAGE text TYPE'I'.\n\" Delete the objects in a bucket. \"\nTRY.\nlo_s3->deleteobject(\niv_bucket = iv_bucket_name\niv_key = iv_key\n).\nlo_s3->deleteobject(\niv_bucket = iv_bucket_name\niv_key = |{ iv_copy_to_folder }/{ iv_key }|\n).\nMESSAGE 'Objects deleted from S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\nBasics API Version 2006-03-01 1801",
      "start_idx": 1953013,
      "end_idx": 1954282,
      "metadata": {
        "num_sentences": 37,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1807",
      "text": "Amazon Simple Storage Service API Reference\n\" Delete the bucket. \"\nTRY.\nlo_s3->deletebucket(\niv_bucket = iv_bucket_name\n).\nMESSAGE 'Deleted S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see the following topics in AWS SDK for SAP ABAP API reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\nimport Foundation\nimport AWSS3\nimport Smithy\nimport ClientRuntime\nBasics API Version 2006-03-01 1802",
      "start_idx": 1954284,
      "end_idx": 1954968,
      "metadata": {
        "num_sentences": 13,
        "num_words": 105,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1809",
      "text": "Amazon Simple Storage Service API Reference\n// https://docs.aws.amazon.com/AmazonS3/latest/API/\nAPI_CreateBucket.html#API_CreateBucket_RequestBody\nif let region = configuration.region {\nif region != \"us-east-1\" {\ninput.createBucketConfiguration =\nS3ClientTypes.CreateBucketConfiguration(locationConstraint:\nS3ClientTypes.BucketLocationConstraint(rawValue: region))\n}\n}\ndo {\n_ = try await client.createBucket(input: input)\n}\ncatch let error as BucketAlreadyOwnedByYou {\nprint(\"The bucket '\\(name)' already exists and is owned by you. You\nmay wish to ignore this exception.\")\nthrow error\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Creating a bucket\"))\nthrow error\n}\n}\n/// Delete a bucket.\n/// - Parameter name: Name of the bucket to delete.\npublic func deleteBucket(name: String) async throws {\nlet input = DeleteBucketInput(\nbucket: name\n)\ndo {\n_ = try await client.deleteBucket(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Deleting a bucket\"))\nthrow error\n}\n}\n/// Upload a file from local storage to the bucket.\n/// - Parameters:\n/// - bucket: Name of the bucket to upload the file to.\n/// - key: Name of the file to create.\n/// - file: Path name of the file to upload.\nBasics API Version 2006-03-01 1804",
      "start_idx": 1956318,
      "end_idx": 1957540,
      "metadata": {
        "num_sentences": 9,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1810",
      "text": "Amazon Simple Storage Service API Reference\npublic func uploadFile(bucket: String, key: String, file: String) async\nthrows {\nlet fileUrl = URL(fileURLWithPath: file)\ndo {\nlet fileData = try Data(contentsOf: fileUrl)\nlet dataStream = ByteStream.data(fileData)\nlet input = PutObjectInput(\nbody: dataStream,\nbucket: bucket,\nkey: key\n)\n_ = try await client.putObject(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Putting an object.\"))\nthrow error\n}\n}\n/// Create a file in the specified bucket with the given name. The new\n/// file's contents are uploaded from a `Data` object.\n///\n/// - Parameters:\n/// - bucket: Name of the bucket to create a file in.\n/// - key: Name of the file to create.\n/// - data: A `Data` object to write into the new file.\npublic func createFile(bucket: String, key: String, withData data: Data)\nasync throws {\nlet dataStream = ByteStream.data(data)\nlet input = PutObjectInput(\nbody: dataStream,\nbucket: bucket,\nkey: key\n)\ndo {\n_ = try await client.putObject(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Putting an object.\"))\nthrow error\nBasics API Version 2006-03-01 1805",
      "start_idx": 1957542,
      "end_idx": 1958664,
      "metadata": {
        "num_sentences": 8,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1815",
      "text": "Amazon Simple Storage Service API Reference\n@Argument(help: \"The name (key) to give the file in the S3 bucket\")\nvar objName: String\n@Argument(help: \"S3 bucket to copy the object to\")\nvar destBucket: String\n@Argument(help: \"Directory where you want to download the file from the S3\nbucket\")\nvar downloadDir: String\nstatic var configuration = CommandConfiguration(\ncommandName: \"s3-basics\",\nabstract: \"Demonstrates a series of basic AWS S3 functions.\",\ndiscussion: \"\"\"\nPerforms the following Amazon S3 commands:\n* `CreateBucket`\n* `PutObject`\n* `GetObject`\n* `CopyObject`\n* `ListObjects`\n* `DeleteObjects`\n* `DeleteBucket`\n\"\"\"\n)\n/// Called by ``main()`` to do the actual running of the AWS\n/// example.\nfunc runAsync() async throws {\nlet serviceHandler = try await ServiceHandler()\n// 1. Create the bucket.\nprint(\"Creating the bucket \\(bucketName)...\")\ntry await serviceHandler.createBucket(name: bucketName)\n// 2. Upload a file to the bucket.\nprint(\"Uploading the file \\(uploadSource)...\")\ntry await serviceHandler.uploadFile(bucket: bucketName, key: objName,\nfile: uploadSource)\n// 3. Download the file.\nprint(\"Downloading the file \\(objName) to \\(downloadDir)...\")\nBasics API Version 2006-03-01 1810",
      "start_idx": 1963080,
      "end_idx": 1964280,
      "metadata": {
        "num_sentences": 9,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1816",
      "text": "Amazon Simple Storage Service API Reference\ntry await serviceHandler.downloadFile(bucket: bucketName, key: objName,\nto: downloadDir)\n// 4. Copy the file to another bucket.\nprint(\"Copying the file to the bucket \\(destBucket)...\")\ntry await serviceHandler.copyFile(from: bucketName, name: objName, to:\ndestBucket)\n// 5. List the contents of the bucket.\nprint(\"Getting a list of the files in the bucket \\(bucketName)\")\nlet fileList = try await serviceHandler.listBucketFiles(bucket:\nbucketName)\nlet numFiles = fileList.count\nif numFiles != 0 {\nprint(\"\\(numFiles) file\\((numFiles > 1) ? \"s\" : \"\") in bucket\n\\(bucketName):\")\nfor name in fileList {\nprint(\" \\(name)\")\n}\n} else {\nprint(\"No files found in bucket \\(bucketName)\")\n}\n// 6. Delete the objects from the bucket.\nprint(\"Deleting the file \\(objName) from the bucket \\(bucketName)...\")\ntry await serviceHandler.deleteFile(bucket: bucketName, key: objName)\nprint(\"Deleting the file \\(objName) from the bucket \\(destBucket)...\")\ntry await serviceHandler.deleteFile(bucket: destBucket, key: objName)\n// 7. Delete the bucket.\nprint(\"Deleting the bucket \\(bucketName)...\")\ntry await serviceHandler.deleteBucket(name: bucketName)\nprint(\"Done.\")\n}\n}\n//\n// Main program entry point.\n//\n@main\nstruct Main {\nBasics API Version 2006-03-01 1811",
      "start_idx": 1964282,
      "end_idx": 1965563,
      "metadata": {
        "num_sentences": 12,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1817",
      "text": "Amazon Simple Storage Service API Reference\nstatic func main() async {\nlet args = Array(CommandLine.arguments.dropFirst())\ndo {\nlet command = try ExampleCommand.parse(args)\ntry await command.runAsync()\n} catch {\nExampleCommand.exit(withError: error)\n}\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for Swift API reference.\n\u2022 CopyObject\n\u2022 CreateBucket\n\u2022 DeleteBucket\n\u2022 DeleteObjects\n\u2022 GetObject\n\u2022 ListObjectsV2\n\u2022 PutObject\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nActions for Amazon S3 using AWS SDKs\nThe following code examples demonstrate how to perform individual Amazon S3 actions with AWS\nSDKs. Each example includes a link to GitHub, where you can find instructions for setting up and\nrunning the code.\nThese excerpts call the Amazon S3 API and are code excerpts from larger programs that must be\nrun in context. You can see actions in context in Scenarios for Amazon S3 using AWS SDKs .\nThe following examples include only the most commonly used actions. For a complete list, see the\nAmazon Simple Storage Service API Reference.\nExamples\nBasics API Version 2006-03-01 1812",
      "start_idx": 1965565,
      "end_idx": 1966832,
      "metadata": {
        "num_sentences": 10,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1820",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Use PutBucketAccelerateConfiguration with an AWS SDK or CLI\n\u2022 Use PutBucketAcl with an AWS SDK or CLI\n\u2022 Use PutBucketCors with an AWS SDK or CLI\n\u2022 Use PutBucketEncryption with an AWS SDK or CLI\n\u2022 Use PutBucketLifecycleConfiguration with an AWS SDK or CLI\n\u2022 Use PutBucketLogging with an AWS SDK or CLI\n\u2022 Use PutBucketNotification with a CLI\n\u2022 Use PutBucketNotificationConfiguration with an AWS SDK or CLI\n\u2022 Use PutBucketPolicy with an AWS SDK or CLI\n\u2022 Use PutBucketReplication with a CLI\n\u2022 Use PutBucketRequestPayment with a CLI\n\u2022 Use PutBucketTagging with a CLI\n\u2022 Use PutBucketVersioning with a CLI\n\u2022 Use PutBucketWebsite with an AWS SDK or CLI\n\u2022 Use PutObject with an AWS SDK or CLI\n\u2022 Use PutObjectAcl with an AWS SDK or CLI\n\u2022 Use PutObjectLegalHold with an AWS SDK or CLI\n\u2022 Use PutObjectLockConfiguration with an AWS SDK or CLI\n\u2022 Use PutObjectRetention with an AWS SDK or CLI\n\u2022 Use RestoreObject with an AWS SDK or CLI\n\u2022 Use SelectObjectContent with an AWS SDK or CLI\n\u2022 Use UploadPart with an AWS SDK or CLI\nUse AbortMultipartUpload with an AWS SDK or CLI\nThe following code examples show how to use AbortMultipartUpload.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Delete incomplete multipart uploads\nBasics API Version 2006-03-01 1815",
      "start_idx": 1969533,
      "end_idx": 1970925,
      "metadata": {
        "num_sentences": 3,
        "num_words": 242,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1821",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n//! Abort a multipart upload to an S3 bucket.\n/*!\n\\param bucket: The name of the S3 bucket where the object will be uploaded.\n\\param key: The unique identifier (key) for the object within the S3 bucket.\n\\param uploadID: An upload ID string.\n\\param client: The S3 client instance used to perform the upload operation.\n\\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::abortMultipartUpload(const Aws::String &bucket,\nconst Aws::String &key,\nconst Aws::String &uploadID,\nconst Aws::S3::S3Client &client) {\nAws::S3::Model::AbortMultipartUploadRequest request;\nrequest.SetBucket(bucket);\nrequest.SetKey(key);\nrequest.SetUploadId(uploadID);\nAws::S3::Model::AbortMultipartUploadOutcome outcome =\nclient.AbortMultipartUpload(request);\nif (outcome.IsSuccess()) {\nstd::cout << \"Multipart upload aborted.\" << std::endl;\n} else {\nstd::cerr << \"Error aborting multipart upload: \" <<\noutcome.GetError().GetMessage() << std::endl;\n}\nreturn outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1816",
      "start_idx": 1970927,
      "end_idx": 1972136,
      "metadata": {
        "num_sentences": 12,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1823",
      "text": "Amazon Simple Storage Service API Reference\nRemove-S3MultipartUpload -BucketName amzn-s3-demo-bucket -InitiatedDate\n\"2014/01/02 10:45:37\"\n\u2022 For API details, see AbortMultipartUpload in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse AbortMultipartUploads with an AWS SDK\nThe following code example shows how to use AbortMultipartUploads.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Transfer;\n/// <summary>\n/// This example shows how to use the Amazon Simple Storage Service\n/// (Amazon S3) to stop a multi-part upload process using the Amazon S3\n/// TransferUtility.\n/// </summary>\npublic class AbortMPU\n{\npublic static async Task Main()\n{\nstring bucketName = \"amzn-s3-demo-bucket\";\n// If the AWS Region defined for your default user is different\nBasics API Version 2006-03-01 1818",
      "start_idx": 1973367,
      "end_idx": 1974543,
      "metadata": {
        "num_sentences": 8,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1824",
      "text": "Amazon Simple Storage Service API Reference\n// from the Region where your Amazon S3 bucket is located,\n// pass the Region name to the S3 client object's constructor.\n// For example: RegionEndpoint.USWest2.\nIAmazonS3 client = new AmazonS3Client();\nawait AbortMPUAsync(client, bucketName);\n}\n/// <summary>\n/// Cancels the multi-part copy process.\n/// </summary>\n/// <param name=\"client\">The initialized client object used to create\n/// the TransferUtility object.</param>\n/// <param name=\"bucketName\">The name of the S3 bucket where the\n/// multi-part copy operation is in progress.</param>\npublic static async Task AbortMPUAsync(IAmazonS3 client, string\nbucketName)\n{\ntry\n{\nvar transferUtility = new TransferUtility(client);\n// Cancel all in-progress uploads initiated before the specified\ndate.\nawait transferUtility.AbortMultipartUploadsAsync(\nbucketName, DateTime.Now.AddDays(-7));\n}\ncatch (AmazonS3Exception e)\n{\nConsole.WriteLine($\"Error: {e.Message}\");\n}\n}\n}\n\u2022 For API details, see AbortMultipartUploads in AWS SDK for .NET API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 1819",
      "start_idx": 1974545,
      "end_idx": 1975840,
      "metadata": {
        "num_sentences": 8,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1825",
      "text": "Amazon Simple Storage Service API Reference\nUse CompleteMultipartUpload with an AWS SDK or CLI\nThe following code examples show how to use CompleteMultipartUpload.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Perform a multipart copy\n\u2022 Perform a multipart upload\n\u2022 Use checksums\n\u2022 Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n//! Complete a multipart upload to an S3 bucket.\n/*!\n\\param bucket: The name of the S3 bucket where the object will be uploaded.\n\\param key: The unique identifier (key) for the object within the S3 bucket.\n\\param uploadID: An upload ID string.\n\\param parts: A vector of CompleteParts.\n\\param client: The S3 client instance used to perform the upload operation.\n\\return CompleteMultipartUploadOutcome: The request outcome.\n*/\nAws::S3::Model::CompleteMultipartUploadOutcome\nAwsDoc::S3::completeMultipartUpload(const Aws::String &bucket,\nconst Aws::String &key,\nconst Aws::String &uploadID,\nconst Aws::Vector<Aws::S3::Model::CompletedPart> &parts,\nBasics API Version 2006-03-01 1820",
      "start_idx": 1975842,
      "end_idx": 1977086,
      "metadata": {
        "num_sentences": 14,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1826",
      "text": "Amazon Simple Storage Service API Reference\nconst Aws::S3::S3Client &client) {\nAws::S3::Model::CompletedMultipartUpload completedMultipartUpload;\ncompletedMultipartUpload.SetParts(parts);\nAws::S3::Model::CompleteMultipartUploadRequest request;\nrequest.SetBucket(bucket);\nrequest.SetKey(key);\nrequest.SetUploadId(uploadID);\nrequest.SetMultipartUpload(completedMultipartUpload);\nAws::S3::Model::CompleteMultipartUploadOutcome outcome =\nclient.CompleteMultipartUpload(request);\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Error completing multipart upload: \" <<\noutcome.GetError().GetMessage() << std::endl;\n}\nreturn outcome;\n}\n\u2022 For API details, see CompleteMultipartUpload in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command completes a multipart upload for the key multipart/01 in the\nbucket my-bucket:\naws s3api complete-multipart-upload --multipart-upload file://\nmpustruct --bucket my-bucket --key 'multipart/01' --upload-\nid dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\nThe upload ID required by this command is output by create-multipart-upload and can\nalso be retrieved with list-multipart-uploads.\nThe multipart upload option in the above command takes a JSON structure that describes\nthe parts of the multipart upload that should be reassembled into the complete file. In\nthis example, the file:// prefix is used to load the JSON structure from a file in the local\nfolder named mpustruct.\nBasics API Version 2006-03-01 1821",
      "start_idx": 1977088,
      "end_idx": 1978617,
      "metadata": {
        "num_sentences": 5,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1828",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// upload_parts: Vec<aws_sdk_s3::types::CompletedPart>\nlet completed_multipart_upload: CompletedMultipartUpload =\nCompletedMultipartUpload::builder()\n.set_parts(Some(upload_parts))\n.build();\nlet _complete_multipart_upload_res = client\n.complete_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.multipart_upload(completed_multipart_upload)\n.upload_id(upload_id)\n.send()\n.await?;\n// Create a multipart upload. Use UploadPart and CompleteMultipartUpload to\n// upload the file.\nlet multipart_upload_res: CreateMultipartUploadOutput = client\n.create_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.send()\n.await?;\nlet upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new(\n\"Missing upload_id after CreateMultipartUpload\",\n))?;\nlet mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new();\nBasics API Version 2006-03-01 1823",
      "start_idx": 1979380,
      "end_idx": 1980422,
      "metadata": {
        "num_sentences": 8,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1829",
      "text": "Amazon Simple Storage Service API Reference\nfor chunk_index in 0..chunk_count {\nlet this_chunk = if chunk_count - 1 == chunk_index {\nsize_of_last_chunk\n} else {\nCHUNK_SIZE\n};\nlet stream = ByteStream::read_from()\n.path(path)\n.offset(chunk_index * CHUNK_SIZE)\n.length(Length::Exact(this_chunk))\n.build()\n.await\n.unwrap();\n// Chunk index needs to start at 0, but part numbers start at 1.\nlet part_number = (chunk_index as i32) + 1;\nlet upload_part_res = client\n.upload_part()\n.key(&key)\n.bucket(&bucket_name)\n.upload_id(upload_id)\n.body(stream)\n.part_number(part_number)\n.send()\n.await?;\nupload_parts.push(\nCompletedPart::builder()\n.e_tag(upload_part_res.e_tag.unwrap_or_default())\n.part_number(part_number)\n.build(),\n);\n}\n\u2022 For API details, see CompleteMultipartUpload in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 1824",
      "start_idx": 1980424,
      "end_idx": 1981477,
      "metadata": {
        "num_sentences": 5,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1830",
      "text": "Amazon Simple Storage Service API Reference\nUse CopyObject with an AWS SDK or CLI\nThe following code examples show how to use CopyObject.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Learn the basics\n\u2022 Get started with encryption\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\npublic class CopyObject\n{\npublic static async Task Main()\n{\n// Specify the AWS Region where your buckets are located if it is\n// different from the AWS Region of the default user.\nIAmazonS3 s3Client = new AmazonS3Client();\n// Remember to change these values to refer to your Amazon S3\nobjects.\nstring sourceBucketName = \"amzn-s3-demo-bucket1\";\nstring destinationBucketName = \"amzn-s3-demo-bucket2\";\nstring sourceObjectKey = \"testfile.txt\";\nstring destinationObjectKey = \"testfilecopy.txt\";\nBasics API Version 2006-03-01 1825",
      "start_idx": 1981479,
      "end_idx": 1982570,
      "metadata": {
        "num_sentences": 7,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1832",
      "text": "Amazon Simple Storage Service API Reference\nSourceBucket = sourceBucketName,\nSourceKey = sourceKey,\nDestinationBucket = destinationBucketName,\nDestinationKey = destinationKey,\n};\nresponse = await client.CopyObjectAsync(request);\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"Error copying object: '{ex.Message}'\");\n}\nreturn response;\n}\n}\n\u2022 For API details, see CopyObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function copy_item_in_bucket\n#\nBasics API Version 2006-03-01 1827",
      "start_idx": 1983983,
      "end_idx": 1985007,
      "metadata": {
        "num_sentences": 5,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1833",
      "text": "Amazon Simple Storage Service API Reference\n# This function creates a copy of the specified file in the same bucket.\n#\n# Parameters:\n# $1 - The name of the bucket to copy the file from and to.\n# $2 - The key of the source file to copy.\n# $3 - The key of the destination file.\n#\n# Returns:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction copy_item_in_bucket() {\nlocal bucket_name=$1\nlocal source_key=$2\nlocal destination_key=$3\nlocal response\nresponse=$(aws s3api copy-object \\\n--bucket \"$bucket_name\" \\\n--copy-source \"$bucket_name/$source_key\" \\\n--key \"$destination_key\")\n# shellcheck disable=SC2181\nif [[ $? -ne 0 ]]; then\nerrecho \"ERROR: AWS reports s3api copy-object operation failed.\\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see CopyObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1828",
      "start_idx": 1985009,
      "end_idx": 1986042,
      "metadata": {
        "num_sentences": 11,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1835",
      "text": "Amazon Simple Storage Service API Reference\n\"LastModified\": \"2015-11-10T01:07:25.000Z\",\n\"ETag\": \"\\\"589c8b79c230a6ecd5a7e1d040a9a030\\\"\"\n},\n\"VersionId\": \"YdnYvTCVDqRRFA.NFJjy36p0hxifMlkA\"\n}\n\u2022 For API details, see CopyObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// CopyToBucket copies an object in a bucket to another bucket.\nfunc (basics BucketBasics) CopyToBucket(ctx context.Context, sourceBucket string,\ndestinationBucket string, objectKey string) error {\n_, err := basics.S3Client.CopyObject(ctx, &s3.CopyObjectInput{\nBucket: aws.String(destinationBucket),\nCopySource: aws.String(fmt.Sprintf(\"%v/%v\", sourceBucket, objectKey)),\nKey: aws.String(objectKey),\n})\nif err != nil {\nlog.Printf(\"Couldn't copy object from %v:%v to %v:%v. Here's why: %v\\n\",\nsourceBucket, objectKey, destinationBucket, objectKey, err)\nBasics API Version 2006-03-01 1830",
      "start_idx": 1987153,
      "end_idx": 1988395,
      "metadata": {
        "num_sentences": 8,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1836",
      "text": "Amazon Simple Storage Service API Reference\n}\nreturn err\n}\n\u2022 For API details, see CopyObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCopy an object using an S3Client.\n/**\n* Asynchronously copies an object from one S3 bucket to another.\n*\n* @param fromBucket the name of the source S3 bucket\n* @param objectKey the key (name) of the object to be copied\n* @param toBucket the name of the destination S3 bucket\n* @return a {@link CompletableFuture} that completes with the copy result as\na {@link String}\n* @throws RuntimeException if the URL could not be encoded or an S3\nexception occurred during the copy\n*/\npublic CompletableFuture<String> copyBucketObjectAsync(String fromBucket,\nString objectKey, String toBucket) {\nCopyObjectRequest copyReq = CopyObjectRequest.builder()\n.sourceBucket(fromBucket)\n.sourceKey(objectKey)\n.destinationBucket(toBucket)\n.destinationKey(objectKey)\n.build();\nBasics API Version 2006-03-01 1831",
      "start_idx": 1988397,
      "end_idx": 1989459,
      "metadata": {
        "num_sentences": 6,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1837",
      "text": "Amazon Simple Storage Service API Reference\nCompletableFuture<CopyObjectResponse> response =\ngetAsyncClient().copyObject(copyReq);\nresponse.whenComplete((copyRes, ex) -> {\nif (copyRes != null) {\nlogger.info(\"The \" + objectKey + \" was copied to \" + toBucket);\n} else {\nthrow new RuntimeException(\"An S3 exception occurred during\ncopy\", ex);\n}\n});\nreturn response.thenApply(CopyObjectResponse::copyObjectResult)\n.thenApply(Object::toString);\n}\nUse an S3TransferManager to copy an object from one bucket to another. View the complete\nfile and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.services.s3.model.CopyObjectRequest;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedCopy;\nimport software.amazon.awssdk.transfer.s3.model.Copy;\nimport software.amazon.awssdk.transfer.s3.model.CopyRequest;\nimport java.util.UUID;\npublic String copyObject(S3TransferManager transferManager, String\nbucketName,\nString key, String destinationBucket, String destinationKey) {\nCopyObjectRequest copyObjectRequest = CopyObjectRequest.builder()\n.sourceBucket(bucketName)\n.sourceKey(key)\n.destinationBucket(destinationBucket)\n.destinationKey(destinationKey)\n.build();\nCopyRequest copyRequest = CopyRequest.builder()\n.copyObjectRequest(copyObjectRequest)\n.build();\nBasics API Version 2006-03-01 1832",
      "start_idx": 1989461,
      "end_idx": 1990906,
      "metadata": {
        "num_sentences": 3,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1838",
      "text": "Amazon Simple Storage Service API Reference\nCopy copy = transferManager.copy(copyRequest);\nCompletedCopy completedCopy = copy.completionFuture().join();\nreturn completedCopy.response().copyObjectResult().eTag();\n}\n\u2022 For API details, see CopyObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCopy the object.\nimport {\nS3Client,\nCopyObjectCommand,\nObjectNotInActiveTierError,\nwaitUntilObjectExists,\n} from \"@aws-sdk/client-s3\";\n/**\n* Copy an S3 object from one bucket to another.\n*\n* @param {{\n* sourceBucket: string,\n* sourceKey: string,\n* destinationBucket: string,\n* destinationKey: string }} config\n*/\nexport const main = async ({\nsourceBucket,\nsourceKey,\ndestinationBucket,\nBasics API Version 2006-03-01 1833",
      "start_idx": 1990908,
      "end_idx": 1991774,
      "metadata": {
        "num_sentences": 6,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1839",
      "text": "Amazon Simple Storage Service API Reference\ndestinationKey,\n}) => {\nconst client = new S3Client({});\ntry {\nawait client.send(\nnew CopyObjectCommand({\nCopySource: `${sourceBucket}/${sourceKey}`,\nBucket: destinationBucket,\nKey: destinationKey,\n}),\n);\nawait waitUntilObjectExists(\n{ client },\n{ Bucket: destinationBucket, Key: destinationKey },\n);\nconsole.log(\n`Successfully copied ${sourceBucket}/${sourceKey} to ${destinationBucket}/\n${destinationKey}`,\n);\n} catch (caught) {\nif (caught instanceof ObjectNotInActiveTierError) {\nconsole.error(\n`Could not copy ${sourceKey} from ${sourceBucket}. Object is not in the\nactive tier.`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For API details, see CopyObject in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1834",
      "start_idx": 1991776,
      "end_idx": 1992547,
      "metadata": {
        "num_sentences": 3,
        "num_words": 99,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1840",
      "text": "Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun copyBucketObject(\nfromBucket: String,\nobjectKey: String,\ntoBucket: String,\n) {\nvar encodedUrl = \"\"\ntry {\nencodedUrl = URLEncoder.encode(\"$fromBucket/$objectKey\",\nStandardCharsets.UTF_8.toString())\n} catch (e: UnsupportedEncodingException) {\nprintln(\"URL could not be encoded: \" + e.message)\n}\nval request =\nCopyObjectRequest {\ncopySource = encodedUrl\nbucket = toBucket\nkey = objectKey\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.copyObject(request)\n}\n}\n\u2022 For API details, see CopyObject in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 1835",
      "start_idx": 1992549,
      "end_idx": 1993316,
      "metadata": {
        "num_sentences": 4,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1841",
      "text": "Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nSimple copy of an object.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\ntry {\n$folder = \"copied-folder\";\n$this->s3client->copyObject([\n'Bucket' => $this->bucketName,\n'CopySource' => \"$this->bucketName/$fileName\",\n'Key' => \"$folder/$fileName-copy\",\n]);\necho \"Copied $fileName to $folder/$fileName-copy.\\n\";\n} catch (Exception $exception) {\necho \"Failed to copy $fileName with error: \" . $exception-\n>getMessage();\nexit(\"Please fix error with object copying before continuing.\");\n}\n\u2022 For API details, see CopyObject in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command copies the object \"sample.txt\" from bucket \"test-files\" to the\nsame bucket but with a new key of \"sample-copy.txt\".\nCopy-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -DestinationKey\nsample-copy.txt\nBasics API Version 2006-03-01 1836",
      "start_idx": 1993318,
      "end_idx": 1994364,
      "metadata": {
        "num_sentences": 8,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1842",
      "text": "Amazon Simple Storage Service API Reference\nExample 2: This command copies the object \"sample.txt\" from bucket \"test-files\" to the\nbucket \"backup-files\" with a key of \"sample-copy.txt\".\nCopy-S3Object -BucketName amzn-s3-demo-source-bucket -Key sample.txt -\nDestinationKey sample-copy.txt -DestinationBucket amzn-s3-demo-destination-bucket\nExample 3: This command downloads the object \"sample.txt\" from bucket \"test-files\" to\na local file with name \"local-sample.txt\".\nCopy-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -LocalFile local-\nsample.txt\nExample 4: Downloads the single object to the specified file. The downloaded file will be\nfound at c:\\downloads\\data\\archive.zip\nCopy-S3Object -BucketName amzn-s3-demo-bucket -Key data/archive.zip -LocalFolder\nc:\\downloads\nExample 5: Downloads all objects that match the specified key prefix to the local folder.\nThe relative key hierarchy will be preserved as subfolders in the overall download\nlocation.\nCopy-S3Object -BucketName amzn-s3-demo-bucket -KeyPrefix data -LocalFolder c:\n\\downloads\n\u2022 For API details, see CopyObject in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\nBasics API Version 2006-03-01 1837",
      "start_idx": 1994366,
      "end_idx": 1995747,
      "metadata": {
        "num_sentences": 10,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1843",
      "text": "Amazon Simple Storage Service API Reference\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\ndef copy(self, dest_object):\n\"\"\"\nCopies the object to another bucket.\n:param dest_object: The destination object initialized with a bucket and\nkey.\nThis is a Boto3 Object resource.\n\"\"\"\ntry:\ndest_object.copy_from(\nCopySource={\"Bucket\": self.object.bucket_name, \"Key\":\nself.object.key}\n)\ndest_object.wait_until_exists()\nlogger.info(\n\"Copied object from %s:%s to %s:%s.\",\nself.object.bucket_name,\nself.object.key,\ndest_object.bucket_name,\ndest_object.key,\n)\nexcept ClientError:\nlogger.exception(\n\"Couldn't copy object from %s/%s to %s/%s.\",\nself.object.bucket_name,\nself.object.key,\ndest_object.bucket_name,\ndest_object.key,\n)\nraise\nBasics API Version 2006-03-01 1838",
      "start_idx": 1995749,
      "end_idx": 1996682,
      "metadata": {
        "num_sentences": 8,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1844",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see CopyObject in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCopy an object.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectCopyWrapper\nattr_reader :source_object\n# @param source_object [Aws::S3::Object] An existing Amazon S3 object. This is\nused as the source object for\n# copy actions.\ndef initialize(source_object)\n@source_object = source_object\nend\n# Copy the source object to the specified target bucket and rename it with the\ntarget key.\n#\n# @param target_bucket [Aws::S3::Bucket] An existing Amazon S3 bucket where the\nobject is copied.\n# @param target_object_key [String] The key to give the copy of the object.\n# @return [Aws::S3::Object, nil] The copied object when successful; otherwise,\nnil.\ndef copy_object(target_bucket, target_object_key)\n@source_object.copy_to(bucket: target_bucket.name, key: target_object_key)\ntarget_bucket.object(target_object_key)\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't copy #{@source_object.key} to #{target_object_key}. Here's\nwhy: #{e.message}\"\nend\nBasics API Version 2006-03-01 1839",
      "start_idx": 1996684,
      "end_idx": 1997946,
      "metadata": {
        "num_sentences": 13,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1845",
      "text": "Amazon Simple Storage Service API Reference\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nsource_bucket_name = \"amzn-s3-demo-bucket1\"\nsource_key = \"my-source-file.txt\"\ntarget_bucket_name = \"amzn-s3-demo-bucket2\"\ntarget_key = \"my-target-file.txt\"\n=======\nsource_bucket_name = 'doc-example-bucket1'\nsource_key = 'my-source-file.txt'\ntarget_bucket_name = 'doc-example-bucket2'\ntarget_key = 'my-target-file.txt'\n>>>>>>> 999c6133e (fixes)\nsource_bucket = Aws::S3::Bucket.new(source_bucket_name)\nwrapper = ObjectCopyWrapper.new(source_bucket.object(source_key))\ntarget_bucket = Aws::S3::Bucket.new(target_bucket_name)\ntarget_object = wrapper.copy_object(target_bucket, target_key)\nreturn unless target_object\nputs \"Copied #{source_key} from #{source_bucket_name} to\n#{target_object.bucket_name}:#{target_object.key}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nCopy an object and add server-side encryption to the destination object.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectCopyEncryptWrapper\nattr_reader :source_object\n# @param source_object [Aws::S3::Object] An existing Amazon S3 object. This is\nused as the source object for\n# copy actions.\ndef initialize(source_object)\n@source_object = source_object\nend\nBasics API Version 2006-03-01 1840",
      "start_idx": 1997948,
      "end_idx": 1999213,
      "metadata": {
        "num_sentences": 6,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1846",
      "text": "Amazon Simple Storage Service API Reference\n# Copy the source object to the specified target bucket, rename it with the\ntarget key, and encrypt it.\n#\n# @param target_bucket [Aws::S3::Bucket] An existing Amazon S3 bucket where the\nobject is copied.\n# @param target_object_key [String] The key to give the copy of the object.\n# @return [Aws::S3::Object, nil] The copied object when successful; otherwise,\nnil.\ndef copy_object(target_bucket, target_object_key, encryption)\n@source_object.copy_to(bucket: target_bucket.name, key: target_object_key,\nserver_side_encryption: encryption)\ntarget_bucket.object(target_object_key)\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't copy #{@source_object.key} to #{target_object_key}. Here's\nwhy: #{e.message}\"\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nsource_bucket_name = \"amzn-s3-demo-bucket1\"\nsource_key = \"my-source-file.txt\"\ntarget_bucket_name = \"amzn-s3-demo-bucket2\"\ntarget_key = \"my-target-file.txt\"\ntarget_encryption = \"AES256\"\n=======\nsource_bucket_name = 'doc-example-bucket1'\nsource_key = 'my-source-file.txt'\ntarget_bucket_name = 'doc-example-bucket2'\ntarget_key = 'my-target-file.txt'\ntarget_encryption = 'AES256'\n>>>>>>> 999c6133e (fixes)\nsource_bucket = Aws::S3::Bucket.new(source_bucket_name)\nwrapper = ObjectCopyEncryptWrapper.new(source_bucket.object(source_key))\ntarget_bucket = Aws::S3::Bucket.new(target_bucket_name)\ntarget_object = wrapper.copy_object(target_bucket, target_key,\ntarget_encryption)\nreturn unless target_object\nputs \"Copied #{source_key} from #{source_bucket_name} to\n#{target_object.bucket_name}:#{target_object.key} and \"\\\nBasics API Version 2006-03-01 1841",
      "start_idx": 1999215,
      "end_idx": 2000863,
      "metadata": {
        "num_sentences": 6,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1847",
      "text": "Amazon Simple Storage Service API Reference\n\"encrypted the target with #{target_object.server_side_encryption}\nencryption.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see CopyObject in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// Copy an object from one bucket to another.\npub async fn copy_object(\nclient: &aws_sdk_s3::Client,\nsource_bucket: &str,\ndestination_bucket: &str,\nsource_object: &str,\ndestination_object: &str,\n) -> Result<(), S3ExampleError> {\nlet source_key = format!(\"{source_bucket}/{source_object}\");\nlet response = client\n.copy_object()\n.copy_source(&source_key)\n.bucket(destination_bucket)\n.key(destination_object)\n.send()\n.await?;\nprintln!(\n\"Copied from {source_key} to {destination_bucket}/{destination_object}\nwith etag {}\",\nresponse\n.copy_object_result\nBasics API Version 2006-03-01 1842",
      "start_idx": 2000865,
      "end_idx": 2001825,
      "metadata": {
        "num_sentences": 9,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1848",
      "text": "Amazon Simple Storage Service API Reference\n.unwrap_or_else(||\naws_sdk_s3::types::CopyObjectResult::builder().build())\n.e_tag()\n.unwrap_or(\"missing\")\n);\nOk(())\n}\n\u2022 For API details, see CopyObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTRY.\nlo_s3->copyobject(\niv_bucket = iv_dest_bucket\niv_key = iv_dest_object\niv_copysource = |{ iv_src_bucket }/{ iv_src_object }|\n).\nMESSAGE 'Object copied to another bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nCATCH /aws1/cx_s3_nosuchkey.\nMESSAGE 'Object key does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see CopyObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 1843",
      "start_idx": 2001827,
      "end_idx": 2002659,
      "metadata": {
        "num_sentences": 16,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1849",
      "text": "Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func copyFile(from sourceBucket: String, name: String, to destBucket:\nString) async throws {\nlet srcUrl = (\"\\(sourceBucket)/\n\\(name)\").addingPercentEncoding(withAllowedCharacters: .urlPathAllowed)\nlet input = CopyObjectInput(\nbucket: destBucket,\ncopySource: srcUrl,\nkey: name\n)\ndo {\n_ = try await client.copyObject(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Copying an object.\"))\nthrow error\n}\n}\n\u2022 For API details, see CopyObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse CreateBucket with an AWS SDK or CLI\nThe following code examples show how to use CreateBucket.\nBasics API Version 2006-03-01 1844",
      "start_idx": 2002661,
      "end_idx": 2003701,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1850",
      "text": "Amazon Simple Storage Service API Reference\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Learn the basics\n\u2022 Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Shows how to create a new Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <param name=\"bucketName\">The name of the bucket to create.</param>\n/// <returns>A boolean value representing the success or failure of\n/// the bucket creation process.</returns>\npublic static async Task<bool> CreateBucketAsync(IAmazonS3 client, string\nbucketName)\n{\ntry\n{\nvar request = new PutBucketRequest\n{\nBucketName = bucketName,\nUseClientRegion = true,\n};\nvar response = await client.PutBucketAsync(request);\nreturn response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"Error creating bucket: '{ex.Message}'\");\nBasics API Version 2006-03-01 1845",
      "start_idx": 2003703,
      "end_idx": 2004852,
      "metadata": {
        "num_sentences": 5,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1852",
      "text": "Amazon Simple Storage Service API Reference\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function iecho\n#\n# This function enables the script to display the specified text only if\n# the global variable $VERBOSE is set to true.\n###############################################################################\nfunction iecho() {\nif [[ $VERBOSE == true ]]; then\necho \"$@\"\nfi\n}\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function create-bucket\n#\n# This function creates the specified bucket in the specified AWS Region, unless\n# it already exists.\n#\n# Parameters:\n# -b bucket_name -- The name of the bucket to create.\n# -r region_code -- The code for an AWS Region in which to\n# create the bucket.\n#\nBasics API Version 2006-03-01 1847",
      "start_idx": 2005913,
      "end_idx": 2007180,
      "metadata": {
        "num_sentences": 8,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1853",
      "text": "Amazon Simple Storage Service API Reference\n# Returns:\n# The URL of the bucket that was created.\n# And:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction create_bucket() {\nlocal bucket_name region_code response\nlocal option OPTARG # Required to use getopts command in a function.\n# bashsupport disable=BP5008\nfunction usage() {\necho \"function create_bucket\"\necho \"Creates an Amazon S3 bucket. You must supply a bucket name:\"\necho \" -b bucket_name The name of the bucket. It must be globally\nunique.\"\necho \" [-r region_code] The code for an AWS Region in which the bucket is\ncreated.\"\necho \"\"\n}\n# Retrieve the calling parameters.\nwhile getopts \"b:r:h\" option; do\ncase \"${option}\" in\nb) bucket_name=\"${OPTARG}\" ;;\nr) region_code=\"${OPTARG}\" ;;\nh)\nusage\nreturn 0\n;;\n\\?)\necho \"Invalid parameter\"\nusage\nreturn 1\n;;\nesac\ndone\nif [[ -z \"$bucket_name\" ]]; then\nerrecho \"ERROR: You must provide a bucket name with the -b parameter.\"\nusage\nreturn 1\nfi\nBasics API Version 2006-03-01 1848",
      "start_idx": 2007182,
      "end_idx": 2008237,
      "metadata": {
        "num_sentences": 12,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1854",
      "text": "Amazon Simple Storage Service API Reference\nlocal bucket_config_arg\n# A location constraint for \"us-east-1\" returns an error.\nif [[ -n \"$region_code\" ]] && [[ \"$region_code\" != \"us-east-1\" ]]; then\nbucket_config_arg=\"--create-bucket-configuration LocationConstraint=\n$region_code\"\nfi\niecho \"Parameters:\\n\"\niecho \" Bucket name: $bucket_name\"\niecho \" Region code: $region_code\"\niecho \"\"\n# If the bucket already exists, we don't want to try to create it.\nif (bucket_exists \"$bucket_name\"); then\nerrecho \"ERROR: A bucket with that name already exists. Try again.\"\nreturn 1\nfi\n# shellcheck disable=SC2086\nresponse=$(aws s3api create-bucket \\\n--bucket \"$bucket_name\" \\\n$bucket_config_arg)\n# shellcheck disable=SC2181\nif [[ ${?} -ne 0 ]]; then\nerrecho \"ERROR: AWS reports create-bucket operation failed.\\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see CreateBucket in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1849",
      "start_idx": 2008239,
      "end_idx": 2009302,
      "metadata": {
        "num_sentences": 9,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1856",
      "text": "Amazon Simple Storage Service API Reference\n--bucket my-bucket \\\n--region us-east-1\nOutput:\n{\n\"Location\": \"/my-bucket\"\n}\nFor more information, see Creating a bucket in the Amazon S3 User Guide.\nExample 2: To create a bucket with owner enforced\nThe following create-bucket example creates a bucket named my-bucket that uses the\nbucket owner enforced setting for S3 Object Ownership.\naws s3api create-bucket \\\n--bucket my-bucket \\\n--region us-east-1 \\\n--object-ownership BucketOwnerEnforced\nOutput:\n{\n\"Location\": \"/my-bucket\"\n}\nFor more information, see Controlling ownership of objects and disabling ACLs in the\nAmazon S3 User Guide.\nExample 3: To create a bucket outside of the ``us-east-1`` region\nThe following create-bucket example creates a bucket named my-bucket in\nthe eu-west-1 region. Regions outside of us-east-1 require the appropriate\nLocationConstraint to be specified in order to create the bucket in the desired region.\naws s3api create-bucket \\\n--bucket my-bucket \\\n--region eu-west-1 \\\n--create-bucket-configuration LocationConstraint=eu-west-1\nBasics API Version 2006-03-01 1851",
      "start_idx": 2010511,
      "end_idx": 2011606,
      "metadata": {
        "num_sentences": 6,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1857",
      "text": "Amazon Simple Storage Service API Reference\nOutput:\n{\n\"Location\": \"http://my-bucket.s3.amazonaws.com/\"\n}\nFor more information, see Creating a bucket in the Amazon S3 User Guide.\n\u2022 For API details, see CreateBucket in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate a bucket with default configuration.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// CreateBucket creates a bucket with the specified name in the specified Region.\nfunc (basics BucketBasics) CreateBucket(ctx context.Context, name string, region\nstring) error {\n_, err := basics.S3Client.CreateBucket(ctx, &s3.CreateBucketInput{\nBucket: aws.String(name),\nCreateBucketConfiguration: &types.CreateBucketConfiguration{\nLocationConstraint: types.BucketLocationConstraint(region),\nBasics API Version 2006-03-01 1852",
      "start_idx": 2011608,
      "end_idx": 2012728,
      "metadata": {
        "num_sentences": 9,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1858",
      "text": "Amazon Simple Storage Service API Reference\n},\n})\nif err != nil {\nlog.Printf(\"Couldn't create bucket %v in Region %v. Here's why: %v\\n\",\nname, region, err)\n}\nreturn err\n}\nCreate a bucket with object locking and wait for it to exist.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// CreateBucketWithLock creates a new S3 bucket with optional object locking\nenabled\n// and waits for the bucket to exist before returning.\nfunc (actor S3Actions) CreateBucketWithLock(ctx context.Context, bucket string,\nregion string, enableObjectLock bool) (string, error) {\ninput := &s3.CreateBucketInput{\nBucket: aws.String(bucket),\nCreateBucketConfiguration: &types.CreateBucketConfiguration{\nLocationConstraint: types.BucketLocationConstraint(region),\n},\n}\nif enableObjectLock {\ninput.ObjectLockEnabledForBucket = aws.Bool(true)\n}\n_, err := actor.S3Client.CreateBucket(ctx, input)\nif err != nil {\nvar owned *types.BucketAlreadyOwnedByYou\nvar exists *types.BucketAlreadyExists\nif errors.As(err, &owned) {\nBasics API Version 2006-03-01 1853",
      "start_idx": 2012730,
      "end_idx": 2013819,
      "metadata": {
        "num_sentences": 5,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1859",
      "text": "Amazon Simple Storage Service API Reference\nlog.Printf(\"You already own bucket %s.\\n\", bucket)\nerr = owned\n} else if errors.As(err, &exists) {\nlog.Printf(\"Bucket %s already exists.\\n\", bucket)\nerr = exists\n}\n} else {\nerr = s3.NewBucketExistsWaiter(actor.S3Client).Wait(\nctx, &s3.HeadBucketInput{Bucket: aws.String(bucket)}, time.Minute)\nif err != nil {\nlog.Printf(\"Failed attempt to wait for bucket %s to exist.\\n\", bucket)\n}\n}\nreturn bucket, err\n}\n\u2022 For API details, see CreateBucket in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate a bucket.\n/**\n* Creates an S3 bucket asynchronously.\n*\n* @param bucketName the name of the S3 bucket to create\n* @return a {@link CompletableFuture} that completes when the bucket is\ncreated and ready\n* @throws RuntimeException if there is a failure while creating the bucket\n*/\nBasics API Version 2006-03-01 1854",
      "start_idx": 2013821,
      "end_idx": 2014805,
      "metadata": {
        "num_sentences": 6,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1861",
      "text": "Amazon Simple Storage Service API Reference\n.bucket(bucketName)\n.build();\n// Wait until the bucket is created and print out the response.\ns3Waiter.waitUntilBucketExists(bucketRequestWait);\nSystem.out.println(bucketName + \" is ready\");\n}\n\u2022 For API details, see CreateBucket in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate the bucket.\nimport {\nBucketAlreadyExists,\nBucketAlreadyOwnedByYou,\nCreateBucketCommand,\nS3Client,\nwaitUntilBucketExists,\n} from \"@aws-sdk/client-s3\";\n/**\n* Create an Amazon S3 bucket.\n* @param {{ bucketName: string }} config\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nconst { Location } = await client.send(\nnew CreateBucketCommand({\nBasics API Version 2006-03-01 1856",
      "start_idx": 2016236,
      "end_idx": 2017129,
      "metadata": {
        "num_sentences": 7,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1862",
      "text": "Amazon Simple Storage Service API Reference\n// The name of the bucket. Bucket names are unique and have several other\nconstraints.\n// See https://docs.aws.amazon.com/AmazonS3/latest/userguide/\nbucketnamingrules.html\nBucket: bucketName,\n}),\n);\nawait waitUntilBucketExists({ client }, { Bucket: bucketName });\nconsole.log(`Bucket created with location ${Location}`);\n} catch (caught) {\nif (caught instanceof BucketAlreadyExists) {\nconsole.error(\n`The bucket \"${bucketName}\" already exists in another AWS account. Bucket\nnames must be globally unique.`,\n);\n}\n// WARNING: If you try to create a bucket in the North Virginia region,\n// and you already own a bucket in that region with the same name, this\n// error will not be thrown. Instead, the call will return successfully\n// and the ACL on that bucket will be reset.\nelse if (caught instanceof BucketAlreadyOwnedByYou) {\nconsole.error(\n`The bucket \"${bucketName}\" already exists in this AWS account.`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see CreateBucket in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1857",
      "start_idx": 2017131,
      "end_idx": 2018295,
      "metadata": {
        "num_sentences": 8,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1863",
      "text": "Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun createNewBucket(bucketName: String) {\nval request =\nCreateBucketRequest {\nbucket = bucketName\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.createBucket(request)\nprintln(\"$bucketName is ready\")\n}\n}\n\u2022 For API details, see CreateBucket in AWS SDK for Kotlin API reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate a bucket.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\ntry {\nBasics API Version 2006-03-01 1858",
      "start_idx": 2018297,
      "end_idx": 2019032,
      "metadata": {
        "num_sentences": 7,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1864",
      "text": "Amazon Simple Storage Service API Reference\n$this->s3client->createBucket([\n'Bucket' => $this->bucketName,\n'CreateBucketConfiguration' => ['LocationConstraint' => $region],\n]);\necho \"Created bucket named: $this->bucketName \\n\";\n} catch (Exception $exception) {\necho \"Failed to create bucket $this->bucketName with error: \" .\n$exception->getMessage();\nexit(\"Please fix error with bucket creation before continuing.\");\n}\n\u2022 For API details, see CreateBucket in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate a bucket with default settings.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef create(self, region_override=None):\n\"\"\"\nBasics API Version 2006-03-01 1859",
      "start_idx": 2019034,
      "end_idx": 2020066,
      "metadata": {
        "num_sentences": 10,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1865",
      "text": "Amazon Simple Storage Service API Reference\nCreate an Amazon S3 bucket in the default Region for the account or in\nthe\nspecified Region.\n:param region_override: The Region in which to create the bucket. If this\nis\nnot specified, the Region configured in your\nshared\ncredentials is used.\n\"\"\"\nif region_override is not None:\nregion = region_override\nelse:\nregion = self.bucket.meta.client.meta.region_name\ntry:\nself.bucket.create(CreateBucketConfiguration={\"LocationConstraint\":\nregion})\nself.bucket.wait_until_exists()\nlogger.info(\"Created bucket '%s' in region=%s\", self.bucket.name,\nregion)\nexcept ClientError as error:\nlogger.exception(\n\"Couldn't create bucket named '%s' in region=%s.\",\nself.bucket.name,\nregion,\n)\nraise error\nCreate a versioned bucket with a lifecycle configuration.\ndef create_versioned_bucket(bucket_name, prefix):\n\"\"\"\nCreates an Amazon S3 bucket, enables it for versioning, and configures a\nlifecycle\nthat expires noncurrent object versions after 7 days.\nAdding a lifecycle configuration to a versioned bucket is a best practice.\nIt helps prevent objects in the bucket from accumulating a large number of\nnoncurrent versions, which can slow down request performance.\nBasics API Version 2006-03-01 1860",
      "start_idx": 2020068,
      "end_idx": 2021293,
      "metadata": {
        "num_sentences": 9,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1867",
      "text": "Amazon Simple Storage Service API Reference\n)\nlogger.info(\n\"Configured lifecycle to expire noncurrent versions after %s days \"\n\"on bucket %s.\",\nexpiration,\nbucket.name,\n)\nexcept ClientError as error:\nlogger.warning(\n\"Couldn't configure lifecycle on bucket %s because %s. \"\n\"Continuing anyway.\",\nbucket.name,\nerror,\n)\nreturn bucket\n\u2022 For API details, see CreateBucket in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket actions.\nclass BucketCreateWrapper\nattr_reader :bucket\n# @param bucket [Aws::S3::Bucket] An Amazon S3 bucket initialized with a name.\nThis is a client-side object until\n# create is called.\ndef initialize(bucket)\nBasics API Version 2006-03-01 1862",
      "start_idx": 2022504,
      "end_idx": 2023350,
      "metadata": {
        "num_sentences": 10,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1868",
      "text": "Amazon Simple Storage Service API Reference\n@bucket = bucket\nend\n# Creates an Amazon S3 bucket in the specified AWS Region.\n#\n# @param region [String] The Region where the bucket is created.\n# @return [Boolean] True when the bucket is created; otherwise, false.\ndef create?(region)\n@bucket.create(create_bucket_configuration: { location_constraint: region })\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't create bucket. Here's why: #{e.message}\"\nfalse\nend\n# Gets the Region where the bucket is located.\n#\n# @return [String] The location of the bucket.\ndef location\nif @bucket.nil?\n'None. You must create a bucket before you can get its location!'\nelse\n@bucket.client.get_bucket_location(bucket:\n@bucket.name).location_constraint\nend\nrescue Aws::Errors::ServiceError => e\n\"Couldn't get the location of #{@bucket.name}. Here's why: #{e.message}\"\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nregion = \"us-west-2\"\nwrapper = BucketCreateWrapper.new(Aws::S3::Bucket.new(\"amzn-s3-demo-bucket-\n#{Random.uuid}\"))\n=======\nregion = 'us-west-2'\nwrapper = BucketCreateWrapper.new(Aws::S3::Bucket.new(\"doc-example-bucket-\n#{Random.uuid}\"))\n>>>>>>> 999c6133e (fixes)\nreturn unless wrapper.create?(region)\nputs \"Created bucket #{wrapper.bucket.name}.\"\nBasics API Version 2006-03-01 1863",
      "start_idx": 2023352,
      "end_idx": 2024640,
      "metadata": {
        "num_sentences": 14,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1869",
      "text": "Amazon Simple Storage Service API Reference\nputs \"Your bucket's region is: #{wrapper.location}\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see CreateBucket in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npub async fn create_bucket(\nclient: &aws_sdk_s3::Client,\nbucket_name: &str,\nregion: &aws_config::Region,\n) -> Result<Option<aws_sdk_s3::operation::create_bucket::CreateBucketOutput>,\nS3ExampleError> {\nlet constraint =\naws_sdk_s3::types::BucketLocationConstraint::from(region.to_string().as_str());\nlet cfg = aws_sdk_s3::types::CreateBucketConfiguration::builder()\n.location_constraint(constraint)\n.build();\nlet create = client\n.create_bucket()\n.create_bucket_configuration(cfg)\n.bucket(bucket_name)\n.send()\n.await;\n// BucketAlreadyExists and BucketAlreadyOwnedByYou are not problems for this\ntask.\ncreate.map(Some).or_else(|err| {\nif err\n.as_service_error()\nBasics API Version 2006-03-01 1864",
      "start_idx": 2024642,
      "end_idx": 2025685,
      "metadata": {
        "num_sentences": 5,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1870",
      "text": "Amazon Simple Storage Service API Reference\n.map(|se| se.is_bucket_already_exists() ||\nse.is_bucket_already_owned_by_you())\n== Some(true)\n{\nOk(None)\n} else {\nErr(S3ExampleError::from(err))\n}\n})\n}\n\u2022 For API details, see CreateBucket in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTRY.\nlo_s3->createbucket(\niv_bucket = iv_bucket_name\n).\nMESSAGE 'S3 bucket created.' TYPE 'I'.\nCATCH /aws1/cx_s3_bucketalrdyexists.\nMESSAGE 'Bucket name already exists.' TYPE 'E'.\nCATCH /aws1/cx_s3_bktalrdyownedbyyou.\nMESSAGE 'Bucket already exists and is owned by you.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see CreateBucket in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 1865",
      "start_idx": 2025687,
      "end_idx": 2026502,
      "metadata": {
        "num_sentences": 16,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1871",
      "text": "Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func createBucket(name: String) async throws {\nvar input = CreateBucketInput(\nbucket: name\n)\n// For regions other than \"us-east-1\", you must set the\nlocationConstraint in the createBucketConfiguration.\n// For more information, see LocationConstraint in the S3 API guide.\n// https://docs.aws.amazon.com/AmazonS3/latest/API/\nAPI_CreateBucket.html#API_CreateBucket_RequestBody\nif let region = configuration.region {\nif region != \"us-east-1\" {\ninput.createBucketConfiguration =\nS3ClientTypes.CreateBucketConfiguration(locationConstraint:\nS3ClientTypes.BucketLocationConstraint(rawValue: region))\n}\n}\ndo {\n_ = try await client.createBucket(input: input)\n}\ncatch let error as BucketAlreadyOwnedByYou {\nprint(\"The bucket '\\(name)' already exists and is owned by you. You\nmay wish to ignore this exception.\")\nthrow error\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Creating a bucket\"))\nthrow error\n}\nBasics API Version 2006-03-01 1866",
      "start_idx": 2026504,
      "end_idx": 2027640,
      "metadata": {
        "num_sentences": 7,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1872",
      "text": "Amazon Simple Storage Service API Reference\n}\n\u2022 For API details, see CreateBucket in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse CreateMultiRegionAccessPoint with an AWS SDK\nThe following code example shows how to use CreateMultiRegionAccessPoint.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nConfigure the S3 control client to send request to the us-west-2 Region.\nsuspend fun createS3ControlClient(): S3ControlClient {\n// Configure your S3ControlClient to send requests to US West\n(Oregon).\nval s3Control = S3ControlClient.fromEnvironment {\nregion = \"us-west-2\"\n}\nreturn s3Control\n}\nCreate the Multi-Region Access Point.\nsuspend fun createMrap(\ns3Control: S3ControlClient,\naccountIdParam: String,\nBasics API Version 2006-03-01 1867",
      "start_idx": 2027642,
      "end_idx": 2028686,
      "metadata": {
        "num_sentences": 10,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1874",
      "text": "Amazon Simple Storage Service API Reference\nsuspend fun waitForSucceededStatus(\ns3Control: S3ControlClient,\nrequestToken: String,\naccountIdParam: String,\ntimeBetweenChecks: Duration = 1.minutes,\n) {\nvar describeResponse: DescribeMultiRegionAccessPointOperationResponse\ndescribeResponse = s3Control.describeMultiRegionAccessPointOperation(\ninput = DescribeMultiRegionAccessPointOperationRequest {\naccountId = accountIdParam\nrequestTokenArn = requestToken\n},\n)\nvar status: String? = describeResponse.asyncOperation?.requestStatus\nwhile (status != \"SUCCEEDED\") {\ndelay(timeBetweenChecks)\ndescribeResponse =\ns3Control.describeMultiRegionAccessPointOperation(\ninput = DescribeMultiRegionAccessPointOperationRequest {\naccountId = accountIdParam\nrequestTokenArn = requestToken\n},\n)\nstatus = describeResponse.asyncOperation?.requestStatus\nprintln(status)\n}\n}\n\u2022 For more information, see AWS SDK for Kotlin developer guide.\n\u2022 For API details, see CreateMultiRegionAccessPoint in AWS SDK for Kotlin API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse CreateMultipartUpload with an AWS SDK or CLI\nThe following code examples show how to use CreateMultipartUpload.\nBasics API Version 2006-03-01 1869",
      "start_idx": 2029759,
      "end_idx": 2031130,
      "metadata": {
        "num_sentences": 7,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1875",
      "text": "Amazon Simple Storage Service API Reference\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Perform a multipart copy\n\u2022 Perform a multipart upload\n\u2022 Use checksums\n\u2022 Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n//! Create a multipart upload.\n/*!\n\\param bucket: The name of the S3 bucket where the object will be uploaded.\n\\param key: The unique identifier (key) for the object within the S3 bucket.\n\\param client: The S3 client instance used to perform the upload operation.\n\\return Aws::String: Upload ID or empty string if failed.\n*/\nAws::String\nAwsDoc::S3::createMultipartUpload(const Aws::String &bucket, const Aws::String\n&key,\nAws::S3::Model::ChecksumAlgorithm\nchecksumAlgorithm,\nconst Aws::S3::S3Client &client) {\nAws::S3::Model::CreateMultipartUploadRequest request;\nrequest.SetBucket(bucket);\nrequest.SetKey(key);\nif (checksumAlgorithm != Aws::S3::Model::ChecksumAlgorithm::NOT_SET) {\nrequest.SetChecksumAlgorithm(checksumAlgorithm);\n}\nAws::S3::Model::CreateMultipartUploadOutcome outcome =\nBasics API Version 2006-03-01 1870",
      "start_idx": 2031132,
      "end_idx": 2032400,
      "metadata": {
        "num_sentences": 11,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1876",
      "text": "Amazon Simple Storage Service API Reference\nclient.CreateMultipartUpload(request);\nAws::String uploadID;\nif (outcome.IsSuccess()) {\nuploadID = outcome.GetResult().GetUploadId();\n} else {\nstd::cerr << \"Error creating multipart upload: \" <<\noutcome.GetError().GetMessage() << std::endl;\n}\nreturn uploadID;\n}\n\u2022 For API details, see CreateMultipartUpload in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command creates a multipart upload in the bucket my-bucket with the key\nmultipart/01:\naws s3api create-multipart-upload --bucket my-bucket --key 'multipart/01'\nOutput:\n{\n\"Bucket\": \"my-bucket\",\n\"UploadId\":\n\"dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\",\n\"Key\": \"multipart/01\"\n}\nThe completed file will be named 01 in a folder called multipart in the bucket my-\nbucket. Save the upload ID, key and bucket name for use with the upload-part\ncommand.\n\u2022 For API details, see CreateMultipartUpload in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1871",
      "start_idx": 2032402,
      "end_idx": 2033452,
      "metadata": {
        "num_sentences": 5,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1877",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Create a multipart upload. Use UploadPart and CompleteMultipartUpload to\n// upload the file.\nlet multipart_upload_res: CreateMultipartUploadOutput = client\n.create_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.send()\n.await?;\nlet upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new(\n\"Missing upload_id after CreateMultipartUpload\",\n))?;\nlet mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new();\nfor chunk_index in 0..chunk_count {\nlet this_chunk = if chunk_count - 1 == chunk_index {\nsize_of_last_chunk\n} else {\nCHUNK_SIZE\n};\nlet stream = ByteStream::read_from()\n.path(path)\n.offset(chunk_index * CHUNK_SIZE)\n.length(Length::Exact(this_chunk))\n.build()\n.await\n.unwrap();\n// Chunk index needs to start at 0, but part numbers start at 1.\nlet part_number = (chunk_index as i32) + 1;\nBasics API Version 2006-03-01 1872",
      "start_idx": 2033454,
      "end_idx": 2034499,
      "metadata": {
        "num_sentences": 7,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1878",
      "text": "Amazon Simple Storage Service API Reference\nlet upload_part_res = client\n.upload_part()\n.key(&key)\n.bucket(&bucket_name)\n.upload_id(upload_id)\n.body(stream)\n.part_number(part_number)\n.send()\n.await?;\nupload_parts.push(\nCompletedPart::builder()\n.e_tag(upload_part_res.e_tag.unwrap_or_default())\n.part_number(part_number)\n.build(),\n);\n}\n// upload_parts: Vec<aws_sdk_s3::types::CompletedPart>\nlet completed_multipart_upload: CompletedMultipartUpload =\nCompletedMultipartUpload::builder()\n.set_parts(Some(upload_parts))\n.build();\nlet _complete_multipart_upload_res = client\n.complete_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.multipart_upload(completed_multipart_upload)\n.upload_id(upload_id)\n.send()\n.await?;\n\u2022 For API details, see CreateMultipartUpload in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 1873",
      "start_idx": 2034501,
      "end_idx": 2035549,
      "metadata": {
        "num_sentences": 6,
        "num_words": 99,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1879",
      "text": "Amazon Simple Storage Service API Reference\nUse DeleteBucket with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucket.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Shows how to delete an Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <param name=\"bucketName\">The name of the Amazon S3 bucket to\ndelete.</param>\n/// <returns>A boolean value that represents the success or failure of\n/// the delete operation.</returns>\npublic static async Task<bool> DeleteBucketAsync(IAmazonS3 client, string\nbucketName)\n{\nvar request = new DeleteBucketRequest\n{\nBucketName = bucketName,\n};\nvar response = await client.DeleteBucketAsync(request);\nreturn response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n}\nBasics API Version 2006-03-01 1874",
      "start_idx": 2035551,
      "end_idx": 2036654,
      "metadata": {
        "num_sentences": 6,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1880",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucket in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function delete_bucket\n#\n# This function deletes the specified bucket.\n#\n# Parameters:\n# $1 - The name of the bucket.\n# Returns:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction delete_bucket() {\nlocal bucket_name=$1\nlocal response\nresponse=$(aws s3api delete-bucket \\\n--bucket \"$bucket_name\")\n# shellcheck disable=SC2181\nif [[ $? -ne 0 ]]; then\nBasics API Version 2006-03-01 1875",
      "start_idx": 2036656,
      "end_idx": 2037776,
      "metadata": {
        "num_sentences": 10,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1881",
      "text": "Amazon Simple Storage Service API Reference\nerrecho \"ERROR: AWS reports s3api delete-bucket failed.\\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see DeleteBucket in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteBucket(const Aws::String &bucketName,\nconst Aws::S3::S3ClientConfiguration &clientConfig)\n{\nAws::S3::S3Client client(clientConfig);\nAws::S3::Model::DeleteBucketRequest request;\nrequest.SetBucket(bucketName);\nAws::S3::Model::DeleteBucketOutcome outcome =\nclient.DeleteBucket(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: deleteBucket: \" <<\nerr.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nstd::cout << \"The bucket was deleted\" << std::endl;\n}\nreturn outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1876",
      "start_idx": 2037778,
      "end_idx": 2038727,
      "metadata": {
        "num_sentences": 4,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1882",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucket in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command deletes a bucket named my-bucket:\naws s3api delete-bucket --bucket my-bucket --region us-east-1\n\u2022 For API details, see DeleteBucket in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// DeleteBucket deletes a bucket. The bucket must be empty or an error is\nreturned.\nfunc (basics BucketBasics) DeleteBucket(ctx context.Context, bucketName string)\nerror {\nBasics API Version 2006-03-01 1877",
      "start_idx": 2038729,
      "end_idx": 2039650,
      "metadata": {
        "num_sentences": 9,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1883",
      "text": "Amazon Simple Storage Service API Reference\n_, err := basics.S3Client.DeleteBucket(ctx, &s3.DeleteBucketInput{\nBucket: aws.String(bucketName)})\nif err != nil {\nlog.Printf(\"Couldn't delete bucket %v. Here's why: %v\\n\", bucketName, err)\n}\nreturn err\n}\n\u2022 For API details, see DeleteBucket in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Deletes an S3 bucket asynchronously.\n*\n* @param bucket the name of the bucket to be deleted\n* @return a {@link CompletableFuture} that completes when the bucket\ndeletion is successful, or throws a {@link RuntimeException}\n* if an error occurs during the deletion process\n*/\npublic CompletableFuture<Void> deleteBucketAsync(String bucket) {\nDeleteBucketRequest deleteBucketRequest = DeleteBucketRequest.builder()\n.bucket(bucket)\n.build();\nCompletableFuture<DeleteBucketResponse> response =\ngetAsyncClient().deleteBucket(deleteBucketRequest);\nresponse.whenComplete((deleteRes, ex) -> {\nif (deleteRes != null) {\nlogger.info(bucket + \" was deleted.\");\n} else {\nBasics API Version 2006-03-01 1878",
      "start_idx": 2039652,
      "end_idx": 2040814,
      "metadata": {
        "num_sentences": 7,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1884",
      "text": "Amazon Simple Storage Service API Reference\nthrow new RuntimeException(\"An S3 exception occurred during\nbucket deletion\", ex);\n}\n});\nreturn response.thenApply(r -> null);\n}\n\u2022 For API details, see DeleteBucket in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete the bucket.\nimport {\nDeleteBucketCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Delete an Amazon S3 bucket.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\nconst command = new DeleteBucketCommand({\nBucket: bucketName,\n});\ntry {\nawait client.send(command);\nconsole.log(\"Bucket was deleted.\");\n} catch (caught) {\nBasics API Version 2006-03-01 1879",
      "start_idx": 2040816,
      "end_idx": 2041672,
      "metadata": {
        "num_sentences": 7,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1885",
      "text": "Amazon Simple Storage Service API Reference\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while deleting bucket. The bucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while deleting the bucket. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see DeleteBucket in AWS SDK for JavaScript API Reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete an empty bucket.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\ntry {\n$this->s3client->deleteBucket([\n'Bucket' => $this->bucketName,\n]);\necho \"Deleted bucket $this->bucketName.\\n\";\nBasics API Version 2006-03-01 1880",
      "start_idx": 2041674,
      "end_idx": 2042579,
      "metadata": {
        "num_sentences": 8,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1886",
      "text": "Amazon Simple Storage Service API Reference\n} catch (Exception $exception) {\necho \"Failed to delete $this->bucketName with error: \" . $exception-\n>getMessage();\nexit(\"Please fix error with bucket deletion before continuing.\");\n}\n\u2022 For API details, see DeleteBucket in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes all objects and object versions from the bucket 'test-\nfiles' and then deletes the bucket. The command will prompt for confirmation before\nproceeding. Add the -Force switch to suppress confirmation. Note that buckets that are\nnot empty cannot be deleted.\nRemove-S3Bucket -BucketName amzn-s3-demo-bucket -DeleteBucketContent\n\u2022 For API details, see DeleteBucket in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\nBasics API Version 2006-03-01 1881",
      "start_idx": 2042581,
      "end_idx": 2043761,
      "metadata": {
        "num_sentences": 14,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1887",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef delete(self):\n\"\"\"\nDelete the bucket. The bucket must be empty or an error is raised.\n\"\"\"\ntry:\nself.bucket.delete()\nself.bucket.wait_until_not_exists()\nlogger.info(\"Bucket %s successfully deleted.\", self.bucket.name)\nexcept ClientError:\nlogger.exception(\"Couldn't delete bucket %s.\", self.bucket.name)\nraise\n\u2022 For API details, see DeleteBucket in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# Deletes the objects in an Amazon S3 bucket and deletes the bucket.\n#\n# @param bucket [Aws::S3::Bucket] The bucket to empty and delete.\ndef delete_bucket(bucket)\nputs(\"\\nDo you want to delete all of the objects as well as the bucket (y/n)?\n\")\nanswer = gets.chomp.downcase\nif answer == 'y'\nbucket.objects.batch_delete!\nbucket.delete\nputs(\"Emptied and deleted bucket #{bucket.name}.\\n\")\nBasics API Version 2006-03-01 1882",
      "start_idx": 2043763,
      "end_idx": 2044810,
      "metadata": {
        "num_sentences": 12,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1888",
      "text": "Amazon Simple Storage Service API Reference\nend\nrescue Aws::Errors::ServiceError => e\nputs(\"Couldn't empty and delete bucket #{bucket.name}.\")\nputs(\"\\t#{e.code}: #{e.message}\")\nraise\nend\n\u2022 For API details, see DeleteBucket in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npub async fn delete_bucket(\nclient: &aws_sdk_s3::Client,\nbucket_name: &str,\n) -> Result<(), S3ExampleError> {\nlet resp = client.delete_bucket().bucket(bucket_name).send().await;\nmatch resp {\nOk(_) => Ok(()),\nErr(err) => {\nif err\n.as_service_error()\n.and_then(aws_sdk_s3::error::ProvideErrorMetadata::code)\n== Some(\"NoSuchBucket\")\n{\nOk(())\n} else {\nErr(S3ExampleError::from(err))\n}\n}\n}\n}\nBasics API Version 2006-03-01 1883",
      "start_idx": 2044812,
      "end_idx": 2045633,
      "metadata": {
        "num_sentences": 5,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1889",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucket in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTRY.\nlo_s3->deletebucket(\niv_bucket = iv_bucket_name\n).\nMESSAGE 'Deleted S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see DeleteBucket in AWS SDK for SAP ABAP API reference.\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func deleteBucket(name: String) async throws {\nlet input = DeleteBucketInput(\nBasics API Version 2006-03-01 1884",
      "start_idx": 2045635,
      "end_idx": 2046429,
      "metadata": {
        "num_sentences": 15,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1890",
      "text": "Amazon Simple Storage Service API Reference\nbucket: name\n)\ndo {\n_ = try await client.deleteBucket(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Deleting a bucket\"))\nthrow error\n}\n}\n\u2022 For API details, see DeleteBucket in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketAnalyticsConfiguration with a CLI\nThe following code examples show how to use DeleteBucketAnalyticsConfiguration.\nCLI\nAWS CLI\nTo delete an analytics configuration for a bucket\nThe following delete-bucket-analytics-configuration example removes the\nanalytics configuration for the specified bucket and ID.\naws s3api delete-bucket-analytics-configuration \\\n--bucket my-bucket \\\n--id 1\nThis command produces no output.\n\u2022 For API details, see DeleteBucketAnalyticsConfiguration in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1885",
      "start_idx": 2046431,
      "end_idx": 2047469,
      "metadata": {
        "num_sentences": 8,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1891",
      "text": "Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: The command removes the analytics filter with name 'testfilter' in the given\nS3 bucket.\nRemove-S3BucketAnalyticsConfiguration -BucketName 'amzn-s3-demo-bucket' -\nAnalyticsId 'testfilter'\n\u2022 For API details, see DeleteBucketAnalyticsConfiguration in AWS Tools for PowerShell\nCmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketCors with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketCors.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Deletes a CORS configuration from an Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used\n/// to delete the CORS configuration from the bucket.</param>\nprivate static async Task DeleteCORSConfigurationAsync(AmazonS3Client\nclient)\n{\nBasics API Version 2006-03-01 1886",
      "start_idx": 2047471,
      "end_idx": 2048652,
      "metadata": {
        "num_sentences": 9,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1892",
      "text": "Amazon Simple Storage Service API Reference\nDeleteCORSConfigurationRequest request = new\nDeleteCORSConfigurationRequest()\n{\nBucketName = BucketName,\n};\nawait client.DeleteCORSConfigurationAsync(request);\n}\n\u2022 For API details, see DeleteBucketCors in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command deletes a Cross-Origin Resource Sharing configuration from a\nbucket named my-bucket:\naws s3api delete-bucket-cors --bucket my-bucket\n\u2022 For API details, see DeleteBucketCors in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nBasics API Version 2006-03-01 1887",
      "start_idx": 2048654,
      "end_idx": 2049530,
      "metadata": {
        "num_sentences": 7,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1893",
      "text": "Amazon Simple Storage Service API Reference\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef delete_cors(self):\n\"\"\"\nDelete the CORS rules from the bucket.\n:param bucket_name: The name of the bucket to update.\n\"\"\"\ntry:\nself.bucket.Cors().delete()\nlogger.info(\"Deleted CORS from bucket '%s'.\", self.bucket.name)\nexcept ClientError:\nlogger.exception(\"Couldn't delete CORS from bucket '%s'.\",\nself.bucket.name)\nraise\n\u2022 For API details, see DeleteBucketCors in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket CORS configuration.\nclass BucketCorsWrapper\nattr_reader :bucket_cors\n# @param bucket_cors [Aws::S3::BucketCors] A bucket CORS object configured with\nan existing bucket.\nBasics API Version 2006-03-01 1888",
      "start_idx": 2049532,
      "end_idx": 2050478,
      "metadata": {
        "num_sentences": 11,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1894",
      "text": "Amazon Simple Storage Service API Reference\ndef initialize(bucket_cors)\n@bucket_cors = bucket_cors\nend\n# Deletes the CORS configuration of a bucket.\n#\n# @return [Boolean] True if the CORS rules were deleted; otherwise, false.\ndef delete_cors\n@bucket_cors.delete\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't delete CORS rules for #{@bucket_cors.bucket.name}. Here's why:\n#{e.message}\"\nfalse\nend\nend\n\u2022 For API details, see DeleteBucketCors in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketEncryption with a CLI\nThe following code examples show how to use DeleteBucketEncryption.\nCLI\nAWS CLI\nTo delete the server-side encryption configuration of a bucket\nThe following delete-bucket-encryption example deletes the server-side encryption\nconfiguration of the specified bucket.\naws s3api delete-bucket-encryption \\\n--bucket my-bucket\nThis command produces no output.\nBasics API Version 2006-03-01 1889",
      "start_idx": 2050480,
      "end_idx": 2051608,
      "metadata": {
        "num_sentences": 10,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1895",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucketEncryption in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This disables the encryption enabled for the S3 bucket provided.\nRemove-S3BucketEncryption -BucketName 'amzn-s3-demo-bucket'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3BucketEncryption (DeleteBucketEncryption)\" on\ntarget \"s3casetestbucket\".\n[Y] Yes [A] Yes to All [N] No [L] No to All [S] Suspend [?] Help (default is\n\"Y\"): Y\n\u2022 For API details, see DeleteBucketEncryption in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketInventoryConfiguration with a CLI\nThe following code examples show how to use DeleteBucketInventoryConfiguration.\nCLI\nAWS CLI\nTo delete the inventory configuration of a bucket\nThe following delete-bucket-inventory-configuration example deletes the\ninventory configuration with ID 1 for the specified bucket.\naws s3api delete-bucket-inventory-configuration \\\nBasics API Version 2006-03-01 1890",
      "start_idx": 2051610,
      "end_idx": 2052870,
      "metadata": {
        "num_sentences": 11,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1896",
      "text": "Amazon Simple Storage Service API Reference\n--bucket my-bucket \\\n--id 1\nThis command produces no output.\n\u2022 For API details, see DeleteBucketInventoryConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes the invventory named 'testInventoryName'\ncorresponding to the given S3 bucket.\nRemove-S3BucketInventoryConfiguration -BucketName 'amzn-s3-demo-bucket' -\nInventoryId 'testInventoryName'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3BucketInventoryConfiguration\n(DeleteBucketInventoryConfiguration)\" on target \"s3testbucket\".\n[Y] Yes [A] Yes to All [N] No [L] No to All [S] Suspend [?] Help (default is\n\"Y\"): Y\n\u2022 For API details, see DeleteBucketInventoryConfiguration in AWS Tools for PowerShell\nCmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketLifecycle with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketLifecycle.\nBasics API Version 2006-03-01 1891",
      "start_idx": 2052872,
      "end_idx": 2054060,
      "metadata": {
        "num_sentences": 11,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1897",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// This method removes the Lifecycle configuration from the named\n/// S3 bucket.\n/// </summary>\n/// <param name=\"client\">The S3 client object used to call\n/// the RemoveLifecycleConfigAsync method.</param>\n/// <param name=\"bucketName\">A string representing the name of the\n/// S3 bucket from which the configuration will be removed.</param>\npublic static async Task RemoveLifecycleConfigAsync(IAmazonS3 client,\nstring bucketName)\n{\nvar request = new DeleteLifecycleConfigurationRequest()\n{\nBucketName = bucketName,\n};\nawait client.DeleteLifecycleConfigurationAsync(request);\n}\n\u2022 For API details, see DeleteBucketLifecycle in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command deletes a lifecycle configuration from a bucket named my-bucket:\naws s3api delete-bucket-lifecycle --bucket my-bucket\nBasics API Version 2006-03-01 1892",
      "start_idx": 2054062,
      "end_idx": 2055110,
      "metadata": {
        "num_sentences": 5,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1898",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucketLifecycle in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef delete_lifecycle_configuration(self):\n\"\"\"\nRemove the lifecycle configuration from the specified bucket.\n\"\"\"\ntry:\nself.bucket.LifecycleConfiguration().delete()\nlogger.info(\n\"Deleted lifecycle configuration for bucket '%s'.\",\nself.bucket.name\n)\nexcept ClientError:\nlogger.exception(\n\"Couldn't delete lifecycle configuration for bucket '%s'.\",\nself.bucket.name,\n)\nraise\nBasics API Version 2006-03-01 1893",
      "start_idx": 2055112,
      "end_idx": 2056062,
      "metadata": {
        "num_sentences": 10,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1899",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucketLifecycle in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketMetricsConfiguration with a CLI\nThe following code examples show how to use DeleteBucketMetricsConfiguration.\nCLI\nAWS CLI\nTo delete a metrics configuration for a bucket\nThe following delete-bucket-metrics-configuration example removes the metrics\nconfiguration for the specified bucket and ID.\naws s3api delete-bucket-metrics-configuration \\\n--bucket my-bucket \\\n--id 123\nThis command produces no output.\n\u2022 For API details, see DeleteBucketMetricsConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command removes the metrics filter with name 'testmetrics' in the given\nS3 bucket.\nRemove-S3BucketMetricsConfiguration -BucketName 'amzn-s3-demo-bucket' -MetricsId\n'testmetrics'\n\u2022 For API details, see DeleteBucketMetricsConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nBasics API Version 2006-03-01 1894",
      "start_idx": 2056064,
      "end_idx": 2057283,
      "metadata": {
        "num_sentences": 10,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1900",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketPolicy with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketPolicy.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteBucketPolicy(const Aws::String &bucketName,\nconst Aws::S3::S3ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client client(clientConfig);\nAws::S3::Model::DeleteBucketPolicyRequest request;\nrequest.SetBucket(bucketName);\nAws::S3::Model::DeleteBucketPolicyOutcome outcome =\nclient.DeleteBucketPolicy(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: deleteBucketPolicy: \" <<\nerr.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nstd::cout << \"Policy was deleted from the bucket.\" << std::endl;\n}\nreturn outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1895",
      "start_idx": 2057285,
      "end_idx": 2058456,
      "metadata": {
        "num_sentences": 7,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1901",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see DeleteBucketPolicy in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command deletes a bucket policy from a bucket named my-bucket:\naws s3api delete-bucket-policy --bucket my-bucket\n\u2022 For API details, see DeleteBucketPolicy in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketPolicyRequest;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n*\n* For more information, see the following documentation topic:\n*\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class DeleteBucketPolicy {\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nBasics API Version 2006-03-01 1896",
      "start_idx": 2058458,
      "end_idx": 2059572,
      "metadata": {
        "num_sentences": 6,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1903",
      "text": "Amazon Simple Storage Service API Reference\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see DeleteBucketPolicy in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete the bucket policy.\nimport {\nDeleteBucketPolicyCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Remove the policy from an Amazon S3 bucket.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nawait client.send(\nnew DeleteBucketPolicyCommand({\nBucket: bucketName,\n}),\n);\nconsole.log(`Bucket policy deleted from \"${bucketName}\".`);\n} catch (caught) {\nif (\nBasics API Version 2006-03-01 1898",
      "start_idx": 2060699,
      "end_idx": 2061496,
      "metadata": {
        "num_sentences": 6,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1904",
      "text": "Amazon Simple Storage Service API Reference\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while deleting policy from ${bucketName}. The bucket\ndoesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while deleting policy from ${bucketName}. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see DeleteBucketPolicy in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun deleteS3BucketPolicy(bucketName: String?) {\nval request =\nDeleteBucketPolicyRequest {\nbucket = bucketName\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.deleteBucketPolicy(request)\nprintln(\"Done!\")\nBasics API Version 2006-03-01 1899",
      "start_idx": 2061498,
      "end_idx": 2062457,
      "metadata": {
        "num_sentences": 9,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1905",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\n\u2022 For API details, see DeleteBucketPolicy in AWS SDK for Kotlin API reference.\nPowerShell\nTools for PowerShell\nExample 1: The command removes the bucket policy associated with the given S3 bucket.\nRemove-S3BucketPolicy -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see DeleteBucketPolicy in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef delete_policy(self):\nBasics API Version 2006-03-01 1900",
      "start_idx": 2062459,
      "end_idx": 2063333,
      "metadata": {
        "num_sentences": 9,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1906",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"\nDelete the security policy from the bucket.\n\"\"\"\ntry:\nself.bucket.Policy().delete()\nlogger.info(\"Deleted policy for bucket '%s'.\", self.bucket.name)\nexcept ClientError:\nlogger.exception(\n\"Couldn't delete policy for bucket '%s'.\", self.bucket.name\n)\nraise\n\u2022 For API details, see DeleteBucketPolicy in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# Wraps an Amazon S3 bucket policy.\nclass BucketPolicyWrapper\nattr_reader :bucket_policy\n# @param bucket_policy [Aws::S3::BucketPolicy] A bucket policy object\nconfigured with an existing bucket.\ndef initialize(bucket_policy)\n@bucket_policy = bucket_policy\nend\ndef delete_policy\n@bucket_policy.delete\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't delete the policy from #{@bucket_policy.bucket.name}. Here's\nwhy: #{e.message}\"\nBasics API Version 2006-03-01 1901",
      "start_idx": 2063335,
      "end_idx": 2064338,
      "metadata": {
        "num_sentences": 10,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1907",
      "text": "Amazon Simple Storage Service API Reference\nfalse\nend\nend\n\u2022 For API details, see DeleteBucketPolicy in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketReplication with a CLI\nThe following code examples show how to use DeleteBucketReplication.\nCLI\nAWS CLI\nThe following command deletes a replication configuration from a bucket named my-\nbucket:\naws s3api delete-bucket-replication --bucket my-bucket\n\u2022 For API details, see DeleteBucketReplication in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Deletes the replication configuration associated with the bucket\nnamed 'mybucket'. Note that this operation requires permission for the\ns3:DeleteReplicationConfiguration action. You will be prompted for confirmation before\nthe operation proceeds - to suppress confirmation, use the -Force switch.\nRemove-S3BucketReplication -BucketName amzn-s3-demo-bucket\n\u2022 For API details, see DeleteBucketReplication in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 1902",
      "start_idx": 2064340,
      "end_idx": 2065560,
      "metadata": {
        "num_sentences": 10,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1908",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteBucketTagging with a CLI\nThe following code examples show how to use DeleteBucketTagging.\nCLI\nAWS CLI\nThe following command deletes a tagging configuration from a bucket named my-bucket:\naws s3api delete-bucket-tagging --bucket my-bucket\n\u2022 For API details, see DeleteBucketTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command removes all the tags associated with the given S3 bucket.\nRemove-S3BucketTagging -BucketName 'amzn-s3-demo-bucket'\nOutput:\nConfirm\nAre you sure you want to perform this action?\nPerforming the operation \"Remove-S3BucketTagging (DeleteBucketTagging)\" on target\n\"s3testbucket\".\n[Y] Yes [A] Yes to All [N] No [L] No to All [S] Suspend [?] Help (default is\n\"Y\"): Y\n\u2022 For API details, see DeleteBucketTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 1903",
      "start_idx": 2065562,
      "end_idx": 2066900,
      "metadata": {
        "num_sentences": 12,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1909",
      "text": "Amazon Simple Storage Service API Reference\nUse DeleteBucketWebsite with an AWS SDK or CLI\nThe following code examples show how to use DeleteBucketWebsite.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteBucketWebsite(const Aws::String &bucketName,\nconst Aws::S3::S3ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client client(clientConfig);\nAws::S3::Model::DeleteBucketWebsiteRequest request;\nrequest.SetBucket(bucketName);\nAws::S3::Model::DeleteBucketWebsiteOutcome outcome =\nclient.DeleteBucketWebsite(request);\nif (!outcome.IsSuccess()) {\nauto err = outcome.GetError();\nstd::cerr << \"Error: deleteBucketWebsite: \" <<\nerr.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nstd::cout << \"Website configuration was removed.\" << std::endl;\n}\nreturn outcome.IsSuccess();\n}\n\u2022 For API details, see DeleteBucketWebsite in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 1904",
      "start_idx": 2066902,
      "end_idx": 2067920,
      "metadata": {
        "num_sentences": 6,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1910",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command deletes a website configuration from a bucket named my-bucket:\naws s3api delete-bucket-website --bucket my-bucket\n\u2022 For API details, see DeleteBucketWebsite in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.DeleteBucketWebsiteRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n* <p>\n* For more information, see the following documentation topic:\n* <p>\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class DeleteWebsiteConfiguration {\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nUsage: <bucketName>\nBasics API Version 2006-03-01 1905",
      "start_idx": 2067922,
      "end_idx": 2069007,
      "metadata": {
        "num_sentences": 5,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1912",
      "text": "Amazon Simple Storage Service API Reference\nSystem.out.println(\"Failed to delete website configuration!\");\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see DeleteBucketWebsite in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete the website configuration from the bucket.\nimport {\nDeleteBucketWebsiteCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Remove the website configuration for a bucket.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nawait client.send(\nnew DeleteBucketWebsiteCommand({\nBucket: bucketName,\n}),\n);\n// The response code will be successful for both removed configurations and\n// configurations that did not exist in the first place.\nBasics API Version 2006-03-01 1907",
      "start_idx": 2070177,
      "end_idx": 2071116,
      "metadata": {
        "num_sentences": 8,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1914",
      "text": "Amazon Simple Storage Service API Reference\nPerforming the operation \"Remove-S3BucketWebsite (DeleteBucketWebsite)\" on target\n\"s3testbucket\".\n[Y] Yes [A] Yes to All [N] No [L] No to All [S] Suspend [?] Help (default is\n\"Y\"): Y\n\u2022 For API details, see DeleteBucketWebsite in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteObject with an AWS SDK or CLI\nThe following code examples show how to use DeleteObject.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Work with Amazon S3 object integrity\n\u2022 Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete an object in a non-versioned S3 bucket.\nusing System;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to delete an object from a non-versioned Amazon\nBasics API Version 2006-03-01 1909",
      "start_idx": 2072120,
      "end_idx": 2073370,
      "metadata": {
        "num_sentences": 11,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1918",
      "text": "Amazon Simple Storage Service API Reference\n/// <param name=\"objectKey\">The name of the Amazon S3 object co create.</\nparam>\n/// <returns>The Version ID of the created object.</returns>\npublic static async Task<string> PutAnObject(IAmazonS3 client, string\nbucketName, string objectKey)\n{\nPutObjectRequest request = new PutObjectRequest()\n{\nBucketName = bucketName,\nKey = objectKey,\nContentBody = \"This is the content body!\",\n};\nPutObjectResponse response = await client.PutObjectAsync(request);\nreturn response.VersionId;\n}\n}\n\u2022 For API details, see DeleteObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\nBasics API Version 2006-03-01 1913",
      "start_idx": 2077491,
      "end_idx": 2078665,
      "metadata": {
        "num_sentences": 6,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1919",
      "text": "Amazon Simple Storage Service API Reference\n# function delete_item_in_bucket\n#\n# This function deletes the specified file from the specified bucket.\n#\n# Parameters:\n# $1 - The name of the bucket.\n# $2 - The key (file name) in the bucket to delete.\n# Returns:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction delete_item_in_bucket() {\nlocal bucket_name=$1\nlocal key=$2\nlocal response\nresponse=$(aws s3api delete-object \\\n--bucket \"$bucket_name\" \\\n--key \"$key\")\n# shellcheck disable=SC2181\nif [[ $? -ne 0 ]]; then\nerrecho \"ERROR: AWS reports s3api delete-object operation failed.\\n\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see DeleteObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1914",
      "start_idx": 2078667,
      "end_idx": 2079592,
      "metadata": {
        "num_sentences": 10,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1921",
      "text": "Amazon Simple Storage Service API Reference\n}\nFor more information about deleting objects, see Deleting Objects in the Amazon S3\nDeveloper Guide.\n\u2022 For API details, see DeleteObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// DeleteObject deletes an object from a bucket.\nfunc (actor S3Actions) DeleteObject(ctx context.Context, bucket string, key\nstring, versionId string, bypassGovernance bool) (bool, error) {\ndeleted := false\ninput := &s3.DeleteObjectInput{\nBucket: aws.String(bucket),\nKey: aws.String(key),\n}\nif versionId != \"\" {\ninput.VersionId = aws.String(versionId)\n}\nif bypassGovernance {\ninput.BypassGovernanceRetention = aws.Bool(true)\n}\n_, err := actor.S3Client.DeleteObject(ctx, input)\nif err != nil {\nBasics API Version 2006-03-01 1916",
      "start_idx": 2080692,
      "end_idx": 2081685,
      "metadata": {
        "num_sentences": 7,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1922",
      "text": "Amazon Simple Storage Service API Reference\nvar noKey *types.NoSuchKey\nvar apiErr *smithy.GenericAPIError\nif errors.As(err, &noKey) {\nlog.Printf(\"Object %s does not exist in %s.\\n\", key, bucket)\nerr = noKey\n} else if errors.As(err, &apiErr) {\nswitch apiErr.ErrorCode() {\ncase \"AccessDenied\":\nlog.Printf(\"Access denied: cannot delete object %s from %s.\\n\", key, bucket)\nerr = nil\ncase \"InvalidArgument\":\nif bypassGovernance {\nlog.Printf(\"You cannot specify bypass governance on a bucket without lock\nenabled.\")\nerr = nil\n}\n}\n}\n} else {\ndeleted = true\n}\nreturn deleted, err\n}\n\u2022 For API details, see DeleteObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Deletes an object from an S3 bucket asynchronously.\n*\nBasics API Version 2006-03-01 1917",
      "start_idx": 2081687,
      "end_idx": 2082570,
      "metadata": {
        "num_sentences": 6,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1923",
      "text": "Amazon Simple Storage Service API Reference\n* @param bucketName the name of the S3 bucket\n* @param key the key (file name) of the object to be deleted\n* @return a {@link CompletableFuture} that completes when the object has\nbeen deleted\n*/\npublic CompletableFuture<Void> deleteObjectFromBucketAsync(String bucketName,\nString key) {\nDeleteObjectRequest deleteObjectRequest = DeleteObjectRequest.builder()\n.bucket(bucketName)\n.key(key)\n.build();\nCompletableFuture<DeleteObjectResponse> response =\ngetAsyncClient().deleteObject(deleteObjectRequest);\nresponse.whenComplete((deleteRes, ex) -> {\nif (deleteRes != null) {\nlogger.info(key + \" was deleted\");\n} else {\nthrow new RuntimeException(\"An S3 exception occurred during\ndelete\", ex);\n}\n});\nreturn response.thenApply(r -> null);\n}\n\u2022 For API details, see DeleteObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete an object.\nimport {\nBasics API Version 2006-03-01 1918",
      "start_idx": 2082572,
      "end_idx": 2083646,
      "metadata": {
        "num_sentences": 5,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1924",
      "text": "Amazon Simple Storage Service API Reference\nDeleteObjectCommand,\nS3Client,\nS3ServiceException,\nwaitUntilObjectNotExists,\n} from \"@aws-sdk/client-s3\";\n/**\n* Delete one object from an Amazon S3 bucket.\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\nconst client = new S3Client({});\ntry {\nawait client.send(\nnew DeleteObjectCommand({\nBucket: bucketName,\nKey: key,\n}),\n);\nawait waitUntilObjectNotExists(\n{ client },\n{ Bucket: bucketName, Key: key },\n);\n// A successful delete, or a delete for a non-existent object, both return\n// a 204 response code.\nconsole.log(\n`The object \"${key}\" from bucket \"${bucketName}\" was deleted, or it didn't\nexist.`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while deleting object from ${bucketName}. The bucket\ndoesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while deleting object from ${bucketName}. ${caught.name}:\n${caught.message}`,\n);\nBasics API Version 2006-03-01 1919",
      "start_idx": 2083648,
      "end_idx": 2084750,
      "metadata": {
        "num_sentences": 5,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1925",
      "text": "Amazon Simple Storage Service API Reference\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For API details, see DeleteObject in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete an object.\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\ndef delete(self):\n\"\"\"\nDeletes the object.\n\"\"\"\ntry:\nself.object.delete()\nself.object.wait_until_not_exists()\nlogger.info(\nBasics API Version 2006-03-01 1920",
      "start_idx": 2084752,
      "end_idx": 2085514,
      "metadata": {
        "num_sentences": 9,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1928",
      "text": "Amazon Simple Storage Service API Reference\n)\nif \"DeleteMarkers\" in response:\nlatest_version = response[\"DeleteMarkers\"][0]\nif latest_version[\"IsLatest\"]:\nlogger.info(\n\"Object %s was indeed deleted on %s. Let's revive it.\",\nobject_key,\nlatest_version[\"LastModified\"],\n)\nobj = bucket.Object(object_key)\nobj.Version(latest_version[\"VersionId\"]).delete()\nlogger.info(\n\"Revived %s, active version is now %s with body '%s'\",\nobject_key,\nobj.version_id,\nobj.get()[\"Body\"].read(),\n)\nelse:\nlogger.warning(\n\"Delete marker is not the latest version for %s!\", object_key\n)\nelif \"Versions\" in response:\nlogger.warning(\"Got an active version for %s, nothing to do.\",\nobject_key)\nelse:\nlogger.error(\"Couldn't get any version info for %s.\", object_key)\nCreate a Lambda handler that removes a delete marker from an S3 object. This handler can\nbe used to efficiently clean up extraneous delete markers in a versioned bucket.\nimport logging\nfrom urllib import parse\nimport boto3\nfrom botocore.exceptions import ClientError\nlogger = logging.getLogger(__name__)\nlogger.setLevel(\"INFO\")\ns3 = boto3.client(\"s3\")\nBasics API Version 2006-03-01 1923",
      "start_idx": 2087949,
      "end_idx": 2089073,
      "metadata": {
        "num_sentences": 8,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1929",
      "text": "Amazon Simple Storage Service API Reference\ndef lambda_handler(event, context):\n\"\"\"\nRemoves a delete marker from the specified versioned object.\n:param event: The S3 batch event that contains the ID of the delete marker\nto remove.\n:param context: Context about the event.\n:return: A result structure that Amazon S3 uses to interpret the result of\nthe\noperation. When the result code is TemporaryFailure, S3 retries the\noperation.\n\"\"\"\n# Parse job parameters from Amazon S3 batch operations\ninvocation_id = event[\"invocationId\"]\ninvocation_schema_version = event[\"invocationSchemaVersion\"]\nresults = []\nresult_code = None\nresult_string = None\ntask = event[\"tasks\"][0]\ntask_id = task[\"taskId\"]\ntry:\nobj_key = parse.unquote(task[\"s3Key\"], encoding=\"utf-8\")\nobj_version_id = task[\"s3VersionId\"]\nbucket_name = task[\"s3BucketArn\"].split(\":\")[-1]\nlogger.info(\n\"Got task: remove delete marker %s from object %s.\", obj_version_id,\nobj_key\n)\ntry:\n# If this call does not raise an error, the object version is not a\ndelete\n# marker and should not be deleted.\nresponse = s3.head_object(\nBucket=bucket_name, Key=obj_key, VersionId=obj_version_id\n)\nresult_code = \"PermanentFailure\"\nresult_string = (\nBasics API Version 2006-03-01 1924",
      "start_idx": 2089075,
      "end_idx": 2090294,
      "metadata": {
        "num_sentences": 8,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1931",
      "text": "Amazon Simple Storage Service API Reference\n# Mark all other exceptions as permanent failures.\nresult_code = \"PermanentFailure\"\nresult_string = str(error)\nlogger.exception(error)\nfinally:\nresults.append(\n{\n\"taskId\": task_id,\n\"resultCode\": result_code,\n\"resultString\": result_string,\n}\n)\nreturn {\n\"invocationSchemaVersion\": invocation_schema_version,\n\"treatMissingKeysAs\": \"PermanentFailure\",\n\"invocationId\": invocation_id,\n\"results\": results,\n}\n\u2022 For API details, see DeleteObject in AWS SDK for Python (Boto3) API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// Delete an object from a bucket.\npub async fn remove_object(\nclient: &aws_sdk_s3::Client,\nbucket: &str,\nkey: &str,\n) -> Result<(), S3ExampleError> {\nclient\n.delete_object()\nBasics API Version 2006-03-01 1926",
      "start_idx": 2091433,
      "end_idx": 2092311,
      "metadata": {
        "num_sentences": 6,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1932",
      "text": "Amazon Simple Storage Service API Reference\n.bucket(bucket)\n.key(key)\n.send()\n.await?;\n// There are no modeled errors to handle when deleting an object.\nOk(())\n}\n\u2022 For API details, see DeleteObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTRY.\nlo_s3->deleteobject(\niv_bucket = iv_bucket_name\niv_key = iv_object_key\n).\nMESSAGE 'Object deleted from S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see DeleteObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 1927",
      "start_idx": 2092313,
      "end_idx": 2093018,
      "metadata": {
        "num_sentences": 15,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1933",
      "text": "Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func deleteFile(bucket: String, key: String) async throws {\nlet input = DeleteObjectInput(\nbucket: bucket,\nkey: key\n)\ndo {\n_ = try await client.deleteObject(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Deleting a file.\"))\nthrow error\n}\n}\n\u2022 For API details, see DeleteObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteObjectTagging with a CLI\nThe following code examples show how to use DeleteObjectTagging.\nBasics API Version 2006-03-01 1928",
      "start_idx": 2093020,
      "end_idx": 2093904,
      "metadata": {
        "num_sentences": 8,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1935",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteObjects with an AWS SDK or CLI\nThe following code examples show how to use DeleteObjects.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Learn the basics\n\u2022 Delete all objects in a bucket\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete all objects in an S3 bucket.\n/// <summary>\n/// Delete all of the objects stored in an existing Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <param name=\"bucketName\">The name of the bucket from which the\n/// contents will be deleted.</param>\n/// <returns>A boolean value that represents the success or failure of\n/// deleting all of the objects in the bucket.</returns>\npublic static async Task<bool> DeleteBucketContentsAsync(IAmazonS3\nclient, string bucketName)\n{\n// Iterate over the contents of the bucket and delete all objects.\nvar request = new ListObjectsV2Request\n{\nBasics API Version 2006-03-01 1930",
      "start_idx": 2094909,
      "end_idx": 2096297,
      "metadata": {
        "num_sentences": 10,
        "num_words": 222,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1937",
      "text": "Amazon Simple Storage Service API Reference\n/// </summary>\npublic class DeleteMultipleObjects\n{\n/// <summary>\n/// The Main method initializes the Amazon S3 client and the name of\n/// the bucket and then passes those values to MultiObjectDeleteAsync.\n/// </summary>\npublic static async Task Main()\n{\nconst string bucketName = \"amzn-s3-demo-bucket\";\n// If the Amazon S3 bucket from which you wish to delete objects is\nnot\n// located in the same AWS Region as the default user, define the\n// AWS Region for the Amazon S3 bucket as a parameter to the client\n// constructor.\nIAmazonS3 s3Client = new AmazonS3Client();\nawait MultiObjectDeleteAsync(s3Client, bucketName);\n}\n/// <summary>\n/// This method uses the passed Amazon S3 client to first create and then\n/// delete three files from the named bucket.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used to\ncall\n/// Amazon S3 methods.</param>\n/// <param name=\"bucketName\">The name of the Amazon S3 bucket where\nobjects\n/// will be created and then deleted.</param>\npublic static async Task MultiObjectDeleteAsync(IAmazonS3 client, string\nbucketName)\n{\n// Create three sample objects which we will then delete.\nvar keysAndVersions = await PutObjectsAsync(client, 3, bucketName);\n// Now perform the multi-object delete, passing the key names and\n// version IDs. Since we are working with a non-versioned bucket,\n// the object keys collection includes null version IDs.\nDeleteObjectsRequest multiObjectDeleteRequest = new\nDeleteObjectsRequest\n{\nBucketName = bucketName,\nBasics API Version 2006-03-01 1932",
      "start_idx": 2097243,
      "end_idx": 2098826,
      "metadata": {
        "num_sentences": 7,
        "num_words": 233,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1938",
      "text": "Amazon Simple Storage Service API Reference\nObjects = keysAndVersions,\n};\n// You can add a specific object key to the delete request using the\n// AddKey method of the multiObjectDeleteRequest.\ntry\n{\nDeleteObjectsResponse response = await\nclient.DeleteObjectsAsync(multiObjectDeleteRequest);\nConsole.WriteLine(\"Successfully deleted all the {0} items\",\nresponse.DeletedObjects.Count);\n}\ncatch (DeleteObjectsException e)\n{\nPrintDeletionErrorStatus(e);\n}\n}\n/// <summary>\n/// Prints the list of errors raised by the call to DeleteObjectsAsync.\n/// </summary>\n/// <param name=\"ex\">A collection of exceptions returned by the call to\n/// DeleteObjectsAsync.</param>\npublic static void PrintDeletionErrorStatus(DeleteObjectsException ex)\n{\nDeleteObjectsResponse errorResponse = ex.Response;\nConsole.WriteLine(\"x {0}\", errorResponse.DeletedObjects.Count);\nConsole.WriteLine($\"Successfully deleted\n{errorResponse.DeletedObjects.Count}.\");\nConsole.WriteLine($\"No. of objects failed to delete =\n{errorResponse.DeleteErrors.Count}\");\nConsole.WriteLine(\"Printing error data...\");\nforeach (DeleteError deleteError in errorResponse.DeleteErrors)\n{\nConsole.WriteLine($\"Object Key:\n{deleteError.Key}\\t{deleteError.Code}\\t{deleteError.Message}\");\n}\n}\n/// <summary>\n/// This method creates simple text file objects that can be used in\n/// the delete method.\nBasics API Version 2006-03-01 1933",
      "start_idx": 2098828,
      "end_idx": 2100199,
      "metadata": {
        "num_sentences": 6,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1941",
      "text": "Amazon Simple Storage Service API Reference\n// Delete objects (without specifying object version in the request).\nvar deletedObjects = await DeleteObjectsAsync(client, bucketName);\n// Additional exercise - remove the delete markers Amazon S3 returned\nfrom\n// the preceding response. This results in the objects reappearing\n// in the bucket (you can verify the appearance/disappearance of\n// objects in the console).\nawait RemoveDeleteMarkersAsync(client, bucketName, deletedObjects);\n}\n/// <summary>\n/// Creates and then deletes non-versioned Amazon S3 objects and then\ndeletes\n/// them again. The method returns a list of the Amazon S3 objects\ndeleted.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used to\ncall\n/// PubObjectsAsync and NonVersionedDeleteAsync.</param>\n/// <param name=\"bucketName\">The name of the bucket where the objects\n/// will be created and then deleted.</param>\n/// <returns>A list of DeletedObjects.</returns>\npublic static async Task<List<DeletedObject>>\nDeleteObjectsAsync(IAmazonS3 client, string bucketName)\n{\n// Upload the sample objects.\nvar keysAndVersions2 = await PutObjectsAsync(client, bucketName, 3);\n// Delete objects using only keys. Amazon S3 creates a delete marker\nand\n// returns its version ID in the response.\nList<DeletedObject> deletedObjects = await\nNonVersionedDeleteAsync(client, bucketName, keysAndVersions2);\nreturn deletedObjects;\n}\n/// <summary>\n/// This method creates several temporary objects and then deletes them.\n/// </summary>\n/// <param name=\"client\">The S3 client.</param>\n/// <param name=\"bucketName\">Name of the bucket.</param>\n/// <returns>Async task.</returns>\nBasics API Version 2006-03-01 1936",
      "start_idx": 2102822,
      "end_idx": 2104517,
      "metadata": {
        "num_sentences": 10,
        "num_words": 217,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1942",
      "text": "Amazon Simple Storage Service API Reference\npublic static async Task DeleteObjectVersionsAsync(IAmazonS3 client,\nstring bucketName)\n{\n// Upload the sample objects.\nvar keysAndVersions1 = await PutObjectsAsync(client, bucketName, 3);\n// Delete the specific object versions.\nawait VersionedDeleteAsync(client, bucketName, keysAndVersions1);\n}\n/// <summary>\n/// Displays the list of information about deleted files to the console.\n/// </summary>\n/// <param name=\"e\">Error information from the delete process.</param>\nprivate static void DisplayDeletionErrors(DeleteObjectsException e)\n{\nvar errorResponse = e.Response;\nConsole.WriteLine($\"No. of objects successfully deleted =\n{errorResponse.DeletedObjects.Count}\");\nConsole.WriteLine($\"No. of objects failed to delete =\n{errorResponse.DeleteErrors.Count}\");\nConsole.WriteLine(\"Printing error data...\");\nforeach (var deleteError in errorResponse.DeleteErrors)\n{\nConsole.WriteLine($\"Object Key:\n{deleteError.Key}\\t{deleteError.Code}\\t{deleteError.Message}\");\n}\n}\n/// <summary>\n/// Delete multiple objects from a version-enabled bucket.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used to\ncall\n/// DeleteObjectVersionsAsync, DeleteObjectsAsync, and\n/// RemoveDeleteMarkersAsync.</param>\n/// <param name=\"bucketName\">The name of the bucket from which to delete\n/// objects.</param>\n/// <param name=\"keys\">A list of key names for the objects to delete.</\nparam>\nprivate static async Task VersionedDeleteAsync(IAmazonS3 client, string\nbucketName, List<KeyVersion> keys)\n{\nvar multiObjectDeleteRequest = new DeleteObjectsRequest\nBasics API Version 2006-03-01 1937",
      "start_idx": 2104519,
      "end_idx": 2106159,
      "metadata": {
        "num_sentences": 7,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1944",
      "text": "Amazon Simple Storage Service API Reference\n}\n// Execute DeleteObjectsAsync.\n// The DeleteObjectsAsync method adds a delete marker for each\n// object deleted. You can verify that the objects were removed\n// using the Amazon S3 console.\nDeleteObjectsResponse response;\ntry\n{\nConsole.WriteLine(\"Executing NonVersionedDelete...\");\nresponse = await\nclient.DeleteObjectsAsync(multiObjectDeleteRequest);\nConsole.WriteLine(\"Successfully deleted all the {0} items\",\nresponse.DeletedObjects.Count);\n}\ncatch (DeleteObjectsException ex)\n{\nDisplayDeletionErrors(ex);\nthrow; // Some deletions failed. Investigate before continuing.\n}\n// This response contains the DeletedObjects list which we use to\ndelete the delete markers.\nreturn response.DeletedObjects;\n}\n/// <summary>\n/// Deletes the markers left after deleting the temporary objects.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used to\ncall\n/// DeleteObjectVersionsAsync, DeleteObjectsAsync, and\n/// RemoveDeleteMarkersAsync.</param>\n/// <param name=\"bucketName\">The name of the bucket from which to delete\n/// objects.</param>\n/// <param name=\"deletedObjects\">A list of the objects that were\ndeleted.</param>\nprivate static async Task RemoveDeleteMarkersAsync(IAmazonS3 client,\nstring bucketName, List<DeletedObject> deletedObjects)\n{\nvar keyVersionList = new List<KeyVersion>();\nforeach (var deletedObject in deletedObjects)\n{\nBasics API Version 2006-03-01 1939",
      "start_idx": 2107539,
      "end_idx": 2108983,
      "metadata": {
        "num_sentences": 8,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1946",
      "text": "Amazon Simple Storage Service API Reference\nprivate static async Task<List<KeyVersion>> PutObjectsAsync(IAmazonS3\nclient, string bucketName, int number)\n{\nvar keys = new List<KeyVersion>();\nfor (var i = 0; i < number; i++)\n{\nstring key = \"ObjectToDelete-\" + new System.Random().Next();\nPutObjectRequest request = new PutObjectRequest\n{\nBucketName = bucketName,\nKey = key,\nContentBody = \"This is the content body!\",\n};\nvar response = await client.PutObjectAsync(request);\nKeyVersion keyVersion = new KeyVersion\n{\nKey = key,\nVersionId = response.VersionId,\n};\nkeys.Add(keyVersion);\n}\nreturn keys;\n}\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1941",
      "start_idx": 2110354,
      "end_idx": 2111213,
      "metadata": {
        "num_sentences": 5,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1948",
      "text": "Amazon Simple Storage Service API Reference\nerrecho \"ERROR: AWS reports s3api delete-object operation failed.\\n\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see DeleteObjects in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::deleteObjects(const std::vector<Aws::String> &objectKeys,\nconst Aws::String &fromBucket,\nconst Aws::S3::S3ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client client(clientConfig);\nAws::S3::Model::DeleteObjectsRequest request;\nAws::S3::Model::Delete deleteObject;\nfor (const Aws::String &objectKey: objectKeys) {\ndeleteObject.AddObjects(Aws::S3::Model::ObjectIdentifier().WithKey(objectKey));\n}\nrequest.SetDelete(deleteObject);\nrequest.SetBucket(fromBucket);\nAws::S3::Model::DeleteObjectsOutcome outcome =\nclient.DeleteObjects(request);\nif (!outcome.IsSuccess()) {\nauto err = outcome.GetError();\nstd::cerr << \"Error deleting objects. \" <<\nBasics API Version 2006-03-01 1943",
      "start_idx": 2112506,
      "end_idx": 2113542,
      "metadata": {
        "num_sentences": 5,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1950",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"Deleted\": [\n{\n\"DeleteMarkerVersionId\": \"mYAT5Mc6F7aeUL8SS7FAAqUPO1koHwzU\",\n\"Key\": \"test1.txt\",\n\"DeleteMarker\": true\n}\n]\n}\n\u2022 For API details, see DeleteObjects in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// DeleteObjects deletes a list of objects from a bucket.\nfunc (actor S3Actions) DeleteObjects(ctx context.Context, bucket string, objects\n[]types.ObjectIdentifier, bypassGovernance bool) error {\nif len(objects) == 0 {\nreturn nil\n}\ninput := s3.DeleteObjectsInput{\nBucket: aws.String(bucket),\nDelete: &types.Delete{\nBasics API Version 2006-03-01 1945",
      "start_idx": 2114362,
      "end_idx": 2115201,
      "metadata": {
        "num_sentences": 6,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1951",
      "text": "Amazon Simple Storage Service API Reference\nObjects: objects,\nQuiet: aws.Bool(true),\n},\n}\nif bypassGovernance {\ninput.BypassGovernanceRetention = aws.Bool(true)\n}\ndelOut, err := actor.S3Client.DeleteObjects(ctx, &input)\nif err != nil || len(delOut.Errors) > 0 {\nlog.Printf(\"Error deleting objects from bucket %s.\\n\", bucket)\nif err != nil {\nvar noBucket *types.NoSuchBucket\nif errors.As(err, &noBucket) {\nlog.Printf(\"Bucket %s does not exist.\\n\", bucket)\nerr = noBucket\n}\n} else if len(delOut.Errors) > 0 {\nfor _, outErr := range delOut.Errors {\nlog.Printf(\"%s: %s\\n\", *outErr.Key, *outErr.Message)\n}\nerr = fmt.Errorf(\"%s\", *delOut.Errors[0].Message)\n}\n}\nreturn err\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.core.sync.RequestBody;\nBasics API Version 2006-03-01 1946",
      "start_idx": 2115203,
      "end_idx": 2116174,
      "metadata": {
        "num_sentences": 4,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1954",
      "text": "Amazon Simple Storage Service API Reference\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete multiple objects.\nimport {\nDeleteObjectsCommand,\nS3Client,\nS3ServiceException,\nwaitUntilObjectNotExists,\n} from \"@aws-sdk/client-s3\";\n/**\n* Delete multiple objects from an S3 bucket.\n* @param {{ bucketName: string, keys: string[] }}\n*/\nexport const main = async ({ bucketName, keys }) => {\nconst client = new S3Client({});\ntry {\nconst { Deleted } = await client.send(\nnew DeleteObjectsCommand({\nBucket: bucketName,\nDelete: {\nBasics API Version 2006-03-01 1949",
      "start_idx": 2118579,
      "end_idx": 2119428,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1955",
      "text": "Amazon Simple Storage Service API Reference\nObjects: keys.map((k) => ({ Key: k })),\n},\n}),\n);\nfor (const key in keys) {\nawait waitUntilObjectNotExists(\n{ client },\n{ Bucket: bucketName, Key: key },\n);\n}\nconsole.log(\n`Successfully deleted ${Deleted.length} objects from S3 bucket. Deleted\nobjects:`,\n);\nconsole.log(Deleted.map((d) => ` \u2022 ${d.Key}`).join(\"\\n\"));\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while deleting objects from ${bucketName}. The bucket\ndoesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while deleting objects from ${bucketName}.\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For API details, see DeleteObjects in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1950",
      "start_idx": 2119430,
      "end_idx": 2120299,
      "metadata": {
        "num_sentences": 5,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1956",
      "text": "Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun deleteBucketObjects(\nbucketName: String,\nobjectName: String,\n) {\nval objectId =\nObjectIdentifier {\nkey = objectName\n}\nval delOb =\nDelete {\nobjects = listOf(objectId)\n}\nval request =\nDeleteObjectsRequest {\nbucket = bucketName\ndelete = delOb\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.deleteObjects(request)\nprintln(\"$objectName was deleted from $bucketName\")\n}\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 1951",
      "start_idx": 2120301,
      "end_idx": 2120981,
      "metadata": {
        "num_sentences": 4,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1957",
      "text": "Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete a set of objects from a list of keys.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\ntry {\n$objects = [];\nforeach ($contents['Contents'] as $content) {\n$objects[] = [\n'Key' => $content['Key'],\n];\n}\n$this->s3client->deleteObjects([\n'Bucket' => $this->bucketName,\n'Delete' => [\n'Objects' => $objects,\n],\n]);\n$check = $this->s3client->listObjectsV2([\n'Bucket' => $this->bucketName,\n]);\nif (count($check) <= 0) {\nthrow new Exception(\"Bucket wasn't empty.\");\n}\necho \"Deleted all objects and folders from $this->bucketName.\\n\";\n} catch (Exception $exception) {\necho \"Failed to delete $fileName from $this->bucketName with error:\n\" . $exception->getMessage();\nexit(\"Please fix error with object deletion before continuing.\");\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for PHP API Reference.\nBasics API Version 2006-03-01 1952",
      "start_idx": 2120983,
      "end_idx": 2122013,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1958",
      "text": "Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command removes the object \"sample.txt\" from bucket \"test-files\". You\nare prompted for confirmation before the command executes; to suppress the prompt\nuse the -Force switch.\nRemove-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt\nExample 2: This command removes the specified version of object \"sample.txt\" from\nbucket \"test-files\", assuming the bucket has been configured to enable object versions.\nRemove-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -VersionId\nHLbxnx6V9omT6AQYVpks8mmFKQcejpqt\nExample 3: This command removes objects \"sample1.txt\", \"sample2.txt\" and\n\"sample3.txt\" from bucket \"test-files\" as a single batch operation. The service response\nwill list all keys processed, regardless of the success or error status of the deletion. To\nobtain only errors for keys that were not able to be processed by the service add the -\nReportErrorsOnly parameter (this parameter can also be specified with the alias -Quiet.\nRemove-S3Object -BucketName amzn-s3-demo-bucket -KeyCollection @( \"sample1.txt\",\n\"sample2.txt\", \"sample3.txt\" )\nExample 4: This example uses an inline expression with the -KeyCollection parameter\nto obtain the keys of the objects to delete. Get-S3Object returns a collection of\nAmazon.S3.Model.S3Object instances, each of which has a Key member of type string\nidentifying the object.\nRemove-S3Object -bucketname \"amzn-s3-demo-bucket\" -KeyCollection (Get-S3Object\n\"test-files\" -KeyPrefix \"prefix/subprefix\" | select -ExpandProperty Key)\nExample 5: This example obtains all objects that have a key prefix \"prefix/subprefix\" in\nthe bucket and deletes them. Note that the incoming objects are processed one at a time.\nFor large collections consider passing the collection to the cmdlet's -InputObject (alias\n-S3ObjectCollection) parameter to enable the deletion to occur as a batch with a single\ncall to the service.\nBasics API Version 2006-03-01 1953",
      "start_idx": 2122015,
      "end_idx": 2124001,
      "metadata": {
        "num_sentences": 12,
        "num_words": 268,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1959",
      "text": "Amazon Simple Storage Service API Reference\nGet-S3Object -BucketName \"amzn-s3-demo-bucket\" -KeyPrefix \"prefix/subprefix\" |\nRemove-S3Object -Force\nExample 6: This example pipes a collection of Amazon.S3.Model.S3ObjectVersion\ninstances that represent delete markers to the cmdlet for deletion. Note that the\nincoming objects are processed one at a time. For large collections consider passing the\ncollection to the cmdlet's -InputObject (alias -S3ObjectCollection) parameter to enable\nthe deletion to occur as a batch with a single call to the service.\n(Get-S3Version -BucketName \"amzn-s3-demo-bucket\").Versions | Where\n{$_.IsDeleteMarker -eq \"True\"} | Remove-S3Object -Force\nExample 7: This script shows how to perform a batch delete of a set of objects (in\nthis case delete markers) by constructing an array of objects to be used with the -\nKeyAndVersionCollection parameter.\n$keyVersions = @()\n$markers = (Get-S3Version -BucketName $BucketName).Versions | Where\n{$_.IsDeleteMarker -eq \"True\"}\nforeach ($marker in $markers) { $keyVersions += @{ Key = $marker.Key; VersionId =\n$marker.VersionId } }\nRemove-S3Object -BucketName $BucketName -KeyAndVersionCollection $keyVersions -\nForce\n\u2022 For API details, see DeleteObjects in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete a set of objects by using a list of object keys.\nclass ObjectWrapper:\nBasics API Version 2006-03-01 1954",
      "start_idx": 2124003,
      "end_idx": 2125535,
      "metadata": {
        "num_sentences": 9,
        "num_words": 216,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1960",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\n@staticmethod\ndef delete_objects(bucket, object_keys):\n\"\"\"\nRemoves a list of objects from a bucket.\nThis operation is done as a batch in a single request.\n:param bucket: The bucket that contains the objects. This is a Boto3\nBucket\nresource.\n:param object_keys: The list of keys that identify the objects to remove.\n:return: The response that contains data about which objects were deleted\nand any that could not be deleted.\n\"\"\"\ntry:\nresponse = bucket.delete_objects(\nDelete={\"Objects\": [{\"Key\": key} for key in object_keys]}\n)\nif \"Deleted\" in response:\nlogger.info(\n\"Deleted objects '%s' from bucket '%s'.\",\n[del_obj[\"Key\"] for del_obj in response[\"Deleted\"]],\nbucket.name,\n)\nif \"Errors\" in response:\nlogger.warning(\n\"Could not delete objects '%s' from bucket '%s'.\",\n[\nf\"{del_obj['Key']}: {del_obj['Code']}\"\nfor del_obj in response[\"Errors\"]\n],\nbucket.name,\n)\nBasics API Version 2006-03-01 1955",
      "start_idx": 2125537,
      "end_idx": 2126739,
      "metadata": {
        "num_sentences": 12,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1961",
      "text": "Amazon Simple Storage Service API Reference\nexcept ClientError:\nlogger.exception(\"Couldn't delete any objects from bucket %s.\",\nbucket.name)\nraise\nelse:\nreturn response\nDelete all objects in a bucket.\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\n@staticmethod\ndef empty_bucket(bucket):\n\"\"\"\nRemove all objects from a bucket.\n:param bucket: The bucket to empty. This is a Boto3 Bucket resource.\n\"\"\"\ntry:\nbucket.objects.delete()\nlogger.info(\"Emptied bucket '%s'.\", bucket.name)\nexcept ClientError:\nlogger.exception(\"Couldn't empty bucket '%s'.\", bucket.name)\nraise\nPermanently delete a versioned object by deleting all of its versions.\ndef permanently_delete_object(bucket, object_key):\nBasics API Version 2006-03-01 1956",
      "start_idx": 2126741,
      "end_idx": 2127698,
      "metadata": {
        "num_sentences": 12,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1962",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"\nPermanently deletes a versioned object by deleting all of its versions.\nUsage is shown in the usage_demo_single_object function at the end of this\nmodule.\n:param bucket: The bucket that contains the object.\n:param object_key: The object to delete.\n\"\"\"\ntry:\nbucket.object_versions.filter(Prefix=object_key).delete()\nlogger.info(\"Permanently deleted all versions of object %s.\", object_key)\nexcept ClientError:\nlogger.exception(\"Couldn't delete all versions of %s.\", object_key)\nraise\n\u2022 For API details, see DeleteObjects in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# Deletes the objects in an Amazon S3 bucket and deletes the bucket.\n#\n# @param bucket [Aws::S3::Bucket] The bucket to empty and delete.\ndef delete_bucket(bucket)\nputs(\"\\nDo you want to delete all of the objects as well as the bucket (y/n)?\n\")\nanswer = gets.chomp.downcase\nif answer == 'y'\nbucket.objects.batch_delete!\nbucket.delete\nputs(\"Emptied and deleted bucket #{bucket.name}.\\n\")\nBasics API Version 2006-03-01 1957",
      "start_idx": 2127700,
      "end_idx": 2128875,
      "metadata": {
        "num_sentences": 14,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1963",
      "text": "Amazon Simple Storage Service API Reference\nend\nrescue Aws::Errors::ServiceError => e\nputs(\"Couldn't empty and delete bucket #{bucket.name}.\")\nputs(\"\\t#{e.code}: #{e.message}\")\nraise\nend\n\u2022 For API details, see DeleteObjects in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// Delete the objects in a bucket.\npub async fn delete_objects(\nclient: &aws_sdk_s3::Client,\nbucket_name: &str,\nobjects_to_delete: Vec<String>,\n) -> Result<(), S3ExampleError> {\n// Push into a mut vector to use `?` early return errors while building\nobject keys.\nlet mut delete_object_ids: Vec<aws_sdk_s3::types::ObjectIdentifier> = vec![];\nfor obj in objects_to_delete {\nlet obj_id = aws_sdk_s3::types::ObjectIdentifier::builder()\n.key(obj)\n.build()\n.map_err(|err| {\nS3ExampleError::new(format!(\"Failed to build key for\ndelete_object: {err:?}\"))\n})?;\ndelete_object_ids.push(obj_id);\n}\nclient\n.delete_objects()\nBasics API Version 2006-03-01 1958",
      "start_idx": 2128877,
      "end_idx": 2129924,
      "metadata": {
        "num_sentences": 11,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1964",
      "text": "Amazon Simple Storage Service API Reference\n.bucket(bucket_name)\n.delete(\naws_sdk_s3::types::Delete::builder()\n.set_objects(Some(delete_object_ids))\n.build()\n.map_err(|err| {\nS3ExampleError::new(format!(\"Failed to build delete_object\ninput {err:?}\"))\n})?,\n)\n.send()\n.await?;\nOk(())\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for Rust API reference.\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func deleteObjects(bucket: String, keys: [String]) async throws {\nlet input = DeleteObjectsInput(\nbucket: bucket,\ndelete: S3ClientTypes.Delete(\nobjects: keys.map { S3ClientTypes.ObjectIdentifier(key: $0) },\nquiet: true\n)\n)\ndo {\n_ = try await client.deleteObjects(input: input)\n} catch {\nBasics API Version 2006-03-01 1959",
      "start_idx": 2129926,
      "end_idx": 2130767,
      "metadata": {
        "num_sentences": 7,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1965",
      "text": "Amazon Simple Storage Service API Reference\nprint(\"ERROR: deleteObjects:\", dump(error))\nthrow error\n}\n}\n\u2022 For API details, see DeleteObjects in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeletePublicAccessBlock with a CLI\nThe following code examples show how to use DeletePublicAccessBlock.\nCLI\nAWS CLI\nTo delete the block public access configuration for a bucket\nThe following delete-public-access-block example removes the block public access\nconfiguration on the specified bucket.\naws s3api delete-public-access-block \\\n--bucket my-bucket\nThis command produces no output.\n\u2022 For API details, see DeletePublicAccessBlock in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command turns off the block public access setting for the given bucket.\nRemove-S3PublicAccessBlock -BucketName 'amzn-s3-demo-bucket' -Force -Select\n'^BucketName'\nOutput:\nBasics API Version 2006-03-01 1960",
      "start_idx": 2130769,
      "end_idx": 2131884,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1966",
      "text": "Amazon Simple Storage Service API Reference\ns3testbucket\n\u2022 For API details, see DeletePublicAccessBlock in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketAccelerateConfiguration with a CLI\nThe following code examples show how to use GetBucketAccelerateConfiguration.\nCLI\nAWS CLI\nTo retrieve the accelerate configuration of a bucket\nThe following get-bucket-accelerate-configuration example retrieves the\naccelerate configuration for the specified bucket.\naws s3api get-bucket-accelerate-configuration \\\n--bucket my-bucket\nOutput:\n{\n\"Status\": \"Enabled\"\n}\n\u2022 For API details, see GetBucketAccelerateConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the value Enabled, if the transfer acceleration settings\nis enabled for the bucket specified.\nGet-S3BucketAccelerateConfiguration -BucketName 'amzn-s3-demo-bucket'\nBasics API Version 2006-03-01 1961",
      "start_idx": 2131886,
      "end_idx": 2133014,
      "metadata": {
        "num_sentences": 8,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1967",
      "text": "Amazon Simple Storage Service API Reference\nOutput:\nValue\n-----\nEnabled\n\u2022 For API details, see GetBucketAccelerateConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketAcl with an AWS SDK or CLI\nThe following code examples show how to use GetBucketAcl.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Manage access control lists (ACLs)\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Get the access control list (ACL) for the new bucket.\n/// </summary>\n/// <param name=\"client\">The initialized client object used to get the\n/// access control list (ACL) of the bucket.</param>\n/// <param name=\"newBucketName\">The name of the newly created bucket.</\nparam>\nBasics API Version 2006-03-01 1962",
      "start_idx": 2133016,
      "end_idx": 2134161,
      "metadata": {
        "num_sentences": 9,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1968",
      "text": "Amazon Simple Storage Service API Reference\n/// <returns>An S3AccessControlList.</returns>\npublic static async Task<S3AccessControlList>\nGetACLForBucketAsync(IAmazonS3 client, string newBucketName)\n{\n// Retrieve bucket ACL to show that the ACL was properly applied to\n// the new bucket.\nGetACLResponse getACLResponse = await client.GetACLAsync(new\nGetACLRequest\n{\nBucketName = newBucketName,\n});\nreturn getACLResponse.AccessControlList;\n}\n\u2022 For API details, see GetBucketAcl in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getBucketAcl(const Aws::String &bucketName,\nconst Aws::S3::S3ClientConfiguration &clientConfig)\n{\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::GetBucketAclRequest request;\nrequest.SetBucket(bucketName);\nAws::S3::Model::GetBucketAclOutcome outcome =\ns3Client.GetBucketAcl(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nBasics API Version 2006-03-01 1963",
      "start_idx": 2134163,
      "end_idx": 2135236,
      "metadata": {
        "num_sentences": 5,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1972",
      "text": "Amazon Simple Storage Service API Reference\n}\n\u2022 For API details, see GetBucketAcl in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetObjectAclRequest;\nimport software.amazon.awssdk.services.s3.model.GetObjectAclResponse;\nimport software.amazon.awssdk.services.s3.model.Grant;\nimport java.util.List;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n* <p>\n* For more information, see the following documentation topic:\n* <p>\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class GetAcl {\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nUsage:\n<bucketName> <objectKey>\nWhere:\nBasics API Version 2006-03-01 1967",
      "start_idx": 2138601,
      "end_idx": 2139673,
      "metadata": {
        "num_sentences": 5,
        "num_words": 119,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1974",
      "text": "Amazon Simple Storage Service API Reference\nList<Grant> grants = aclRes.grants();\nString grantee = \"\";\nfor (Grant grant : grants) {\nSystem.out.format(\" %s: %s\\n\", grant.grantee().id(),\ngrant.permission());\ngrantee = grant.grantee().id();\n}\nreturn grantee;\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\nreturn \"\";\n}\n}\n\u2022 For API details, see GetBucketAcl in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet the ACL permissions.\nimport {\nGetBucketAclCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Retrieves the Access Control List (ACL) for an S3 bucket.\n* @param {{ bucketName: string }}\nBasics API Version 2006-03-01 1969",
      "start_idx": 2140963,
      "end_idx": 2141814,
      "metadata": {
        "num_sentences": 6,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1975",
      "text": "Amazon Simple Storage Service API Reference\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nconst response = await client.send(\nnew GetBucketAclCommand({\nBucket: bucketName,\n}),\n);\nconsole.log(`ACL for bucket \"${bucketName}\":`);\nconsole.log(JSON.stringify(response, null, 2));\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while getting ACL for ${bucketName}. The bucket doesn't\nexist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting ACL for ${bucketName}. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see GetBucketAcl in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1970",
      "start_idx": 2141816,
      "end_idx": 2142698,
      "metadata": {
        "num_sentences": 5,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1976",
      "text": "Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef get_acl(self):\n\"\"\"\nGet the ACL of the bucket.\n:return: The ACL of the bucket.\n\"\"\"\ntry:\nacl = self.bucket.Acl()\nlogger.info(\n\"Got ACL for bucket %s. Owner is %s.\", self.bucket.name,\nacl.owner\n)\nexcept ClientError:\nlogger.exception(\"Couldn't get ACL for bucket %s.\", self.bucket.name)\nraise\nelse:\nreturn acl\nBasics API Version 2006-03-01 1971",
      "start_idx": 2142700,
      "end_idx": 2143514,
      "metadata": {
        "num_sentences": 11,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1977",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketAcl in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketAnalyticsConfiguration with a CLI\nThe following code examples show how to use GetBucketAnalyticsConfiguration.\nCLI\nAWS CLI\nTo retrieve the analytics configuration for a bucket with a specific ID\nThe following get-bucket-analytics-configuration example displays the analytics\nconfiguration for the specified bucket and ID.\naws s3api get-bucket-analytics-configuration \\\n--bucket my-bucket \\\n--id 1\nOutput:\n{\n\"AnalyticsConfiguration\": {\n\"StorageClassAnalysis\": {},\n\"Id\": \"1\"\n}\n}\n\u2022 For API details, see GetBucketAnalyticsConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details of the analytics filter with the name\n'testfilter' in the given S3 bucket.\nBasics API Version 2006-03-01 1972",
      "start_idx": 2143516,
      "end_idx": 2144618,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1978",
      "text": "Amazon Simple Storage Service API Reference\nGet-S3BucketAnalyticsConfiguration -BucketName 'amzn-s3-demo-bucket' -AnalyticsId\n'testfilter'\n\u2022 For API details, see GetBucketAnalyticsConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketCors with an AWS SDK or CLI\nThe following code examples show how to use GetBucketCors.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Retrieve the CORS configuration applied to the Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used\n/// to retrieve the CORS configuration.</param>\n/// <returns>The created CORS configuration object.</returns>\nprivate static async Task<CORSConfiguration>\nRetrieveCORSConfigurationAsync(AmazonS3Client client)\n{\nGetCORSConfigurationRequest request = new\nGetCORSConfigurationRequest()\n{\nBucketName = BucketName,\n};\nvar response = await client.GetCORSConfigurationAsync(request);\nBasics API Version 2006-03-01 1973",
      "start_idx": 2144620,
      "end_idx": 2145902,
      "metadata": {
        "num_sentences": 8,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1980",
      "text": "Amazon Simple Storage Service API Reference\n],\n\"MaxAgeSeconds\": 3000,\n\"AllowedMethods\": [\n\"GET\"\n],\n\"AllowedOrigins\": [\n\"*\"\n]\n}\n]\n}\n\u2022 For API details, see GetBucketCors in AWS CLI Command Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet the CORS policy for the bucket.\nimport {\nGetBucketCorsCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Log the Cross-Origin Resource Sharing (CORS) configuration information\n* set for the bucket.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\nconst command = new GetBucketCorsCommand({\nBucket: bucketName,\n});\nBasics API Version 2006-03-01 1975",
      "start_idx": 2146587,
      "end_idx": 2147388,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1981",
      "text": "Amazon Simple Storage Service API Reference\ntry {\nconst { CORSRules } = await client.send(command);\nconsole.log(JSON.stringify(CORSRules));\nCORSRules.forEach((cr, i) => {\nconsole.log(\n`\\nCORSRule ${i + 1}`,\n`\\n${\"-\".repeat(10)}`,\n`\\nAllowedHeaders: ${cr.AllowedHeaders}`,\n`\\nAllowedMethods: ${cr.AllowedMethods}`,\n`\\nAllowedOrigins: ${cr.AllowedOrigins}`,\n`\\nExposeHeaders: ${cr.ExposeHeaders}`,\n`\\nMaxAgeSeconds: ${cr.MaxAgeSeconds}`,\n);\n});\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while getting bucket CORS rules for ${bucketName}. The\nbucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting bucket CORS rules for ${bucketName}.\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see GetBucketCors in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 1976",
      "start_idx": 2147390,
      "end_idx": 2148425,
      "metadata": {
        "num_sentences": 5,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1982",
      "text": "Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef get_cors(self):\n\"\"\"\nGet the CORS rules for the bucket.\n:return The CORS rules for the specified bucket.\n\"\"\"\ntry:\ncors = self.bucket.Cors()\nlogger.info(\n\"Got CORS rules %s for bucket '%s'.\", cors.cors_rules,\nself.bucket.name\n)\nexcept ClientError:\nlogger.exception((\"Couldn't get CORS for bucket %s.\",\nself.bucket.name))\nraise\nelse:\nreturn cors\nBasics API Version 2006-03-01 1977",
      "start_idx": 2148427,
      "end_idx": 2149278,
      "metadata": {
        "num_sentences": 10,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1983",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketCors in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket CORS configuration.\nclass BucketCorsWrapper\nattr_reader :bucket_cors\n# @param bucket_cors [Aws::S3::BucketCors] A bucket CORS object configured with\nan existing bucket.\ndef initialize(bucket_cors)\n@bucket_cors = bucket_cors\nend\n# Gets the CORS configuration of a bucket.\n#\n# @return [Aws::S3::Type::GetBucketCorsOutput, nil] The current CORS\nconfiguration for the bucket.\ndef cors\n@bucket_cors.data\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't get CORS configuration for #{@bucket_cors.bucket.name}. Here's\nwhy: #{e.message}\"\nnil\nend\nend\nBasics API Version 2006-03-01 1978",
      "start_idx": 2149280,
      "end_idx": 2150174,
      "metadata": {
        "num_sentences": 9,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1984",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketCors in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketEncryption with an AWS SDK or CLI\nThe following code examples show how to use GetBucketEncryption.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Get and print the encryption settings of a bucket.\n/// </summary>\n/// <param name=\"bucketName\">Name of the bucket.</param>\n/// <returns>Async task.</returns>\npublic static async Task GetEncryptionSettings(string bucketName)\n{\n// Check and print the bucket encryption settings.\nConsole.WriteLine($\"Getting encryption settings for bucket\n{bucketName}.\");\ntry\n{\nvar settings =\nawait _s3Client.GetBucketEncryptionAsync(\nnew GetBucketEncryptionRequest() { BucketName =\nbucketName });\nforeach (var encryptionSettings in\nsettings?.ServerSideEncryptionConfiguration?.ServerSideEncryptionRules!)\n{\nBasics API Version 2006-03-01 1979",
      "start_idx": 2150176,
      "end_idx": 2151408,
      "metadata": {
        "num_sentences": 11,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1986",
      "text": "Amazon Simple Storage Service API Reference\n]\n}\n}\n\u2022 For API details, see GetBucketEncryption in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns all the server side encryption rules associated with the\ngiven bucket.\nGet-S3BucketEncryption -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetBucketEncryption in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketInventoryConfiguration with a CLI\nThe following code examples show how to use GetBucketInventoryConfiguration.\nCLI\nAWS CLI\nTo retrieve the inventory configuration for a bucket\nThe following get-bucket-inventory-configuration example retrieves the inventory\nconfiguration for the specified bucket with ID 1.\naws s3api get-bucket-inventory-configuration \\\n--bucket my-bucket \\\n--id 1\nOutput:\nBasics API Version 2006-03-01 1981",
      "start_idx": 2152407,
      "end_idx": 2153465,
      "metadata": {
        "num_sentences": 7,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1987",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"InventoryConfiguration\": {\n\"IsEnabled\": true,\n\"Destination\": {\n\"S3BucketDestination\": {\n\"Format\": \"ORC\",\n\"Bucket\": \"arn:aws:s3:::my-bucket\",\n\"AccountId\": \"123456789012\"\n}\n},\n\"IncludedObjectVersions\": \"Current\",\n\"Id\": \"1\",\n\"Schedule\": {\n\"Frequency\": \"Weekly\"\n}\n}\n}\n\u2022 For API details, see GetBucketInventoryConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details of the inventory named 'testinventory' for\nthe given S3 bucket.\nGet-S3BucketInventoryConfiguration -BucketName 'amzn-s3-demo-bucket' -InventoryId\n'testinventory'\n\u2022 For API details, see GetBucketInventoryConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketLifecycleConfiguration with an AWS SDK or CLI\nThe following code examples show how to use GetBucketLifecycleConfiguration.\nBasics API Version 2006-03-01 1982",
      "start_idx": 2153467,
      "end_idx": 2154589,
      "metadata": {
        "num_sentences": 7,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1988",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Returns a configuration object for the supplied bucket name.\n/// </summary>\n/// <param name=\"client\">The S3 client object used to call\n/// the GetLifecycleConfigurationAsync method.</param>\n/// <param name=\"bucketName\">The name of the S3 bucket for which a\n/// configuration will be created.</param>\n/// <returns>Returns a new LifecycleConfiguration object.</returns>\npublic static async Task<LifecycleConfiguration>\nRetrieveLifecycleConfigAsync(IAmazonS3 client, string bucketName)\n{\nvar request = new GetLifecycleConfigurationRequest()\n{\nBucketName = bucketName,\n};\nvar response = await client.GetLifecycleConfigurationAsync(request);\nvar configuration = response.Configuration;\nreturn configuration;\n}\n\u2022 For API details, see GetBucketLifecycleConfiguration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following command retrieves the lifecycle configuration for a bucket named my-\nbucket:\nBasics API Version 2006-03-01 1983",
      "start_idx": 2154591,
      "end_idx": 2155731,
      "metadata": {
        "num_sentences": 5,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1989",
      "text": "Amazon Simple Storage Service API Reference\naws s3api get-bucket-lifecycle-configuration --bucket my-bucket\nOutput:\n{\n\"Rules\": [\n{\n\"ID\": \"Move rotated logs to Glacier\",\n\"Prefix\": \"rotated/\",\n\"Status\": \"Enabled\",\n\"Transitions\": [\n{\n\"Date\": \"2015-11-10T00:00:00.000Z\",\n\"StorageClass\": \"GLACIER\"\n}\n]\n},\n{\n\"Status\": \"Enabled\",\n\"Prefix\": \"\",\n\"NoncurrentVersionTransitions\": [\n{\n\"NoncurrentDays\": 0,\n\"StorageClass\": \"GLACIER\"\n}\n],\n\"ID\": \"Move old versions to Glacier\"\n}\n]\n}\n\u2022 For API details, see GetBucketLifecycleConfiguration in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 1984",
      "start_idx": 2155733,
      "end_idx": 2156474,
      "metadata": {
        "num_sentences": 4,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1990",
      "text": "Amazon Simple Storage Service API Reference\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef get_lifecycle_configuration(self):\n\"\"\"\nGet the lifecycle configuration of the bucket.\n:return: The lifecycle rules of the specified bucket.\n\"\"\"\ntry:\nconfig = self.bucket.LifecycleConfiguration()\nlogger.info(\n\"Got lifecycle rules %s for bucket '%s'.\",\nconfig.rules,\nself.bucket.name,\n)\nexcept:\nlogger.exception(\n\"Couldn't get lifecycle rules for bucket '%s'.\", self.bucket.name\n)\nraise\nelse:\nreturn config.rules\n\u2022 For API details, see GetBucketLifecycleConfiguration in AWS SDK for Python (Boto3) API\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 1985",
      "start_idx": 2156476,
      "end_idx": 2157558,
      "metadata": {
        "num_sentences": 11,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1992",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nasync fn show_buckets(\nstrict: bool,\nclient: &Client,\nregion: BucketLocationConstraint,\n) -> Result<(), S3ExampleError> {\nlet mut buckets = client.list_buckets().into_paginator().send();\nlet mut num_buckets = 0;\nlet mut in_region = 0;\nwhile let Some(Ok(output)) = buckets.next().await {\nfor bucket in output.buckets() {\nnum_buckets += 1;\nif strict {\nlet r = client\n.get_bucket_location()\n.bucket(bucket.name().unwrap_or_default())\n.send()\n.await?;\nif r.location_constraint() == Some(&region) {\nprintln!(\"{}\", bucket.name().unwrap_or_default());\nin_region += 1;\n}\n} else {\nprintln!(\"{}\", bucket.name().unwrap_or_default());\n}\n}\n}\nprintln!();\nif strict {\nBasics API Version 2006-03-01 1987",
      "start_idx": 2158352,
      "end_idx": 2159225,
      "metadata": {
        "num_sentences": 7,
        "num_words": 115,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1993",
      "text": "Amazon Simple Storage Service API Reference\nprintln!(\n\"Found {} buckets in the {} region out of a total of {} buckets.\",\nin_region, region, num_buckets\n);\n} else {\nprintln!(\"Found {} buckets in all regions.\", num_buckets);\n}\nOk(())\n}\n\u2022 For API details, see GetBucketLocation in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketLogging with a CLI\nThe following code examples show how to use GetBucketLogging.\nCLI\nAWS CLI\nTo retrieve the logging status for a bucket\nThe following get-bucket-logging example retrieves the logging status for the specified\nbucket.\naws s3api get-bucket-logging \\\n--bucket my-bucket\nOutput:\n{\n\"LoggingEnabled\": {\n\"TargetPrefix\": \"\",\n\"TargetBucket\": \"my-bucket-logs\"\n}\n}\nBasics API Version 2006-03-01 1988",
      "start_idx": 2159227,
      "end_idx": 2160171,
      "metadata": {
        "num_sentences": 10,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1994",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketLogging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the logging status for the specified bucket.\nGet-S3BucketLogging -BucketName 'amzn-s3-demo-bucket'\nOutput:\nTargetBucketName Grants TargetPrefix\n---------------- ------ ------------\ntestbucket1 {} testprefix\n\u2022 For API details, see GetBucketLogging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketMetricsConfiguration with a CLI\nThe following code examples show how to use GetBucketMetricsConfiguration.\nCLI\nAWS CLI\nTo retrieve the metrics configuration for a bucket with a specific ID\nThe following get-bucket-metrics-configuration example displays the metrics\nconfiguration for the specified bucket and ID.\naws s3api get-bucket-metrics-configuration \\\n--bucket my-bucket \\\n--id 123\nOutput:\nBasics API Version 2006-03-01 1989",
      "start_idx": 2160173,
      "end_idx": 2161303,
      "metadata": {
        "num_sentences": 8,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1995",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"MetricsConfiguration\": {\n\"Filter\": {\n\"Prefix\": \"logs\"\n},\n\"Id\": \"123\"\n}\n}\n\u2022 For API details, see GetBucketMetricsConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details about the metrics filter named 'testfilter'\nfor the given S3 bucket.\nGet-S3BucketMetricsConfiguration -BucketName 'amzn-s3-demo-bucket' -MetricsId\n'testfilter'\n\u2022 For API details, see GetBucketMetricsConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketNotification with a CLI\nThe following code examples show how to use GetBucketNotification.\nCLI\nAWS CLI\nThe following command retrieves the notification configuration for a bucket named my-\nbucket:\naws s3api get-bucket-notification --bucket my-bucket\nBasics API Version 2006-03-01 1990",
      "start_idx": 2161305,
      "end_idx": 2162357,
      "metadata": {
        "num_sentences": 7,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1996",
      "text": "Amazon Simple Storage Service API Reference\nOutput:\n{\n\"TopicConfiguration\": {\n\"Topic\": \"arn:aws:sns:us-west-2:123456789012:my-notification-topic\",\n\"Id\": \"YmQzMmEwM2EjZWVlI0NGItNzVtZjI1MC00ZjgyLWZDBiZWNl\",\n\"Event\": \"s3:ObjectCreated:*\",\n\"Events\": [\n\"s3:ObjectCreated:*\"\n]\n}\n}\n\u2022 For API details, see GetBucketNotification in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This example retrieves notification configuration of the given bucket\nGet-S3BucketNotification -BucketName amzn-s3-demo-bucket | select -ExpandProperty\nTopicConfigurations\nOutput:\nId Topic\n-- -----\nmimo arn:aws:sns:eu-west-1:123456789012:topic-1\n\u2022 For API details, see GetBucketNotification in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketPolicy with an AWS SDK or CLI\nThe following code examples show how to use GetBucketPolicy.\nBasics API Version 2006-03-01 1991",
      "start_idx": 2162359,
      "end_idx": 2163444,
      "metadata": {
        "num_sentences": 6,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1997",
      "text": "Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getBucketPolicy(const Aws::String &bucketName,\nconst Aws::S3::S3ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::GetBucketPolicyRequest request;\nrequest.SetBucket(bucketName);\nAws::S3::Model::GetBucketPolicyOutcome outcome =\ns3Client.GetBucketPolicy(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: getBucketPolicy: \"\n<< err.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nAws::StringStream policy_stream;\nAws::String line;\noutcome.GetResult().GetPolicy() >> line;\npolicy_stream << line;\nstd::cout << \"Retrieve the policy for bucket '\" << bucketName << \"':\\n\\n\"\n<<\npolicy_stream.str() << std::endl;\n}\nreturn outcome.IsSuccess();\n}\nBasics API Version 2006-03-01 1992",
      "start_idx": 2163446,
      "end_idx": 2164440,
      "metadata": {
        "num_sentences": 3,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1998",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketPolicy in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command retrieves the bucket policy for a bucket named my-bucket:\naws s3api get-bucket-policy --bucket my-bucket\nOutput:\n{\n\"Policy\": \"{\\\"Version\\\":\\\"2008-10-17\\\",\\\"Statement\\\":[{\\\"Sid\\\":\\\"\\\",\\\"Effect\n\\\":\\\"Allow\\\",\\\"Principal\\\":\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\n\\\"arn:aws:s3:::my-bucket/*\\\"},{\\\"Sid\\\":\\\"\\\",\\\"Effect\\\":\\\"Deny\\\",\\\"Principal\\\":\n\\\"*\\\",\\\"Action\\\":\\\"s3:GetObject\\\",\\\"Resource\\\":\\\"arn:aws:s3:::my-bucket/secret/*\n\\\"}]}\"\n}\nGet and put a bucket policyThe following example shows how you can download an Amazon\nS3 bucket policy, make modifications to the file, and then use put-bucket-policy to\napply the modified bucket policy. To download the bucket policy to a file, you can run:\naws s3api get-bucket-policy --bucket mybucket --query Policy --output text >\npolicy.json\nYou can then modify the policy.json file as needed. Finally you can apply this modified\npolicy back to the S3 bucket by running:\npolicy.json file as needed. Finally you can apply this modified policy back to the S3\nbucket by running:\nfile as needed. Finally you can apply this modified policy back to the S3 bucket by running:\naws s3api put-bucket-policy --bucket mybucket --policy file://policy.json\n\u2022 For API details, see GetBucketPolicy in AWS CLI Command Reference.\nBasics API Version 2006-03-01 1993",
      "start_idx": 2164442,
      "end_idx": 2165880,
      "metadata": {
        "num_sentences": 7,
        "num_words": 184,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_1999",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetBucketPolicyRequest;\nimport software.amazon.awssdk.services.s3.model.GetBucketPolicyResponse;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n* <p>\n* For more information, see the following documentation topic:\n* <p>\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class GetBucketPolicy {\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nUsage:\n<bucketName>\nWhere:\nbucketName - The Amazon S3 bucket to get the policy from.\n\"\"\";\nif (args.length != 1) {\nSystem.out.println(usage);\nSystem.exit(1);\n}\nBasics API Version 2006-03-01 1994",
      "start_idx": 2165882,
      "end_idx": 2166943,
      "metadata": {
        "num_sentences": 5,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2001",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketPolicy in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet the bucket policy.\nimport {\nGetBucketPolicyCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Logs the policy for a specified bucket.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nconst { Policy } = await client.send(\nnew GetBucketPolicyCommand({\nBucket: bucketName,\n}),\n);\nconsole.log(`Policy for \"${bucketName}\":\\n${Policy}`);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while getting policy from ${bucketName}. The bucket\ndoesn't exist.`,\nBasics API Version 2006-03-01 1996",
      "start_idx": 2168127,
      "end_idx": 2169074,
      "metadata": {
        "num_sentences": 7,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2002",
      "text": "Amazon Simple Storage Service API Reference\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting policy from ${bucketName}. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see GetBucketPolicy in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun getPolicy(bucketName: String): String? {\nprintln(\"Getting policy for bucket $bucketName\")\nval request =\nGetBucketPolicyRequest {\nbucket = bucketName\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\nval policyRes = s3.getBucketPolicy(request)\nreturn policyRes.policy\n}\n}\nBasics API Version 2006-03-01 1997",
      "start_idx": 2169076,
      "end_idx": 2169923,
      "metadata": {
        "num_sentences": 7,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2003",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetBucketPolicy in AWS SDK for Kotlin API reference.\nPowerShell\nTools for PowerShell\nExample 1: This command outputs the bucket policy associated with the given S3 bucket.\nGet-S3BucketPolicy -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetBucketPolicy in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef get_policy(self):\n\"\"\"\nGet the security policy of the bucket.\n:return: The security policy of the specified bucket, in JSON format.\nBasics API Version 2006-03-01 1998",
      "start_idx": 2169925,
      "end_idx": 2170897,
      "metadata": {
        "num_sentences": 11,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2004",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"\ntry:\npolicy = self.bucket.Policy()\nlogger.info(\n\"Got policy %s for bucket '%s'.\", policy.policy, self.bucket.name\n)\nexcept ClientError:\nlogger.exception(\"Couldn't get policy for bucket '%s'.\",\nself.bucket.name)\nraise\nelse:\nreturn json.loads(policy.policy)\n\u2022 For API details, see GetBucketPolicy in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# Wraps an Amazon S3 bucket policy.\nclass BucketPolicyWrapper\nattr_reader :bucket_policy\n# @param bucket_policy [Aws::S3::BucketPolicy] A bucket policy object\nconfigured with an existing bucket.\ndef initialize(bucket_policy)\n@bucket_policy = bucket_policy\nend\n# Gets the policy of a bucket.\n#\n# @return [Aws::S3::GetBucketPolicyOutput, nil] The current bucket policy.\ndef policy\npolicy = @bucket_policy.data.policy\nBasics API Version 2006-03-01 1999",
      "start_idx": 2170899,
      "end_idx": 2171878,
      "metadata": {
        "num_sentences": 10,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2005",
      "text": "Amazon Simple Storage Service API Reference\npolicy.respond_to?(:read) ? policy.read : policy\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't get the policy for #{@bucket_policy.bucket.name}. Here's why:\n#{e.message}\"\nnil\nend\nend\n\u2022 For API details, see GetBucketPolicy in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketPolicyStatus with a CLI\nThe following code examples show how to use GetBucketPolicyStatus.\nCLI\nAWS CLI\nTo retrieve the policy status for a bucket indicating whether the bucket is public\nThe following get-bucket-policy-status example retrieves the policy status for the\nbucket my-bucket.\naws s3api get-bucket-policy-status \\\n--bucket my-bucket\nOutput:\n{\n\"PolicyStatus\": {\n\"IsPublic\": false\n}\n}\n\u2022 For API details, see GetBucketPolicyStatus in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2000",
      "start_idx": 2171880,
      "end_idx": 2172920,
      "metadata": {
        "num_sentences": 10,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2006",
      "text": "Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command returns policy status for the given S3 bucket, indicating\nwhether the bucket is public.\nGet-S3BucketPolicyStatus -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetBucketPolicyStatus in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketReplication with a CLI\nThe following code examples show how to use GetBucketReplication.\nCLI\nAWS CLI\nThe following command retrieves the replication configuration for a bucket named my-\nbucket:\naws s3api get-bucket-replication --bucket my-bucket\nOutput:\n{\n\"ReplicationConfiguration\": {\n\"Rules\": [\n{\n\"Status\": \"Enabled\",\n\"Prefix\": \"\",\n\"Destination\": {\n\"Bucket\": \"arn:aws:s3:::my-bucket-backup\",\n\"StorageClass\": \"STANDARD\"\n},\n\"ID\": \"ZmUwNzE4ZmQ4tMjVhOS00MTlkLOGI4NDkzZTIWJjNTUtYTA1\"\nBasics API Version 2006-03-01 2001",
      "start_idx": 2172922,
      "end_idx": 2174005,
      "metadata": {
        "num_sentences": 6,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2007",
      "text": "Amazon Simple Storage Service API Reference\n}\n],\n\"Role\": \"arn:aws:iam::123456789012:role/s3-replication-role\"\n}\n}\n\u2022 For API details, see GetBucketReplication in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Returns the replication configuration information set on the bucket named\n'mybucket'.\nGet-S3BucketReplication -BucketName amzn-s3-demo-bucket\n\u2022 For API details, see GetBucketReplication in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketRequestPayment with a CLI\nThe following code examples show how to use GetBucketRequestPayment.\nCLI\nAWS CLI\nTo retrieve the request payment configuration for a bucket\nThe following get-bucket-request-payment example retrieves the requester pays\nconfiguration for the specified bucket.\naws s3api get-bucket-request-payment \\\n--bucket my-bucket\nOutput:\nBasics API Version 2006-03-01 2002",
      "start_idx": 2174007,
      "end_idx": 2175084,
      "metadata": {
        "num_sentences": 8,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2008",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"Payer\": \"BucketOwner\"\n}\n\u2022 For API details, see GetBucketRequestPayment in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Returns the request payment configuration for the bucket named 'mybucket'.\nBy default, the bucket owner pays for downloads from the bucket.\nGet-S3BucketRequestPayment -BucketName amzn-s3-demo-bucket\n\u2022 For API details, see GetBucketRequestPayment in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketTagging with a CLI\nThe following code examples show how to use GetBucketTagging.\nCLI\nAWS CLI\nThe following command retrieves the tagging configuration for a bucket named my-\nbucket:\naws s3api get-bucket-tagging --bucket my-bucket\nOutput:\n{\n\"TagSet\": [\nBasics API Version 2006-03-01 2003",
      "start_idx": 2175086,
      "end_idx": 2176085,
      "metadata": {
        "num_sentences": 8,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2009",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"Value\": \"marketing\",\n\"Key\": \"organization\"\n}\n]\n}\n\u2022 For API details, see GetBucketTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns all the tags associated with the given bucket.\nGet-S3BucketTagging -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetBucketTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketVersioning with a CLI\nThe following code examples show how to use GetBucketVersioning.\nCLI\nAWS CLI\nThe following command retrieves the versioning configuration for a bucket named my-\nbucket:\naws s3api get-bucket-versioning --bucket my-bucket\nOutput:\n{\nBasics API Version 2006-03-01 2004",
      "start_idx": 2176087,
      "end_idx": 2177020,
      "metadata": {
        "num_sentences": 7,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2010",
      "text": "Amazon Simple Storage Service API Reference\n\"Status\": \"Enabled\"\n}\n\u2022 For API details, see GetBucketVersioning in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the status of versioning with respect to the given\nbucket.\nGet-S3BucketVersioning -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetBucketVersioning in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetBucketWebsite with an AWS SDK or CLI\nThe following code examples show how to use GetBucketWebsite.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Get the website configuration.\nGetBucketWebsiteRequest getRequest = new\nGetBucketWebsiteRequest()\n{\nBucketName = bucketName,\nBasics API Version 2006-03-01 2005",
      "start_idx": 2177022,
      "end_idx": 2178061,
      "metadata": {
        "num_sentences": 10,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2011",
      "text": "Amazon Simple Storage Service API Reference\n};\nGetBucketWebsiteResponse getResponse = await\nclient.GetBucketWebsiteAsync(getRequest);\nConsole.WriteLine($\"Index document:\n{getResponse.WebsiteConfiguration.IndexDocumentSuffix}\");\nConsole.WriteLine($\"Error document:\n{getResponse.WebsiteConfiguration.ErrorDocument}\");\n\u2022 For API details, see GetBucketWebsite in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getWebsiteConfig(const Aws::String &bucketName,\nconst Aws::S3::S3ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::GetBucketWebsiteRequest request;\nrequest.SetBucket(bucketName);\nAws::S3::Model::GetBucketWebsiteOutcome outcome =\ns3Client.GetBucketWebsite(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: GetBucketWebsite: \"\n<< err.GetMessage() << std::endl;\n} else {\nAws::S3::Model::GetBucketWebsiteResult websiteResult =\noutcome.GetResult();\nBasics API Version 2006-03-01 2006",
      "start_idx": 2178063,
      "end_idx": 2179193,
      "metadata": {
        "num_sentences": 4,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2013",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet the website configuration.\nimport {\nGetBucketWebsiteCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Log the website configuration for a bucket.\n* @param {{ bucketName }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nconst response = await client.send(\nnew GetBucketWebsiteCommand({\nBucket: bucketName,\n}),\n);\nconsole.log(\n`Your bucket is set up to host a website with the following configuration:\n\\n${JSON.stringify(response, null, 2)}`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchWebsiteConfiguration\"\n) {\nconsole.error(\n`Error from S3 while getting website configuration for ${bucketName}. The\nbucket isn't configured as a website.`,\nBasics API Version 2006-03-01 2008",
      "start_idx": 2179984,
      "end_idx": 2180978,
      "metadata": {
        "num_sentences": 6,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2014",
      "text": "Amazon Simple Storage Service API Reference\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting website configuration for ${bucketName}.\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For API details, see GetBucketWebsite in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the details of the static website configurations of the\ngiven S3 bucket.\nGet-S3BucketWebsite -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetBucketWebsite in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetObject with an AWS SDK or CLI\nThe following code examples show how to use GetObject.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Learn the basics\n\u2022 Get an object from a bucket if it has been modified\n\u2022 Get an object from a Multi-Region Access Point\nBasics API Version 2006-03-01 2009",
      "start_idx": 2180980,
      "end_idx": 2182205,
      "metadata": {
        "num_sentences": 9,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2015",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Get started with encryption\n\u2022 Track uploads and downloads\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Shows how to download an object from an Amazon S3 bucket to the\n/// local computer.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <param name=\"bucketName\">The name of the bucket where the object is\n/// currently stored.</param>\n/// <param name=\"objectName\">The name of the object to download.</param>\n/// <param name=\"filePath\">The path, including filename, where the\n/// downloaded object will be stored.</param>\n/// <returns>A boolean value indicating the success or failure of the\n/// download process.</returns>\npublic static async Task<bool> DownloadObjectFromBucketAsync(\nIAmazonS3 client,\nstring bucketName,\nstring objectName,\nstring filePath)\n{\n// Create a GetObject request\nvar request = new GetObjectRequest\n{\nBucketName = bucketName,\nKey = objectName,\n};\n// Issue request and remember to dispose of the response\nBasics API Version 2006-03-01 2010",
      "start_idx": 2182207,
      "end_idx": 2183378,
      "metadata": {
        "num_sentences": 4,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2016",
      "text": "Amazon Simple Storage Service API Reference\nusing GetObjectResponse response = await\nclient.GetObjectAsync(request);\ntry\n{\n// Save object to local file\nawait response.WriteResponseStreamToFileAsync($\"{filePath}\\\n\\{objectName}\", true, CancellationToken.None);\nreturn response.HttpStatusCode == System.Net.HttpStatusCode.OK;\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"Error saving {objectName}: {ex.Message}\");\nreturn false;\n}\n}\n\u2022 For API details, see GetObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function download_object_from_bucket\nBasics API Version 2006-03-01 2011",
      "start_idx": 2183380,
      "end_idx": 2184501,
      "metadata": {
        "num_sentences": 5,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2017",
      "text": "Amazon Simple Storage Service API Reference\n#\n# This function downloads an object in a bucket to a file.\n#\n# Parameters:\n# $1 - The name of the bucket to download the object from.\n# $2 - The path and file name to store the downloaded bucket.\n# $3 - The key (name) of the object in the bucket.\n#\n# Returns:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction download_object_from_bucket() {\nlocal bucket_name=$1\nlocal destination_file_name=$2\nlocal object_name=$3\nlocal response\nresponse=$(aws s3api get-object \\\n--bucket \"$bucket_name\" \\\n--key \"$object_name\" \\\n\"$destination_file_name\")\n# shellcheck disable=SC2181\nif [[ ${?} -ne 0 ]]; then\nerrecho \"ERROR: AWS reports put-object operation failed.\\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see GetObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2012",
      "start_idx": 2184503,
      "end_idx": 2185541,
      "metadata": {
        "num_sentences": 11,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2018",
      "text": "Amazon Simple Storage Service API Reference\nbool AwsDoc::S3::getObject(const Aws::String &objectKey,\nconst Aws::String &fromBucket,\nconst Aws::S3::S3ClientConfiguration &clientConfig) {\nAws::S3::S3Client client(clientConfig);\nAws::S3::Model::GetObjectRequest request;\nrequest.SetBucket(fromBucket);\nrequest.SetKey(objectKey);\nAws::S3::Model::GetObjectOutcome outcome =\nclient.GetObject(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: getObject: \" <<\nerr.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nstd::cout << \"Successfully retrieved '\" << objectKey << \"' from '\"\n<< fromBucket << \"'.\" << std::endl;\n}\nreturn outcome.IsSuccess();\n}\n\u2022 For API details, see GetObject in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following example uses the get-object command to download an object from\nAmazon S3:\naws s3api get-object --bucket text-content --key dir/\nmy_images.tar.bz2 my_images.tar.bz2\nNote that the outfile parameter is specified without an option name such as \"--outfile\". The\nname of the output file must be the last parameter in the command.\nBasics API Version 2006-03-01 2013",
      "start_idx": 2185543,
      "end_idx": 2186714,
      "metadata": {
        "num_sentences": 5,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2019",
      "text": "Amazon Simple Storage Service API Reference\nThe example below demonstrates the use of --range to download a specific byte range\nfrom an object. Note the byte ranges needs to be prefixed with \"bytes=\":\naws s3api get-object --bucket text-content --key dir/my_data --\nrange bytes=8888-9999 my_data_range\nFor more information about retrieving objects, see Getting Objects in the Amazon S3\nDeveloper Guide.\n\u2022 For API details, see GetObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// DownloadFile gets an object from a bucket and stores it in a local file.\nfunc (basics BucketBasics) DownloadFile(ctx context.Context, bucketName string,\nobjectKey string, fileName string) error {\nresult, err := basics.S3Client.GetObject(ctx, &s3.GetObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n})\nBasics API Version 2006-03-01 2014",
      "start_idx": 2186716,
      "end_idx": 2187948,
      "metadata": {
        "num_sentences": 9,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2020",
      "text": "Amazon Simple Storage Service API Reference\nif err != nil {\nlog.Printf(\"Couldn't get object %v:%v. Here's why: %v\\n\", bucketName,\nobjectKey, err)\nreturn err\n}\ndefer result.Body.Close()\nfile, err := os.Create(fileName)\nif err != nil {\nlog.Printf(\"Couldn't create file %v. Here's why: %v\\n\", fileName, err)\nreturn err\n}\ndefer file.Close()\nbody, err := io.ReadAll(result.Body)\nif err != nil {\nlog.Printf(\"Couldn't read object body from %v. Here's why: %v\\n\", objectKey,\nerr)\n}\n_, err = file.Write(body)\nreturn err\n}\n\u2022 For API details, see GetObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nRead data as a byte array using an S3Client.\n/**\n* Asynchronously retrieves the bytes of an object from an Amazon S3 bucket\nand writes them to a local file.\n*\nBasics API Version 2006-03-01 2015",
      "start_idx": 2187950,
      "end_idx": 2188868,
      "metadata": {
        "num_sentences": 9,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2021",
      "text": "Amazon Simple Storage Service API Reference\n* @param bucketName the name of the S3 bucket containing the object\n* @param keyName the key (or name) of the S3 object to retrieve\n* @param path the local file path where the object's bytes will be\nwritten\n* @return a {@link CompletableFuture} that completes when the object bytes\nhave been written to the local file\n*/\npublic CompletableFuture<Void> getObjectBytesAsync(String bucketName, String\nkeyName, String path) {\nGetObjectRequest objectRequest = GetObjectRequest.builder()\n.key(keyName)\n.bucket(bucketName)\n.build();\nCompletableFuture<ResponseBytes<GetObjectResponse>> response =\ngetAsyncClient().getObject(objectRequest, AsyncResponseTransformer.toBytes());\nreturn response.thenAccept(objectBytes -> {\ntry {\nbyte[] data = objectBytes.asByteArray();\nPath filePath = Paths.get(path);\nFiles.write(filePath, data);\nlogger.info(\"Successfully obtained bytes from an S3 object\");\n} catch (IOException ex) {\nthrow new RuntimeException(\"Failed to write data to file\", ex);\n}\n}).whenComplete((resp, ex) -> {\nif (ex != null) {\nthrow new RuntimeException(\"Failed to get object bytes from S3\",\nex);\n}\n});\n}\nUse an S3TransferManager to download an object in an S3 bucket to a local file. View the\ncomplete file and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedFileDownload;\nBasics API Version 2006-03-01 2016",
      "start_idx": 2188870,
      "end_idx": 2190407,
      "metadata": {
        "num_sentences": 3,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2031",
      "text": "Amazon Simple Storage Service API Reference\nResponseBytes<GetObjectResponse> objectBytes =\ns3.getObject(objectRequest, ResponseTransformer.toBytes());\nbyte[] data = objectBytes.asByteArray();\n// Write the data to a local file.\nFile myFile = new File(path);\nOutputStream os = new FileOutputStream(myFile);\nos.write(data);\nSystem.out.println(\"Successfully obtained bytes from an S3 object\");\nos.close();\n} catch (IOException ex) {\nex.printStackTrace();\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see GetObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDownload the object.\nimport {\nGetObjectCommand,\nNoSuchKey,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\nBasics API Version 2006-03-01 2026",
      "start_idx": 2201643,
      "end_idx": 2202581,
      "metadata": {
        "num_sentences": 6,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2032",
      "text": "Amazon Simple Storage Service API Reference\n/**\n* Get a single object from a specified S3 bucket.\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\nconst client = new S3Client({});\ntry {\nconst response = await client.send(\nnew GetObjectCommand({\nBucket: bucketName,\nKey: key,\n}),\n);\n// The Body object also has 'transformToByteArray' and 'transformToWebStream'\nmethods.\nconst str = await response.Body.transformToString();\nconsole.log(str);\n} catch (caught) {\nif (caught instanceof NoSuchKey) {\nconsole.error(\n`Error from S3 while getting object \"${key}\" from \"${bucketName}\". No\nsuch key exists.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting object from ${bucketName}. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see GetObject in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 2027",
      "start_idx": 2202583,
      "end_idx": 2203605,
      "metadata": {
        "num_sentences": 7,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2033",
      "text": "Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun getObjectBytes(\nbucketName: String,\nkeyName: String,\npath: String,\n) {\nval request =\nGetObjectRequest {\nkey = keyName\nbucket = bucketName\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.getObject(request) { resp ->\nval myFile = File(path)\nresp.body?.writeToFile(myFile)\nprintln(\"Successfully read $keyName from $bucketName\")\n}\n}\n}\n\u2022 For API details, see GetObject in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 2028",
      "start_idx": 2203607,
      "end_idx": 2204247,
      "metadata": {
        "num_sentences": 4,
        "num_words": 100,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2034",
      "text": "Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet an object.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\ntry {\n$file = $this->s3client->getObject([\n'Bucket' => $this->bucketName,\n'Key' => $fileName,\n]);\n$body = $file->get('Body');\n$body->rewind();\necho \"Downloaded the file and it begins with: {$body->read(26)}.\\n\";\n} catch (Exception $exception) {\necho \"Failed to download $fileName from $this->bucketName with error:\n\" . $exception->getMessage();\nexit(\"Please fix error with file downloading before continuing.\");\n}\n\u2022 For API details, see GetObject in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command retrieves item \"sample.txt\" from bucket \"test-files\" and saves\nit to a file named \"local-sample.txt\" in the current location. The file \"local-sample.txt\"\ndoes not have to exist before this command is called.\nRead-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt -File local-\nsample.txt\nBasics API Version 2006-03-01 2029",
      "start_idx": 2204249,
      "end_idx": 2205373,
      "metadata": {
        "num_sentences": 9,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2035",
      "text": "Amazon Simple Storage Service API Reference\nExample 2: This command retrieves virtual directory \"DIR\" from bucket \"test-files\" and\nsaves it to a folder named \"Local-DIR\" in the current location. The folder \"Local-DIR\"\ndoes not have to exist before this command is called.\nRead-S3Object -BucketName amzn-s3-demo-bucket -KeyPrefix DIR -Folder Local-DIR\nExample 3: Downloads all objects with keys ending in '.json' from buckets with 'config'\nin the bucket name to files in the specified folder. The object keys are used to set the\nfilenames.\nGet-S3Bucket | ? { $_.BucketName -like '*config*' } | Get-S3Object | ? { $_.Key -\nlike '*.json' } | Read-S3Object -Folder C:\\ConfigObjects\n\u2022 For API details, see GetObject in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\ndef get(self):\n\"\"\"\nBasics API Version 2006-03-01 2030",
      "start_idx": 2205375,
      "end_idx": 2206623,
      "metadata": {
        "num_sentences": 13,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2036",
      "text": "Amazon Simple Storage Service API Reference\nGets the object.\n:return: The object data in bytes.\n\"\"\"\ntry:\nbody = self.object.get()[\"Body\"].read()\nlogger.info(\n\"Got object '%s' from bucket '%s'.\",\nself.object.key,\nself.object.bucket_name,\n)\nexcept ClientError:\nlogger.exception(\n\"Couldn't get object '%s' from bucket '%s'.\",\nself.object.key,\nself.object.bucket_name,\n)\nraise\nelse:\nreturn body\n\u2022 For API details, see GetObject in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet an object.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectGetWrapper\nattr_reader :object\nBasics API Version 2006-03-01 2031",
      "start_idx": 2206625,
      "end_idx": 2207383,
      "metadata": {
        "num_sentences": 10,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2037",
      "text": "Amazon Simple Storage Service API Reference\n# @param object [Aws::S3::Object] An existing Amazon S3 object.\ndef initialize(object)\n@object = object\nend\n# Gets the object directly to a file.\n#\n# @param target_path [String] The path to the file where the object is\ndownloaded.\n# @return [Aws::S3::Types::GetObjectOutput, nil] The retrieved object data if\nsuccessful; otherwise nil.\ndef get_object(target_path)\n@object.get(response_target: target_path)\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't get object #{@object.key}. Here's why: #{e.message}\"\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-object.txt\"\ntarget_path = \"my-object-as-file.txt\"\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-object.txt'\ntarget_path = 'my-object-as-file.txt'\n>>>>>>> 999c6133e (fixes)\nwrapper = ObjectGetWrapper.new(Aws::S3::Object.new(bucket_name, object_key))\nobj_data = wrapper.get_object(target_path)\nreturn unless obj_data\nputs \"Object #{object_key} (#{obj_data.content_length} bytes} downloaded to\n#{target_path}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nGet an object and report its server-side encryption state.\nBasics API Version 2006-03-01 2032",
      "start_idx": 2207385,
      "end_idx": 2208602,
      "metadata": {
        "num_sentences": 8,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2038",
      "text": "Amazon Simple Storage Service API Reference\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectGetEncryptionWrapper\nattr_reader :object\n# @param object [Aws::S3::Object] An existing Amazon S3 object.\ndef initialize(object)\n@object = object\nend\n# Gets the object into memory.\n#\n# @return [Aws::S3::Types::GetObjectOutput, nil] The retrieved object data if\nsuccessful; otherwise nil.\ndef object\n@object.get\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't get object #{@object.key}. Here's why: #{e.message}\"\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-object.txt\"\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-object.txt'\n>>>>>>> 999c6133e (fixes)\nwrapper = ObjectGetEncryptionWrapper.new(Aws::S3::Object.new(bucket_name,\nobject_key))\nobj_data = wrapper.get_object\nreturn unless obj_data\nencryption = obj_data.server_side_encryption.nil? ? 'no' :\nobj_data.server_side_encryption\nputs \"Object #{object_key} uses #{encryption} encryption.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nBasics API Version 2006-03-01 2033",
      "start_idx": 2208604,
      "end_idx": 2209711,
      "metadata": {
        "num_sentences": 9,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2039",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetObject in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nasync fn get_object(client: Client, opt: Opt) -> Result<usize, S3ExampleError> {\ntrace!(\"bucket: {}\", opt.bucket);\ntrace!(\"object: {}\", opt.object);\ntrace!(\"destination: {}\", opt.destination.display());\nlet mut file = File::create(opt.destination.clone()).map_err(|err| {\nS3ExampleError::new(format!(\n\"Failed to initialize file for saving S3 download: {err:?}\"\n))\n})?;\nlet mut object = client\n.get_object()\n.bucket(opt.bucket)\n.key(opt.object)\n.send()\n.await?;\nlet mut byte_count = 0_usize;\nwhile let Some(bytes) = object.body.try_next().await.map_err(|err| {\nS3ExampleError::new(format!(\"Failed to read from S3 download stream:\n{err:?}\"))\n})? {\nlet bytes_len = bytes.len();\nfile.write_all(&bytes).map_err(|err| {\nS3ExampleError::new(format!(\n\"Failed to write from S3 download stream to local file: {err:?}\"\n))\nBasics API Version 2006-03-01 2034",
      "start_idx": 2209713,
      "end_idx": 2210812,
      "metadata": {
        "num_sentences": 16,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2040",
      "text": "Amazon Simple Storage Service API Reference\n})?;\ntrace!(\"Intermediate write of {bytes_len}\");\nbyte_count += bytes_len;\n}\nOk(byte_count)\n}\n\u2022 For API details, see GetObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTRY.\noo_result = lo_s3->getobject( \" oo_result is returned for\ntesting purposes. \"\niv_bucket = iv_bucket_name\niv_key = iv_object_key\n).\nDATA(lv_object_data) = oo_result->get_body( ).\nMESSAGE 'Object retrieved from S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nCATCH /aws1/cx_s3_nosuchkey.\nMESSAGE 'Object key does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see GetObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 2035",
      "start_idx": 2210814,
      "end_idx": 2211671,
      "metadata": {
        "num_sentences": 20,
        "num_words": 129,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2041",
      "text": "Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func downloadFile(bucket: String, key: String, to: String) async\nthrows {\nlet fileUrl = URL(fileURLWithPath: to).appendingPathComponent(key)\nlet input = GetObjectInput(\nbucket: bucket,\nkey: key\n)\ndo {\nlet output = try await client.getObject(input: input)\nguard let body = output.body else {\nthrow HandlerError.getObjectBody(\"GetObjectInput missing body.\")\n}\nguard let data = try await body.readData() else {\nthrow HandlerError.readGetObjectBody(\"GetObjectInput unable to\nread data.\")\n}\ntry data.write(to: fileUrl)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Downloading a file.\"))\nthrow error\n}\n}\nimport AWSS3\nBasics API Version 2006-03-01 2036",
      "start_idx": 2211673,
      "end_idx": 2212527,
      "metadata": {
        "num_sentences": 6,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2042",
      "text": "Amazon Simple Storage Service API Reference\npublic func readFile(bucket: String, key: String) async throws -> Data {\nlet input = GetObjectInput(\nbucket: bucket,\nkey: key\n)\ndo {\nlet output = try await client.getObject(input: input)\nguard let body = output.body else {\nthrow HandlerError.getObjectBody(\"GetObjectInput missing body.\")\n}\nguard let data = try await body.readData() else {\nthrow HandlerError.readGetObjectBody(\"GetObjectInput unable to\nread data.\")\n}\nreturn data\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Reading a file.\"))\nthrow error\n}\n}\n\u2022 For API details, see GetObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetObjectAcl with an AWS SDK or CLI\nThe following code examples show how to use GetObjectAcl.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Manage access control lists (ACLs)\nBasics API Version 2006-03-01 2037",
      "start_idx": 2212529,
      "end_idx": 2213688,
      "metadata": {
        "num_sentences": 9,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2043",
      "text": "Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::getObjectAcl(const Aws::String &bucketName,\nconst Aws::String &objectKey,\nconst Aws::S3::S3ClientConfiguration &clientConfig)\n{\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::GetObjectAclRequest request;\nrequest.SetBucket(bucketName);\nrequest.SetKey(objectKey);\nAws::S3::Model::GetObjectAclOutcome outcome =\ns3Client.GetObjectAcl(request);\nif (!outcome.IsSuccess()) {\nconst Aws::S3::S3Error &err = outcome.GetError();\nstd::cerr << \"Error: getObjectAcl: \"\n<< err.GetExceptionName() << \": \" << err.GetMessage() <<\nstd::endl;\n} else {\nAws::Vector<Aws::S3::Model::Grant> grants =\noutcome.GetResult().GetGrants();\nfor (auto it = grants.begin(); it != grants.end(); it++) {\nstd::cout << \"For object \" << objectKey << \": \"\n<< std::endl << std::endl;\nAws::S3::Model::Grant grant = *it;\nAws::S3::Model::Grantee grantee = grant.GetGrantee();\nif (grantee.TypeHasBeenSet()) {\nstd::cout << \"Type: \"\nBasics API Version 2006-03-01 2038",
      "start_idx": 2213690,
      "end_idx": 2214822,
      "metadata": {
        "num_sentences": 3,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2047",
      "text": "Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun getBucketACL(\nobjectKey: String,\nbucketName: String,\n) {\nval request =\nGetObjectAclRequest {\nbucket = bucketName\nkey = objectKey\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\nval response = s3.getObjectAcl(request)\nresponse.grants?.forEach { grant ->\nprintln(\"Grant permission is ${grant.permission}\")\n}\n}\n}\n\u2022 For API details, see GetObjectAcl in AWS SDK for Kotlin API reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2042",
      "start_idx": 2217814,
      "end_idx": 2218587,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2048",
      "text": "Amazon Simple Storage Service API Reference\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\ndef get_acl(self):\n\"\"\"\nGets the ACL of the object.\n:return: The ACL of the object.\n\"\"\"\ntry:\nacl = self.object.Acl()\nlogger.info(\n\"Got ACL for object %s owned by %s.\",\nself.object.key,\nacl.owner[\"DisplayName\"],\n)\nexcept ClientError:\nlogger.exception(\"Couldn't get ACL for object %s.\", self.object.key)\nraise\nelse:\nreturn acl\n\u2022 For API details, see GetObjectAcl in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 2043",
      "start_idx": 2218589,
      "end_idx": 2219573,
      "metadata": {
        "num_sentences": 11,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2049",
      "text": "Amazon Simple Storage Service API Reference\nUse GetObjectAttributes with an AWS SDK or CLI\nThe following code examples show how to use GetObjectAttributes.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// ! Routine which retrieves the hash value of an object stored in an S3 bucket.\n/*!\n\\param bucket: The name of the S3 bucket where the object is stored.\n\\param key: The unique identifier (key) of the object within the S3 bucket.\n\\param hashMethod: The hashing algorithm used to calculate the hash value of\nthe object.\n\\param[out] hashData: The retrieved hash.\n\\param[out] partHashes: The part hashes if available.\n\\param client: The S3 client instance used to retrieve the object.\n\\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::retrieveObjectHash(const Aws::String &bucket, const Aws::String\n&key,\nAwsDoc::S3::HASH_METHOD hashMethod,\nAws::String &hashData,\nstd::vector<Aws::String> *partHashes,\nconst Aws::S3::S3Client &client) {\nAws::S3::Model::GetObjectAttributesRequest request;\nrequest.SetBucket(bucket);\nrequest.SetKey(key);\nif (hashMethod == MD5) {\nAws::Vector<Aws::S3::Model::ObjectAttributes> attributes;\nBasics API Version 2006-03-01 2044",
      "start_idx": 2219575,
      "end_idx": 2221014,
      "metadata": {
        "num_sentences": 15,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2053",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetObjectAttributes in AWS CLI Command Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetObjectLegalHold with an AWS SDK or CLI\nThe following code examples show how to use GetObjectLegalHold.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Lock Amazon S3 objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Get the legal hold details for an S3 object.\n/// </summary>\n/// <param name=\"bucketName\">The bucket of the object.</param>\n/// <param name=\"objectKey\">The object key.</param>\n/// <returns>The object legal hold details.</returns>\npublic async Task<ObjectLockLegalHold> GetObjectLegalHold(string bucketName,\nstring objectKey)\n{\ntry\n{\nvar request = new GetObjectLegalHoldRequest()\n{\nBucketName = bucketName,\nKey = objectKey\nBasics API Version 2006-03-01 2048",
      "start_idx": 2224747,
      "end_idx": 2225984,
      "metadata": {
        "num_sentences": 9,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2055",
      "text": "Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// GetObjectLegalHold retrieves the legal hold status for an S3 object.\nfunc (actor S3Actions) GetObjectLegalHold(ctx context.Context, bucket string, key\nstring, versionId string) (*types.ObjectLockLegalHoldStatus, error) {\nvar status *types.ObjectLockLegalHoldStatus\ninput := &s3.GetObjectLegalHoldInput{\nBucket: aws.String(bucket),\nKey: aws.String(key),\nVersionId: aws.String(versionId),\n}\noutput, err := actor.S3Client.GetObjectLegalHold(ctx, input)\nif err != nil {\nvar noSuchKeyErr *types.NoSuchKey\nvar apiErr *smithy.GenericAPIError\nif errors.As(err, &noSuchKeyErr) {\nlog.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket)\nerr = noSuchKeyErr\n} else if errors.As(err, &apiErr) {\nswitch apiErr.ErrorCode() {\ncase \"NoSuchObjectLockConfiguration\":\nlog.Printf(\"Object %s does not have an object lock configuration.\\n\", key)\nerr = nil\ncase \"InvalidRequest\":\nBasics API Version 2006-03-01 2050",
      "start_idx": 2226861,
      "end_idx": 2228063,
      "metadata": {
        "num_sentences": 5,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2056",
      "text": "Amazon Simple Storage Service API Reference\nlog.Printf(\"Bucket %s does not have an object lock configuration.\\n\", bucket)\nerr = nil\n}\n}\n} else {\nstatus = &output.LegalHold.Status\n}\nreturn status, err\n}\n\u2022 For API details, see GetObjectLegalHold in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Get the legal hold details for an S3 object.\npublic ObjectLockLegalHold getObjectLegalHold(String bucketName, String\nobjectKey) {\ntry {\nGetObjectLegalHoldRequest legalHoldRequest =\nGetObjectLegalHoldRequest.builder()\n.bucket(bucketName)\n.key(objectKey)\n.build();\nGetObjectLegalHoldResponse response =\ngetClient().getObjectLegalHold(legalHoldRequest);\nSystem.out.println(\"Object legal hold for \" + objectKey + \" in \" +\nbucketName +\n\":\\n\\tStatus: \" + response.legalHold().status());\nreturn response.legalHold();\nBasics API Version 2006-03-01 2051",
      "start_idx": 2228065,
      "end_idx": 2229035,
      "metadata": {
        "num_sentences": 5,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2057",
      "text": "Amazon Simple Storage Service API Reference\n} catch (S3Exception ex) {\nSystem.out.println(\"\\tUnable to fetch legal hold: '\" +\nex.getMessage() + \"'\");\n}\nreturn null;\n}\n\u2022 For API details, see GetObjectLegalHold in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport {\nGetObjectLegalHoldCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Get an object's current legal hold status.\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\nconst client = new S3Client({});\ntry {\nconst response = await client.send(\nnew GetObjectLegalHoldCommand({\nBucket: bucketName,\nKey: key,\n// Optionally, you can provide additional parameters\nBasics API Version 2006-03-01 2052",
      "start_idx": 2229037,
      "end_idx": 2229915,
      "metadata": {
        "num_sentences": 5,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2058",
      "text": "Amazon Simple Storage Service API Reference\n// ExpectedBucketOwner: \"<account ID that is expected to own the\nbucket>\",\n// VersionId: \"<the specific version id of the object to check>\",\n}),\n);\nconsole.log(`Legal Hold Status: ${response.LegalHold.Status}`);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while getting legal hold status for ${key} in\n${bucketName}. The bucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting legal hold status for ${key} in\n${bucketName} from ${bucketName}. ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport {\nisMain,\nvalidateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => {\nconst options = {\nbucketName: {\ntype: \"string\",\nrequired: true,\n},\nkey: {\ntype: \"string\",\nrequired: true,\n},\n};\nBasics API Version 2006-03-01 2053",
      "start_idx": 2229917,
      "end_idx": 2230953,
      "metadata": {
        "num_sentences": 3,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2059",
      "text": "Amazon Simple Storage Service API Reference\nconst results = parseArgs({ options });\nconst { errors } = validateArgs({ options }, results);\nreturn { errors, results };\n};\nif (isMain(import.meta.url)) {\nconst { errors, results } = loadArgs();\nif (!errors) {\nmain(results.values);\n} else {\nconsole.error(errors.join(\"\\n\"));\n}\n}\n\u2022 For API details, see GetObjectLegalHold in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nPut an object legal hold.\ndef get_legal_hold(s3_client, bucket: str, key: str) -> None:\n\"\"\"\nGet the legal hold status of a specific file in a bucket.\nArgs:\ns3_client: Boto3 S3 client.\nbucket: The name of the bucket containing the file.\nkey: The key of the file to get the legal hold status of.\n\"\"\"\nprint()\nlogger.info(\"Getting legal hold status of file [%s] in bucket [%s]\", key,\nbucket)\ntry:\nBasics API Version 2006-03-01 2054",
      "start_idx": 2230955,
      "end_idx": 2231944,
      "metadata": {
        "num_sentences": 9,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2060",
      "text": "Amazon Simple Storage Service API Reference\nresponse = s3_client.get_object_legal_hold(Bucket=bucket, Key=key)\nlegal_hold_status = response[\"LegalHold\"][\"Status\"]\nlogger.debug(\n\"Legal hold status of file [%s] in bucket [%s] is [%s]\",\nkey,\nbucket,\nlegal_hold_status,\n)\nexcept Exception as e:\nlogger.error(\n\"Failed to get legal hold status of file [%s] in bucket [%s]: %s\",\nkey,\nbucket,\ne,\n)\n\u2022 For API details, see GetObjectLegalHold in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetObjectLockConfiguration with an AWS SDK or CLI\nThe following code examples show how to use GetObjectLockConfiguration.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Lock Amazon S3 objects\nBasics API Version 2006-03-01 2055",
      "start_idx": 2231946,
      "end_idx": 2232974,
      "metadata": {
        "num_sentences": 6,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2061",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Get the object lock configuration details for an S3 bucket.\n/// </summary>\n/// <param name=\"bucketName\">The bucket to get details.</param>\n/// <returns>The bucket's object lock configuration details.</returns>\npublic async Task<ObjectLockConfiguration>\nGetBucketObjectLockConfiguration(string bucketName)\n{\ntry\n{\nvar request = new GetObjectLockConfigurationRequest()\n{\nBucketName = bucketName\n};\nvar response = await\n_amazonS3.GetObjectLockConfigurationAsync(request);\nConsole.WriteLine($\"\\tBucket object lock config for {bucketName} in\n{bucketName}: \" +\n$\"\\n\\tEnabled:\n{response.ObjectLockConfiguration.ObjectLockEnabled}\" +\n$\"\\n\\tRule:\n{response.ObjectLockConfiguration.Rule?.DefaultRetention}\");\nreturn response.ObjectLockConfiguration;\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"\\tUnable to fetch object lock config:\n'{ex.Message}'\");\nreturn new ObjectLockConfiguration();\n}\nBasics API Version 2006-03-01 2056",
      "start_idx": 2232976,
      "end_idx": 2234107,
      "metadata": {
        "num_sentences": 4,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2063",
      "text": "Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// GetObjectLockConfiguration retrieves the object lock configuration for an S3\nbucket.\nfunc (actor S3Actions) GetObjectLockConfiguration(ctx context.Context, bucket\nstring) (*types.ObjectLockConfiguration, error) {\nvar lockConfig *types.ObjectLockConfiguration\ninput := &s3.GetObjectLockConfigurationInput{\nBucket: aws.String(bucket),\n}\noutput, err := actor.S3Client.GetObjectLockConfiguration(ctx, input)\nif err != nil {\nvar noBucket *types.NoSuchBucket\nvar apiErr *smithy.GenericAPIError\nif errors.As(err, &noBucket) {\nlog.Printf(\"Bucket %s does not exist.\\n\", bucket)\nerr = noBucket\n} else if errors.As(err, &apiErr) && apiErr.ErrorCode() ==\n\"ObjectLockConfigurationNotFoundError\" {\nlog.Printf(\"Bucket %s does not have an object lock configuration.\\n\", bucket)\nerr = nil\n}\n} else {\nlockConfig = output.ObjectLockConfiguration\nBasics API Version 2006-03-01 2058",
      "start_idx": 2234762,
      "end_idx": 2235924,
      "metadata": {
        "num_sentences": 5,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2064",
      "text": "Amazon Simple Storage Service API Reference\n}\nreturn lockConfig, err\n}\n\u2022 For API details, see GetObjectLockConfiguration in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Get the object lock configuration details for an S3 bucket.\npublic void getBucketObjectLockConfiguration(String bucketName) {\nGetObjectLockConfigurationRequest objectLockConfigurationRequest =\nGetObjectLockConfigurationRequest.builder()\n.bucket(bucketName)\n.build();\nGetObjectLockConfigurationResponse response =\ngetClient().getObjectLockConfiguration(objectLockConfigurationRequest);\nSystem.out.println(\"Bucket object lock config for \"+bucketName +\": \");\nSystem.out.println(\"\\tEnabled:\n\"+response.objectLockConfiguration().objectLockEnabled());\nSystem.out.println(\"\\tRule: \"+\nresponse.objectLockConfiguration().rule().defaultRetention());\n}\n\u2022 For API details, see GetObjectLockConfiguration in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2059",
      "start_idx": 2235926,
      "end_idx": 2236994,
      "metadata": {
        "num_sentences": 6,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2065",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport {\nGetObjectLockConfigurationCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Gets the Object Lock configuration for a bucket.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nconst { ObjectLockConfiguration } = await client.send(\nnew GetObjectLockConfigurationCommand({\nBucket: bucketName,\n// Optionally, you can provide additional parameters\n// ExpectedBucketOwner: \"<account ID that is expected to own the\nbucket>\",\n}),\n);\nconsole.log(\n`Object Lock Configuration:\\n${JSON.stringify(ObjectLockConfiguration)}`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\nBasics API Version 2006-03-01 2060",
      "start_idx": 2236996,
      "end_idx": 2237969,
      "metadata": {
        "num_sentences": 4,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2067",
      "text": "Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command returns the value 'Enabled' if Object lock configuration is\nenabled for the given S3 bucket.\nGet-S3ObjectLockConfiguration -BucketName 'amzn-s3-demo-bucket' -Select\nObjectLockConfiguration.ObjectLockEnabled\nOutput:\nValue\n-----\nEnabled\n\u2022 For API details, see GetObjectLockConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGet the object lock configuration.\ndef is_object_lock_enabled(s3_client, bucket: str) -> bool:\n\"\"\"\nCheck if object lock is enabled for a bucket.\nArgs:\ns3_client: Boto3 S3 client.\nbucket: The name of the bucket to check.\nBasics API Version 2006-03-01 2062",
      "start_idx": 2238990,
      "end_idx": 2239829,
      "metadata": {
        "num_sentences": 9,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2068",
      "text": "Amazon Simple Storage Service API Reference\nReturns:\nTrue if object lock is enabled, False otherwise.\n\"\"\"\ntry:\nresponse = s3_client.get_object_lock_configuration(Bucket=bucket)\nreturn (\n\"ObjectLockConfiguration\" in response\nand response[\"ObjectLockConfiguration\"][\"ObjectLockEnabled\"] ==\n\"Enabled\"\n)\nexcept s3_client.exceptions.ClientError as e:\nif e.response[\"Error\"][\"Code\"] == \"ObjectLockConfigurationNotFoundError\":\nreturn False\nelse:\nraise\n\u2022 For API details, see GetObjectLockConfiguration in AWS SDK for Python (Boto3) API\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetObjectRetention with an AWS SDK or CLI\nThe following code examples show how to use GetObjectRetention.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Lock Amazon S3 objects\nBasics API Version 2006-03-01 2063",
      "start_idx": 2239831,
      "end_idx": 2240906,
      "metadata": {
        "num_sentences": 7,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2069",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Get the retention period for an S3 object.\n/// </summary>\n/// <param name=\"bucketName\">The bucket of the object.</param>\n/// <param name=\"objectKey\">The object key.</param>\n/// <returns>The object retention details.</returns>\npublic async Task<ObjectLockRetention> GetObjectRetention(string bucketName,\nstring objectKey)\n{\ntry\n{\nvar request = new GetObjectRetentionRequest()\n{\nBucketName = bucketName,\nKey = objectKey\n};\nvar response = await _amazonS3.GetObjectRetentionAsync(request);\nConsole.WriteLine($\"\\tObject retention for {objectKey} in\n{bucketName}: \" +\n$\"\\n\\t{response.Retention.Mode} until\n{response.Retention.RetainUntilDate:d}.\");\nreturn response.Retention;\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"\\tUnable to fetch object lock retention:\n'{ex.Message}'\");\nreturn new ObjectLockRetention();\n}\n}\nBasics API Version 2006-03-01 2064",
      "start_idx": 2240908,
      "end_idx": 2241970,
      "metadata": {
        "num_sentences": 5,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2070",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see GetObjectRetention in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo retrieve the object retention configuration for an object\nThe following get-object-retention example retrieves the object retention\nconfiguration for the specified object.\naws s3api get-object-retention \\\n--bucket my-bucket-with-object-lock \\\n--key doc1.rtf\nOutput:\n{\n\"Retention\": {\n\"Mode\": \"GOVERNANCE\",\n\"RetainUntilDate\": \"2025-01-01T00:00:00.000Z\"\n}\n}\n\u2022 For API details, see GetObjectRetention in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nBasics API Version 2006-03-01 2065",
      "start_idx": 2241972,
      "end_idx": 2242773,
      "metadata": {
        "num_sentences": 7,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2072",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Get the retention period for an S3 object.\npublic ObjectLockRetention getObjectRetention(String bucketName, String key){\ntry {\nGetObjectRetentionRequest retentionRequest =\nGetObjectRetentionRequest.builder()\n.bucket(bucketName)\n.key(key)\n.build();\nGetObjectRetentionResponse response =\ngetClient().getObjectRetention(retentionRequest);\nSystem.out.println(\"tObject retention for \"+key +\"\nin \"+ bucketName +\": \" + response.retention().mode() +\" until \"+\nresponse.retention().retainUntilDate() +\".\");\nreturn response.retention();\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nreturn null;\n}\n}\n\u2022 For API details, see GetObjectRetention in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2067",
      "start_idx": 2243847,
      "end_idx": 2244781,
      "metadata": {
        "num_sentences": 6,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2073",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport {\nGetObjectRetentionCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Log the \"RetainUntilDate\" for an object in an S3 bucket.\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\nconst client = new S3Client({});\ntry {\nconst { Retention } = await client.send(\nnew GetObjectRetentionCommand({\nBucket: bucketName,\nKey: key,\n}),\n);\nconsole.log(\n`${key} in ${bucketName} will be retained until\n${Retention.RetainUntilDate}`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchObjectLockConfiguration\"\n) {\nconsole.warn(\nBasics API Version 2006-03-01 2068",
      "start_idx": 2244783,
      "end_idx": 2245655,
      "metadata": {
        "num_sentences": 4,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2074",
      "text": "Amazon Simple Storage Service API Reference\n`The object \"${key}\" in the bucket \"${bucketName}\" does not have an\nObjectLock configuration.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while getting object retention settings for\n\"${bucketName}\". ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport {\nisMain,\nvalidateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => {\nconst options = {\nbucketName: {\ntype: \"string\",\nrequired: true,\n},\nkey: {\ntype: \"string\",\nrequired: true,\n},\n};\nconst results = parseArgs({ options });\nconst { errors } = validateArgs({ options }, results);\nreturn { errors, results };\n};\nif (isMain(import.meta.url)) {\nconst { errors, results } = loadArgs();\nif (!errors) {\nmain(results.values);\n} else {\nconsole.error(errors.join(\"\\n\"));\n}\nBasics API Version 2006-03-01 2069",
      "start_idx": 2245657,
      "end_idx": 2246619,
      "metadata": {
        "num_sentences": 2,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2075",
      "text": "Amazon Simple Storage Service API Reference\n}\n\u2022 For API details, see GetObjectRetention in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command returns the mode and date till the object would be retained.\nGet-S3ObjectRetention -BucketName 'amzn-s3-demo-bucket' -Key 'testfile.txt'\n\u2022 For API details, see GetObjectRetention in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetObjectTagging with a CLI\nThe following code examples show how to use GetObjectTagging.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Get started with tags\nCLI\nAWS CLI\nTo retrieve the tags attached to an object\nThe following get-object-tagging example retrieves the values for the specified key\nfrom the specified object.\naws s3api get-object-tagging \\\n--bucket my-bucket \\\n--key doc1.rtf\nBasics API Version 2006-03-01 2070",
      "start_idx": 2246621,
      "end_idx": 2247781,
      "metadata": {
        "num_sentences": 9,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2077",
      "text": "Amazon Simple Storage Service API Reference\n\"Key\": \"department\"\n},\n{\n\"Value\": \"payroll\",\n\"Key\": \"team\"\n}\n]\n}\n\u2022 For API details, see GetObjectTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The sample returns the tags associated with the object present on the given\nS3 bucket.\nGet-S3ObjectTagSet -Key 'testfile.txt' -BucketName 'amzn-s3-demo-bucket'\nOutput:\nKey Value\n--- -----\ntest value\n\u2022 For API details, see GetObjectTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetPublicAccessBlock with a CLI\nThe following code examples show how to use GetPublicAccessBlock.\nCLI\nAWS CLI\nTo set or modify the block public access configuration for a bucket\nBasics API Version 2006-03-01 2072",
      "start_idx": 2248421,
      "end_idx": 2249361,
      "metadata": {
        "num_sentences": 7,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2078",
      "text": "Amazon Simple Storage Service API Reference\nThe following get-public-access-block example displays the block public access\nconfiguration for the specified bucket.\naws s3api get-public-access-block \\\n--bucket my-bucket\nOutput:\n{\n\"PublicAccessBlockConfiguration\": {\n\"IgnorePublicAcls\": true,\n\"BlockPublicPolicy\": true,\n\"BlockPublicAcls\": true,\n\"RestrictPublicBuckets\": true\n}\n}\n\u2022 For API details, see GetPublicAccessBlock in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command returns the public access block configuration of the given S3\nbucket.\nGet-S3PublicAccessBlock -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see GetPublicAccessBlock in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse HeadBucket with an AWS SDK or CLI\nThe following code examples show how to use HeadBucket.\nBasics API Version 2006-03-01 2073",
      "start_idx": 2249363,
      "end_idx": 2250431,
      "metadata": {
        "num_sentences": 8,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2079",
      "text": "Amazon Simple Storage Service API Reference\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function bucket_exists\n#\n# This function checks to see if the specified bucket already exists.\n#\n# Parameters:\n# $1 - The name of the bucket to check.\n#\n# Returns:\n# 0 - If the bucket already exists.\n# 1 - If the bucket doesn't exist.\n###############################################################################\nfunction bucket_exists() {\nlocal bucket_name\nbucket_name=$1\n# Check whether the bucket already exists.\n# We suppress all output - we're interested only in the return code.\nif aws s3api head-bucket \\\n--bucket \"$bucket_name\" \\\n>/dev/null 2>&1; then\nreturn 0 # 0 in Bash script means true.\nelse\nreturn 1 # 1 in Bash script means false.\nfi\n}\n\u2022 For API details, see HeadBucket in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2074",
      "start_idx": 2250433,
      "end_idx": 2251464,
      "metadata": {
        "num_sentences": 12,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2080",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command verifies access to a bucket named my-bucket:\naws s3api head-bucket --bucket my-bucket\nIf the bucket exists and you have access to it, no output is returned. Otherwise, an error\nmessage will be shown. For example:\nA client error (404) occurred when calling the HeadBucket operation: Not Found\n\u2022 For API details, see HeadBucket in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// BucketExists checks whether a bucket exists in the current account.\nfunc (basics BucketBasics) BucketExists(ctx context.Context, bucketName string)\n(bool, error) {\nBasics API Version 2006-03-01 2075",
      "start_idx": 2251466,
      "end_idx": 2252506,
      "metadata": {
        "num_sentences": 9,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2081",
      "text": "Amazon Simple Storage Service API Reference\n_, err := basics.S3Client.HeadBucket(ctx, &s3.HeadBucketInput{\nBucket: aws.String(bucketName),\n})\nexists := true\nif err != nil {\nvar apiError smithy.APIError\nif errors.As(err, &apiError) {\nswitch apiError.(type) {\ncase *types.NotFound:\nlog.Printf(\"Bucket %v is available.\\n\", bucketName)\nexists = false\nerr = nil\ndefault:\nlog.Printf(\"Either you don't have access to bucket %v or another error\noccurred. \"+\n\"Here's what happened: %v\\n\", bucketName, err)\n}\n}\n} else {\nlog.Printf(\"Bucket %v exists and you already own it.\", bucketName)\n}\nreturn exists, err\n}\n\u2022 For API details, see HeadBucket in AWS SDK for Go API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\nBasics API Version 2006-03-01 2076",
      "start_idx": 2252508,
      "end_idx": 2253422,
      "metadata": {
        "num_sentences": 8,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2082",
      "text": "Amazon Simple Storage Service API Reference\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef exists(self):\n\"\"\"\nDetermine whether the bucket exists and you have access to it.\n:return: True when the bucket exists; otherwise, False.\n\"\"\"\ntry:\nself.bucket.meta.client.head_bucket(Bucket=self.bucket.name)\nlogger.info(\"Bucket %s exists.\", self.bucket.name)\nexists = True\nexcept ClientError:\nlogger.warning(\n\"Bucket %s doesn't exist or you don't have access to it.\",\nself.bucket.name,\n)\nexists = False\nreturn exists\n\u2022 For API details, see HeadBucket in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse HeadObject with an AWS SDK or CLI\nThe following code examples show how to use HeadObject.\nBasics API Version 2006-03-01 2077",
      "start_idx": 2253424,
      "end_idx": 2254525,
      "metadata": {
        "num_sentences": 11,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2083",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command retrieves metadata for an object in a bucket named my-bucket:\naws s3api head-object --bucket my-bucket --key index.html\nOutput:\n{\n\"AcceptRanges\": \"bytes\",\n\"ContentType\": \"text/html\",\n\"LastModified\": \"Thu, 16 Apr 2015 18:19:14 GMT\",\n\"ContentLength\": 77,\n\"VersionId\": \"null\",\n\"ETag\": \"\\\"30a6ec7e1a9ad79c203d05a589c8b400\\\"\",\n\"Metadata\": {}\n}\n\u2022 For API details, see HeadObject in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDetermine the content type of an object.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nimport software.amazon.awssdk.services.s3.model.HeadObjectResponse;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nBasics API Version 2006-03-01 2078",
      "start_idx": 2254527,
      "end_idx": 2255523,
      "metadata": {
        "num_sentences": 5,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2087",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see HeadObject in AWS SDK for Java 2.x API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectExistsWrapper\nattr_reader :object\n# @param object [Aws::S3::Object] An Amazon S3 object.\ndef initialize(object)\n@object = object\nend\n# Checks whether the object exists.\n#\n# @return [Boolean] True if the object exists; otherwise false.\ndef exists?\n@object.exists?\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't check existence of object\n#{@object.bucket.name}:#{@object.key}. Here's why: #{e.message}\"\nfalse\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-object.txt\"\nBasics API Version 2006-03-01 2082",
      "start_idx": 2259004,
      "end_idx": 2259893,
      "metadata": {
        "num_sentences": 11,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2088",
      "text": "Amazon Simple Storage Service API Reference\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-object.txt'\n>>>>>>> 999c6133e (fixes)\nwrapper = ObjectExistsWrapper.new(Aws::S3::Object.new(bucket_name, object_key))\nexists = wrapper.exists?\nputs \"Object #{object_key} #{exists ? 'does' : 'does not'} exist.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see HeadObject in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListBucketAnalyticsConfigurations with a CLI\nThe following code examples show how to use ListBucketAnalyticsConfigurations.\nCLI\nAWS CLI\nTo retrieve a list of analytics configurations for a bucket\nThe following list-bucket-analytics-configurations retrieves a list of analytics\nconfigurations for the specified bucket.\naws s3api list-bucket-analytics-configurations \\\n--bucket my-bucket\nOutput:\n{\n\"AnalyticsConfigurationList\": [\n{\nBasics API Version 2006-03-01 2083",
      "start_idx": 2259895,
      "end_idx": 2261005,
      "metadata": {
        "num_sentences": 9,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2089",
      "text": "Amazon Simple Storage Service API Reference\n\"StorageClassAnalysis\": {},\n\"Id\": \"1\"\n}\n],\n\"IsTruncated\": false\n}\n\u2022 For API details, see ListBucketAnalyticsConfigurations in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns the first 100 analytics configurations of the given S3\nbucket.\nGet-S3BucketAnalyticsConfigurationList -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see ListBucketAnalyticsConfigurations in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListBucketInventoryConfigurations with a CLI\nThe following code examples show how to use ListBucketInventoryConfigurations.\nCLI\nAWS CLI\nTo retrieve a list of inventory configurations for a bucket\nThe following list-bucket-inventory-configurations example lists the inventory\nconfigurations for the specified bucket.\naws s3api list-bucket-inventory-configurations \\\n--bucket my-bucket\nBasics API Version 2006-03-01 2084",
      "start_idx": 2261007,
      "end_idx": 2262146,
      "metadata": {
        "num_sentences": 8,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2091",
      "text": "Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command returns the first 100 inventory configurations of the given S3\nbucket.\nGet-S3BucketInventoryConfigurationList -BucketName 'amzn-s3-demo-bucket'\n\u2022 For API details, see ListBucketInventoryConfigurations in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListBuckets with an AWS SDK or CLI\nThe following code examples show how to use ListBuckets.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nnamespace ListBucketsExample\n{\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example uses the AWS SDK for .NET to list the Amazon Simple Storage\n/// Service (Amazon S3) buckets belonging to the default account.\nBasics API Version 2006-03-01 2086",
      "start_idx": 2262857,
      "end_idx": 2264003,
      "metadata": {
        "num_sentences": 9,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2092",
      "text": "Amazon Simple Storage Service API Reference\n/// </summary>\npublic class ListBuckets\n{\nprivate static IAmazonS3 _s3Client;\n/// <summary>\n/// Get a list of the buckets owned by the default user.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <returns>The response from the ListingBuckets call that contains a\n/// list of the buckets owned by the default user.</returns>\npublic static async Task<ListBucketsResponse> GetBuckets(IAmazonS3\nclient)\n{\nreturn await client.ListBucketsAsync();\n}\n/// <summary>\n/// This method lists the name and creation date for the buckets in\n/// the passed List of S3 buckets.\n/// </summary>\n/// <param name=\"bucketList\">A List of S3 bucket objects.</param>\npublic static void DisplayBucketList(List<S3Bucket> bucketList)\n{\nbucketList\n.ForEach(b => Console.WriteLine($\"Bucket name: {b.BucketName},\ncreated on: {b.CreationDate}\"));\n}\npublic static async Task Main()\n{\n// The client uses the AWS Region of the default user.\n// If the Region where the buckets were created is different,\n// pass the Region to the client constructor. For example:\n// _s3Client = new AmazonS3Client(RegionEndpoint.USEast1);\n_s3Client = new AmazonS3Client();\nvar response = await GetBuckets(_s3Client);\nDisplayBucketList(response.Buckets);\n}\n}\n}\nBasics API Version 2006-03-01 2087",
      "start_idx": 2264005,
      "end_idx": 2265334,
      "metadata": {
        "num_sentences": 5,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2093",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see ListBuckets in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::listBuckets(const Aws::S3::S3ClientConfiguration &clientConfig)\n{\nAws::S3::S3Client client(clientConfig);\nauto outcome = client.ListBuckets();\nbool result = true;\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Failed with error: \" << outcome.GetError() << std::endl;\nresult = false;\n} else {\nstd::cout << \"Found \" << outcome.GetResult().GetBuckets().size() << \"\nbuckets\\n\";\nfor (auto &&b: outcome.GetResult().GetBuckets()) {\nstd::cout << b.GetName() << std::endl;\n}\n}\nreturn result;\n}\n\u2022 For API details, see ListBuckets in AWS SDK for C++ API Reference.\nBasics API Version 2006-03-01 2088",
      "start_idx": 2265336,
      "end_idx": 2266190,
      "metadata": {
        "num_sentences": 5,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2094",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command uses the list-buckets command to display the names of all your\nAmazon S3 buckets (across all regions):\naws s3api list-buckets --query \"Buckets[].Name\"\nThe query option filters the output of list-buckets down to only the bucket names.\nFor more information about buckets, see Working with Amazon S3 Buckets in the Amazon S3\nDeveloper Guide.\n\u2022 For API details, see ListBuckets in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// ListBuckets lists the buckets in the current account.\nfunc (basics BucketBasics) ListBuckets(ctx context.Context) ([]types.Bucket,\nerror) {\nBasics API Version 2006-03-01 2089",
      "start_idx": 2266192,
      "end_idx": 2267256,
      "metadata": {
        "num_sentences": 9,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2095",
      "text": "Amazon Simple Storage Service API Reference\nresult, err := basics.S3Client.ListBuckets(ctx, &s3.ListBucketsInput{})\nvar buckets []types.Bucket\nif err != nil {\nlog.Printf(\"Couldn't list buckets for your account. Here's why: %v\\n\", err)\n} else {\nbuckets = result.Buckets\n}\nreturn buckets, err\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.Bucket;\nimport software.amazon.awssdk.services.s3.model.ListBucketsResponse;\nimport java.util.List;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n*\n* For more information, see the following documentation topic:\n*\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class ListBuckets {\npublic static void main(String[] args) {\nRegion region = Region.US_EAST_1;\nBasics API Version 2006-03-01 2090",
      "start_idx": 2267258,
      "end_idx": 2268416,
      "metadata": {
        "num_sentences": 6,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2096",
      "text": "Amazon Simple Storage Service API Reference\nS3Client s3 = S3Client.builder()\n.region(region)\n.build();\nlistAllBuckets(s3);\n}\n/**\n* Lists all the S3 buckets available in the current AWS account.\n*\n* @param s3 The {@link S3Client} instance to use for interacting with the\nAmazon S3 service.\n*/\npublic static void listAllBuckets(S3Client s3) {\nListBucketsResponse response = s3.listBuckets();\nList<Bucket> bucketList = response.buckets();\nfor (Bucket bucket: bucketList) {\nSystem.out.println(\"Bucket name \"+bucket.name());\n}\n}\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nList the buckets.\nimport {\npaginateListBuckets,\nS3Client,\nS3ServiceException,\nBasics API Version 2006-03-01 2091",
      "start_idx": 2268418,
      "end_idx": 2269289,
      "metadata": {
        "num_sentences": 7,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2097",
      "text": "Amazon Simple Storage Service API Reference\n} from \"@aws-sdk/client-s3\";\n/**\n* List the Amazon S3 buckets in your account.\n*/\nexport const main = async () => {\nconst client = new S3Client({});\n/** @type {?import('@aws-sdk/client-s3').Owner} */\nlet Owner = null;\n/** @type {import('@aws-sdk/client-s3').Bucket[]} */\nconst Buckets = [];\ntry {\nconst paginator = paginateListBuckets({ client }, {});\nfor await (const page of paginator) {\nif (!Owner) {\nOwner = page.Owner;\n}\nBuckets.push(...page.Buckets);\n}\nconsole.log(\n`${Owner.DisplayName} owns ${Buckets.length} bucket${\nBuckets.length === 1 ? \"\" : \"s\"\n}:`,\n);\nconsole.log(`${Buckets.map((b) => ` \u2022 ${b.Name}`).join(\"\\n\")}`);\n} catch (caught) {\nif (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while listing buckets. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\nBasics API Version 2006-03-01 2092",
      "start_idx": 2269291,
      "end_idx": 2270253,
      "metadata": {
        "num_sentences": 5,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2098",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see ListBuckets in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command returns all S3 buckets.\nGet-S3Bucket\nExample 2: This command returns bucket named \"test-files\"\nGet-S3Bucket -BucketName amzn-s3-demo-bucket\n\u2022 For API details, see ListBuckets in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\n@staticmethod\nBasics API Version 2006-03-01 2093",
      "start_idx": 2270255,
      "end_idx": 2271126,
      "metadata": {
        "num_sentences": 9,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2099",
      "text": "Amazon Simple Storage Service API Reference\ndef list(s3_resource):\n\"\"\"\nGet the buckets in all Regions for the current account.\n:param s3_resource: A Boto3 S3 resource. This is a high-level resource in\nBoto3\nthat contains collections and factory methods to\ncreate\nother high-level S3 sub-resources.\n:return: The list of buckets.\n\"\"\"\ntry:\nbuckets = list(s3_resource.buckets.all())\nlogger.info(\"Got buckets: %s.\", buckets)\nexcept ClientError:\nlogger.exception(\"Couldn't get buckets.\")\nraise\nelse:\nreturn buckets\n\u2022 For API details, see ListBuckets in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 resource actions.\nclass BucketListWrapper\nattr_reader :s3_resource\n# @param s3_resource [Aws::S3::Resource] An Amazon S3 resource.\ndef initialize(s3_resource)\nBasics API Version 2006-03-01 2094",
      "start_idx": 2271128,
      "end_idx": 2272091,
      "metadata": {
        "num_sentences": 12,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2100",
      "text": "Amazon Simple Storage Service API Reference\n@s3_resource = s3_resource\nend\n# Lists buckets for the current account.\n#\n# @param count [Integer] The maximum number of buckets to list.\ndef list_buckets(count)\nputs 'Found these buckets:'\n@s3_resource.buckets.each do |bucket|\nputs \"\\t#{bucket.name}\"\ncount -= 1\nbreak if count.zero?\nend\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't list buckets. Here's why: #{e.message}\"\nfalse\nend\nend\n# Example usage:\ndef run_demo\nwrapper = BucketListWrapper.new(Aws::S3::Resource.new)\nwrapper.list_buckets(25)\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see ListBuckets in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nasync fn show_buckets(\nBasics API Version 2006-03-01 2095",
      "start_idx": 2272093,
      "end_idx": 2272958,
      "metadata": {
        "num_sentences": 8,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2102",
      "text": "Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\n/// Return an array containing information about every available bucket.\n///\n/// - Returns: An array of ``S3ClientTypes.Bucket`` objects describing\n/// each bucket.\npublic func getAllBuckets() async throws -> [S3ClientTypes.Bucket] {\nreturn try await client.listBuckets(input: ListBucketsInput())\n}\n\u2022 For API details, see ListBuckets in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListMultipartUploads with an AWS SDK or CLI\nThe following code examples show how to use ListMultipartUploads.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Delete incomplete multipart uploads\nBasics API Version 2006-03-01 2097",
      "start_idx": 2273930,
      "end_idx": 2275053,
      "metadata": {
        "num_sentences": 10,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2103",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nThe following command lists all of the active multipart uploads for a bucket named my-\nbucket:\naws s3api list-multipart-uploads --bucket my-bucket\nOutput:\n{\n\"Uploads\": [\n{\n\"Initiator\": {\n\"DisplayName\": \"username\",\n\"ID\": \"arn:aws:iam::0123456789012:user/username\"\n},\n\"Initiated\": \"2015-06-02T18:01:30.000Z\",\n\"UploadId\":\n\"dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\",\n\"StorageClass\": \"STANDARD\",\n\"Key\": \"multipart/01\",\n\"Owner\": {\n\"DisplayName\": \"aws-account-name\",\n\"ID\":\n\"100719349fc3b6dcd7c820a124bf7aecd408092c3d7b51b38494939801fc248b\"\n}\n}\n],\n\"CommonPrefixes\": []\n}\nIn progress multipart uploads incur storage costs in Amazon S3. Complete or abort an active\nmultipart upload to remove its parts from your account.\n\u2022 For API details, see ListMultipartUploads in AWS CLI Command Reference.\nBasics API Version 2006-03-01 2098",
      "start_idx": 2275055,
      "end_idx": 2276018,
      "metadata": {
        "num_sentences": 4,
        "num_words": 102,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2104",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.ListMultipartUploadsRequest;\nimport software.amazon.awssdk.services.s3.model.ListMultipartUploadsResponse;\nimport software.amazon.awssdk.services.s3.model.MultipartUpload;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.util.List;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n*\n* For more information, see the following documentation topic:\n*\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class ListMultipartUploads {\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nUsage:\n<bucketName>\\s\nWhere:\nbucketName - The name of the Amazon S3 bucket where an in-\nprogress multipart upload is occurring.\n\"\"\";\nif (args.length != 1) {\nSystem.out.println(usage);\nBasics API Version 2006-03-01 2099",
      "start_idx": 2276020,
      "end_idx": 2277201,
      "metadata": {
        "num_sentences": 5,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2106",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListObjectVersions with an AWS SDK or CLI\nThe following code examples show how to use ListObjectVersions.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example lists the versions of the objects in a version enabled\n/// Amazon Simple Storage Service (Amazon S3) bucket.\n/// </summary>\npublic class ListObjectVersions\n{\npublic static async Task Main()\n{\nstring bucketName = \"amzn-s3-demo-bucket\";\n// If the AWS Region where your bucket is defined is different from\n// the AWS Region where the Amazon S3 bucket is defined, pass the\nconstant\nBasics API Version 2006-03-01 2101",
      "start_idx": 2278367,
      "end_idx": 2279590,
      "metadata": {
        "num_sentences": 8,
        "num_words": 196,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2110",
      "text": "Amazon Simple Storage Service API Reference\n\"ID\":\n\"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\"\n},\n\"IsLatest\": false,\n\"Size\": 38\n},\n{\n\"LastModified\": \"2015-11-09T22:50:50.000Z\",\n\"VersionId\": \"null\",\n\"ETag\": \"\\\"d1f45267a863c8392e07d24dd592f1b9\\\"\",\n\"StorageClass\": \"STANDARD\",\n\"Key\": \"index.html\",\n\"Owner\": {\n\"DisplayName\": \"my-username\",\n\"ID\":\n\"7009a8971cd660687538875e7c86c5b672fe116bd438f46db45460ddcd036c32\"\n},\n\"IsLatest\": false,\n\"Size\": 533823\n}\n]\n}\n\u2022 For API details, see ListObjectVersions in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\nBasics API Version 2006-03-01 2105",
      "start_idx": 2282845,
      "end_idx": 2283679,
      "metadata": {
        "num_sentences": 5,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2111",
      "text": "Amazon Simple Storage Service API Reference\n// ListObjectVersions lists all versions of all objects in a bucket.\nfunc (actor S3Actions) ListObjectVersions(ctx context.Context, bucket string)\n([]types.ObjectVersion, error) {\nvar err error\nvar output *s3.ListObjectVersionsOutput\nvar versions []types.ObjectVersion\ninput := &s3.ListObjectVersionsInput{Bucket: aws.String(bucket)}\nversionPaginator := s3.NewListObjectVersionsPaginator(actor.S3Client, input)\nfor versionPaginator.HasMorePages() {\noutput, err = versionPaginator.NextPage(ctx)\nif err != nil {\nvar noBucket *types.NoSuchBucket\nif errors.As(err, &noBucket) {\nlog.Printf(\"Bucket %s does not exist.\\n\", bucket)\nerr = noBucket\n}\nbreak\n} else {\nversions = append(versions, output.Versions...)\n}\n}\nreturn versions, err\n}\n\u2022 For API details, see ListObjectVersions in AWS SDK for Go API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nasync fn show_versions(client: &Client, bucket: &str) -> Result<(), Error> {\nlet resp = client.list_object_versions().bucket(bucket).send().await?;\nBasics API Version 2006-03-01 2106",
      "start_idx": 2283681,
      "end_idx": 2284855,
      "metadata": {
        "num_sentences": 6,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2112",
      "text": "Amazon Simple Storage Service API Reference\nfor version in resp.versions() {\nprintln!(\"{}\", version.key().unwrap_or_default());\nprintln!(\" version ID: {}\", version.version_id().unwrap_or_default());\nprintln!();\n}\nOk(())\n}\n\u2022 For API details, see ListObjectVersions in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListObjects with a CLI\nThe following code examples show how to use ListObjects.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Create a web page that lists Amazon S3 objects\nCLI\nAWS CLI\nThe following example uses the list-objects command to display the names of all the\nobjects in the specified bucket:\naws s3api list-objects --bucket text-content --query 'Contents[].{Key: Key, Size:\nSize}'\nThe example uses the --query argument to filter the output of list-objects down to\nthe key value and size for each object\nFor more information about objects, see Working with Amazon S3 Objects in the Amazon S3\nDeveloper Guide.\nBasics API Version 2006-03-01 2107",
      "start_idx": 2284857,
      "end_idx": 2286134,
      "metadata": {
        "num_sentences": 11,
        "num_words": 196,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2113",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see ListObjects in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command retrieves the information about all of the items in the bucket\n\"test-files\".\nGet-S3Object -BucketName amzn-s3-demo-bucket\nExample 2: This command retrieves the information about the item \"sample.txt\" from\nbucket \"test-files\".\nGet-S3Object -BucketName amzn-s3-demo-bucket -Key sample.txt\nExample 3: This command retrieves the information about all items with the prefix\n\"sample\" from bucket \"test-files\".\nGet-S3Object -BucketName amzn-s3-demo-bucket -KeyPrefix sample\n\u2022 For API details, see ListObjects in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse ListObjectsV2 with an AWS SDK or CLI\nThe following code examples show how to use ListObjectsV2.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Learn the basics\n\u2022 Delete all objects in a bucket\nBasics API Version 2006-03-01 2108",
      "start_idx": 2286136,
      "end_idx": 2287402,
      "metadata": {
        "num_sentences": 10,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2114",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Shows how to list the objects in an Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <param name=\"bucketName\">The name of the bucket for which to list\n/// the contents.</param>\n/// <returns>A boolean value indicating the success or failure of the\n/// copy operation.</returns>\npublic static async Task<bool> ListBucketContentsAsync(IAmazonS3 client,\nstring bucketName)\n{\ntry\n{\nvar request = new ListObjectsV2Request\n{\nBucketName = bucketName,\nMaxKeys = 5,\n};\nConsole.WriteLine(\"--------------------------------------\");\nConsole.WriteLine($\"Listing the contents of {bucketName}:\");\nConsole.WriteLine(\"--------------------------------------\");\nListObjectsV2Response response;\ndo\n{\nresponse = await client.ListObjectsV2Async(request);\nresponse.S3Objects\nBasics API Version 2006-03-01 2109",
      "start_idx": 2287404,
      "end_idx": 2288458,
      "metadata": {
        "num_sentences": 4,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2117",
      "text": "Amazon Simple Storage Service API Reference\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function list_items_in_bucket\n#\n# This function displays a list of the files in the bucket with each file's\n# size. The function uses the --query parameter to retrieve only the key and\n# size fields from the Contents collection.\n#\n# Parameters:\n# $1 - The name of the bucket.\n#\n# Returns:\n# The list of files in text format.\n# And:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction list_items_in_bucket() {\nlocal bucket_name=$1\nlocal response\nresponse=$(aws s3api list-objects \\\n--bucket \"$bucket_name\" \\\n--output text \\\nBasics API Version 2006-03-01 2112",
      "start_idx": 2290512,
      "end_idx": 2291735,
      "metadata": {
        "num_sentences": 10,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2118",
      "text": "Amazon Simple Storage Service API Reference\n--query 'Contents[].{Key: Key, Size: Size}')\n# shellcheck disable=SC2181\nif [[ ${?} -eq 0 ]]; then\necho \"$response\"\nelse\nerrecho \"ERROR: AWS reports s3api list-objects operation failed.\\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see ListObjectsV2 in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::listObjects(const Aws::String &bucketName,\nAws::Vector<Aws::String> &keysResult,\nconst Aws::S3::S3ClientConfiguration &clientConfig)\n{\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::ListObjectsV2Request request;\nrequest.WithBucket(bucketName);\nAws::String continuationToken; // Used for pagination.\nAws::Vector<Aws::S3::Model::Object> allObjects;\ndo {\nif (!continuationToken.empty()) {\nrequest.SetContinuationToken(continuationToken);\n}\nauto outcome = s3Client.ListObjectsV2(request);\nBasics API Version 2006-03-01 2113",
      "start_idx": 2291737,
      "end_idx": 2292747,
      "metadata": {
        "num_sentences": 7,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2120",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"LastModified\": \"2019-11-05T23:11:50.000Z\",\n\"ETag\": \"\\\"621503c373607d548b37cff8778d992c\\\"\",\n\"StorageClass\": \"STANDARD\",\n\"Key\": \"doc1.rtf\",\n\"Size\": 391\n},\n{\n\"LastModified\": \"2019-11-05T23:11:50.000Z\",\n\"ETag\": \"\\\"a2cecc36ab7c7fe3a71a273b9d45b1b5\\\"\",\n\"StorageClass\": \"STANDARD\",\n\"Key\": \"doc2.rtf\",\n\"Size\": 373\n},\n{\n\"LastModified\": \"2019-11-05T23:11:50.000Z\",\n\"ETag\": \"\\\"08210852f65a2e9cb999972539a64d68\\\"\",\n\"StorageClass\": \"STANDARD\",\n\"Key\": \"doc3.rtf\",\n\"Size\": 399\n},\n{\n\"LastModified\": \"2019-11-05T23:11:50.000Z\",\n\"ETag\": \"\\\"d1852dd683f404306569471af106988e\\\"\",\n\"StorageClass\": \"STANDARD\",\n\"Key\": \"doc4.rtf\",\n\"Size\": 6225\n}\n]\n}\n\u2022 For API details, see ListObjectsV2 in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2115",
      "start_idx": 2293708,
      "end_idx": 2294622,
      "metadata": {
        "num_sentences": 4,
        "num_words": 100,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2121",
      "text": "Amazon Simple Storage Service API Reference\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// ListObjects lists the objects in a bucket.\nfunc (basics BucketBasics) ListObjects(ctx context.Context, bucketName string)\n([]types.Object, error) {\nresult, err := basics.S3Client.ListObjectsV2(ctx, &s3.ListObjectsV2Input{\nBucket: aws.String(bucketName),\n})\nvar contents []types.Object\nif err != nil {\nlog.Printf(\"Couldn't list objects in bucket %v. Here's why: %v\\n\", bucketName,\nerr)\n} else {\ncontents = result.Contents\n}\nreturn contents, err\n}\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2116",
      "start_idx": 2294624,
      "end_idx": 2295631,
      "metadata": {
        "num_sentences": 8,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2124",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nList all of the objects in your bucket. If there is more than one object, IsTruncated and\nNextContinuationToken will be used to iterate over the full list.\nimport {\nS3Client,\nS3ServiceException,\n// This command supersedes the ListObjectsCommand and is the recommended way to\nlist objects.\npaginateListObjectsV2,\n} from \"@aws-sdk/client-s3\";\n/**\n* Log all of the object keys in a bucket.\n* @param {{ bucketName: string, pageSize: string }}\n*/\nexport const main = async ({ bucketName, pageSize }) => {\nconst client = new S3Client({});\n/** @type {string[][]} */\nconst objects = [];\ntry {\nconst paginator = paginateListObjectsV2(\n{ client, /* Max items per page */ pageSize: Number.parseInt(pageSize) },\n{ Bucket: bucketName },\n);\nfor await (const page of paginator) {\nBasics API Version 2006-03-01 2119",
      "start_idx": 2298082,
      "end_idx": 2299164,
      "metadata": {
        "num_sentences": 8,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2125",
      "text": "Amazon Simple Storage Service API Reference\nobjects.push(page.Contents.map((o) => o.Key));\n}\nobjects.forEach((objectList, pageNum) => {\nconsole.log(\n`Page ${pageNum + 1}\\n------\\n${objectList.map((o) => `\u2022\n${o}`).join(\"\\n\")}\\n`,\n);\n});\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while listing objects for \"${bucketName}\". The bucket\ndoesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while listing objects for \"${bucketName}\".\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For API details, see ListObjectsV2 in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun listBucketObjects(bucketName: String) {\nBasics API Version 2006-03-01 2120",
      "start_idx": 2299166,
      "end_idx": 2300108,
      "metadata": {
        "num_sentences": 6,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2126",
      "text": "Amazon Simple Storage Service API Reference\nval request =\nListObjectsRequest {\nbucket = bucketName\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\nval response = s3.listObjects(request)\nresponse.contents?.forEach { myObject ->\nprintln(\"The name of the key is ${myObject.key}\")\nprintln(\"The object is ${myObject.size?.let { calKb(it) }} KBs\")\nprintln(\"The owner is ${myObject.owner}\")\n}\n}\n}\nprivate fun calKb(intValue: Long): Long = intValue / 1024\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Kotlin API reference.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nList objects in a bucket.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\ntry {\n$contents = $this->s3client->listObjectsV2([\n'Bucket' => $this->bucketName,\n]);\necho \"The contents of your bucket are: \\n\";\nforeach ($contents['Contents'] as $content) {\necho $content['Key'] . \"\\n\";\n}\nBasics API Version 2006-03-01 2121",
      "start_idx": 2300110,
      "end_idx": 2301099,
      "metadata": {
        "num_sentences": 6,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2127",
      "text": "Amazon Simple Storage Service API Reference\n} catch (Exception $exception) {\necho \"Failed to list objects in $this->bucketName with error: \" .\n$exception->getMessage();\nexit(\"Please fix error with listing objects before continuing.\");\n}\n\u2022 For API details, see ListObjectsV2 in AWS SDK for PHP API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\n@staticmethod\ndef list(bucket, prefix=None):\n\"\"\"\nLists the objects in a bucket, optionally filtered by a prefix.\n:param bucket: The bucket to query. This is a Boto3 Bucket resource.\n:param prefix: When specified, only objects that start with this prefix\nare listed.\n:return: The list of objects.\n\"\"\"\nBasics API Version 2006-03-01 2122",
      "start_idx": 2301101,
      "end_idx": 2302181,
      "metadata": {
        "num_sentences": 14,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2128",
      "text": "Amazon Simple Storage Service API Reference\ntry:\nif not prefix:\nobjects = list(bucket.objects.all())\nelse:\nobjects = list(bucket.objects.filter(Prefix=prefix))\nlogger.info(\n\"Got objects %s from bucket '%s'\", [o.key for o in objects],\nbucket.name\n)\nexcept ClientError:\nlogger.exception(\"Couldn't get objects for bucket '%s'.\",\nbucket.name)\nraise\nelse:\nreturn objects\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket actions.\nclass BucketListObjectsWrapper\nattr_reader :bucket\n# @param bucket [Aws::S3::Bucket] An existing Amazon S3 bucket.\ndef initialize(bucket)\n@bucket = bucket\nend\n# Lists object in a bucket.\nBasics API Version 2006-03-01 2123",
      "start_idx": 2302183,
      "end_idx": 2303049,
      "metadata": {
        "num_sentences": 8,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2129",
      "text": "Amazon Simple Storage Service API Reference\n#\n# @param max_objects [Integer] The maximum number of objects to list.\n# @return [Integer] The number of objects listed.\ndef list_objects(max_objects)\ncount = 0\nputs \"The objects in #{@bucket.name} are:\"\n@bucket.objects.each do |obj|\nputs \"\\t#{obj.key}\"\ncount += 1\nbreak if count == max_objects\nend\ncount\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't list objects in bucket #{bucket.name}. Here's why:\n#{e.message}\"\n0\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\n=======\nbucket_name = 'doc-example-bucket'\n>>>>>>> 999c6133e (fixes)\nwrapper = BucketListObjectsWrapper.new(Aws::S3::Bucket.new(bucket_name))\ncount = wrapper.list_objects(25)\nputs \"Listed #{count} objects.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Ruby API Reference.\nBasics API Version 2006-03-01 2124",
      "start_idx": 2303051,
      "end_idx": 2303963,
      "metadata": {
        "num_sentences": 6,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2130",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npub async fn list_objects(client: &aws_sdk_s3::Client, bucket: &str) ->\nResult<(), S3ExampleError> {\nlet mut response = client\n.list_objects_v2()\n.bucket(bucket.to_owned())\n.max_keys(10) // In this example, go 10 at a time.\n.into_paginator()\n.send();\nwhile let Some(result) = response.next().await {\nmatch result {\nOk(output) => {\nfor object in output.contents() {\nprintln!(\" - {}\", object.key().unwrap_or(\"Unknown\"));\n}\n}\nErr(err) => {\neprintln!(\"{err:?}\")\n}\n}\n}\nOk(())\n}\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Rust API reference.\nBasics API Version 2006-03-01 2125",
      "start_idx": 2303965,
      "end_idx": 2304730,
      "metadata": {
        "num_sentences": 7,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2131",
      "text": "Amazon Simple Storage Service API Reference\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTRY.\noo_result = lo_s3->listobjectsv2( \" oo_result is returned for\ntesting purposes. \"\niv_bucket = iv_bucket_name\n).\nMESSAGE 'Retrieved list of objects in S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see ListObjectsV2 in AWS SDK for SAP ABAP API reference.\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\npublic func listBucketFiles(bucket: String) async throws -> [String] {\ndo {\nlet input = ListObjectsV2Input(\nbucket: bucket\n)\nBasics API Version 2006-03-01 2126",
      "start_idx": 2304732,
      "end_idx": 2305578,
      "metadata": {
        "num_sentences": 15,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2132",
      "text": "Amazon Simple Storage Service API Reference\n// Use \"Paginated\" to get all the objects.\n// This lets the SDK handle the 'continuationToken' in\n\"ListObjectsV2Output\".\nlet output = client.listObjectsV2Paginated(input: input)\nvar names: [String] = []\nfor try await page in output {\nguard let objList = page.contents else {\nprint(\"ERROR: listObjectsV2Paginated returned nil contents.\")\ncontinue\n}\nfor obj in objList {\nif let objName = obj.key {\nnames.append(objName)\n}\n}\n}\nreturn names\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Listing objects.\"))\nthrow error\n}\n}\n\u2022 For API details, see ListObjectsV2 in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketAccelerateConfiguration with an AWS SDK or CLI\nThe following code examples show how to use PutBucketAccelerateConfiguration.\nBasics API Version 2006-03-01 2127",
      "start_idx": 2305580,
      "end_idx": 2306605,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2133",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// Amazon Simple Storage Service (Amazon S3) Transfer Acceleration is a\n/// bucket-level feature that enables you to perform faster data transfers\n/// to Amazon S3. This example shows how to configure Transfer\n/// Acceleration.\n/// </summary>\npublic class TransferAcceleration\n{\n/// <summary>\n/// The main method initializes the client object and sets the\n/// Amazon Simple Storage Service (Amazon S3) bucket name before\n/// calling EnableAccelerationAsync.\n/// </summary>\npublic static async Task Main()\n{\nvar s3Client = new AmazonS3Client();\nconst string bucketName = \"amzn-s3-demo-bucket\";\nawait EnableAccelerationAsync(s3Client, bucketName);\n}\n/// <summary>\n/// This method sets the configuration to enable transfer acceleration\n/// for the bucket referred to in the bucketName parameter.\n/// </summary>\n/// <param name=\"client\">An Amazon S3 client used to enable the\n/// acceleration on an Amazon S3 bucket.</param>\nBasics API Version 2006-03-01 2128",
      "start_idx": 2306607,
      "end_idx": 2307851,
      "metadata": {
        "num_sentences": 7,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2134",
      "text": "Amazon Simple Storage Service API Reference\n/// <param name=\"bucketName\">The name of the Amazon S3 bucket for which\nthe\n/// method will be enabling acceleration.</param>\nprivate static async Task EnableAccelerationAsync(AmazonS3Client client,\nstring bucketName)\n{\ntry\n{\nvar putRequest = new PutBucketAccelerateConfigurationRequest\n{\nBucketName = bucketName,\nAccelerateConfiguration = new AccelerateConfiguration\n{\nStatus = BucketAccelerateStatus.Enabled,\n},\n};\nawait client.PutBucketAccelerateConfigurationAsync(putRequest);\nvar getRequest = new GetBucketAccelerateConfigurationRequest\n{\nBucketName = bucketName,\n};\nvar response = await\nclient.GetBucketAccelerateConfigurationAsync(getRequest);\nConsole.WriteLine($\"Acceleration state = '{response.Status}' \");\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"Error occurred. Message:'{ex.Message}' when\nsetting transfer acceleration\");\n}\n}\n}\n\u2022 For API details, see PutBucketAccelerateConfiguration in AWS SDK for .NET API Reference.\nBasics API Version 2006-03-01 2129",
      "start_idx": 2307853,
      "end_idx": 2308874,
      "metadata": {
        "num_sentences": 3,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2135",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nTo set the accelerate configuration of a bucket\nThe following put-bucket-accelerate-configuration example enables the accelerate\nconfiguration for the specified bucket.\naws s3api put-bucket-accelerate-configuration \\\n--bucket my-bucket \\\n--accelerate-configuration Status=Enabled\nThis command produces no output.\n\u2022 For API details, see PutBucketAccelerateConfiguration in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command enables the transfer acceleration for the given S3 bucket.\n$statusVal = New-Object Amazon.S3.BucketAccelerateStatus('Enabled')\nWrite-S3BucketAccelerateConfiguration -BucketName 'amzn-s3-demo-bucket' -\nAccelerateConfiguration_Status $statusVal\n\u2022 For API details, see PutBucketAccelerateConfiguration in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketAcl with an AWS SDK or CLI\nThe following code examples show how to use PutBucketAcl.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\nBasics API Version 2006-03-01 2130",
      "start_idx": 2308876,
      "end_idx": 2310230,
      "metadata": {
        "num_sentences": 10,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2136",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Manage access control lists (ACLs)\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Creates an Amazon S3 bucket with an ACL to control access to the\n/// bucket and the objects stored in it.\n/// </summary>\n/// <param name=\"client\">The initialized client object used to create\n/// an Amazon S3 bucket, with an ACL applied to the bucket.\n/// </param>\n/// <param name=\"region\">The AWS Region where the bucket will be\ncreated.</param>\n/// <param name=\"newBucketName\">The name of the bucket to create.</param>\n/// <returns>A boolean value indicating success or failure.</returns>\npublic static async Task<bool> CreateBucketUseCannedACLAsync(IAmazonS3\nclient, S3Region region, string newBucketName)\n{\ntry\n{\n// Create a new Amazon S3 bucket with Canned ACL.\nvar putBucketRequest = new PutBucketRequest()\n{\nBucketName = newBucketName,\nBucketRegion = region,\nCannedACL = S3CannedACL.LogDeliveryWrite,\n};\nPutBucketResponse putBucketResponse = await\nclient.PutBucketAsync(putBucketRequest);\nreturn putBucketResponse.HttpStatusCode ==\nSystem.Net.HttpStatusCode.OK;\nBasics API Version 2006-03-01 2131",
      "start_idx": 2310232,
      "end_idx": 2311479,
      "metadata": {
        "num_sentences": 6,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2137",
      "text": "Amazon Simple Storage Service API Reference\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"Amazon S3 error: {ex.Message}\");\n}\nreturn false;\n}\n\u2022 For API details, see PutBucketAcl in AWS SDK for .NET API Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::putBucketAcl(const Aws::String &bucketName, const Aws::String\n&ownerID,\nconst Aws::String &granteePermission,\nconst Aws::String &granteeType, const Aws::String\n&granteeID,\nconst Aws::String &granteeEmailAddress,\nconst Aws::String &granteeURI, const\nAws::S3::S3ClientConfiguration &clientConfig) {\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::Owner owner;\nowner.SetID(ownerID);\nAws::S3::Model::Grantee grantee;\ngrantee.SetType(setGranteeType(granteeType));\nif (!granteeEmailAddress.empty()) {\ngrantee.SetEmailAddress(granteeEmailAddress);\n}\nBasics API Version 2006-03-01 2132",
      "start_idx": 2311481,
      "end_idx": 2312444,
      "metadata": {
        "num_sentences": 4,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2140",
      "text": "Amazon Simple Storage Service API Reference\naws s3api put-bucket-acl --bucket MyBucket --grant-full-\ncontrol emailaddress=user1@example.com,emailaddress=user2@example.com --grant-\nread uri=http://acs.amazonaws.com/groups/global/AllUsers\nSee http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTacl.html for\ndetails on custom ACLs (the s3api ACL commands, such as put-bucket-acl, use the same\nshorthand argument notation).\n\u2022 For API details, see PutBucketAcl in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.AccessControlPolicy;\nimport software.amazon.awssdk.services.s3.model.Grant;\nimport software.amazon.awssdk.services.s3.model.Permission;\nimport software.amazon.awssdk.services.s3.model.PutBucketAclRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.Type;\nimport java.util.ArrayList;\nimport java.util.List;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n* <p>\n* For more information, see the following documentation topic:\n* <p>\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\nBasics API Version 2006-03-01 2135",
      "start_idx": 2314834,
      "end_idx": 2316300,
      "metadata": {
        "num_sentences": 6,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2142",
      "text": "Amazon Simple Storage Service API Reference\nGrant ownerGrant = Grant.builder()\n.grantee(builder -> builder.id(id)\n.type(Type.CANONICAL_USER))\n.permission(Permission.FULL_CONTROL)\n.build();\nList<Grant> grantList2 = new ArrayList<>();\ngrantList2.add(ownerGrant);\nAccessControlPolicy acl = AccessControlPolicy.builder()\n.owner(builder -> builder.id(id))\n.grants(grantList2)\n.build();\nPutBucketAclRequest putAclReq = PutBucketAclRequest.builder()\n.bucket(bucketName)\n.accessControlPolicy(acl)\n.build();\ns3.putBucketAcl(putAclReq);\n} catch (S3Exception e) {\ne.printStackTrace();\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see PutBucketAcl in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nPut the bucket ACL.\nBasics API Version 2006-03-01 2137",
      "start_idx": 2317487,
      "end_idx": 2318371,
      "metadata": {
        "num_sentences": 5,
        "num_words": 100,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2143",
      "text": "Amazon Simple Storage Service API Reference\nimport {\nPutBucketAclCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Grant read access to a user using their canonical AWS account ID.\n*\n* Most Amazon S3 use cases don't require the use of access control lists (ACLs).\n* We recommend that you disable ACLs, except in unusual circumstances where\n* you need to control access for each object individually. Consider a policy\ninstead.\n* For more information see https://docs.aws.amazon.com/AmazonS3/latest/\nuserguide/bucket-policies.html.\n* @param {{ bucketName: string, granteeCanonicalUserId: string,\nownerCanonicalUserId }}\n*/\nexport const main = async ({\nbucketName,\ngranteeCanonicalUserId,\nownerCanonicalUserId,\n}) => {\nconst client = new S3Client({});\nconst command = new PutBucketAclCommand({\nBucket: bucketName,\nAccessControlPolicy: {\nGrants: [\n{\nGrantee: {\n// The canonical ID of the user. This ID is an obfuscated form of\nyour AWS account number.\n// It's unique to Amazon S3 and can't be found elsewhere.\n// For more information, see https://docs.aws.amazon.com/AmazonS3/\nlatest/userguide/finding-canonical-user-id.html.\nID: granteeCanonicalUserId,\nType: \"CanonicalUser\",\n},\n// One of FULL_CONTROL | READ | WRITE | READ_ACP | WRITE_ACP\n// https://docs.aws.amazon.com/AmazonS3/latest/API/\nAPI_Grant.html#AmazonS3-Type-Grant-Permission\nPermission: \"READ\",\n},\nBasics API Version 2006-03-01 2138",
      "start_idx": 2318373,
      "end_idx": 2319789,
      "metadata": {
        "num_sentences": 10,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2144",
      "text": "Amazon Simple Storage Service API Reference\n],\nOwner: {\nID: ownerCanonicalUserId,\n},\n},\n});\ntry {\nawait client.send(command);\nconsole.log(`Granted READ access to ${bucketName}`);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while setting ACL for bucket ${bucketName}. The bucket\ndoesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while setting ACL for bucket ${bucketName}.\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see PutBucketAcl in AWS SDK for JavaScript API Reference.\nBasics API Version 2006-03-01 2139",
      "start_idx": 2319791,
      "end_idx": 2320547,
      "metadata": {
        "num_sentences": 5,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2145",
      "text": "Amazon Simple Storage Service API Reference\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun setBucketAcl(\nbucketName: String,\nidVal: String,\n) {\nval myGrant =\nGrantee {\nid = idVal\ntype = Type.CanonicalUser\n}\nval ownerGrant =\nGrant {\ngrantee = myGrant\npermission = Permission.FullControl\n}\nval grantList = mutableListOf<Grant>()\ngrantList.add(ownerGrant)\nval ownerOb =\nOwner {\nid = idVal\n}\nval acl =\nAccessControlPolicy {\nowner = ownerOb\ngrants = grantList\n}\nval request =\nPutBucketAclRequest {\nBasics API Version 2006-03-01 2140",
      "start_idx": 2320549,
      "end_idx": 2321187,
      "metadata": {
        "num_sentences": 3,
        "num_words": 102,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2146",
      "text": "Amazon Simple Storage Service API Reference\nbucket = bucketName\naccessControlPolicy = acl\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\ns3.putBucketAcl(request)\nprintln(\"An ACL was successfully set on $bucketName\")\n}\n}\n\u2022 For API details, see PutBucketAcl in AWS SDK for Kotlin API reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef grant_log_delivery_access(self):\n\"\"\"\nGrant the AWS Log Delivery group write access to the bucket so that\nAmazon S3 can deliver access logs to the bucket. This is the only\nrecommended\nuse of an S3 bucket ACL.\nBasics API Version 2006-03-01 2141",
      "start_idx": 2321189,
      "end_idx": 2322155,
      "metadata": {
        "num_sentences": 9,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2147",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"\ntry:\nacl = self.bucket.Acl()\n# Putting an ACL overwrites the existing ACL. If you want to preserve\n# existing grants, append new grants to the list of existing grants.\ngrants = acl.grants if acl.grants else []\ngrants.append(\n{\n\"Grantee\": {\n\"Type\": \"Group\",\n\"URI\": \"http://acs.amazonaws.com/groups/s3/LogDelivery\",\n},\n\"Permission\": \"WRITE\",\n}\n)\nacl.put(AccessControlPolicy={\"Grants\": grants, \"Owner\": acl.owner})\nlogger.info(\"Granted log delivery access to bucket '%s'\",\nself.bucket.name)\nexcept ClientError:\nlogger.exception(\"Couldn't add ACL to bucket '%s'.\",\nself.bucket.name)\nraise\n\u2022 For API details, see PutBucketAcl in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketCors with an AWS SDK or CLI\nThe following code examples show how to use PutBucketCors.\nBasics API Version 2006-03-01 2142",
      "start_idx": 2322157,
      "end_idx": 2323222,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2148",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Add CORS configuration to the Amazon S3 bucket.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client object used\n/// to apply the CORS configuration to an Amazon S3 bucket.</param>\n/// <param name=\"configuration\">The CORS configuration to apply.</param>\nprivate static async Task PutCORSConfigurationAsync(AmazonS3Client\nclient, CORSConfiguration configuration)\n{\nPutCORSConfigurationRequest request = new\nPutCORSConfigurationRequest()\n{\nBucketName = BucketName,\nConfiguration = configuration,\n};\n_ = await client.PutCORSConfigurationAsync(request);\n}\n\u2022 For API details, see PutBucketCors in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nThe following example enables PUT, POST, and DELETE requests from www.example.com,\nand enables GET requests from any domain:\nBasics API Version 2006-03-01 2143",
      "start_idx": 2323224,
      "end_idx": 2324247,
      "metadata": {
        "num_sentences": 5,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2149",
      "text": "Amazon Simple Storage Service API Reference\naws s3api put-bucket-cors --bucket MyBucket --cors-configuration file://cors.json\ncors.json:\n{\n\"CORSRules\": [\n{\n\"AllowedOrigins\": [\"http://www.example.com\"],\n\"AllowedHeaders\": [\"*\"],\n\"AllowedMethods\": [\"PUT\", \"POST\", \"DELETE\"],\n\"MaxAgeSeconds\": 3000,\n\"ExposeHeaders\": [\"x-amz-server-side-encryption\"]\n},\n{\n\"AllowedOrigins\": [\"*\"],\n\"AllowedHeaders\": [\"Authorization\"],\n\"AllowedMethods\": [\"GET\"],\n\"MaxAgeSeconds\": 3000\n}\n]\n}\n\u2022 For API details, see PutBucketCors in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport java.util.ArrayList;\nimport java.util.List;\nimport software.amazon.awssdk.services.s3.model.GetBucketCorsRequest;\nBasics API Version 2006-03-01 2144",
      "start_idx": 2324249,
      "end_idx": 2325182,
      "metadata": {
        "num_sentences": 4,
        "num_words": 97,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2153",
      "text": "Amazon Simple Storage Service API Reference\n.allowedMethods(allowMethods)\n.allowedOrigins(allowOrigins)\n.build();\nList<CORSRule> corsRules = new ArrayList<>();\ncorsRules.add(corsRule);\nCORSConfiguration configuration = CORSConfiguration.builder()\n.corsRules(corsRules)\n.build();\nPutBucketCorsRequest putBucketCorsRequest =\nPutBucketCorsRequest.builder()\n.bucket(bucketName)\n.corsConfiguration(configuration)\n.expectedBucketOwner(accountId)\n.build();\ns3.putBucketCors(putBucketCorsRequest);\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see PutBucketCors in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nAdd a CORS rule.\nimport {\nBasics API Version 2006-03-01 2148",
      "start_idx": 2329268,
      "end_idx": 2330157,
      "metadata": {
        "num_sentences": 5,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2154",
      "text": "Amazon Simple Storage Service API Reference\nPutBucketCorsCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Allows cross-origin requests to an S3 bucket by setting the CORS\nconfiguration.\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nawait client.send(\nnew PutBucketCorsCommand({\nBucket: bucketName,\nCORSConfiguration: {\nCORSRules: [\n{\n// Allow all headers to be sent to this bucket.\nAllowedHeaders: [\"*\"],\n// Allow only GET and PUT methods to be sent to this bucket.\nAllowedMethods: [\"GET\", \"PUT\"],\n// Allow only requests from the specified origin.\nAllowedOrigins: [\"https://www.example.com\"],\n// Allow the entity tag (ETag) header to be returned in the\nresponse. The ETag header\n// The entity tag represents a specific version of the object. The\nETag reflects\n// changes only to the contents of an object, not its metadata.\nExposeHeaders: [\"ETag\"],\n// How long the requesting browser should cache the preflight\nresponse. After\n// this time, the preflight request will have to be made again.\nMaxAgeSeconds: 3600,\n},\n],\n},\n}),\n);\nconsole.log(`Successfully set CORS rules for bucket: ${bucketName}`);\n} catch (caught) {\nif (\nBasics API Version 2006-03-01 2149",
      "start_idx": 2330159,
      "end_idx": 2331418,
      "metadata": {
        "num_sentences": 10,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2155",
      "text": "Amazon Simple Storage Service API Reference\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while setting CORS rules for ${bucketName}. The bucket\ndoesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while setting CORS rules for ${bucketName}.\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see PutBucketCors in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nBasics API Version 2006-03-01 2150",
      "start_idx": 2331420,
      "end_idx": 2332399,
      "metadata": {
        "num_sentences": 10,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2156",
      "text": "Amazon Simple Storage Service API Reference\nself.bucket = bucket\nself.name = bucket.name\ndef put_cors(self, cors_rules):\n\"\"\"\nApply CORS rules to the bucket. CORS rules specify the HTTP actions that\nare\nallowed from other domains.\n:param cors_rules: The CORS rules to apply.\n\"\"\"\ntry:\nself.bucket.Cors().put(CORSConfiguration={\"CORSRules\": cors_rules})\nlogger.info(\n\"Put CORS rules %s for bucket '%s'.\", cors_rules,\nself.bucket.name\n)\nexcept ClientError:\nlogger.exception(\"Couldn't put CORS rules for bucket %s.\",\nself.bucket.name)\nraise\n\u2022 For API details, see PutBucketCors in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket CORS configuration.\nclass BucketCorsWrapper\nattr_reader :bucket_cors\nBasics API Version 2006-03-01 2151",
      "start_idx": 2332401,
      "end_idx": 2333310,
      "metadata": {
        "num_sentences": 10,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2157",
      "text": "Amazon Simple Storage Service API Reference\n# @param bucket_cors [Aws::S3::BucketCors] A bucket CORS object configured with\nan existing bucket.\ndef initialize(bucket_cors)\n@bucket_cors = bucket_cors\nend\n# Sets CORS rules on a bucket.\n#\n# @param allowed_methods [Array<String>] The types of HTTP requests to allow.\n# @param allowed_origins [Array<String>] The origins to allow.\n# @returns [Boolean] True if the CORS rules were set; otherwise, false.\ndef set_cors(allowed_methods, allowed_origins)\n@bucket_cors.put(\ncors_configuration: {\ncors_rules: [\n{\nallowed_methods: allowed_methods,\nallowed_origins: allowed_origins,\nallowed_headers: %w[*],\nmax_age_seconds: 3600\n}\n]\n}\n)\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't set CORS rules for #{@bucket_cors.bucket.name}. Here's why:\n#{e.message}\"\nfalse\nend\nend\n\u2022 For API details, see PutBucketCors in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 2152",
      "start_idx": 2333312,
      "end_idx": 2334455,
      "metadata": {
        "num_sentences": 10,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2158",
      "text": "Amazon Simple Storage Service API Reference\nUse PutBucketEncryption with an AWS SDK or CLI\nThe following code examples show how to use PutBucketEncryption.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Set the bucket server side encryption to use AWSKMS with a customer-\nmanaged key id.\n/// </summary>\n/// <param name=\"bucketName\">Name of the bucket.</param>\n/// <param name=\"kmsKeyId\">The Id of the KMS Key.</param>\n/// <returns>True if successful.</returns>\npublic static async Task<bool> SetBucketServerSideEncryption(string\nbucketName, string kmsKeyId)\n{\nvar serverSideEncryptionByDefault = new ServerSideEncryptionConfiguration\n{\nServerSideEncryptionRules = new List<ServerSideEncryptionRule>\n{\nnew ServerSideEncryptionRule\n{\nServerSideEncryptionByDefault = new\nServerSideEncryptionByDefault\n{\nServerSideEncryptionAlgorithm =\nServerSideEncryptionMethod.AWSKMS,\nServerSideEncryptionKeyManagementServiceKeyId = kmsKeyId\n}\n}\n}\n};\ntry\n{\nBasics API Version 2006-03-01 2153",
      "start_idx": 2334457,
      "end_idx": 2335547,
      "metadata": {
        "num_sentences": 5,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2160",
      "text": "Amazon Simple Storage Service API Reference\nPowerShell\nTools for PowerShell\nExample 1: This command enables default AES256 server side encryption with Amazon\nS3 Managed Keys(SSE-S3) on the given bucket.\n$Encryptionconfig = @{ServerSideEncryptionByDefault =\n@{ServerSideEncryptionAlgorithm = \"AES256\"}}\nSet-S3BucketEncryption -BucketName 'amzn-s3-demo-bucket' -\nServerSideEncryptionConfiguration_ServerSideEncryptionRule $Encryptionconfig\n\u2022 For API details, see PutBucketEncryption in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketLifecycleConfiguration with an AWS SDK or CLI\nThe following code examples show how to use PutBucketLifecycleConfiguration.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Delete incomplete multipart uploads\n\u2022 Work with versioned objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\nBasics API Version 2006-03-01 2155",
      "start_idx": 2336689,
      "end_idx": 2337981,
      "metadata": {
        "num_sentences": 9,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2162",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"Date\": \"2015-11-10T00:00:00.000Z\",\n\"StorageClass\": \"GLACIER\"\n}\n]\n},\n{\n\"Status\": \"Enabled\",\n\"Prefix\": \"\",\n\"NoncurrentVersionTransitions\": [\n{\n\"NoncurrentDays\": 2,\n\"StorageClass\": \"GLACIER\"\n}\n],\n\"ID\": \"Move old versions to Glacier\"\n}\n]\n}\nThe first rule moves files with the prefix rotated to Glacier on the specified date. The\nsecond rule moves old object versions to Glacier when they are no longer current. For\ninformation on acceptable timestamp formats, see Specifying Parameter Values in the AWS\nCLI User Guide.\n\u2022 For API details, see PutBucketLifecycleConfiguration in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.LifecycleRuleFilter;\nBasics API Version 2006-03-01 2157",
      "start_idx": 2339350,
      "end_idx": 2340344,
      "metadata": {
        "num_sentences": 7,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2168",
      "text": "Amazon Simple Storage Service API Reference\nDeleteBucketLifecycleRequest deleteBucketLifecycleRequest =\nDeleteBucketLifecycleRequest\n.builder()\n.bucket(bucketName)\n.expectedBucketOwner(accountId)\n.build();\ns3.deleteBucketLifecycle(deleteBucketLifecycleRequest);\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see PutBucketLifecycleConfiguration in AWS SDK for Java 2.x API\nReference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\nBasics API Version 2006-03-01 2163",
      "start_idx": 2346986,
      "end_idx": 2347906,
      "metadata": {
        "num_sentences": 7,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2169",
      "text": "Amazon Simple Storage Service API Reference\ndef put_lifecycle_configuration(self, lifecycle_rules):\n\"\"\"\nApply a lifecycle configuration to the bucket. The lifecycle\nconfiguration can\nbe used to archive or delete the objects in the bucket according to\nspecified\nparameters, such as a number of days.\n:param lifecycle_rules: The lifecycle rules to apply.\n\"\"\"\ntry:\nself.bucket.LifecycleConfiguration().put(\nLifecycleConfiguration={\"Rules\": lifecycle_rules}\n)\nlogger.info(\n\"Put lifecycle rules %s for bucket '%s'.\",\nlifecycle_rules,\nself.bucket.name,\n)\nexcept ClientError:\nlogger.exception(\n\"Couldn't put lifecycle rules for bucket '%s'.\", self.bucket.name\n)\nraise\n\u2022 For API details, see PutBucketLifecycleConfiguration in AWS SDK for Python (Boto3) API\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketLogging with an AWS SDK or CLI\nThe following code examples show how to use PutBucketLogging.\nBasics API Version 2006-03-01 2164",
      "start_idx": 2347908,
      "end_idx": 2349026,
      "metadata": {
        "num_sentences": 10,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2170",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.IO;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Microsoft.Extensions.Configuration;\n/// <summary>\n/// This example shows how to enable logging on an Amazon Simple Storage\n/// Service (Amazon S3) bucket. You need to have two Amazon S3 buckets for\n/// this example. The first is the bucket for which you wish to enable\n/// logging, and the second is the location where you want to store the\n/// logs.\n/// </summary>\npublic class ServerAccessLogging\n{\nprivate static IConfiguration _configuration = null!;\npublic static async Task Main()\n{\nLoadConfig();\nstring bucketName = _configuration[\"BucketName\"];\nstring logBucketName = _configuration[\"LogBucketName\"];\nstring logObjectKeyPrefix = _configuration[\"LogObjectKeyPrefix\"];\nstring accountId = _configuration[\"AccountId\"];\n// If the AWS Region defined for your default user is different\n// from the Region where your Amazon S3 bucket is located,\n// pass the Region name to the Amazon S3 client object's constructor.\n// For example: RegionEndpoint.USWest2 or RegionEndpoint.USEast2.\nIAmazonS3 client = new AmazonS3Client();\nBasics API Version 2006-03-01 2165",
      "start_idx": 2349028,
      "end_idx": 2350382,
      "metadata": {
        "num_sentences": 9,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2172",
      "text": "Amazon Simple Storage Service API Reference\nstring logPrefix,\nstring accountId)\n{\nvar resourceArn = @\"\"\"arn:aws:s3:::\" + logBucketName + \"/\" +\nlogPrefix + @\"*\"\"\";\nvar newPolicy = @\"{\n\"\"Statement\"\":[{\n\"\"Sid\"\": \"\"S3ServerAccessLogsPolicy\"\",\n\"\"Effect\"\": \"\"Allow\"\",\n\"\"Principal\"\": { \"\"Service\"\":\n\"\"logging.s3.amazonaws.com\"\" },\n\"\"Action\"\": [\"\"s3:PutObject\"\"],\n\"\"Resource\"\": [\" + resourceArn + @\"],\n\"\"Condition\"\": {\n\"\"ArnLike\"\": { \"\"aws:SourceArn\"\":\n\"\"arn:aws:s3:::\" + sourceBucketName + @\"\"\" },\n\"\"StringEquals\"\": { \"\"aws:SourceAccount\"\": \"\"\" +\naccountId + @\"\"\" }\n}\n}]\n}\";\nConsole.WriteLine($\"The policy to apply to bucket {logBucketName} to\nenable logging:\");\nConsole.WriteLine(newPolicy);\nPutBucketPolicyRequest putRequest = new PutBucketPolicyRequest\n{\nBucketName = logBucketName,\nPolicy = newPolicy,\n};\nawait client.PutBucketPolicyAsync(putRequest);\nConsole.WriteLine(\"Policy applied.\");\n}\n/// <summary>\n/// This method enables logging for an Amazon S3 bucket. Logs will be\nstored\n/// in the bucket you selected for logging. Selected prefix\n/// will be prepended to each log object.\n/// </summary>\n/// <param name=\"client\">The initialized Amazon S3 client which will be\nused\nBasics API Version 2006-03-01 2167",
      "start_idx": 2351649,
      "end_idx": 2352857,
      "metadata": {
        "num_sentences": 5,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2174",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\n\u2022 For API details, see PutBucketLogging in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nExample 1: To set bucket policy logging\nThe following put-bucket-logging example sets the logging policy for MyBucket. First,\ngrant the logging service principal permission in your bucket policy using the put-bucket-\npolicy command.\naws s3api put-bucket-policy \\\n--bucket MyBucket \\\n--policy file://policy.json\nContents of policy.json:\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"S3ServerAccessLogsPolicy\",\n\"Effect\": \"Allow\",\n\"Principal\": {\"Service\": \"logging.s3.amazonaws.com\"},\n\"Action\": \"s3:PutObject\",\n\"Resource\": \"arn:aws:s3:::MyBucket/Logs/*\",\n\"Condition\": {\n\"ArnLike\": {\"aws:SourceARN\": \"arn:aws:s3:::SOURCE-BUCKET-NAME\"},\n\"StringEquals\": {\"aws:SourceAccount\": \"SOURCE-AWS-ACCOUNT-ID\"}\n}\n}\n]\n}\nTo apply the logging policy, use put-bucket-logging.\nBasics API Version 2006-03-01 2169",
      "start_idx": 2354264,
      "end_idx": 2355195,
      "metadata": {
        "num_sentences": 5,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2175",
      "text": "Amazon Simple Storage Service API Reference\naws s3api put-bucket-logging \\\n--bucket MyBucket \\\n--bucket-logging-status file://logging.json\nContents of logging.json:\n{\n\"LoggingEnabled\": {\n\"TargetBucket\": \"MyBucket\",\n\"TargetPrefix\": \"Logs/\"\n}\n}\nThe put-bucket-policy command is required to grant s3:PutObject permissions to the\nlogging service principal.\nFor more information, see Amazon S3 Server Access Logging in the Amazon S3 User Guide.\nExample 2: To set a bucket policy for logging access to only a single user\nThe following put-bucket-logging example sets the logging policy for MyBucket. The\nAWS user bob@example.com will have full control over the log files, and no one else has any\naccess. First, grant S3 permission with put-bucket-acl.\naws s3api put-bucket-acl \\\n--bucket MyBucket \\\n--grant-write URI=http://acs.amazonaws.com/groups/s3/LogDelivery \\\n--grant-read-acp URI=http://acs.amazonaws.com/groups/s3/LogDelivery\nThen apply the logging policy using put-bucket-logging.\naws s3api put-bucket-logging \\\n--bucket MyBucket \\\n--bucket-logging-status file://logging.json\nContents of logging.json:\n{\n\"LoggingEnabled\": {\nBasics API Version 2006-03-01 2170",
      "start_idx": 2355197,
      "end_idx": 2356358,
      "metadata": {
        "num_sentences": 7,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2176",
      "text": "Amazon Simple Storage Service API Reference\n\"TargetBucket\": \"MyBucket\",\n\"TargetPrefix\": \"MyBucketLogs/\",\n\"TargetGrants\": [\n{\n\"Grantee\": {\n\"Type\": \"AmazonCustomerByEmail\",\n\"EmailAddress\": \"bob@example.com\"\n},\n\"Permission\": \"FULL_CONTROL\"\n}\n]\n}\n}\nthe put-bucket-acl command is required to grant S3's log delivery system the necessary\npermissions (write and read-acp permissions).\nFor more information, see Amazon S3 Server Access Logging in the Amazon S3 Developer\nGuide.\n\u2022 For API details, see PutBucketLogging in AWS CLI Command Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketNotification with a CLI\nThe following code examples show how to use PutBucketNotification.\nCLI\nAWS CLI\nThe applies a notification configuration to a bucket named my-bucket:\naws s3api put-bucket-notification --bucket my-bucket --notification-\nconfiguration file://notification.json\nThe file notification.json is a JSON document in the current folder that specifies an\nSNS topic and an event type to monitor:\nBasics API Version 2006-03-01 2171",
      "start_idx": 2356360,
      "end_idx": 2357571,
      "metadata": {
        "num_sentences": 7,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2179",
      "text": "Amazon Simple Storage Service API Reference\n)\n}\n}\n}\n#Lambda Config 2\n$secondlambdaConfig = [Amazon.S3.Model.LambdaFunctionConfiguration] @{\nEvents = [Amazon.S3.EventType]::ObjectCreatedAll\nFunctionArn = \"arn:aws:lambda:eu-west-1:123456789012:function:verifyssm\"\nId = \"ObjectCreated-dada-json\"\nFilter = @{\nS3KeyFilter = @{\nFilterRules = @(\n@{Name=\"Prefix\";Value=\"dada\"}\n@{Name=\"Suffix\";Value=\".json\"}\n)\n}\n}\n}\nWrite-S3BucketNotification -BucketName amzn-s3-demo-bucket -\nLambdaFunctionConfiguration $firstLambdaConfig,$secondlambdaConfig\n\u2022 For API details, see PutBucketNotification in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketNotificationConfiguration with an AWS SDK or CLI\nThe following code examples show how to use PutBucketNotificationConfiguration.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Process S3 event notifications\n\u2022 Send event notifications to EventBridge\nBasics API Version 2006-03-01 2174",
      "start_idx": 2359803,
      "end_idx": 2361048,
      "metadata": {
        "num_sentences": 6,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2180",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to enable notifications for an Amazon Simple\n/// Storage Service (Amazon S3) bucket.\n/// </summary>\npublic class EnableNotifications\n{\npublic static async Task Main()\n{\nconst string bucketName = \"amzn-s3-demo-bucket1\";\nconst string snsTopic = \"arn:aws:sns:us-east-2:0123456789ab:bucket-\nnotify\";\nconst string sqsQueue = \"arn:aws:sqs:us-\neast-2:0123456789ab:Example_Queue\";\nIAmazonS3 client = new AmazonS3Client(Amazon.RegionEndpoint.USEast2);\nawait EnableNotificationAsync(client, bucketName, snsTopic,\nsqsQueue);\n}\n/// <summary>\n/// This method makes the call to the PutBucketNotificationAsync method.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client used to call\n/// the PutBucketNotificationAsync method.</param>\n/// <param name=\"bucketName\">The name of the bucket for which\n/// notifications will be turned on.</param>\nBasics API Version 2006-03-01 2175",
      "start_idx": 2361050,
      "end_idx": 2362279,
      "metadata": {
        "num_sentences": 5,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2182",
      "text": "Amazon Simple Storage Service API Reference\nConsole.WriteLine($\"Error: {ex.Message}\");\n}\n}\n}\n\u2022 For API details, see PutBucketNotificationConfiguration in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo enable the specified notifications to a bucket\nThe following put-bucket-notification-configuration example applies a\nnotification configuration to a bucket named my-bucket. The file notification.json\nis a JSON document in the current folder that specifies an SNS topic and an event type to\nmonitor.\naws s3api put-bucket-notification-configuration \\\n--bucket my-bucket \\\n--notification-configuration file://notification.json\nContents of notification.json:\n{\n\"TopicConfigurations\": [\n{\n\"TopicArn\": \"arn:aws:sns:us-west-2:123456789012:s3-notification-\ntopic\",\n\"Events\": [\n\"s3:ObjectCreated:*\"\n]\n}\n]\n}\nThe SNS topic must have an IAM policy attached to it that allows Amazon S3 to publish to it.\n{\nBasics API Version 2006-03-01 2177",
      "start_idx": 2363519,
      "end_idx": 2364447,
      "metadata": {
        "num_sentences": 5,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2183",
      "text": "Amazon Simple Storage Service API Reference\n\"Version\": \"2008-10-17\",\n\"Id\": \"example-ID\",\n\"Statement\": [\n{\n\"Sid\": \"example-statement-ID\",\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"Service\": \"s3.amazonaws.com\"\n},\n\"Action\": [\n\"SNS:Publish\"\n],\n\"Resource\": \"arn:aws:sns:us-west-2:123456789012::s3-notification-\ntopic\",\n\"Condition\": {\n\"ArnLike\": {\n\"aws:SourceArn\": \"arn:aws:s3:*:*:my-bucket\"\n}\n}\n}\n]\n}\n\u2022 For API details, see PutBucketNotificationConfiguration in AWS CLI Command Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketPolicy with an AWS SDK or CLI\nThe following code examples show how to use PutBucketPolicy.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2178",
      "start_idx": 2364449,
      "end_idx": 2365421,
      "metadata": {
        "num_sentences": 7,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2185",
      "text": "Amazon Simple Storage Service API Reference\n\" \\\"Version\\\":\\\"2012-10-17\\\",\\n\"\n\" \\\"Statement\\\":[\\n\"\n\" {\\n\"\n\" \\\"Sid\\\": \\\"1\\\",\\n\"\n\" \\\"Effect\\\": \\\"Allow\\\",\\n\"\n\" \\\"Principal\\\": {\\n\"\n\" \\\"AWS\\\": \\\"\"\n+ userArn +\n\"\\\"\\n\"\" },\\n\"\n\" \\\"Action\\\": [ \\\"s3:getObject\\\" ],\\n\"\n\" \\\"Resource\\\": [ \\\"arn:aws:s3:::\"\n+ bucketName +\n\"/*\\\" ]\\n\"\n\" }\\n\"\n\" ]\\n\"\n\"}\";\n}\n\u2022 For API details, see PutBucketPolicy in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThis example allows all users to retrieve any object in MyBucket except those in the\nMySecretFolder. It also grants put and delete permission to the root user of the AWS\naccount 1234-5678-9012:\naws s3api put-bucket-policy --bucket MyBucket --policy file://policy.json\npolicy.json:\n{\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Principal\": \"*\",\n\"Action\": \"s3:GetObject\",\n\"Resource\": \"arn:aws:s3:::MyBucket/*\"\n},\n{\n\"Effect\": \"Deny\",\nBasics API Version 2006-03-01 2180",
      "start_idx": 2366705,
      "end_idx": 2367586,
      "metadata": {
        "num_sentences": 3,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2186",
      "text": "Amazon Simple Storage Service API Reference\n\"Principal\": \"*\",\n\"Action\": \"s3:GetObject\",\n\"Resource\": \"arn:aws:s3:::MyBucket/MySecretFolder/*\"\n},\n{\n\"Effect\": \"Allow\",\n\"Principal\": {\n\"AWS\": \"arn:aws:iam::123456789012:root\"\n},\n\"Action\": [\n\"s3:DeleteObject\",\n\"s3:PutObject\"\n],\n\"Resource\": \"arn:aws:s3:::MyBucket/*\"\n}\n]\n}\n\u2022 For API details, see PutBucketPolicy in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.PutBucketPolicyRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\nimport java.io.IOException;\nimport java.nio.charset.StandardCharsets;\nimport java.nio.file.Files;\nimport java.nio.file.Paths;\nimport java.util.List;\nBasics API Version 2006-03-01 2181",
      "start_idx": 2367588,
      "end_idx": 2368533,
      "metadata": {
        "num_sentences": 4,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2189",
      "text": "Amazon Simple Storage Service API Reference\nfileText.append(line);\n}\n} catch (IOException e) {\nSystem.out.format(\"Problem reading file: \\\"%s\\\"\", policyFile);\nSystem.out.println(e.getMessage());\n}\ntry {\nfinal JsonParser parser = new\nObjectMapper().getFactory().createParser(fileText.toString());\nwhile (parser.nextToken() != null) {\n}\n} catch (IOException jpe) {\njpe.printStackTrace();\n}\nreturn fileText.toString();\n}\n}\n\u2022 For API details, see PutBucketPolicy in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nAdd the policy.\nimport {\nPutBucketPolicyCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\nBasics API Version 2006-03-01 2184",
      "start_idx": 2370988,
      "end_idx": 2371786,
      "metadata": {
        "num_sentences": 5,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2190",
      "text": "Amazon Simple Storage Service API Reference\n/**\n* Grant an IAM role GetObject access to all of the objects\n* in the provided bucket.\n* @param {{ bucketName: string, iamRoleArn: string }}\n*/\nexport const main = async ({ bucketName, iamRoleArn }) => {\nconst client = new S3Client({});\nconst command = new PutBucketPolicyCommand({\n// This is a resource-based policy. For more information on resource-based\npolicies,\n// see https://docs.aws.amazon.com/IAM/latest/UserGuide/\naccess_policies.html#policies_resource-based.\nPolicy: JSON.stringify({\nVersion: \"2012-10-17\",\nStatement: [\n{\nEffect: \"Allow\",\nPrincipal: {\nAWS: iamRoleArn,\n},\nAction: \"s3:GetObject\",\nResource: `arn:aws:s3:::${bucketName}/*`,\n},\n],\n}),\n// Apply the preceding policy to this bucket.\nBucket: bucketName,\n});\ntry {\nawait client.send(command);\nconsole.log(\n`GetObject access to the bucket \"${bucketName}\" was granted to the provided\nIAM role.`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"MalformedPolicy\"\n) {\nconsole.error(\n`Error from S3 while setting the bucket policy for the bucket\n\"${bucketName}\". The policy was malformed.`,\n);\nBasics API Version 2006-03-01 2185",
      "start_idx": 2371788,
      "end_idx": 2372962,
      "metadata": {
        "num_sentences": 6,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2191",
      "text": "Amazon Simple Storage Service API Reference\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while setting the bucket policy for the bucket\n\"${bucketName}\". ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see PutBucketPolicy in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef put_policy(self, policy):\n\"\"\"\nApply a security policy to the bucket. Policies control users' ability\nBasics API Version 2006-03-01 2186",
      "start_idx": 2372964,
      "end_idx": 2373935,
      "metadata": {
        "num_sentences": 10,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2192",
      "text": "Amazon Simple Storage Service API Reference\nto perform specific actions, such as listing the objects in the bucket.\n:param policy: The policy to apply to the bucket.\n\"\"\"\ntry:\nself.bucket.Policy().put(Policy=json.dumps(policy))\nlogger.info(\"Put policy %s for bucket '%s'.\", policy,\nself.bucket.name)\nexcept ClientError:\nlogger.exception(\"Couldn't apply policy to bucket '%s'.\",\nself.bucket.name)\nraise\n\u2022 For API details, see PutBucketPolicy in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n# Wraps an Amazon S3 bucket policy.\nclass BucketPolicyWrapper\nattr_reader :bucket_policy\n# @param bucket_policy [Aws::S3::BucketPolicy] A bucket policy object\nconfigured with an existing bucket.\ndef initialize(bucket_policy)\n@bucket_policy = bucket_policy\nend\n# Sets a policy on a bucket.\n#\ndef policy(policy)\n@bucket_policy.put(policy: policy)\ntrue\nBasics API Version 2006-03-01 2187",
      "start_idx": 2373937,
      "end_idx": 2374948,
      "metadata": {
        "num_sentences": 11,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2193",
      "text": "Amazon Simple Storage Service API Reference\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't set the policy for #{@bucket_policy.bucket.name}. Here's why:\n#{e.message}\"\nfalse\nend\nend\n\u2022 For API details, see PutBucketPolicy in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketReplication with a CLI\nThe following code examples show how to use PutBucketReplication.\nCLI\nAWS CLI\nTo configure replication for an S3 bucket\nThe following put-bucket-replication example applies a replication configuration to\nthe specified S3 bucket.\naws s3api put-bucket-replication \\\n--bucket AWSDOC-EXAMPLE-BUCKET1 \\\n--replication-configuration file://replication.json\nContents of replication.json:\n{\n\"Role\": \"arn:aws:iam::123456789012:role/s3-replication-role\",\n\"Rules\": [\n{\n\"Status\": \"Enabled\",\n\"Priority\": 1,\n\"DeleteMarkerReplication\": { \"Status\": \"Disabled\" },\n\"Filter\" : { \"Prefix\": \"\"},\nBasics API Version 2006-03-01 2188",
      "start_idx": 2374950,
      "end_idx": 2376072,
      "metadata": {
        "num_sentences": 7,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2194",
      "text": "Amazon Simple Storage Service API Reference\n\"Destination\": {\n\"Bucket\": \"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET2\"\n}\n}\n]\n}\nThe destination bucket must have versioning enabled. The specified role must have\npermission to write to the destination bucket and have a trust relationship that allows\nAmazon S3 to assume the role.\nExample role permission policy:\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetReplicationConfiguration\",\n\"s3:ListBucket\"\n],\n\"Resource\": [\n\"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET1\"\n]\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:GetObjectVersion\",\n\"s3:GetObjectVersionAcl\",\n\"s3:GetObjectVersionTagging\"\n],\n\"Resource\": [\n\"arn:aws:s3:::AWSDOC-EXAMPLE-BUCKET1/*\"\n]\n},\n{\n\"Effect\": \"Allow\",\n\"Action\": [\n\"s3:ReplicateObject\",\n\"s3:ReplicateDelete\",\n\"s3:ReplicateTags\"\nBasics API Version 2006-03-01 2189",
      "start_idx": 2376074,
      "end_idx": 2376911,
      "metadata": {
        "num_sentences": 3,
        "num_words": 95,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2196",
      "text": "Amazon Simple Storage Service API Reference\n$params = @{\nBucketName = \"amzn-s3-demo-bucket\"\nConfiguration_Role = \"arn:aws:iam::35667example:role/\nCrossRegionReplicationRoleForS3\"\nConfiguration_Rule = $rule1\n}\nWrite-S3BucketReplication @params\nExample 2: This example sets a replication configuration with multiple rules enabling\nreplication to the 'exampletargetbucket' bucket any new objects created with either the\nkey name prefix \"TaxDocs\" or \"OtherDocs\". The key prefixes must not overlap.\n$rule1 = New-Object Amazon.S3.Model.ReplicationRule\n$rule1.ID = \"Rule-1\"\n$rule1.Status = \"Enabled\"\n$rule1.Prefix = \"TaxDocs\"\n$rule1.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" }\n$rule2 = New-Object Amazon.S3.Model.ReplicationRule\n$rule2.ID = \"Rule-2\"\n$rule2.Status = \"Enabled\"\n$rule2.Prefix = \"OtherDocs\"\n$rule2.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" }\n$params = @{\nBucketName = \"amzn-s3-demo-bucket\"\nConfiguration_Role = \"arn:aws:iam::35667example:role/\nCrossRegionReplicationRoleForS3\"\nConfiguration_Rule = $rule1,$rule2\n}\nWrite-S3BucketReplication @params\nExample 3: This example updates the replication configuration on the specified bucket to\ndisable the rule controlling replication of objects with the key name prefix \"TaxDocs\" to\nthe bucket 'exampletargetbucket'.\n$rule1 = New-Object Amazon.S3.Model.ReplicationRule\nBasics API Version 2006-03-01 2191",
      "start_idx": 2377913,
      "end_idx": 2379336,
      "metadata": {
        "num_sentences": 4,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2197",
      "text": "Amazon Simple Storage Service API Reference\n$rule1.ID = \"Rule-1\"\n$rule1.Status = \"Disabled\"\n$rule1.Prefix = \"TaxDocs\"\n$rule1.Destination = @{ BucketArn = \"arn:aws:s3:::amzn-s3-demo-destination-\nbucket\" }\n$params = @{\nBucketName = \"amzn-s3-demo-bucket\"\nConfiguration_Role = \"arn:aws:iam::35667example:role/\nCrossRegionReplicationRoleForS3\"\nConfiguration_Rule = $rule1\n}\nWrite-S3BucketReplication @params\n\u2022 For API details, see PutBucketReplication in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketRequestPayment with a CLI\nThe following code examples show how to use PutBucketRequestPayment.\nCLI\nAWS CLI\nExample 1: To enable ``requester pays`` configuration for a bucket\nThe following put-bucket-request-payment example enables requester pays for the\nspecified bucket.\naws s3api put-bucket-request-payment \\\n--bucket my-bucket \\\n--request-payment-configuration '{\"Payer\":\"Requester\"}'\nThis command produces no output.\nExample 2: To disable ``requester pays`` configuration for a bucket\nBasics API Version 2006-03-01 2192",
      "start_idx": 2379338,
      "end_idx": 2380584,
      "metadata": {
        "num_sentences": 7,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2198",
      "text": "Amazon Simple Storage Service API Reference\nThe following put-bucket-request-payment example disables requester pays for\nthe specified bucket.\naws s3api put-bucket-request-payment \\\n--bucket my-bucket \\\n--request-payment-configuration '{\"Payer\":\"BucketOwner\"}'\nThis command produces no output.\n\u2022 For API details, see PutBucketRequestPayment in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: Updates the request payment configuration for the bucket named 'mybucket'\nso that the person requesting downloads from the bucket will be charged for the\ndownload. By default the bucket owner pays for downloads. To set the request payment\nback to the default use 'BucketOwner' for the RequestPaymentConfiguration_Payer\nparameter.\nWrite-S3BucketRequestPayment -BucketName amzn-s3-demo-bucket -\nRequestPaymentConfiguration_Payer Requester\n\u2022 For API details, see PutBucketRequestPayment in AWS Tools for PowerShell Cmdlet\nReference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketTagging with a CLI\nThe following code examples show how to use PutBucketTagging.\nCLI\nAWS CLI\nThe following command applies a tagging configuration to a bucket named my-bucket:\nBasics API Version 2006-03-01 2193",
      "start_idx": 2380586,
      "end_idx": 2381970,
      "metadata": {
        "num_sentences": 11,
        "num_words": 184,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2199",
      "text": "Amazon Simple Storage Service API Reference\naws s3api put-bucket-tagging --bucket my-bucket --tagging file://tagging.json\nThe file tagging.json is a JSON document in the current folder that specifies tags:\n{\n\"TagSet\": [\n{\n\"Key\": \"organization\",\n\"Value\": \"marketing\"\n}\n]\n}\nOr apply a tagging configuration to my-bucket directly from the command line:\naws s3api put-bucket-tagging --bucket my-bucket --tagging\n'TagSet=[{Key=organization,Value=marketing}]'\n\u2022 For API details, see PutBucketTagging in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command applies two tags to a bucket named cloudtrail-test-2018:\na tag with a key of Stage and a value of Test, and a tag with a key of Environment\nand a value of Alpha. To verify that the tags were added to the bucket, run Get-\nS3BucketTagging -BucketName bucket_name. The results should show the tags that\nyou applied to the bucket in the first command. Note that Write-S3BucketTagging\noverwrites the entire existing tag set on a bucket. To add or delete individual tags, run\nthe Resource Groups and Tagging API cmdlets, Add-RGTResourceTag and Remove-\nRGTResourceTag. Alternatively, use Tag Editor in the AWS Management Console to\nmanage S3 bucket tags.\nWrite-S3BucketTagging -BucketName amzn-s3-demo-bucket -TagSet @( @{ Key=\"Stage\";\nValue=\"Test\" }, @{ Key=\"Environment\"; Value=\"Alpha\" } )\nExample 2: This command pipes a bucket named cloudtrail-test-2018 into\nthe Write-S3BucketTagging cmdlet. It applies tags Stage:Production and\nBasics API Version 2006-03-01 2194",
      "start_idx": 2381972,
      "end_idx": 2383513,
      "metadata": {
        "num_sentences": 9,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2200",
      "text": "Amazon Simple Storage Service API Reference\nDepartment:Finance to the bucket. Note that Write-S3BucketTagging overwrites the\nentire existing tag set on a bucket.\nGet-S3Bucket -BucketName amzn-s3-demo-bucket | Write-S3BucketTagging\n-TagSet @( @{ Key=\"Stage\"; Value=\"Production\" }, @{ Key=\"Department\";\nValue=\"Finance\" } )\n\u2022 For API details, see PutBucketTagging in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketVersioning with a CLI\nThe following code examples show how to use PutBucketVersioning.\nCLI\nAWS CLI\nThe following command enables versioning on a bucket named my-bucket:\naws s3api put-bucket-versioning --bucket my-bucket --versioning-\nconfiguration Status=Enabled\nThe following command enables versioning, and uses an mfa code\naws s3api put-bucket-versioning --bucket my-bucket --versioning-\nconfiguration Status=Enabled --mfa \"SERIAL 123456\"\n\u2022 For API details, see PutBucketVersioning in AWS CLI Command Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command enables versioning for the given S3 bucket.\nBasics API Version 2006-03-01 2195",
      "start_idx": 2383515,
      "end_idx": 2384800,
      "metadata": {
        "num_sentences": 9,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2201",
      "text": "Amazon Simple Storage Service API Reference\nWrite-S3BucketVersioning -BucketName 'amzn-s3-demo-bucket' -\nVersioningConfig_Status Enabled\n\u2022 For API details, see PutBucketVersioning in AWS Tools for PowerShell Cmdlet Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutBucketWebsite with an AWS SDK or CLI\nThe following code examples show how to use PutBucketWebsite.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Put the website configuration.\nPutBucketWebsiteRequest putRequest = new\nPutBucketWebsiteRequest()\n{\nBucketName = bucketName,\nWebsiteConfiguration = new WebsiteConfiguration()\n{\nIndexDocumentSuffix = indexDocumentSuffix,\nErrorDocument = errorDocument,\n},\n};\nPutBucketWebsiteResponse response = await\nclient.PutBucketWebsiteAsync(putRequest);\n\u2022 For API details, see PutBucketWebsite in AWS SDK for .NET API Reference.\nBasics API Version 2006-03-01 2196",
      "start_idx": 2384802,
      "end_idx": 2385950,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2202",
      "text": "Amazon Simple Storage Service API Reference\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::putWebsiteConfig(const Aws::String &bucketName,\nconst Aws::String &indexPage, const Aws::String\n&errorPage,\nconst Aws::S3::S3ClientConfiguration\n&clientConfig) {\nAws::S3::S3Client client(clientConfig);\nAws::S3::Model::IndexDocument indexDocument;\nindexDocument.SetSuffix(indexPage);\nAws::S3::Model::ErrorDocument errorDocument;\nerrorDocument.SetKey(errorPage);\nAws::S3::Model::WebsiteConfiguration websiteConfiguration;\nwebsiteConfiguration.SetIndexDocument(indexDocument);\nwebsiteConfiguration.SetErrorDocument(errorDocument);\nAws::S3::Model::PutBucketWebsiteRequest request;\nrequest.SetBucket(bucketName);\nrequest.SetWebsiteConfiguration(websiteConfiguration);\nAws::S3::Model::PutBucketWebsiteOutcome outcome =\nclient.PutBucketWebsite(request);\nif (!outcome.IsSuccess()) {\nstd::cerr << \"Error: PutBucketWebsite: \"\n<< outcome.GetError().GetMessage() << std::endl;\n} else {\nstd::cout << \"Success: Set website configuration for bucket '\"\n<< bucketName << \"'.\" << std::endl;\n}\nBasics API Version 2006-03-01 2197",
      "start_idx": 2385952,
      "end_idx": 2387162,
      "metadata": {
        "num_sentences": 4,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2203",
      "text": "Amazon Simple Storage Service API Reference\nreturn outcome.IsSuccess();\n}\n\u2022 For API details, see PutBucketWebsite in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe applies a static website configuration to a bucket named my-bucket:\naws s3api put-bucket-website --bucket my-bucket --website-configuration file://\nwebsite.json\nThe file website.json is a JSON document in the current folder that specifies index and\nerror pages for the website:\n{\n\"IndexDocument\": {\n\"Suffix\": \"index.html\"\n},\n\"ErrorDocument\": {\n\"Key\": \"error.html\"\n}\n}\n\u2022 For API details, see PutBucketWebsite in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2198",
      "start_idx": 2387164,
      "end_idx": 2387946,
      "metadata": {
        "num_sentences": 5,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2204",
      "text": "Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.IndexDocument;\nimport software.amazon.awssdk.services.s3.model.PutBucketWebsiteRequest;\nimport software.amazon.awssdk.services.s3.model.WebsiteConfiguration;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.regions.Region;\n/**\n* Before running this Java V2 code example, set up your development\n* environment, including your credentials.\n* <p>\n* For more information, see the following documentation topic:\n* <p>\n* https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/get-\nstarted.html\n*/\npublic class SetWebsiteConfiguration {\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nUsage: <bucketName> [indexdoc]\\s\nWhere:\nbucketName - The Amazon S3 bucket to set the website\nconfiguration on.\\s\nindexdoc - The index document, ex. 'index.html'\nIf not specified, 'index.html' will be set.\n\"\"\";\nif (args.length != 1) {\nSystem.out.println(usage);\nSystem.exit(1);\n}\nString bucketName = args[0];\nString indexDoc = \"index.html\";\nRegion region = Region.US_EAST_1;\nS3Client s3 = S3Client.builder()\n.region(region)\n.build();\nsetWebsiteConfig(s3, bucketName, indexDoc);\ns3.close();\nBasics API Version 2006-03-01 2199",
      "start_idx": 2387948,
      "end_idx": 2389262,
      "metadata": {
        "num_sentences": 4,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2206",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nSet the website configuration.\nimport {\nPutBucketWebsiteCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Configure an Amazon S3 bucket to serve a static website.\n* Website access must also be granted separately. For more information\n* on setting the permissions for website access, see\n* https://docs.aws.amazon.com/AmazonS3/latest/userguide/\nWebsiteAccessPermissionsReqd.html.\n*\n* @param {{ bucketName: string }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\nconst command = new PutBucketWebsiteCommand({\nBucket: bucketName,\nWebsiteConfiguration: {\nErrorDocument: {\n// The object key name to use when a 4XX class error occurs.\nKey: \"error.html\",\n},\nIndexDocument: {\n// A suffix that is appended to a request when the request is\n// for a directory.\nSuffix: \"index.html\",\n},\n},\n});\nBasics API Version 2006-03-01 2201",
      "start_idx": 2390280,
      "end_idx": 2391361,
      "metadata": {
        "num_sentences": 9,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2207",
      "text": "Amazon Simple Storage Service API Reference\ntry {\nawait client.send(command);\nconsole.log(\n`The bucket \"${bucketName}\" has been configured as a static website.`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while configuring the bucket \"${bucketName}\" as a static\nwebsite. The bucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while configuring the bucket \"${bucketName}\" as a static\nwebsite. ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see PutBucketWebsite in AWS SDK for JavaScript API Reference.\nPowerShell\nTools for PowerShell\nExample 1: The command enables website hosting for the given bucket with the index\ndocument as 'index.html' and error document as 'error.html'.\nWrite-S3BucketWebsite -BucketName 'amzn-s3-demo-bucket'\n-WebsiteConfiguration_IndexDocumentSuffix 'index.html' -\nWebsiteConfiguration_ErrorDocument 'error.html'\n\u2022 For API details, see PutBucketWebsite in AWS Tools for PowerShell Cmdlet Reference.\nBasics API Version 2006-03-01 2202",
      "start_idx": 2391363,
      "end_idx": 2392576,
      "metadata": {
        "num_sentences": 7,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2208",
      "text": "Amazon Simple Storage Service API Reference\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 bucket website actions.\nclass BucketWebsiteWrapper\nattr_reader :bucket_website\n# @param bucket_website [Aws::S3::BucketWebsite] A bucket website object\nconfigured with an existing bucket.\ndef initialize(bucket_website)\n@bucket_website = bucket_website\nend\n# Sets a bucket as a static website.\n#\n# @param index_document [String] The name of the index document for the\nwebsite.\n# @param error_document [String] The name of the error document to show for 4XX\nerrors.\n# @return [Boolean] True when the bucket is configured as a website; otherwise,\nfalse.\ndef set_website(index_document, error_document)\n@bucket_website.put(\nwebsite_configuration: {\nindex_document: { suffix: index_document },\nerror_document: { key: error_document }\n}\n)\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't configure #{@bucket_website.bucket.name} as a website. Here's\nwhy: #{e.message}\"\nfalse\nBasics API Version 2006-03-01 2203",
      "start_idx": 2392578,
      "end_idx": 2393715,
      "metadata": {
        "num_sentences": 10,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2209",
      "text": "Amazon Simple Storage Service API Reference\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nindex_document = \"index.html\"\nerror_document = \"404.html\"\n=======\nbucket_name = 'doc-example-bucket'\nindex_document = 'index.html'\nerror_document = '404.html'\n>>>>>>> 999c6133e (fixes)\nwrapper = BucketWebsiteWrapper.new(Aws::S3::BucketWebsite.new(bucket_name))\nreturn unless wrapper.set_website(index_document, error_document)\nputs \"Successfully configured bucket #{bucket_name} as a static website.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see PutBucketWebsite in AWS SDK for Ruby API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutObject with an AWS SDK or CLI\nThe following code examples show how to use PutObject.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Learn the basics\n\u2022 Track uploads and downloads\n\u2022 Work with Amazon S3 object integrity\nBasics API Version 2006-03-01 2204",
      "start_idx": 2393717,
      "end_idx": 2394947,
      "metadata": {
        "num_sentences": 7,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2210",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Shows how to upload a file from the local computer to an Amazon S3\n/// bucket.\n/// </summary>\n/// <param name=\"client\">An initialized Amazon S3 client object.</param>\n/// <param name=\"bucketName\">The Amazon S3 bucket to which the object\n/// will be uploaded.</param>\n/// <param name=\"objectName\">The object to upload.</param>\n/// <param name=\"filePath\">The path, including file name, of the object\n/// on the local computer to upload.</param>\n/// <returns>A boolean value indicating the success or failure of the\n/// upload procedure.</returns>\npublic static async Task<bool> UploadFileAsync(\nIAmazonS3 client,\nstring bucketName,\nstring objectName,\nstring filePath)\n{\nvar request = new PutObjectRequest\n{\nBucketName = bucketName,\nKey = objectName,\nFilePath = filePath,\n};\nvar response = await client.PutObjectAsync(request);\nif (response.HttpStatusCode == System.Net.HttpStatusCode.OK)\n{\nConsole.WriteLine($\"Successfully uploaded {objectName} to\n{bucketName}.\");\nreturn true;\nBasics API Version 2006-03-01 2205",
      "start_idx": 2394949,
      "end_idx": 2396167,
      "metadata": {
        "num_sentences": 5,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2213",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see PutObject in AWS SDK for .NET API Reference.\nBash\nAWS CLI with Bash script\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n###############################################################################\n# function errecho\n#\n# This function outputs everything sent to it to STDERR (standard error output).\n###############################################################################\nfunction errecho() {\nprintf \"%s\\n\" \"$*\" 1>&2\n}\n###############################################################################\n# function copy_file_to_bucket\n#\n# This function creates a file in the specified bucket.\n#\n# Parameters:\n# $1 - The name of the bucket to copy the file to.\n# $2 - The path and file name of the local file to copy to the bucket.\n# $3 - The key (name) to call the copy of the file in the bucket.\n#\n# Returns:\n# 0 - If successful.\n# 1 - If it fails.\n###############################################################################\nfunction copy_file_to_bucket() {\nlocal response bucket_name source_file destination_file_name\nbucket_name=$1\nsource_file=$2\ndestination_file_name=$3\nBasics API Version 2006-03-01 2208",
      "start_idx": 2398527,
      "end_idx": 2399791,
      "metadata": {
        "num_sentences": 11,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2214",
      "text": "Amazon Simple Storage Service API Reference\nresponse=$(aws s3api put-object \\\n--bucket \"$bucket_name\" \\\n--body \"$source_file\" \\\n--key \"$destination_file_name\")\n# shellcheck disable=SC2181\nif [[ ${?} -ne 0 ]]; then\nerrecho \"ERROR: AWS reports put-object operation failed.\\n$response\"\nreturn 1\nfi\n}\n\u2022 For API details, see PutObject in AWS CLI Command Reference.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nbool AwsDoc::S3::putObject(const Aws::String &bucketName,\nconst Aws::String &fileName,\nconst Aws::S3::S3ClientConfiguration &clientConfig) {\nAws::S3::S3Client s3Client(clientConfig);\nAws::S3::Model::PutObjectRequest request;\nrequest.SetBucket(bucketName);\n//We are using the name of the file as the key for the object in the bucket.\n//However, this is just a string and can be set according to your retrieval\nneeds.\nrequest.SetKey(fileName);\nstd::shared_ptr<Aws::IOStream> inputData =\nAws::MakeShared<Aws::FStream>(\"SampleAllocationTag\",\nfileName.c_str(),\nBasics API Version 2006-03-01 2209",
      "start_idx": 2399793,
      "end_idx": 2400883,
      "metadata": {
        "num_sentences": 7,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2216",
      "text": "Amazon Simple Storage Service API Reference\nFor more information about uploading objects, see Uploading Objects in the Amazon S3\nDeveloper Guide.\n\u2022 For API details, see PutObject in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nPut an object in a bucket by using the low-level API.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nS3Client *s3.Client\n}\n// UploadFile reads from a file and puts the data into an object in a bucket.\nfunc (basics BucketBasics) UploadFile(ctx context.Context, bucketName string,\nobjectKey string, fileName string) error {\nfile, err := os.Open(fileName)\nif err != nil {\nlog.Printf(\"Couldn't open file %v to upload. Here's why: %v\\n\", fileName, err)\n} else {\ndefer file.Close()\n_, err = basics.S3Client.PutObject(ctx, &s3.PutObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\nBody: file,\nBasics API Version 2006-03-01 2211",
      "start_idx": 2401954,
      "end_idx": 2403141,
      "metadata": {
        "num_sentences": 10,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2217",
      "text": "Amazon Simple Storage Service API Reference\n})\nif err != nil {\nlog.Printf(\"Couldn't upload file %v to %v:%v. Here's why: %v\\n\",\nfileName, bucketName, objectKey, err)\n}\n}\nreturn err\n}\nUpload an object to a bucket by using a transfer manager.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// UploadObject uses the S3 upload manager to upload an object to a bucket.\nfunc (actor S3Actions) UploadObject(ctx context.Context, bucket string, key\nstring, contents string) (string, error) {\nvar outKey string\ninput := &s3.PutObjectInput{\nBucket: aws.String(bucket),\nKey: aws.String(key),\nBody: bytes.NewReader([]byte(contents)),\nChecksumAlgorithm: types.ChecksumAlgorithmSha256,\n}\noutput, err := actor.S3Manager.Upload(ctx, input)\nif err != nil {\nvar noBucket *types.NoSuchBucket\nif errors.As(err, &noBucket) {\nlog.Printf(\"Bucket %s does not exist.\\n\", bucket)\nerr = noBucket\n}\n} else {\nerr := s3.NewObjectExistsWaiter(actor.S3Client).Wait(ctx, &s3.HeadObjectInput{\nBucket: aws.String(bucket),\nKey: aws.String(key),\nBasics API Version 2006-03-01 2212",
      "start_idx": 2403143,
      "end_idx": 2404251,
      "metadata": {
        "num_sentences": 5,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2218",
      "text": "Amazon Simple Storage Service API Reference\n}, time.Minute)\nif err != nil {\nlog.Printf(\"Failed attempt to wait for object %s to exist in %s.\\n\", key,\nbucket)\n} else {\noutKey = *output.Key\n}\n}\nreturn outKey, err\n}\n\u2022 For API details, see PutObject in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUpload a file to a bucket using an S3Client.\n/**\n* Uploads a local file to an AWS S3 bucket asynchronously.\n*\n* @param bucketName the name of the S3 bucket to upload the file to\n* @param key the key (object name) to use for the uploaded file\n* @param objectPath the local file path of the file to be uploaded\n* @return a {@link CompletableFuture} that completes with the {@link\nPutObjectResponse} when the upload is successful, or throws a {@link\nRuntimeException} if the upload fails\n*/\npublic CompletableFuture<PutObjectResponse> uploadLocalFileAsync(String\nbucketName, String key, String objectPath) {\nPutObjectRequest objectRequest = PutObjectRequest.builder()\n.bucket(bucketName)\nBasics API Version 2006-03-01 2213",
      "start_idx": 2404253,
      "end_idx": 2405397,
      "metadata": {
        "num_sentences": 6,
        "num_words": 186,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2219",
      "text": "Amazon Simple Storage Service API Reference\n.key(key)\n.build();\nCompletableFuture<PutObjectResponse> response =\ngetAsyncClient().putObject(objectRequest,\nAsyncRequestBody.fromFile(Paths.get(objectPath)));\nreturn response.whenComplete((resp, ex) -> {\nif (ex != null) {\nthrow new RuntimeException(\"Failed to upload file\", ex);\n}\n});\n}\nUse an S3TransferManager to upload a file to a bucket. View the complete file and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedFileUpload;\nimport software.amazon.awssdk.transfer.s3.model.FileUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadFileRequest;\nimport software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\nimport java.util.UUID;\npublic String uploadFile(S3TransferManager transferManager, String\nbucketName,\nString key, URI filePathURI) {\nUploadFileRequest uploadFileRequest = UploadFileRequest.builder()\n.putObjectRequest(b -> b.bucket(bucketName).key(key))\n.source(Paths.get(filePathURI))\n.build();\nFileUpload fileUpload = transferManager.uploadFile(uploadFileRequest);\nCompletedFileUpload uploadResult = fileUpload.completionFuture().join();\nreturn uploadResult.response().eTag();\n}\nBasics API Version 2006-03-01 2214",
      "start_idx": 2405399,
      "end_idx": 2406830,
      "metadata": {
        "num_sentences": 3,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2227",
      "text": "Amazon Simple Storage Service API Reference\nObjectLockRetention lockRetention = ObjectLockRetention.builder()\n.mode(\"COMPLIANCE\")\n.retainUntilDate(instant)\n.build();\nPutObjectRetentionRequest retentionRequest =\nPutObjectRetentionRequest.builder()\n.bucket(bucket)\n.key(key)\n.bypassGovernanceRetention(true)\n.retention(lockRetention)\n.build();\n// To set Retention on an object, the Amazon S3 bucket must support\nobject\n// locking, otherwise an exception is thrown.\ns3.putObjectRetention(retentionRequest);\nSystem.out.print(\"An object retention configuration was successfully\nplaced on the object\");\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\n}\n}\n\u2022 For API details, see PutObject in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUpload the object.\nBasics API Version 2006-03-01 2222",
      "start_idx": 2415160,
      "end_idx": 2416145,
      "metadata": {
        "num_sentences": 6,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2228",
      "text": "Amazon Simple Storage Service API Reference\nimport { readFile } from \"node:fs/promises\";\nimport {\nPutObjectCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Upload a file to an S3 bucket.\n* @param {{ bucketName: string, key: string, filePath: string }}\n*/\nexport const main = async ({ bucketName, key, filePath }) => {\nconst client = new S3Client({});\nconst command = new PutObjectCommand({\nBucket: bucketName,\nKey: key,\nBody: await readFile(filePath),\n});\ntry {\nconst response = await client.send(command);\nconsole.log(response);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"EntityTooLarge\"\n) {\nconsole.error(\n`Error from S3 while uploading object to ${bucketName}. \\\nThe object was too large. To upload objects larger than 5GB, use the S3 console\n(160GB max) \\\nor the multipart upload API (5TB max).`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while uploading object to ${bucketName}. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\nBasics API Version 2006-03-01 2223",
      "start_idx": 2416147,
      "end_idx": 2417236,
      "metadata": {
        "num_sentences": 5,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2229",
      "text": "Amazon Simple Storage Service API Reference\n};\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\n\u2022 For API details, see PutObject in AWS SDK for JavaScript API Reference.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nsuspend fun putS3Object(\nbucketName: String,\nobjectKey: String,\nobjectPath: String,\n) {\nval metadataVal = mutableMapOf<String, String>()\nmetadataVal[\"myVal\"] = \"test\"\nval request =\nPutObjectRequest {\nbucket = bucketName\nkey = objectKey\nmetadata = metadataVal\nbody = File(objectPath).asByteStream()\n}\nS3Client { region = \"us-east-1\" }.use { s3 ->\nval response = s3.putObject(request)\nprintln(\"Tag information is ${response.eTag}\")\n}\n}\n\u2022 For API details, see PutObject in AWS SDK for Kotlin API reference.\nBasics API Version 2006-03-01 2224",
      "start_idx": 2417238,
      "end_idx": 2418111,
      "metadata": {
        "num_sentences": 6,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2230",
      "text": "Amazon Simple Storage Service API Reference\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUpload an object to a bucket.\n$s3client = new Aws\\S3\\S3Client(['region' => 'us-west-2']);\n$fileName = __DIR__ . \"/local-file-\" . uniqid();\ntry {\n$this->s3client->putObject([\n'Bucket' => $this->bucketName,\n'Key' => $fileName,\n'SourceFile' => __DIR__ . '/testfile.txt'\n]);\necho \"Uploaded $fileName to $this->bucketName.\\n\";\n} catch (Exception $exception) {\necho \"Failed to upload $fileName with error: \" . $exception-\n>getMessage();\nexit(\"Please fix error with file upload before continuing.\");\n}\n\u2022 For API details, see PutObject in AWS SDK for PHP API Reference.\nPowerShell\nTools for PowerShell\nExample 1: This command uploads the single file \"local-sample.txt\" to Amazon S3,\ncreating an object with key \"sample.txt\" in bucket \"test-files\".\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Key \"sample.txt\" -File .\\local-\nsample.txt\nBasics API Version 2006-03-01 2225",
      "start_idx": 2418113,
      "end_idx": 2419162,
      "metadata": {
        "num_sentences": 11,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2231",
      "text": "Amazon Simple Storage Service API Reference\nExample 2: This command uploads the single file \"sample.txt\" to Amazon S3, creating an\nobject with key \"sample.txt\" in bucket \"test-files\". If the -Key parameter is not supplied,\nthe filename is used as the S3 object key.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -File .\\sample.txt\nExample 3: This command uploads the single file \"local-sample.txt\" to Amazon S3,\ncreating an object with key \"prefix/to/sample.txt\" in bucket \"test-files\".\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Key \"prefix/to/sample.txt\" -\nFile .\\local-sample.txt\nExample 4: This command uploads all files in the subdirectory \"Scripts\" to the bucket\n\"test-files\" and applies the common key prefix \"SampleScripts\" to each object. Each\nuploaded file will have a key of \"SampleScripts/filename\" where 'filename' varies.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Folder .\\Scripts -KeyPrefix\nSampleScripts\\\nExample 5: This command uploads all *.ps1 files in the local director \"Scripts\" to bucket\n\"test-files\" and applies the common key prefix \"SampleScripts\" to each object. Each\nuploaded file will have a key of \"SampleScripts/filename.ps1\" where 'filename' varies.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Folder .\\Scripts -KeyPrefix\nSampleScripts\\ -SearchPattern *.ps1\nExample 6: This command creates a new S3 object containing the specified content string\nwith key 'sample.txt'.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Key \"sample.txt\" -Content \"object\ncontents\"\nExample 7: This command uploads the specified file (the filename is used as the key) and\napplies the specified tags to the new object.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -File \"sample.txt\" -TagSet\n@{Key=\"key1\";Value=\"value1\"},@{Key=\"key2\";Value=\"value2\"}\nBasics API Version 2006-03-01 2226",
      "start_idx": 2419164,
      "end_idx": 2420974,
      "metadata": {
        "num_sentences": 10,
        "num_words": 229,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2232",
      "text": "Amazon Simple Storage Service API Reference\nExample 8: This command recursively uploads the specified folder and applies the\nspecified tags to all the new objects.\nWrite-S3Object -BucketName amzn-s3-demo-bucket -Folder . -KeyPrefix \"TaggedFiles\"\n-Recurse -TagSet @{Key=\"key1\";Value=\"value1\"},@{Key=\"key2\";Value=\"value2\"}\n\u2022 For API details, see PutObject in AWS Tools for PowerShell Cmdlet Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass ObjectWrapper:\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\ndef put(self, data):\n\"\"\"\nUpload data to the object.\n:param data: The data to upload. This can either be bytes or a string.\nWhen this\nargument is a string, it is interpreted as a file name,\nwhich is\nopened in read bytes mode.\n\"\"\"\nBasics API Version 2006-03-01 2227",
      "start_idx": 2420976,
      "end_idx": 2422077,
      "metadata": {
        "num_sentences": 13,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2233",
      "text": "Amazon Simple Storage Service API Reference\nput_data = data\nif isinstance(data, str):\ntry:\nput_data = open(data, \"rb\")\nexcept IOError:\nlogger.exception(\"Expected file name or binary data, got '%s'.\",\ndata)\nraise\ntry:\nself.object.put(Body=put_data)\nself.object.wait_until_exists()\nlogger.info(\n\"Put object '%s' to bucket '%s'.\",\nself.object.key,\nself.object.bucket_name,\n)\nexcept ClientError:\nlogger.exception(\n\"Couldn't put object '%s' to bucket '%s'.\",\nself.object.key,\nself.object.bucket_name,\n)\nraise\nfinally:\nif getattr(put_data, \"close\", None):\nput_data.close()\n\u2022 For API details, see PutObject in AWS SDK for Python (Boto3) API Reference.\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2228",
      "start_idx": 2422079,
      "end_idx": 2422900,
      "metadata": {
        "num_sentences": 7,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2234",
      "text": "Amazon Simple Storage Service API Reference\nUpload a file using a managed uploader (Object.upload_file).\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectUploadFileWrapper\nattr_reader :object\n# @param object [Aws::S3::Object] An existing Amazon S3 object.\ndef initialize(object)\n@object = object\nend\n# Uploads a file to an Amazon S3 object by using a managed uploader.\n#\n# @param file_path [String] The path to the file to upload.\n# @return [Boolean] True when the file is uploaded; otherwise false.\ndef upload_file(file_path)\n@object.upload_file(file_path)\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't upload file #{file_path} to #{@object.key}. Here's why:\n#{e.message}\"\nfalse\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-uploaded-file\"\nfile_path = \"object_upload_file.rb\"\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-uploaded-file'\nfile_path = 'object_upload_file.rb'\n>>>>>>> 999c6133e (fixes)\nwrapper = ObjectUploadFileWrapper.new(Aws::S3::Object.new(bucket_name,\nobject_key))\nreturn unless wrapper.upload_file(file_path)\nputs \"File #{file_path} successfully uploaded to #{bucket_name}:#{object_key}.\"\nBasics API Version 2006-03-01 2229",
      "start_idx": 2422902,
      "end_idx": 2424147,
      "metadata": {
        "num_sentences": 9,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2235",
      "text": "Amazon Simple Storage Service API Reference\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nUpload a file using Object.put.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectPutWrapper\nattr_reader :object\n# @param object [Aws::S3::Object] An existing Amazon S3 object.\ndef initialize(object)\n@object = object\nend\ndef put_object(source_file_path)\nFile.open(source_file_path, 'rb') do |file|\n@object.put(body: file)\nend\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't put #{source_file_path} to #{object.key}. Here's why:\n#{e.message}\"\nfalse\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-object-key\"\nfile_path = \"my-local-file.txt\"\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-object-key'\nfile_path = 'my-local-file.txt'\n>>>>>>> 999c6133e (fixes)\nwrapper = ObjectPutWrapper.new(Aws::S3::Object.new(bucket_name, object_key))\nBasics API Version 2006-03-01 2230",
      "start_idx": 2424149,
      "end_idx": 2425099,
      "metadata": {
        "num_sentences": 5,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2236",
      "text": "Amazon Simple Storage Service API Reference\nsuccess = wrapper.put_object(file_path)\nreturn unless success\nputs \"Put file #{file_path} into #{object_key} in #{bucket_name}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nUpload a file using Object.put and add server-side encryption.\nrequire 'aws-sdk-s3'\n# Wraps Amazon S3 object actions.\nclass ObjectPutSseWrapper\nattr_reader :object\n# @param object [Aws::S3::Object] An existing Amazon S3 object.\ndef initialize(object)\n@object = object\nend\ndef put_object_encrypted(object_content, encryption)\n@object.put(body: object_content, server_side_encryption: encryption)\ntrue\nrescue Aws::Errors::ServiceError => e\nputs \"Couldn't put your content to #{object.key}. Here's why: #{e.message}\"\nfalse\nend\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-encrypted-content\"\nobject_content = \"This is my super-secret content.\"\nencryption = \"AES256\"\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-encrypted-content'\nobject_content = 'This is my super-secret content.'\nencryption = 'AES256'\nBasics API Version 2006-03-01 2231",
      "start_idx": 2425101,
      "end_idx": 2426220,
      "metadata": {
        "num_sentences": 8,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2237",
      "text": "Amazon Simple Storage Service API Reference\n>>>>>>> 999c6133e (fixes)\nwrapper = ObjectPutSseWrapper.new(Aws::S3::Object.new(bucket_name,\nobject_content))\nreturn unless wrapper.put_object_encrypted(object_content, encryption)\nputs \"Put your content into #{bucket_name}:#{object_key} and encrypted it with\n#{encryption}.\"\nend\nrun_demo if $PROGRAM_NAME == __FILE__\n\u2022 For API details, see PutObject in AWS SDK for Ruby API Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\npub async fn upload_object(\nclient: &aws_sdk_s3::Client,\nbucket_name: &str,\nfile_name: &str,\nkey: &str,\n) -> Result<aws_sdk_s3::operation::put_object::PutObjectOutput, S3ExampleError> {\nlet body =\naws_sdk_s3::primitives::ByteStream::from_path(std::path::Path::new(file_name)).await;\nclient\n.put_object()\n.bucket(bucket_name)\n.key(key)\n.body(body.unwrap())\n.send()\n.await\n.map_err(S3ExampleError::from)\n}\nBasics API Version 2006-03-01 2232",
      "start_idx": 2426222,
      "end_idx": 2427232,
      "metadata": {
        "num_sentences": 5,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2238",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see PutObject in AWS SDK for Rust API reference.\nSAP ABAP\nSDK for SAP ABAP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n\"Get contents of file from application server.\"\nDATA lv_body TYPE xstring.\nOPEN DATASET iv_file_name FOR INPUT IN BINARY MODE.\nREAD DATASET iv_file_name INTO lv_body.\nCLOSE DATASET iv_file_name.\n\"Upload/put an object to an S3 bucket.\"\nTRY.\nlo_s3->putobject(\niv_bucket = iv_bucket_name\niv_key = iv_file_name\niv_body = lv_body\n).\nMESSAGE 'Object uploaded to S3 bucket.' TYPE 'I'.\nCATCH /aws1/cx_s3_nosuchbucket.\nMESSAGE 'Bucket does not exist.' TYPE 'E'.\nENDTRY.\n\u2022 For API details, see PutObject in AWS SDK for SAP ABAP API reference.\nBasics API Version 2006-03-01 2233",
      "start_idx": 2427234,
      "end_idx": 2428063,
      "metadata": {
        "num_sentences": 19,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2239",
      "text": "Amazon Simple Storage Service API Reference\nSwift\nSDK for Swift\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport AWSS3\nimport Smithy\npublic func uploadFile(bucket: String, key: String, file: String) async\nthrows {\nlet fileUrl = URL(fileURLWithPath: file)\ndo {\nlet fileData = try Data(contentsOf: fileUrl)\nlet dataStream = ByteStream.data(fileData)\nlet input = PutObjectInput(\nbody: dataStream,\nbucket: bucket,\nkey: key\n)\n_ = try await client.putObject(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Putting an object.\"))\nthrow error\n}\n}\nimport AWSS3\nimport Smithy\npublic func createFile(bucket: String, key: String, withData data: Data)\nasync throws {\nlet dataStream = ByteStream.data(data)\nBasics API Version 2006-03-01 2234",
      "start_idx": 2428065,
      "end_idx": 2428885,
      "metadata": {
        "num_sentences": 4,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2240",
      "text": "Amazon Simple Storage Service API Reference\nlet input = PutObjectInput(\nbody: dataStream,\nbucket: bucket,\nkey: key\n)\ndo {\n_ = try await client.putObject(input: input)\n}\ncatch {\nprint(\"ERROR: \", dump(error, name: \"Putting an object.\"))\nthrow error\n}\n}\n\u2022 For API details, see PutObject in AWS SDK for Swift API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutObjectAcl with an AWS SDK or CLI\nThe following code examples show how to use PutObjectAcl.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Manage access control lists (ACLs)\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2235",
      "start_idx": 2428887,
      "end_idx": 2429882,
      "metadata": {
        "num_sentences": 9,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2243",
      "text": "Amazon Simple Storage Service API Reference\nreturn Aws::S3::Model::Type::AmazonCustomerByEmail;\nif (type == \"Canonical user\")\nreturn Aws::S3::Model::Type::CanonicalUser;\nif (type == \"Group\")\nreturn Aws::S3::Model::Type::Group;\nreturn Aws::S3::Model::Type::NOT_SET;\n}\n\u2022 For API details, see PutObjectAcl in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command grants full control to two AWS users (user1@example.com and\nuser2@example.com) and read permission to everyone:\naws s3api put-object-acl --bucket MyBucket --key file.txt --grant-full-\ncontrol emailaddress=user1@example.com,emailaddress=user2@example.com --grant-\nread uri=http://acs.amazonaws.com/groups/global/AllUsers\nSee http://docs.aws.amazon.com/AmazonS3/latest/API/RESTBucketPUTacl.html for\ndetails on custom ACLs (the s3api ACL commands, such as put-object-acl, use the same\nshorthand argument notation).\n\u2022 For API details, see PutObjectAcl in AWS CLI Command Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nclass ObjectWrapper:\nBasics API Version 2006-03-01 2238",
      "start_idx": 2432492,
      "end_idx": 2433650,
      "metadata": {
        "num_sentences": 6,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2244",
      "text": "Amazon Simple Storage Service API Reference\n\"\"\"Encapsulates S3 object actions.\"\"\"\ndef __init__(self, s3_object):\n\"\"\"\n:param s3_object: A Boto3 Object resource. This is a high-level resource\nin Boto3\nthat wraps object actions in a class-like structure.\n\"\"\"\nself.object = s3_object\nself.key = self.object.key\ndef put_acl(self, email):\n\"\"\"\nApplies an ACL to the object that grants read access to an AWS user\nidentified\nby email address.\n:param email: The email address of the user to grant access.\n\"\"\"\ntry:\nacl = self.object.Acl()\n# Putting an ACL overwrites the existing ACL, so append new grants\n# if you want to preserve existing grants.\ngrants = acl.grants if acl.grants else []\ngrants.append(\n{\n\"Grantee\": {\"Type\": \"AmazonCustomerByEmail\", \"EmailAddress\":\nemail},\n\"Permission\": \"READ\",\n}\n)\nacl.put(AccessControlPolicy={\"Grants\": grants, \"Owner\": acl.owner})\nlogger.info(\"Granted read access to %s.\", email)\nexcept ClientError:\nlogger.exception(\"Couldn't add ACL to object '%s'.\", self.object.key)\nraise\n\u2022 For API details, see PutObjectAcl in AWS SDK for Python (Boto3) API Reference.\nBasics API Version 2006-03-01 2239",
      "start_idx": 2433652,
      "end_idx": 2434772,
      "metadata": {
        "num_sentences": 10,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2245",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutObjectLegalHold with an AWS SDK or CLI\nThe following code examples show how to use PutObjectLegalHold.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Lock Amazon S3 objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Set or modify a legal hold on an object in an S3 bucket.\n/// </summary>\n/// <param name=\"bucketName\">The bucket of the object.</param>\n/// <param name=\"objectKey\">The key of the object.</param>\n/// <param name=\"holdStatus\">The On or Off status for the legal hold.</param>\n/// <returns>True if successful.</returns>\npublic async Task<bool> ModifyObjectLegalHold(string bucketName,\nstring objectKey, ObjectLockLegalHoldStatus holdStatus)\n{\ntry\n{\nvar request = new PutObjectLegalHoldRequest()\n{\nBucketName = bucketName,\nKey = objectKey,\nLegalHold = new ObjectLockLegalHold()\n{\nBasics API Version 2006-03-01 2240",
      "start_idx": 2434774,
      "end_idx": 2436091,
      "metadata": {
        "num_sentences": 8,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2247",
      "text": "Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// PutObjectLegalHold sets the legal hold configuration for an S3 object.\nfunc (actor S3Actions) PutObjectLegalHold(ctx context.Context, bucket string, key\nstring, versionId string, legalHoldStatus types.ObjectLockLegalHoldStatus) error\n{\ninput := &s3.PutObjectLegalHoldInput{\nBucket: aws.String(bucket),\nKey: aws.String(key),\nLegalHold: &types.ObjectLockLegalHold{\nStatus: legalHoldStatus,\n},\n}\nif versionId != \"\" {\ninput.VersionId = aws.String(versionId)\n}\n_, err := actor.S3Client.PutObjectLegalHold(ctx, input)\nif err != nil {\nvar noKey *types.NoSuchKey\nif errors.As(err, &noKey) {\nlog.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket)\nerr = noKey\n}\n}\nBasics API Version 2006-03-01 2242",
      "start_idx": 2436951,
      "end_idx": 2437953,
      "metadata": {
        "num_sentences": 5,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2248",
      "text": "Amazon Simple Storage Service API Reference\nreturn err\n}\n\u2022 For API details, see PutObjectLegalHold in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Set or modify a legal hold on an object in an S3 bucket.\npublic void modifyObjectLegalHold(String bucketName, String objectKey,\nboolean legalHoldOn) {\nObjectLockLegalHold legalHold ;\nif (legalHoldOn) {\nlegalHold = ObjectLockLegalHold.builder()\n.status(ObjectLockLegalHoldStatus.ON)\n.build();\n} else {\nlegalHold = ObjectLockLegalHold.builder()\n.status(ObjectLockLegalHoldStatus.OFF)\n.build();\n}\nPutObjectLegalHoldRequest legalHoldRequest =\nPutObjectLegalHoldRequest.builder()\n.bucket(bucketName)\n.key(objectKey)\n.legalHold(legalHold)\n.build();\ngetClient().putObjectLegalHold(legalHoldRequest) ;\nSystem.out.println(\"Modified legal hold for \"+ objectKey +\" in\n\"+bucketName +\".\");\nBasics API Version 2006-03-01 2243",
      "start_idx": 2437955,
      "end_idx": 2438947,
      "metadata": {
        "num_sentences": 6,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2249",
      "text": "Amazon Simple Storage Service API Reference\n}\n\u2022 For API details, see PutObjectLegalHold in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport {\nPutObjectLegalHoldCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Apply a legal hold configuration to the specified object.\n* @param {{ bucketName: string, objectKey: string, legalHoldStatus: \"ON\" |\n\"OFF\" }}\n*/\nexport const main = async ({ bucketName, objectKey, legalHoldStatus }) => {\nif (![\"OFF\", \"ON\"].includes(legalHoldStatus.toUpperCase())) {\nthrow new Error(\n\"Invalid parameter. legalHoldStatus must be 'ON' or 'OFF'.\",\n);\n}\nconst client = new S3Client({});\nconst command = new PutObjectLegalHoldCommand({\nBucket: bucketName,\nKey: objectKey,\nLegalHold: {\n// Set the status to 'ON' to place a legal hold on the object.\n// Set the status to 'OFF' to remove the legal hold.\nStatus: legalHoldStatus,\n},\nBasics API Version 2006-03-01 2244",
      "start_idx": 2438949,
      "end_idx": 2440010,
      "metadata": {
        "num_sentences": 10,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2250",
      "text": "Amazon Simple Storage Service API Reference\n});\ntry {\nawait client.send(command);\nconsole.log(\n`Legal hold status set to \"${legalHoldStatus}\" for \"${objectKey}\" in\n\"${bucketName}\"`,\n);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while modifying legal hold status for \"${objectKey}\" in\n\"${bucketName}\". The bucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while modifying legal hold status for \"${objectKey}\" in\n\"${bucketName}\". ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport {\nisMain,\nvalidateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => {\nconst options = {\nbucketName: {\ntype: \"string\",\nrequired: true,\n},\nobjectKey: {\ntype: \"string\",\nrequired: true,\nBasics API Version 2006-03-01 2245",
      "start_idx": 2440012,
      "end_idx": 2440982,
      "metadata": {
        "num_sentences": 3,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2251",
      "text": "Amazon Simple Storage Service API Reference\n},\nlegalHoldStatus: {\ntype: \"string\",\ndefault: \"ON\",\n},\n};\nconst results = parseArgs({ options });\nconst { errors } = validateArgs({ options }, results);\nreturn { errors, results };\n};\nif (isMain(import.meta.url)) {\nconst { errors, results } = loadArgs();\nif (!errors) {\nmain(results.values);\n} else {\nconsole.error(errors.join(\"\\n\"));\n}\n}\n\u2022 For API details, see PutObjectLegalHold in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nPut an object legal hold.\ndef set_legal_hold(s3_client, bucket: str, key: str) -> None:\n\"\"\"\nSet a legal hold on a specific file in a bucket.\nArgs:\ns3_client: Boto3 S3 client.\nbucket: The name of the bucket containing the file.\nBasics API Version 2006-03-01 2246",
      "start_idx": 2440984,
      "end_idx": 2441866,
      "metadata": {
        "num_sentences": 8,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2252",
      "text": "Amazon Simple Storage Service API Reference\nkey: The key of the file to set the legal hold on.\n\"\"\"\nprint()\nlogger.info(\"Setting legal hold on file [%s] in bucket [%s]\", key, bucket)\ntry:\nbefore_status = \"OFF\"\nafter_status = \"ON\"\ns3_client.put_object_legal_hold(\nBucket=bucket, Key=key, LegalHold={\"Status\": after_status}\n)\nlogger.debug(\n\"Legal hold set successfully on file [%s] in bucket [%s]\", key,\nbucket\n)\n_print_legal_hold_update(bucket, key, before_status, after_status)\nexcept Exception as e:\nlogger.error(\n\"Failed to set legal hold on file [%s] in bucket [%s]: %s\", key,\nbucket, e\n)\n\u2022 For API details, see PutObjectLegalHold in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutObjectLockConfiguration with an AWS SDK or CLI\nThe following code examples show how to use PutObjectLockConfiguration.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Lock Amazon S3 objects\nBasics API Version 2006-03-01 2247",
      "start_idx": 2441868,
      "end_idx": 2443097,
      "metadata": {
        "num_sentences": 7,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2253",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nSet the object lock configuration of a bucket.\n/// <summary>\n/// Enable object lock on an existing bucket.\n/// </summary>\n/// <param name=\"bucketName\">The name of the bucket to modify.</param>\n/// <returns>True if successful.</returns>\npublic async Task<bool> EnableObjectLockOnBucket(string bucketName)\n{\ntry\n{\n// First, enable Versioning on the bucket.\nawait _amazonS3.PutBucketVersioningAsync(new\nPutBucketVersioningRequest()\n{\nBucketName = bucketName,\nVersioningConfig = new S3BucketVersioningConfig()\n{\nEnableMfaDelete = false,\nStatus = VersionStatus.Enabled\n}\n});\nvar request = new PutObjectLockConfigurationRequest()\n{\nBucketName = bucketName,\nObjectLockConfiguration = new ObjectLockConfiguration()\n{\nObjectLockEnabled = new ObjectLockEnabled(\"Enabled\"),\n},\n};\nBasics API Version 2006-03-01 2248",
      "start_idx": 2443099,
      "end_idx": 2444092,
      "metadata": {
        "num_sentences": 6,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2256",
      "text": "Amazon Simple Storage Service API Reference\n--bucket my-bucket-with-object-lock \\\n--object-lock-configuration '{ \"ObjectLockEnabled\": \"Enabled\", \"Rule\":\n{ \"DefaultRetention\": { \"Mode\": \"COMPLIANCE\", \"Days\": 50 }}}'\nThis command produces no output.\n\u2022 For API details, see PutObjectLockConfiguration in AWS CLI Command Reference.\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nSet the object lock configuration of a bucket.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// EnableObjectLockOnBucket enables object locking on an existing bucket.\nfunc (actor S3Actions) EnableObjectLockOnBucket(ctx context.Context, bucket\nstring) error {\n// Versioning must be enabled on the bucket before object locking is enabled.\nverInput := &s3.PutBucketVersioningInput{\nBucket: aws.String(bucket),\nVersioningConfiguration: &types.VersioningConfiguration{\nMFADelete: types.MFADeleteDisabled,\nStatus: types.BucketVersioningStatusEnabled,\n},\n}\n_, err := actor.S3Client.PutBucketVersioning(ctx, verInput)\nif err != nil {\nBasics API Version 2006-03-01 2251",
      "start_idx": 2446489,
      "end_idx": 2447685,
      "metadata": {
        "num_sentences": 9,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2258",
      "text": "Amazon Simple Storage Service API Reference\nctx context.Context, bucket string, lockMode types.ObjectLockEnabled,\nretentionPeriod int32, retentionMode types.ObjectLockRetentionMode) error {\ninput := &s3.PutObjectLockConfigurationInput{\nBucket: aws.String(bucket),\nObjectLockConfiguration: &types.ObjectLockConfiguration{\nObjectLockEnabled: lockMode,\nRule: &types.ObjectLockRule{\nDefaultRetention: &types.DefaultRetention{\nDays: aws.Int32(retentionPeriod),\nMode: retentionMode,\n},\n},\n},\n}\n_, err := actor.S3Client.PutObjectLockConfiguration(ctx, input)\nif err != nil {\nvar noBucket *types.NoSuchBucket\nif errors.As(err, &noBucket) {\nlog.Printf(\"Bucket %s does not exist.\\n\", bucket)\nerr = noBucket\n}\n}\nreturn err\n}\n\u2022 For API details, see PutObjectLockConfiguration in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nSet the object lock configuration of a bucket.\nBasics API Version 2006-03-01 2253",
      "start_idx": 2448628,
      "end_idx": 2449652,
      "metadata": {
        "num_sentences": 5,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2261",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nSet the object lock configuration of a bucket.\nimport {\nPutObjectLockConfigurationCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Enable S3 Object Lock for an Amazon S3 bucket.\n* After you enable Object Lock on a bucket, you can't\n* disable Object Lock or suspend versioning for that bucket.\n* @param {{ bucketName: string, enabled: boolean }}\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\nconst command = new PutObjectLockConfigurationCommand({\nBucket: bucketName,\n// The Object Lock configuration that you want to apply to the specified\nbucket.\nObjectLockConfiguration: {\nObjectLockEnabled: \"Enabled\",\n},\n});\ntry {\nawait client.send(command);\nconsole.log(`Object Lock for \"${bucketName}\" enabled.`);\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nBasics API Version 2006-03-01 2256",
      "start_idx": 2452127,
      "end_idx": 2453229,
      "metadata": {
        "num_sentences": 7,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2262",
      "text": "Amazon Simple Storage Service API Reference\nconsole.error(\n`Error from S3 while modifying the object lock configuration for the\nbucket \"${bucketName}\". The bucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while modifying the object lock configuration for the\nbucket \"${bucketName}\". ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport {\nisMain,\nvalidateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => {\nconst options = {\nbucketName: {\ntype: \"string\",\nrequired: true,\n},\n};\nconst results = parseArgs({ options });\nconst { errors } = validateArgs({ options }, results);\nreturn { errors, results };\n};\nif (isMain(import.meta.url)) {\nconst { errors, results } = loadArgs();\nif (!errors) {\nmain(results.values);\n} else {\nconsole.error(errors.join(\"\\n\"));\n}\n}\nBasics API Version 2006-03-01 2257",
      "start_idx": 2453231,
      "end_idx": 2454210,
      "metadata": {
        "num_sentences": 3,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2263",
      "text": "Amazon Simple Storage Service API Reference\nSet the default retention period of a bucket.\nimport {\nPutObjectLockConfigurationCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Change the default retention settings for an object in an Amazon S3 bucket.\n* @param {{ bucketName: string, retentionDays: string }}\n*/\nexport const main = async ({ bucketName, retentionDays }) => {\nconst client = new S3Client({});\ntry {\nawait client.send(\nnew PutObjectLockConfigurationCommand({\nBucket: bucketName,\n// The Object Lock configuration that you want to apply to the specified\nbucket.\nObjectLockConfiguration: {\nObjectLockEnabled: \"Enabled\",\nRule: {\n// The default Object Lock retention mode and period that you want to\napply\n// to new objects placed in the specified bucket. Bucket settings\nrequire\n// both a mode and a period. The period can be either Days or Years\nbut\n// you must select one.\nDefaultRetention: {\n// In governance mode, users can't overwrite or delete an object\nversion\n// or alter its lock settings unless they have special permissions.\nWith\n// governance mode, you protect objects against being deleted by\nmost users,\n// but you can still grant some users permission to alter the\nretention settings\n// or delete the objects if necessary.\nMode: \"GOVERNANCE\",\nDays: Number.parseInt(retentionDays),\nBasics API Version 2006-03-01 2258",
      "start_idx": 2454212,
      "end_idx": 2455575,
      "metadata": {
        "num_sentences": 9,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2265",
      "text": "Amazon Simple Storage Service API Reference\nrequired: true,\n},\n};\nconst results = parseArgs({ options });\nconst { errors } = validateArgs({ options }, results);\nreturn { errors, results };\n};\nif (isMain(import.meta.url)) {\nconst { errors, results } = loadArgs();\nif (!errors) {\nmain(results.values);\n} else {\nconsole.error(errors.join(\"\\n\"));\n}\n}\n\u2022 For API details, see PutObjectLockConfiguration in AWS SDK for JavaScript API Reference.\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nPut object lock configuration.\ns3_client.put_object_lock_configuration(\nBucket=bucket,\nObjectLockConfiguration={\"ObjectLockEnabled\": \"Disabled\", \"Rule\":\n{}},\n)\n\u2022 For API details, see PutObjectLockConfiguration in AWS SDK for Python (Boto3) API\nReference.\nBasics API Version 2006-03-01 2260",
      "start_idx": 2456494,
      "end_idx": 2457375,
      "metadata": {
        "num_sentences": 6,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2266",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutObjectRetention with an AWS SDK or CLI\nThe following code examples show how to use PutObjectRetention.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Lock Amazon S3 objects\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/// <summary>\n/// Set or modify a retention period on an object in an S3 bucket.\n/// </summary>\n/// <param name=\"bucketName\">The bucket of the object.</param>\n/// <param name=\"objectKey\">The key of the object.</param>\n/// <param name=\"retention\">The retention mode.</param>\n/// <param name=\"retainUntilDate\">The date retention expires.</param>\n/// <returns>True if successful.</returns>\npublic async Task<bool> ModifyObjectRetentionPeriod(string bucketName,\nstring objectKey, ObjectLockRetentionMode retention, DateTime\nretainUntilDate)\n{\ntry\n{\nvar request = new PutObjectRetentionRequest()\n{\nBucketName = bucketName,\nKey = objectKey,\nBasics API Version 2006-03-01 2261",
      "start_idx": 2457377,
      "end_idx": 2458737,
      "metadata": {
        "num_sentences": 8,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2268",
      "text": "Amazon Simple Storage Service API Reference\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// S3Actions wraps S3 service actions.\ntype S3Actions struct {\nS3Client *s3.Client\nS3Manager *manager.Uploader\n}\n// PutObjectRetention sets the object retention configuration for an S3 object.\nfunc (actor S3Actions) PutObjectRetention(ctx context.Context, bucket string, key\nstring, retentionMode types.ObjectLockRetentionMode, retentionPeriodDays int32)\nerror {\ninput := &s3.PutObjectRetentionInput{\nBucket: aws.String(bucket),\nKey: aws.String(key),\nRetention: &types.ObjectLockRetention{\nMode: retentionMode,\nRetainUntilDate: aws.Time(time.Now().AddDate(0, 0, int(retentionPeriodDays))),\n},\nBypassGovernanceRetention: aws.Bool(true),\n}\n_, err := actor.S3Client.PutObjectRetention(ctx, input)\nif err != nil {\nvar noKey *types.NoSuchKey\nif errors.As(err, &noKey) {\nlog.Printf(\"Object %s does not exist in bucket %s.\\n\", key, bucket)\nerr = noKey\n}\n}\nBasics API Version 2006-03-01 2263",
      "start_idx": 2459811,
      "end_idx": 2460879,
      "metadata": {
        "num_sentences": 5,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2269",
      "text": "Amazon Simple Storage Service API Reference\nreturn err\n}\n\u2022 For API details, see PutObjectRetention in AWS SDK for Go API Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n// Set or modify a retention period on an object in an S3 bucket.\npublic void modifyObjectRetentionPeriod(String bucketName, String objectKey)\n{\n// Calculate the instant one day from now.\nInstant futureInstant = Instant.now().plus(1, ChronoUnit.DAYS);\n// Convert the Instant to a ZonedDateTime object with a specific time\nzone.\nZonedDateTime zonedDateTime =\nfutureInstant.atZone(ZoneId.systemDefault());\n// Define a formatter for human-readable output.\nDateTimeFormatter formatter = DateTimeFormatter.ofPattern(\"yyyy-MM-dd\nHH:mm:ss\");\n// Format the ZonedDateTime object to a human-readable date string.\nString humanReadableDate = formatter.format(zonedDateTime);\n// Print the formatted date string.\nSystem.out.println(\"Formatted Date: \" + humanReadableDate);\nObjectLockRetention retention = ObjectLockRetention.builder()\n.mode(ObjectLockRetentionMode.GOVERNANCE)\n.retainUntilDate(futureInstant)\n.build();\nBasics API Version 2006-03-01 2264",
      "start_idx": 2460881,
      "end_idx": 2462098,
      "metadata": {
        "num_sentences": 10,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2270",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectRetentionRequest retentionRequest =\nPutObjectRetentionRequest.builder()\n.bucket(bucketName)\n.key(objectKey)\n.retention(retention)\n.build();\ngetClient().putObjectRetention(retentionRequest);\nSystem.out.println(\"Set retention for \"+objectKey +\" in \" +bucketName +\"\nuntil \"+ humanReadableDate +\".\");\n}\n\u2022 For API details, see PutObjectRetention in AWS SDK for Java 2.x API Reference.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport {\nPutObjectRetentionCommand,\nS3Client,\nS3ServiceException,\n} from \"@aws-sdk/client-s3\";\n/**\n* Place a 24-hour retention period on an object in an Amazon S3 bucket.\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\nconst client = new S3Client({});\nconst command = new PutObjectRetentionCommand({\nBucket: bucketName,\nKey: key,\nBypassGovernanceRetention: false,\nRetention: {\nBasics API Version 2006-03-01 2265",
      "start_idx": 2462100,
      "end_idx": 2463158,
      "metadata": {
        "num_sentences": 6,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2271",
      "text": "Amazon Simple Storage Service API Reference\n// In governance mode, users can't overwrite or delete an object version\n// or alter its lock settings unless they have special permissions. With\n// governance mode, you protect objects against being deleted by most\nusers,\n// but you can still grant some users permission to alter the retention\nsettings\n// or delete the objects if necessary.\nMode: \"GOVERNANCE\",\nRetainUntilDate: new Date(new Date().getTime() + 24 * 60 * 60 * 1000),\n},\n});\ntry {\nawait client.send(command);\nconsole.log(\"Object Retention settings updated.\");\n} catch (caught) {\nif (\ncaught instanceof S3ServiceException &&\ncaught.name === \"NoSuchBucket\"\n) {\nconsole.error(\n`Error from S3 while modifying the governance mode and retention period\non an object. The bucket doesn't exist.`,\n);\n} else if (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while modifying the governance mode and retention period\non an object. ${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\n// Call function if run directly\nimport { parseArgs } from \"node:util\";\nimport {\nisMain,\nvalidateArgs,\n} from \"@aws-doc-sdk-examples/lib/utils/util-node.js\";\nconst loadArgs = () => {\nconst options = {\nBasics API Version 2006-03-01 2266",
      "start_idx": 2463160,
      "end_idx": 2464417,
      "metadata": {
        "num_sentences": 6,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2273",
      "text": "Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nPut an object retention.\ns3_client.put_object_retention(\nBucket=bucket,\nKey=key,\nVersionId=version_id,\nRetention={\"Mode\": \"GOVERNANCE\", \"RetainUntilDate\":\nfar_future_date},\nBypassGovernanceRetention=True,\n)\n\u2022 For API details, see PutObjectRetention in AWS SDK for Python (Boto3) API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse RestoreObject with an AWS SDK or CLI\nThe following code examples show how to use RestoreObject.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2268",
      "start_idx": 2465380,
      "end_idx": 2466369,
      "metadata": {
        "num_sentences": 10,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2276",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see RestoreObject in AWS SDK for .NET API Reference.\nCLI\nAWS CLI\nTo create a restore request for an object\nThe following restore-object example restores the specified Amazon S3 Glacier object\nfor the bucket my-glacier-bucket for 10 days.\naws s3api restore-object \\\n--bucket my-glacier-bucket \\\n--key doc1.rtf \\\n--restore-request Days=10\nThis command produces no output.\n\u2022 For API details, see RestoreObject in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.RestoreRequest;\nimport software.amazon.awssdk.services.s3.model.GlacierJobParameters;\nimport software.amazon.awssdk.services.s3.model.RestoreObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.model.Tier;\nBasics API Version 2006-03-01 2271",
      "start_idx": 2469036,
      "end_idx": 2470133,
      "metadata": {
        "num_sentences": 7,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2279",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse SelectObjectContent with an AWS SDK or CLI\nThe following code examples show how to use SelectObjectContent.\nCLI\nAWS CLI\nTo filter the contents of an Amazon S3 object based on an SQL statement\nThe following select-object-content example filters the object my-data-file.csv\nwith the specified SQL statement and sends output to a file.\naws s3api select-object-content \\\n--bucket my-bucket \\\n--key my-data-file.csv \\\n--expression \"select * from s3object limit 100\" \\\n--expression-type 'SQL' \\\n--input-serialization '{\"CSV\": {}, \"CompressionType\": \"NONE\"}' \\\n--output-serialization '{\"CSV\": {}}' \"output.csv\"\nThis command produces no output.\n\u2022 For API details, see SelectObjectContent in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nThe following example shows a query using a JSON object. The complete example also\nshows the use of a CSV object.\nBasics API Version 2006-03-01 2274",
      "start_idx": 2472511,
      "end_idx": 2473780,
      "metadata": {
        "num_sentences": 11,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2282",
      "text": "Amazon Simple Storage Service API Reference\n// Supply an EventStreamInfo object to the response handler to gather\nrecords and information from the response.\ns3AsyncClient.selectObjectContent(select,\nbuildResponseHandler(eventStreamInfo)).join();\n// Log out information gathered while processing the response stream.\nlong recordCount = eventStreamInfo.getRecords().stream().mapToInt(record\n->\nrecord.split(\"\\n\").length\n).sum();\nlogger.info(\"Total records {}: {}\", fileType, recordCount);\nlogger.info(\"Visitor onRecords for fileType {} called {} times\",\nfileType, eventStreamInfo.getCountOnRecordsCalled());\nlogger.info(\"Visitor onStats for fileType {}, {}\", fileType,\neventStreamInfo.getStats());\nlogger.info(\"Visitor onContinuations for fileType {}, {}\", fileType,\neventStreamInfo.getCountContinuationEvents());\nreturn eventStreamInfo;\n}\nstatic SelectObjectContentResponseHandler\nbuildResponseHandler(EventStreamInfo eventStreamInfo) {\n// Use a Visitor to process the response stream. This visitor logs\ninformation and gathers details while processing.\nfinal SelectObjectContentResponseHandler.Visitor visitor =\nSelectObjectContentResponseHandler.Visitor.builder()\n.onRecords(r -> {\nlogger.info(\"Record event received.\");\neventStreamInfo.addRecord(r.payload().asUtf8String());\neventStreamInfo.incrementOnRecordsCalled();\n})\n.onCont(ce -> {\nlogger.info(\"Continuation event received.\");\neventStreamInfo.incrementContinuationEvents();\n})\n.onProgress(pe -> {\nProgress progress = pe.details();\nlogger.info(\"Progress event received:\\n bytesScanned:\n{}\\nbytesProcessed: {}\\nbytesReturned:{}\",\nprogress.bytesScanned(),\nprogress.bytesProcessed(),\nprogress.bytesReturned());\n})\n.onEnd(ee -> logger.info(\"End event received.\"))\nBasics API Version 2006-03-01 2277",
      "start_idx": 2477412,
      "end_idx": 2479163,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2284",
      "text": "Amazon Simple Storage Service API Reference\npublic Integer getCountContinuationEvents() {\nreturn countContinuationEvents;\n}\npublic Stats getStats() {\nreturn stats;\n}\n}\n\u2022 For API details, see SelectObjectContent in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse UploadPart with an AWS SDK or CLI\nThe following code examples show how to use UploadPart.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code examples:\n\u2022 Perform a multipart upload\n\u2022 Use checksums\n\u2022 Work with Amazon S3 object integrity\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n//! Upload a part to an S3 bucket.\n/*!\n\\param bucket: The name of the S3 bucket where the object will be uploaded.\nBasics API Version 2006-03-01 2279",
      "start_idx": 2480188,
      "end_idx": 2481272,
      "metadata": {
        "num_sentences": 12,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2286",
      "text": "Amazon Simple Storage Service API Reference\ncase Aws::S3::Model::ChecksumAlgorithm::CRC32C:\nrequest.SetChecksumCRC32C(calculatedHash);\nbreak;\ncase Aws::S3::Model::ChecksumAlgorithm::SHA1:\nrequest.SetChecksumSHA1(calculatedHash);\nbreak;\ncase Aws::S3::Model::ChecksumAlgorithm::SHA256:\nrequest.SetChecksumSHA256(calculatedHash);\nbreak;\n}\n}\nreturn client.UploadPart(request);\n}\n\u2022 For API details, see UploadPart in AWS SDK for C++ API Reference.\nCLI\nAWS CLI\nThe following command uploads the first part in a multipart upload initiated with the\ncreate-multipart-upload command:\naws s3api upload-part --bucket my-bucket --key 'multipart/01' --part-number 1 --\nbody part01 --upload-id\n\"dfRtDYU0WWCCcH43C3WFbkRONycyCpTJJvxu2i5GYkZljF.Yxwh6XG7WfS2vC4to6HiV6Yjlx.cph0gtNBtJ8P3URCSbB7rjxI5iEwVDmgaXZOGgkk5nVTW16HOQ5l0R\"\nThe body option takes the name or path of a local file for upload (do not use the file://\nprefix). The minimum part size is 5 MB. Upload ID is returned by create-multipart-\nupload and can also be retrieved with list-multipart-uploads. Bucket and key are\nspecified when you create the multipart upload.\nOutput:\n{\n\"ETag\": \"\\\"e868e0f4719e394144ef36531ee6824c\\\"\"\n}\nBasics API Version 2006-03-01 2281",
      "start_idx": 2482738,
      "end_idx": 2483943,
      "metadata": {
        "num_sentences": 6,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2287",
      "text": "Amazon Simple Storage Service API Reference\nSave the ETag value of each part for later. They are required to complete the multipart\nupload.\n\u2022 For API details, see UploadPart in AWS CLI Command Reference.\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nlet mut upload_parts: Vec<aws_sdk_s3::types::CompletedPart> = Vec::new();\nfor chunk_index in 0..chunk_count {\nlet this_chunk = if chunk_count - 1 == chunk_index {\nsize_of_last_chunk\n} else {\nCHUNK_SIZE\n};\nlet stream = ByteStream::read_from()\n.path(path)\n.offset(chunk_index * CHUNK_SIZE)\n.length(Length::Exact(this_chunk))\n.build()\n.await\n.unwrap();\n// Chunk index needs to start at 0, but part numbers start at 1.\nlet part_number = (chunk_index as i32) + 1;\nlet upload_part_res = client\n.upload_part()\n.key(&key)\n.bucket(&bucket_name)\n.upload_id(upload_id)\n.body(stream)\n.part_number(part_number)\n.send()\n.await?;\nBasics API Version 2006-03-01 2282",
      "start_idx": 2483945,
      "end_idx": 2484940,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2288",
      "text": "Amazon Simple Storage Service API Reference\nupload_parts.push(\nCompletedPart::builder()\n.e_tag(upload_part_res.e_tag.unwrap_or_default())\n.part_number(part_number)\n.build(),\n);\n}\n// Create a multipart upload. Use UploadPart and CompleteMultipartUpload to\n// upload the file.\nlet multipart_upload_res: CreateMultipartUploadOutput = client\n.create_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.send()\n.await?;\nlet upload_id = multipart_upload_res.upload_id().ok_or(S3ExampleError::new(\n\"Missing upload_id after CreateMultipartUpload\",\n))?;\n// upload_parts: Vec<aws_sdk_s3::types::CompletedPart>\nlet completed_multipart_upload: CompletedMultipartUpload =\nCompletedMultipartUpload::builder()\n.set_parts(Some(upload_parts))\n.build();\nlet _complete_multipart_upload_res = client\n.complete_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.multipart_upload(completed_multipart_upload)\n.upload_id(upload_id)\n.send()\n.await?;\n\u2022 For API details, see UploadPart in AWS SDK for Rust API reference.\nBasics API Version 2006-03-01 2283",
      "start_idx": 2484942,
      "end_idx": 2485972,
      "metadata": {
        "num_sentences": 7,
        "num_words": 85,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2289",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nScenarios for Amazon S3 using AWS SDKs\nThe following code examples show you how to implement common scenarios in Amazon S3 with\nAWS SDKs. These scenarios show you how to accomplish specific tasks by calling multiple functions\nwithin Amazon S3 or combined with other AWS services. Each scenario includes a link to the\ncomplete source code, where you can find instructions on how to set up and run the code.\nScenarios target an intermediate level of experience to help you understand service actions in\ncontext.\nExamples\n\u2022 Convert text to speech and back to text using an AWS SDK\n\u2022 Create a presigned URL for Amazon S3 using an AWS SDK\n\u2022 Create a photo asset management application that lets users manage photos using labels\n\u2022 A web page that lists Amazon S3 objects using an AWS SDK\n\u2022 Create an Amazon Textract explorer application\n\u2022 Delete all objects in a given Amazon S3 bucket using an AWS SDK.\n\u2022 Delete incomplete multipart uploads to Amazon S3 using an AWS SDK\n\u2022 Detect PPE in images with Amazon Rekognition using an AWS SDK\n\u2022 Detect entities in text extracted from an image using an AWS SDK\n\u2022 Detect faces in an image using an AWS SDK\n\u2022 Detect objects in images with Amazon Rekognition using an AWS SDK\n\u2022 Detect people and objects in a video with Amazon Rekognition using an AWS SDK\n\u2022 Download all objects in an Amazon Simple Storage Service (Amazon S3) bucket to a local\ndirectory\n\u2022 Get an Amazon S3 object from a Multi-Region Access Point by using an AWS SDK\n\u2022 Get an object from an Amazon S3 bucket using an AWS SDK, specifying an If-Modified-Since\nheader\n\u2022 Get started with encryption for Amazon S3 objects using an AWS SDK\n\u2022 Get started with tags for Amazon S3 objects using an AWS SDK\nScenarios API Version 2006-03-01 2284",
      "start_idx": 2485974,
      "end_idx": 2487969,
      "metadata": {
        "num_sentences": 8,
        "num_words": 355,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2291",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nUse Amazon Polly to synthesize a plain text (UTF-8) input file to an audio file, upload the\naudio file to an Amazon S3 bucket, use Amazon Transcribe to convert that audio file to text,\nand display the text.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Polly\n\u2022 Amazon S3\n\u2022 Amazon Transcribe\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nCreate a presigned URL for Amazon S3 using an AWS SDK\nThe following code examples show how to create a presigned URL for Amazon S3 and upload an\nobject.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGenerate a presigned URL that can perform an Amazon S3 action for a limited time.\nusing System;\nusing Amazon;\nusing Amazon.S3;\nScenarios API Version 2006-03-01 2286",
      "start_idx": 2489583,
      "end_idx": 2490709,
      "metadata": {
        "num_sentences": 9,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2292",
      "text": "Amazon Simple Storage Service API Reference\nusing Amazon.S3.Model;\npublic class GenPresignedUrl\n{\npublic static void Main()\n{\nconst string bucketName = \"amzn-s3-demo-bucket\";\nconst string objectKey = \"sample.txt\";\n// Specify how long the presigned URL lasts, in hours\nconst double timeoutDuration = 12;\n// Specify the AWS Region of your Amazon S3 bucket. If it is\n// different from the Region defined for the default user,\n// pass the Region to the constructor for the client. For\n// example: new AmazonS3Client(RegionEndpoint.USEast1);\n// If using the Region us-east-1, and server-side encryption with AWS\nKMS, you must specify Signature Version 4.\n// Region us-east-1 defaults to Signature Version 2 unless explicitly\nset to Version 4 as shown below.\n// For more details, see https://docs.aws.amazon.com/AmazonS3/latest/\nuserguide/UsingAWSSDK.html#specify-signature-version\n// and https://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/Amazon/\nTAWSConfigsS3.html\nAWSConfigsS3.UseSignatureVersion4 = true;\nIAmazonS3 s3Client = new AmazonS3Client(RegionEndpoint.USEast1);\nstring urlString = GeneratePresignedURL(s3Client, bucketName,\nobjectKey, timeoutDuration);\nConsole.WriteLine($\"The generated URL is: {urlString}.\");\n}\n/// <summary>\n/// Generate a presigned URL that can be used to access the file named\n/// in the objectKey parameter for the amount of time specified in the\n/// duration parameter.\n/// </summary>\n/// <param name=\"client\">An initialized S3 client object used to call\n/// the GetPresignedUrl method.</param>\n/// <param name=\"bucketName\">The name of the S3 bucket containing the\n/// object for which to create the presigned URL.</param>\n/// <param name=\"objectKey\">The name of the object to access with the\n/// presigned URL.</param>\nScenarios API Version 2006-03-01 2287",
      "start_idx": 2490711,
      "end_idx": 2492501,
      "metadata": {
        "num_sentences": 7,
        "num_words": 233,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2293",
      "text": "Amazon Simple Storage Service API Reference\n/// <param name=\"duration\">The length of time for which the presigned\n/// URL will be valid.</param>\n/// <returns>A string representing the generated presigned URL.</returns>\npublic static string GeneratePresignedURL(IAmazonS3 client, string\nbucketName, string objectKey, double duration)\n{\nstring urlString = string.Empty;\ntry\n{\nvar request = new GetPreSignedUrlRequest()\n{\nBucketName = bucketName,\nKey = objectKey,\nExpires = DateTime.UtcNow.AddHours(duration),\n};\nurlString = client.GetPreSignedURL(request);\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine($\"Error:'{ex.Message}'\");\n}\nreturn urlString;\n}\n}\nGenerate a presigned URL and perform an upload using that URL.\nusing System;\nusing System.IO;\nusing System.Net.Http;\nusing System.Threading.Tasks;\nusing Amazon;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to upload an object to an Amazon Simple Storage\n/// Service (Amazon S3) bucket using a presigned URL. The code first\n/// creates a presigned URL and then uses it to upload an object to an\n/// Amazon S3 bucket using that URL.\nScenarios API Version 2006-03-01 2288",
      "start_idx": 2492503,
      "end_idx": 2493663,
      "metadata": {
        "num_sentences": 4,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2294",
      "text": "Amazon Simple Storage Service API Reference\n/// </summary>\npublic class UploadUsingPresignedURL\n{\nprivate static HttpClient httpClient = new HttpClient();\npublic static async Task Main()\n{\nstring bucketName = \"amzn-s3-demo-bucket\";\nstring keyName = \"samplefile.txt\";\nstring filePath = $\"source\\\\{keyName}\";\n// Specify how long the signed URL will be valid in hours.\ndouble timeoutDuration = 12;\n// Specify the AWS Region of your Amazon S3 bucket. If it is\n// different from the Region defined for the default user,\n// pass the Region to the constructor for the client. For\n// example: new AmazonS3Client(RegionEndpoint.USEast1);\n// If using the Region us-east-1, and server-side encryption with AWS\nKMS, you must specify Signature Version 4.\n// Region us-east-1 defaults to Signature Version 2 unless explicitly\nset to Version 4 as shown below.\n// For more details, see https://docs.aws.amazon.com/AmazonS3/latest/\nuserguide/UsingAWSSDK.html#specify-signature-version\n// and https://docs.aws.amazon.com/sdkfornet/v3/apidocs/items/Amazon/\nTAWSConfigsS3.html\nAWSConfigsS3.UseSignatureVersion4 = true;\nIAmazonS3 client = new AmazonS3Client(RegionEndpoint.USEast1);\nvar url = GeneratePreSignedURL(client, bucketName, keyName,\ntimeoutDuration);\nvar success = await UploadObject(filePath, url);\nif (success)\n{\nConsole.WriteLine(\"Upload succeeded.\");\n}\nelse\n{\nConsole.WriteLine(\"Upload failed.\");\n}\n}\nScenarios API Version 2006-03-01 2289",
      "start_idx": 2493665,
      "end_idx": 2495096,
      "metadata": {
        "num_sentences": 8,
        "num_words": 175,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2296",
      "text": "Amazon Simple Storage Service API Reference\nKey = objectKey,\nVerb = HttpVerb.PUT,\nExpires = DateTime.UtcNow.AddHours(duration),\n};\nstring url = client.GetPreSignedURL(request);\nreturn url;\n}\n}\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGenerate a pre-signed URL to download an object.\n//! Routine which demonstrates creating a pre-signed URL to download an object\nfrom an\n//! Amazon Simple Storage Service (Amazon S3) bucket.\n/*!\n\\param bucketName: Name of the bucket.\n\\param key: Name of an object key.\n\\param expirationSeconds: Expiration in seconds for pre-signed URL.\n\\param clientConfig: Aws client configuration.\n\\return Aws::String: A pre-signed URL.\n*/\nAws::String AwsDoc::S3::generatePreSignedGetObjectUrl(const Aws::String\n&bucketName,\nconst Aws::String &key,\nuint64_t expirationSeconds,\nconst\nAws::S3::S3ClientConfiguration &clientConfig) {\nAws::S3::S3Client client(clientConfig);\nScenarios API Version 2006-03-01 2291",
      "start_idx": 2496685,
      "end_idx": 2497711,
      "metadata": {
        "num_sentences": 13,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2301",
      "text": "Amazon Simple Storage Service API Reference\nresult = curl_easy_setopt(curl, CURLOPT_UPLOAD, 1L);\nif (result != CURLE_OK) {\nstd::cerr << \"Failed to set CURLOPT_PUT\" << std::endl;\nreturn false;\n}\nresult = curl_easy_perform(curl);\nif (result != CURLE_OK) {\nstd::cerr << \"Failed to perform CURL request\" << std::endl;\nreturn false;\n}\nstd::string outString = outWriteString.str();\nif (outString.empty()) {\nstd::cout << \"Successfully put object.\" << std::endl;\nreturn true;\n} else {\nstd::cout << \"A server error was encountered, output:\\n\" << outString\n<< std::endl;\nreturn false;\n}\n}\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate functions that wrap S3 presigning actions.\n// Presigner encapsulates the Amazon Simple Storage Service (Amazon S3) presign\nactions\n// used in the examples.\nScenarios API Version 2006-03-01 2296",
      "start_idx": 2502327,
      "end_idx": 2503247,
      "metadata": {
        "num_sentences": 6,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2302",
      "text": "Amazon Simple Storage Service API Reference\n// It contains PresignClient, a client that is used to presign requests to Amazon\nS3.\n// Presigned requests contain temporary credentials and can be made from any HTTP\nclient.\ntype Presigner struct {\nPresignClient *s3.PresignClient\n}\n// GetObject makes a presigned request that can be used to get an object from a\nbucket.\n// The presigned request is valid for the specified number of seconds.\nfunc (presigner Presigner) GetObject(\nctx context.Context, bucketName string, objectKey string, lifetimeSecs int64)\n(*v4.PresignedHTTPRequest, error) {\nrequest, err := presigner.PresignClient.PresignGetObject(ctx,\n&s3.GetObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n}, func(opts *s3.PresignOptions) {\nopts.Expires = time.Duration(lifetimeSecs * int64(time.Second))\n})\nif err != nil {\nlog.Printf(\"Couldn't get a presigned request to get %v:%v. Here's why: %v\\n\",\nbucketName, objectKey, err)\n}\nreturn request, err\n}\n// PutObject makes a presigned request that can be used to put an object in a\nbucket.\n// The presigned request is valid for the specified number of seconds.\nfunc (presigner Presigner) PutObject(\nctx context.Context, bucketName string, objectKey string, lifetimeSecs int64)\n(*v4.PresignedHTTPRequest, error) {\nrequest, err := presigner.PresignClient.PresignPutObject(ctx,\n&s3.PutObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n}, func(opts *s3.PresignOptions) {\nopts.Expires = time.Duration(lifetimeSecs * int64(time.Second))\nScenarios API Version 2006-03-01 2297",
      "start_idx": 2503249,
      "end_idx": 2504815,
      "metadata": {
        "num_sentences": 8,
        "num_words": 196,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2303",
      "text": "Amazon Simple Storage Service API Reference\n})\nif err != nil {\nlog.Printf(\"Couldn't get a presigned request to put %v:%v. Here's why: %v\\n\",\nbucketName, objectKey, err)\n}\nreturn request, err\n}\n// DeleteObject makes a presigned request that can be used to delete an object\nfrom a bucket.\nfunc (presigner Presigner) DeleteObject(ctx context.Context, bucketName string,\nobjectKey string) (*v4.PresignedHTTPRequest, error) {\nrequest, err := presigner.PresignClient.PresignDeleteObject(ctx,\n&s3.DeleteObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n})\nif err != nil {\nlog.Printf(\"Couldn't get a presigned request to delete object %v. Here's why:\n%v\\n\", objectKey, err)\n}\nreturn request, err\n}\nfunc (presigner Presigner) PresignPostObject(ctx context.Context, bucketName\nstring, objectKey string, lifetimeSecs int64) (*s3.PresignedPostRequest, error)\n{\nrequest, err := presigner.PresignClient.PresignPostObject(ctx,\n&s3.PutObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n}, func(options *s3.PresignPostOptions) {\noptions.Expires = time.Duration(lifetimeSecs) * time.Second\n})\nif err != nil {\nlog.Printf(\"Couldn't get a presigned post request to put %v:%v. Here's why: %v\n\\n\", bucketName, objectKey, err)\n}\nreturn request, nil\n}\nScenarios API Version 2006-03-01 2298",
      "start_idx": 2504817,
      "end_idx": 2506126,
      "metadata": {
        "num_sentences": 5,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2304",
      "text": "Amazon Simple Storage Service API Reference\nRun an interactive example that generates and uses presigned URLs to upload, download,\nand delete an S3 object.\n// RunPresigningScenario is an interactive example that shows you how to get\npresigned\n// HTTP requests that you can use to move data into and out of Amazon Simple\nStorage\n// Service (Amazon S3). The presigned requests contain temporary credentials and\ncan\n// be used by an HTTP client.\n//\n// 1. Get a presigned request to put an object in a bucket.\n// 2. Use the net/http package to use the presigned request to upload a local\nfile to the bucket.\n// 3. Get a presigned request to get an object from a bucket.\n// 4. Use the net/http package to use the presigned request to download the\nobject to a local file.\n// 5. Get a presigned request to delete an object from a bucket.\n// 6. Use the net/http package to use the presigned request to delete the object.\n//\n// This example creates an Amazon S3 presign client from the specified sdkConfig\nso that\n// you can replace it with a mocked or stubbed config for unit testing.\n//\n// It uses a questioner from the `demotools` package to get input during the\nexample.\n// This package can be found in the ..\\..\\demotools folder of this repo.\n//\n// It uses an IHttpRequester interface to abstract HTTP requests so they can be\nmocked\n// during testing.\nfunc RunPresigningScenario(ctx context.Context, sdkConfig aws.Config, questioner\ndemotools.IQuestioner, httpRequester IHttpRequester) {\ndefer func() {\nif r := recover(); r != nil {\nfmt.Printf(\"Something went wrong with the demo\")\n}\n}()\nScenarios API Version 2006-03-01 2299",
      "start_idx": 2506128,
      "end_idx": 2507749,
      "metadata": {
        "num_sentences": 20,
        "num_words": 278,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2305",
      "text": "Amazon Simple Storage Service API Reference\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Println(\"Welcome to the Amazon S3 presigning demo.\")\nlog.Println(strings.Repeat(\"-\", 88))\ns3Client := s3.NewFromConfig(sdkConfig)\nbucketBasics := actions.BucketBasics{S3Client: s3Client}\npresignClient := s3.NewPresignClient(s3Client)\npresigner := actions.Presigner{PresignClient: presignClient}\nbucketName := questioner.Ask(\"We'll need a bucket. Enter a name for a bucket \"+\n\"you own or one you want to create:\", demotools.NotEmpty{})\nbucketExists, err := bucketBasics.BucketExists(ctx, bucketName)\nif err != nil {\npanic(err)\n}\nif !bucketExists {\nerr = bucketBasics.CreateBucket(ctx, bucketName, sdkConfig.Region)\nif err != nil {\npanic(err)\n} else {\nlog.Println(\"Bucket created.\")\n}\n}\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Printf(\"Let's presign a request to upload a file to your bucket.\")\nuploadFilename := questioner.Ask(\"Enter the path to a file you want to upload:\",\ndemotools.NotEmpty{})\nuploadKey := questioner.Ask(\"What would you like to name the uploaded object?\",\ndemotools.NotEmpty{})\nuploadFile, err := os.Open(uploadFilename)\nif err != nil {\npanic(err)\n}\ndefer uploadFile.Close()\npresignedPutRequest, err := presigner.PutObject(ctx, bucketName, uploadKey, 60)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"Got a presigned %v request to URL:\\n\\t%v\\n\",\npresignedPutRequest.Method,\npresignedPutRequest.URL)\nlog.Println(\"Using net/http to send the request...\")\nScenarios API Version 2006-03-01 2300",
      "start_idx": 2507751,
      "end_idx": 2509240,
      "metadata": {
        "num_sentences": 6,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2306",
      "text": "Amazon Simple Storage Service API Reference\ninfo, err := uploadFile.Stat()\nif err != nil {\npanic(err)\n}\nputResponse, err := httpRequester.Put(presignedPutRequest.URL, info.Size(),\nuploadFile)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"%v object %v with presigned URL returned %v.\",\npresignedPutRequest.Method,\nuploadKey, putResponse.StatusCode)\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Printf(\"Let's presign a request to download the object.\")\nquestioner.Ask(\"Press Enter when you're ready.\")\npresignedGetRequest, err := presigner.GetObject(ctx, bucketName, uploadKey, 60)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"Got a presigned %v request to URL:\\n\\t%v\\n\",\npresignedGetRequest.Method,\npresignedGetRequest.URL)\nlog.Println(\"Using net/http to send the request...\")\ngetResponse, err := httpRequester.Get(presignedGetRequest.URL)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"%v object %v with presigned URL returned %v.\",\npresignedGetRequest.Method,\nuploadKey, getResponse.StatusCode)\ndefer getResponse.Body.Close()\ndownloadBody, err := io.ReadAll(getResponse.Body)\nif err != nil {\npanic(err)\n}\nlog.Printf(\"Downloaded %v bytes. Here are the first 100 of them:\\n\",\nlen(downloadBody))\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Println(string(downloadBody[:100]))\nlog.Println(strings.Repeat(\"-\", 88))\nlog.Println(\"Now we'll create a new request to put the same object using a\npresigned post request\")\nScenarios API Version 2006-03-01 2301",
      "start_idx": 2509242,
      "end_idx": 2510668,
      "metadata": {
        "num_sentences": 6,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2309",
      "text": "Amazon Simple Storage Service API Reference\nfunc (httpReq HttpRequester) Delete(url string) (resp *http.Response, err error)\n{\ndelRequest, err := http.NewRequest(\"DELETE\", url, nil)\nif err != nil {\nreturn nil, err\n}\nreturn http.DefaultClient.Do(delRequest)\n}\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGenerate a pre-signed URL for an object, then download it (GET request).\nImports.\nimport com.example.s3.util.PresignUrlUtils;\nimport org.slf4j.Logger;\nimport software.amazon.awssdk.http.HttpExecuteRequest;\nimport software.amazon.awssdk.http.HttpExecuteResponse;\nimport software.amazon.awssdk.http.SdkHttpClient;\nimport software.amazon.awssdk.http.SdkHttpMethod;\nimport software.amazon.awssdk.http.SdkHttpRequest;\nimport software.amazon.awssdk.http.apache.ApacheHttpClient;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.GetObjectRequest;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport software.amazon.awssdk.services.s3.presigner.S3Presigner;\nimport\nsoftware.amazon.awssdk.services.s3.presigner.model.GetObjectPresignRequest;\nimport\nsoftware.amazon.awssdk.services.s3.presigner.model.PresignedGetObjectRequest;\nimport software.amazon.awssdk.utils.IoUtils;\nScenarios API Version 2006-03-01 2304",
      "start_idx": 2513546,
      "end_idx": 2514918,
      "metadata": {
        "num_sentences": 5,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2311",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\nDownload the object by using any one of the following three approaches.\nUse JDK HttpURLConnection (since v1.1) class to do the download.\n/* Use the JDK HttpURLConnection (since v1.1) class to do the download. */\npublic byte[] useHttpUrlConnectionToGet(String presignedUrlString) {\nByteArrayOutputStream byteArrayOutputStream = new\nByteArrayOutputStream(); // Capture the response body to a byte array.\ntry {\nURL presignedUrl = new URL(presignedUrlString);\nHttpURLConnection connection = (HttpURLConnection)\npresignedUrl.openConnection();\nconnection.setRequestMethod(\"GET\");\n// Download the result of executing the request.\ntry (InputStream content = connection.getInputStream()) {\nIoUtils.copy(content, byteArrayOutputStream);\n}\nlogger.info(\"HTTP response code is \" + connection.getResponseCode());\n} catch (S3Exception | IOException e) {\nlogger.error(e.getMessage(), e);\n}\nreturn byteArrayOutputStream.toByteArray();\n}\nUse JDK HttpClient (since v11) class to do the download.\n/* Use the JDK HttpClient (since v11) class to do the download. */\npublic byte[] useHttpClientToGet(String presignedUrlString) {\nByteArrayOutputStream byteArrayOutputStream = new\nByteArrayOutputStream(); // Capture the response body to a byte array.\nHttpRequest.Builder requestBuilder = HttpRequest.newBuilder();\nHttpClient httpClient = HttpClient.newHttpClient();\ntry {\nURL presignedUrl = new URL(presignedUrlString);\nHttpResponse<InputStream> response = httpClient.send(requestBuilder\nScenarios API Version 2006-03-01 2306",
      "start_idx": 2516201,
      "end_idx": 2517750,
      "metadata": {
        "num_sentences": 9,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2312",
      "text": "Amazon Simple Storage Service API Reference\n.uri(presignedUrl.toURI())\n.GET()\n.build(),\nHttpResponse.BodyHandlers.ofInputStream());\nIoUtils.copy(response.body(), byteArrayOutputStream);\nlogger.info(\"HTTP response code is \" + response.statusCode());\n} catch (URISyntaxException | InterruptedException | IOException e) {\nlogger.error(e.getMessage(), e);\n}\nreturn byteArrayOutputStream.toByteArray();\n}\nUse the AWS SDK for Java SdkHttpClient class to do the download.\n/* Use the AWS SDK for Java SdkHttpClient class to do the download. */\npublic byte[] useSdkHttpClientToPut(String presignedUrlString) {\nByteArrayOutputStream byteArrayOutputStream = new\nByteArrayOutputStream(); // Capture the response body to a byte array.\ntry {\nURL presignedUrl = new URL(presignedUrlString);\nSdkHttpRequest request = SdkHttpRequest.builder()\n.method(SdkHttpMethod.GET)\n.uri(presignedUrl.toURI())\n.build();\nHttpExecuteRequest executeRequest = HttpExecuteRequest.builder()\n.request(request)\n.build();\ntry (SdkHttpClient sdkHttpClient = ApacheHttpClient.create()) {\nHttpExecuteResponse response =\nsdkHttpClient.prepareRequest(executeRequest).call();\nresponse.responseBody().ifPresentOrElse(\nabortableInputStream -> {\ntry {\nIoUtils.copy(abortableInputStream,\nbyteArrayOutputStream);\n} catch (IOException e) {\nScenarios API Version 2006-03-01 2307",
      "start_idx": 2517752,
      "end_idx": 2519078,
      "metadata": {
        "num_sentences": 4,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2315",
      "text": "Amazon Simple Storage Service API Reference\nUpload a file object by using any one of the following three approaches.\nUse the JDK HttpURLConnection (since v1.1) class to do the upload.\n/* Use the JDK HttpURLConnection (since v1.1) class to do the upload. */\npublic void useHttpUrlConnectionToPut(String presignedUrlString, File\nfileToPut, Map<String, String> metadata) {\nlogger.info(\"Begin [{}] upload\", fileToPut.toString());\ntry {\nURL presignedUrl = new URL(presignedUrlString);\nHttpURLConnection connection = (HttpURLConnection)\npresignedUrl.openConnection();\nconnection.setDoOutput(true);\nmetadata.forEach((k, v) -> connection.setRequestProperty(\"x-amz-\nmeta-\" + k, v));\nconnection.setRequestMethod(\"PUT\");\nOutputStream out = connection.getOutputStream();\ntry (RandomAccessFile file = new RandomAccessFile(fileToPut, \"r\");\nFileChannel inChannel = file.getChannel()) {\nByteBuffer buffer = ByteBuffer.allocate(8192); //Buffer size is\n8k\nwhile (inChannel.read(buffer) > 0) {\nbuffer.flip();\nfor (int i = 0; i < buffer.limit(); i++) {\nout.write(buffer.get());\n}\nbuffer.clear();\n}\n} catch (IOException e) {\nlogger.error(e.getMessage(), e);\n}\nout.close();\nconnection.getResponseCode();\nlogger.info(\"HTTP response code is \" + connection.getResponseCode());\n} catch (S3Exception | IOException e) {\nlogger.error(e.getMessage(), e);\n}\n}\nScenarios API Version 2006-03-01 2310",
      "start_idx": 2521877,
      "end_idx": 2523243,
      "metadata": {
        "num_sentences": 4,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2316",
      "text": "Amazon Simple Storage Service API Reference\nUse the JDK HttpClient (since v11) class to do the upload.\n/* Use the JDK HttpClient (since v11) class to do the upload. */\npublic void useHttpClientToPut(String presignedUrlString, File fileToPut,\nMap<String, String> metadata) {\nlogger.info(\"Begin [{}] upload\", fileToPut.toString());\nHttpRequest.Builder requestBuilder = HttpRequest.newBuilder();\nmetadata.forEach((k, v) -> requestBuilder.header(\"x-amz-meta-\" + k, v));\nHttpClient httpClient = HttpClient.newHttpClient();\ntry {\nfinal HttpResponse<Void> response = httpClient.send(requestBuilder\n.uri(new URL(presignedUrlString).toURI())\n.PUT(HttpRequest.BodyPublishers.ofFile(Path.of(fileToPut.toURI())))\n.build(),\nHttpResponse.BodyHandlers.discarding());\nlogger.info(\"HTTP response code is \" + response.statusCode());\n} catch (URISyntaxException | InterruptedException | IOException e) {\nlogger.error(e.getMessage(), e);\n}\n}\nUse the AWS for Java V2 SdkHttpClient class to do the upload.\n/* Use the AWS SDK for Java V2 SdkHttpClient class to do the upload. */\npublic void useSdkHttpClientToPut(String presignedUrlString, File fileToPut,\nMap<String, String> metadata) {\nlogger.info(\"Begin [{}] upload\", fileToPut.toString());\ntry {\nURL presignedUrl = new URL(presignedUrlString);\nSdkHttpRequest.Builder requestBuilder = SdkHttpRequest.builder()\n.method(SdkHttpMethod.PUT)\n.uri(presignedUrl.toURI());\n// Add headers\nScenarios API Version 2006-03-01 2311",
      "start_idx": 2523245,
      "end_idx": 2524692,
      "metadata": {
        "num_sentences": 5,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2317",
      "text": "Amazon Simple Storage Service API Reference\nmetadata.forEach((k, v) -> requestBuilder.putHeader(\"x-amz-meta-\" +\nk, v));\n// Finish building the request.\nSdkHttpRequest request = requestBuilder.build();\nHttpExecuteRequest executeRequest = HttpExecuteRequest.builder()\n.request(request)\n.contentStreamProvider(new\nFileContentStreamProvider(fileToPut.toPath()))\n.build();\ntry (SdkHttpClient sdkHttpClient = ApacheHttpClient.create()) {\nHttpExecuteResponse response =\nsdkHttpClient.prepareRequest(executeRequest).call();\nlogger.info(\"Response code: {}\",\nresponse.httpResponse().statusCode());\n}\n} catch (URISyntaxException | IOException e) {\nlogger.error(e.getMessage(), e);\n}\n}\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate a presigned URL to upload an object to a bucket.\nimport https from \"node:https\";\nimport { XMLParser } from \"fast-xml-parser\";\nimport { PutObjectCommand, S3Client } from \"@aws-sdk/client-s3\";\nimport { fromIni } from \"@aws-sdk/credential-providers\";\nimport { HttpRequest } from \"@smithy/protocol-http\";\nimport {\nScenarios API Version 2006-03-01 2312",
      "start_idx": 2524694,
      "end_idx": 2525881,
      "metadata": {
        "num_sentences": 5,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2319",
      "text": "Amazon Simple Storage Service API Reference\nconst parser = new XMLParser();\nif (res.statusCode >= 200 && res.statusCode <= 299) {\nresolve(parser.parse(responseBody, true));\n} else {\nreject(parser.parse(responseBody, true));\n}\n});\n},\n);\nreq.on(\"error\", (err) => {\nreject(err);\n});\nreq.write(data);\nreq.end();\n});\n};\n/**\n* Create two presigned urls for uploading an object to an S3 bucket.\n* The first presigned URL is created with credentials from the shared INI file\n* in the current environment. The second presigned URL is created using an\n* existing S3Client instance that has already been provided with credentials.\n* @param {{ bucketName: string, key: string, region: string }}\n*/\nexport const main = async ({ bucketName, key, region }) => {\ntry {\nconst noClientUrl = await createPresignedUrlWithoutClient({\nbucket: bucketName,\nkey,\nregion,\n});\nconst clientUrl = await createPresignedUrlWithClient({\nbucket: bucketName,\nregion,\nkey,\n});\n// After you get the presigned URL, you can provide your own file\n// data. Refer to put() above.\nconsole.log(\"Calling PUT using presigned URL without client\");\nawait put(noClientUrl, \"Hello World\");\nconsole.log(\"Calling PUT using presigned URL with client\");\nScenarios API Version 2006-03-01 2314",
      "start_idx": 2527207,
      "end_idx": 2528445,
      "metadata": {
        "num_sentences": 6,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2320",
      "text": "Amazon Simple Storage Service API Reference\nawait put(clientUrl, \"Hello World\");\nconsole.log(\"\\nDone. Check your S3 console.\");\n} catch (caught) {\nif (caught instanceof Error && caught.name === \"CredentialsProviderError\") {\nconsole.error(\n`There was an error getting your credentials. Are your local credentials\nconfigured?\\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\nCreate a presigned URL to download an object from a bucket.\nimport { GetObjectCommand, S3Client } from \"@aws-sdk/client-s3\";\nimport { fromIni } from \"@aws-sdk/credential-providers\";\nimport { HttpRequest } from \"@smithy/protocol-http\";\nimport {\ngetSignedUrl,\nS3RequestPresigner,\n} from \"@aws-sdk/s3-request-presigner\";\nimport { parseUrl } from \"@smithy/url-parser\";\nimport { formatUrl } from \"@aws-sdk/util-format-url\";\nimport { Hash } from \"@smithy/hash-node\";\nconst createPresignedUrlWithoutClient = async ({ region, bucket, key }) => {\nconst url = parseUrl(`https://${bucket}.s3.${region}.amazonaws.com/${key}`);\nconst presigner = new S3RequestPresigner({\ncredentials: fromIni(),\nregion,\nsha256: Hash.bind(null, \"sha256\"),\n});\nconst signedUrlObject = await presigner.presign(new HttpRequest(url));\nreturn formatUrl(signedUrlObject);\n};\nconst createPresignedUrlWithClient = ({ region, bucket, key }) => {\nconst client = new S3Client({ region });\nScenarios API Version 2006-03-01 2315",
      "start_idx": 2528447,
      "end_idx": 2529825,
      "metadata": {
        "num_sentences": 5,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2321",
      "text": "Amazon Simple Storage Service API Reference\nconst command = new GetObjectCommand({ Bucket: bucket, Key: key });\nreturn getSignedUrl(client, command, { expiresIn: 3600 });\n};\n/**\n* Create two presigned urls for downloading an object from an S3 bucket.\n* The first presigned URL is created with credentials from the shared INI file\n* in the current environment. The second presigned URL is created using an\n* existing S3Client instance that has already been provided with credentials.\n* @param {{ bucketName: string, key: string, region: string }}\n*/\nexport const main = async ({ bucketName, key, region }) => {\ntry {\nconst noClientUrl = await createPresignedUrlWithoutClient({\nbucket: bucketName,\nregion,\nkey,\n});\nconst clientUrl = await createPresignedUrlWithClient({\nbucket: bucketName,\nregion,\nkey,\n});\nconsole.log(\"Presigned URL without client\");\nconsole.log(noClientUrl);\nconsole.log(\"\\n\");\nconsole.log(\"Presigned URL with client\");\nconsole.log(clientUrl);\n} catch (caught) {\nif (caught instanceof Error && caught.name === \"CredentialsProviderError\") {\nconsole.error(\n`There was an error getting your credentials. Are your local credentials\nconfigured?\\n${caught.name}: ${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n};\nScenarios API Version 2006-03-01 2316",
      "start_idx": 2529827,
      "end_idx": 2531091,
      "metadata": {
        "num_sentences": 5,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2322",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For more information, see AWS SDK for JavaScript Developer Guide.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate a GetObject presigned request and use the URL to download an object.\nsuspend fun getObjectPresigned(\ns3: S3Client,\nbucketName: String,\nkeyName: String,\n): String {\n// Create a GetObjectRequest.\nval unsignedRequest =\nGetObjectRequest {\nbucket = bucketName\nkey = keyName\n}\n// Presign the GetObject request.\nval presignedRequest = s3.presignGetObject(unsignedRequest, 24.hours)\n// Use the URL from the presigned HttpRequest in a subsequent HTTP GET\nrequest to retrieve the object.\nval objectContents = URL(presignedRequest.url.toString()).readText()\nreturn objectContents\n}\nCreate a GetObject presigned request with advanced options.\nsuspend fun getObjectPresignedMoreOptions(\ns3: S3Client,\nScenarios API Version 2006-03-01 2317",
      "start_idx": 2531093,
      "end_idx": 2532083,
      "metadata": {
        "num_sentences": 9,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2324",
      "text": "Amazon Simple Storage Service API Reference\n// Create a PUT request using the OKHttpClient API.\nval putRequest =\nRequest\n.Builder()\n.url(presignedRequest.url.toString())\n.apply {\npresignedRequest.headers.forEach { key, values ->\nheader(key, values.joinToString(\", \"))\n}\n}.put(content.toRequestBody())\n.build()\nval response = OkHttpClient().newCall(putRequest).execute()\nassert(response.isSuccessful)\n}\n\u2022 For more information, see AWS SDK for Kotlin developer guide.\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nnamespace S3;\nuse Aws\\Exception\\AwsException;\nuse AwsUtilities\\PrintableLineBreak;\nuse AwsUtilities\\TestableReadline;\nuse DateTime;\nrequire 'vendor/autoload.php';\nclass PresignedURL\n{\nuse PrintableLineBreak;\nuse TestableReadline;\nScenarios API Version 2006-03-01 2319",
      "start_idx": 2533239,
      "end_idx": 2534112,
      "metadata": {
        "num_sentences": 5,
        "num_words": 102,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2326",
      "text": "Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nGenerate a presigned URL that can perform an S3 action for a limited time. Use the\nRequests package to make a request with the URL.\nimport argparse\nimport logging\nimport boto3\nfrom botocore.exceptions import ClientError\nimport requests\nlogger = logging.getLogger(__name__)\ndef generate_presigned_url(s3_client, client_method, method_parameters,\nexpires_in):\n\"\"\"\nGenerate a presigned Amazon S3 URL that can be used to perform an action.\n:param s3_client: A Boto3 Amazon S3 client.\n:param client_method: The name of the client method that the URL performs.\n:param method_parameters: The parameters of the specified client method.\n:param expires_in: The number of seconds the presigned URL is valid for.\n:return: The presigned URL.\n\"\"\"\ntry:\nurl = s3_client.generate_presigned_url(\nClientMethod=client_method, Params=method_parameters,\nExpiresIn=expires_in\n)\nlogger.info(\"Got presigned URL: %s\", url)\nexcept ClientError:\nlogger.exception(\n\"Couldn't get a presigned URL for client method '%s'.\", client_method\nScenarios API Version 2006-03-01 2321",
      "start_idx": 2535120,
      "end_idx": 2536360,
      "metadata": {
        "num_sentences": 12,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2327",
      "text": "Amazon Simple Storage Service API Reference\n)\nraise\nreturn url\ndef usage_demo():\nlogging.basicConfig(level=logging.INFO, format=\"%(levelname)s: %(message)s\")\nprint(\"-\" * 88)\nprint(\"Welcome to the Amazon S3 presigned URL demo.\")\nprint(\"-\" * 88)\nparser = argparse.ArgumentParser()\nparser.add_argument(\"bucket\", help=\"The name of the bucket.\")\nparser.add_argument(\n\"key\",\nhelp=\"For a GET operation, the key of the object in Amazon S3. For a \"\n\"PUT operation, the name of a file to upload.\",\n)\nparser.add_argument(\"action\", choices=(\"get\", \"put\"), help=\"The action to\nperform.\")\nargs = parser.parse_args()\ns3_client = boto3.client(\"s3\")\nclient_action = \"get_object\" if args.action == \"get\" else \"put_object\"\nurl = generate_presigned_url(\ns3_client, client_action, {\"Bucket\": args.bucket, \"Key\": args.key}, 1000\n)\nprint(\"Using the Requests package to send a request to the URL.\")\nresponse = None\nif args.action == \"get\":\nresponse = requests.get(url)\nif response.status_code == 200:\nwith open(args.key.split(\"/\")[-1], 'wb') as object_file:\nobject_file.write(response.content)\nelif args.action == \"put\":\nprint(\"Putting data to the URL.\")\ntry:\nwith open(args.key, \"rb\") as object_file:\nobject_text = object_file.read()\nresponse = requests.put(url, data=object_text)\nexcept FileNotFoundError:\nprint(\nScenarios API Version 2006-03-01 2322",
      "start_idx": 2536362,
      "end_idx": 2537690,
      "metadata": {
        "num_sentences": 8,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2328",
      "text": "Amazon Simple Storage Service API Reference\nf\"Couldn't find {args.key}. For a PUT operation, the key must be\nthe \"\nf\"name of a file that exists on your computer.\"\n)\nif response is not None:\nprint(f\"Status: {response.status_code}\\nReason: {response.reason}\")\nprint(\"-\" * 88)\nif __name__ == \"__main__\":\nusage_demo()\nGenerate a presigned POST request to upload a file.\nclass BucketWrapper:\n\"\"\"Encapsulates S3 bucket actions.\"\"\"\ndef __init__(self, bucket):\n\"\"\"\n:param bucket: A Boto3 Bucket resource. This is a high-level resource in\nBoto3\nthat wraps bucket actions in a class-like structure.\n\"\"\"\nself.bucket = bucket\nself.name = bucket.name\ndef generate_presigned_post(self, object_key, expires_in):\n\"\"\"\nGenerate a presigned Amazon S3 POST request to upload a file.\nA presigned POST can be used for a limited time to let someone without an\nAWS\naccount upload a file to a bucket.\n:param object_key: The object key to identify the uploaded object.\n:param expires_in: The number of seconds the presigned POST is valid.\n:return: A dictionary that contains the URL and form fields that contain\nrequired access data.\n\"\"\"\ntry:\nScenarios API Version 2006-03-01 2323",
      "start_idx": 2537692,
      "end_idx": 2538846,
      "metadata": {
        "num_sentences": 12,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2329",
      "text": "Amazon Simple Storage Service API Reference\nresponse = self.bucket.meta.client.generate_presigned_post(\nBucket=self.bucket.name, Key=object_key, ExpiresIn=expires_in\n)\nlogger.info(\"Got presigned POST URL: %s\", response[\"url\"])\nexcept ClientError:\nlogger.exception(\n\"Couldn't get a presigned POST URL for bucket '%s' and object\n'%s'\",\nself.bucket.name,\nobject_key,\n)\nraise\nreturn response\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nrequire 'aws-sdk-s3'\nrequire 'net/http'\n# Creates a presigned URL that can be used to upload content to an object.\n#\n# @param bucket [Aws::S3::Bucket] An existing Amazon S3 bucket.\n# @param object_key [String] The key to give the uploaded object.\n# @return [URI, nil] The parsed URI if successful; otherwise nil.\ndef get_presigned_url(bucket, object_key)\nurl = bucket.object(object_key).presigned_url(:put)\nputs \"Created presigned URL: #{url}\"\nURI(url)\nrescue Aws::Errors::ServiceError => e\nScenarios API Version 2006-03-01 2324",
      "start_idx": 2538848,
      "end_idx": 2539906,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2330",
      "text": "Amazon Simple Storage Service API Reference\nputs \"Couldn't create presigned URL for #{bucket.name}:#{object_key}. Here's\nwhy: #{e.message}\"\nend\n# Example usage:\ndef run_demo\n<<<<<<< HEAD\nbucket_name = \"amzn-s3-demo-bucket\"\nobject_key = \"my-file.txt\"\nobject_content = \"This is the content of my-file.txt.\"\n=======\nbucket_name = 'doc-example-bucket'\nobject_key = 'my-file.txt'\nobject_content = 'This is the content of my-file.txt.'\n>>>>>>> 999c6133e (fixes)\nbucket = Aws::S3::Bucket.new(bucket_name)\npresigned_url = get_presigned_url(bucket, object_key)\nreturn unless presigned_url\nresponse = Net::HTTP.start(presigned_url.host) do |http|\nhttp.send_request('PUT', presigned_url.request_uri, object_content,\n'content_type' => '')\nend\ncase response\nwhen Net::HTTPSuccess\nputs 'Content uploaded!'\nelse\nputs response.value\nend\nend\nrun_demo if $PROGRAM_NAME == __FILE__\nScenarios API Version 2006-03-01 2325",
      "start_idx": 2539908,
      "end_idx": 2540808,
      "metadata": {
        "num_sentences": 5,
        "num_words": 100,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2331",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate presigning requests to GET S3 objects.\n/// Generate a URL for a presigned GET request.\nasync fn get_object(\nclient: &Client,\nbucket: &str,\nobject: &str,\nexpires_in: u64,\n) -> Result<(), Box<dyn Error>> {\nlet expires_in = Duration::from_secs(expires_in);\nlet presigned_request = client\n.get_object()\n.bucket(bucket)\n.key(object)\n.presigned(PresigningConfig::expires_in(expires_in)?)\n.await?;\nprintln!(\"Object URI: {}\", presigned_request.uri());\nlet valid_until = chrono::offset::Local::now() + expires_in;\nprintln!(\"Valid until: {valid_until}\");\nOk(())\n}\nCreate presigning requests to PUT S3 objects.\nasync fn put_object(\nclient: &Client,\nbucket: &str,\nobject: &str,\nexpires_in: u64,\nScenarios API Version 2006-03-01 2326",
      "start_idx": 2540810,
      "end_idx": 2541723,
      "metadata": {
        "num_sentences": 10,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2332",
      "text": "Amazon Simple Storage Service API Reference\n) -> Result<String, S3ExampleError> {\nlet expires_in: std::time::Duration =\nstd::time::Duration::from_secs(expires_in);\nlet expires_in: aws_sdk_s3::presigning::PresigningConfig =\nPresigningConfig::expires_in(expires_in).map_err(|err| {\nS3ExampleError::new(format!(\n\"Failed to convert expiration to PresigningConfig: {err:?}\"\n))\n})?;\nlet presigned_request = client\n.put_object()\n.bucket(bucket)\n.key(object)\n.presigned(expires_in)\n.await?;\nOk(presigned_request.uri().into())\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nCreate a photo asset management application that lets users manage photos\nusing labels\nThe following code examples show how to create a serverless application that lets users manage\nphotos using labels.\n.NET\nAWS SDK for .NET\nShows how to develop a photo asset management application that detects labels in images\nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\nScenarios API Version 2006-03-01 2327",
      "start_idx": 2541725,
      "end_idx": 2543053,
      "metadata": {
        "num_sentences": 11,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2336",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nShows how to develop a photo asset management application that detects labels in images\nusing Amazon Rekognition and stores them for later retrieval.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nFor a deep dive into the origin of this example see the post on AWS Community.\nServices used in this example\n\u2022 API Gateway\n\u2022 DynamoDB\n\u2022 Lambda\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\n\u2022 Amazon SNS\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nA web page that lists Amazon S3 objects using an AWS SDK\nThe following code example shows how to list Amazon S3 objects in a web page.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nScenarios API Version 2006-03-01 2331",
      "start_idx": 2545720,
      "end_idx": 2546769,
      "metadata": {
        "num_sentences": 9,
        "num_words": 184,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2337",
      "text": "Amazon Simple Storage Service API Reference\nThe following code is the relevant React component that makes calls to the AWS SDK.\nA runnable version of the application containing this component can be found at the\npreceding GitHub link.\nimport { useEffect, useState } from \"react\";\nimport {\nListObjectsCommand,\ntype ListObjectsCommandOutput,\nS3Client,\n} from \"@aws-sdk/client-s3\";\nimport { fromCognitoIdentityPool } from \"@aws-sdk/credential-providers\";\nimport \"./App.css\";\nfunction App() {\nconst [objects, setObjects] = useState<\nRequired<ListObjectsCommandOutput>[\"Contents\"]\n>([]);\nuseEffect(() => {\nconst client = new S3Client({\nregion: \"us-east-1\",\n// Unless you have a public bucket, you'll need access to a private bucket.\n// One way to do this is to create an Amazon Cognito identity pool, attach\na role to the pool,\n// and grant the role access to the 's3:GetObject' action.\n//\n// You'll also need to configure the CORS settings on the bucket to allow\ntraffic from\n// this example site. Here's an example configuration that allows all\norigins. Don't\n// do this in production.\n//[\n// {\n// \"AllowedHeaders\": [\"*\"],\n// \"AllowedMethods\": [\"GET\"],\n// \"AllowedOrigins\": [\"*\"],\n// \"ExposeHeaders\": [],\n// },\n//]\n//\ncredentials: fromCognitoIdentityPool({\nclientConfig: { region: \"us-east-1\" },\nidentityPoolId: \"<YOUR_IDENTITY_POOL_ID>\",\nScenarios API Version 2006-03-01 2332",
      "start_idx": 2546771,
      "end_idx": 2548144,
      "metadata": {
        "num_sentences": 8,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2338",
      "text": "Amazon Simple Storage Service API Reference\n}),\n});\nconst command = new ListObjectsCommand({ Bucket: \"bucket-name\" });\nclient.send(command).then(({ Contents }) => setObjects(Contents || []));\n}, []);\nreturn (\n<div className=\"App\">\n{objects.map((o) => (\n<div key={o.ETag}>{o.Key}</div>\n))}\n</div>\n);\n}\nexport default App;\n\u2022 For API details, see ListObjects in AWS SDK for JavaScript API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nCreate an Amazon Textract explorer application\nThe following code examples show how to explore Amazon Textract output through an interactive\napplication.\nJavaScript\nSDK for JavaScript (v3)\nShows how to use the AWS SDK for JavaScript to build a React application that uses Amazon\nTextract to extract data from a document image and display it in an interactive web page.\nThis example runs in a web browser and requires an authenticated Amazon Cognito identity\nfor credentials. It uses Amazon Simple Storage Service (Amazon S3) for storage, and\nfor notifications it polls an Amazon Simple Queue Service (Amazon SQS) queue that is\nsubscribed to an Amazon Simple Notification Service (Amazon SNS) topic.\nScenarios API Version 2006-03-01 2333",
      "start_idx": 2548146,
      "end_idx": 2549496,
      "metadata": {
        "num_sentences": 8,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2339",
      "text": "Amazon Simple Storage Service API Reference\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Cognito Identity\n\u2022 Amazon S3\n\u2022 Amazon SNS\n\u2022 Amazon SQS\n\u2022 Amazon Textract\nPython\nSDK for Python (Boto3)\nShows how to use the AWS SDK for Python (Boto3) with Amazon Textract to detect text,\nform, and table elements in a document image. The input image and Amazon Textract\noutput are shown in a Tkinter application that lets you explore the detected elements.\n\u2022 Submit a document image to Amazon Textract and explore the output of detected\nelements.\n\u2022 Submit images directly to Amazon Textract or through an Amazon Simple Storage Service\n(Amazon S3) bucket.\n\u2022 Use asynchronous APIs to start a job that publishes a notification to an Amazon Simple\nNotification Service (Amazon SNS) topic when the job completes.\n\u2022 Poll an Amazon Simple Queue Service (Amazon SQS) queue for a job completion message\nand display the results.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon S3\n\u2022 Amazon SNS\n\u2022 Amazon SQS\n\u2022 Amazon Textract\nScenarios API Version 2006-03-01 2334",
      "start_idx": 2549498,
      "end_idx": 2550723,
      "metadata": {
        "num_sentences": 9,
        "num_words": 212,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2340",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDelete all objects in a given Amazon S3 bucket using an AWS SDK.\nThe following code example shows how to delete all of the objects in an Amazon S3 bucket.\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nDelete all objects for a given Amazon S3 bucket.\nimport {\nDeleteObjectsCommand,\npaginateListObjectsV2,\nS3Client,\n} from \"@aws-sdk/client-s3\";\n/**\n*\n* @param {{ bucketName: string }} config\n*/\nexport const main = async ({ bucketName }) => {\nconst client = new S3Client({});\ntry {\nconsole.log(`Deleting all objects in bucket: ${bucketName}`);\nconst paginator = paginateListObjectsV2(\n{ client },\n{\nBucket: bucketName,\n},\n);\nScenarios API Version 2006-03-01 2335",
      "start_idx": 2550725,
      "end_idx": 2551759,
      "metadata": {
        "num_sentences": 8,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2341",
      "text": "Amazon Simple Storage Service API Reference\nconst objectKeys = [];\nfor await (const { Contents } of paginator) {\nobjectKeys.push(...Contents.map((obj) => ({ Key: obj.Key })));\n}\nconst deleteCommand = new DeleteObjectsCommand({\nBucket: bucketName,\nDelete: { Objects: objectKeys },\n});\nawait client.send(deleteCommand);\nconsole.log(`All objects deleted from bucket: ${bucketName}`);\n} catch (caught) {\nif (caught instanceof Error) {\nconsole.error(\n`Failed to empty ${bucketName}. ${caught.name}: ${caught.message}`,\n);\n}\n}\n};\n// Call function if run directly.\nimport { fileURLToPath } from \"node:url\";\nimport { parseArgs } from \"node:util\";\nif (process.argv[1] === fileURLToPath(import.meta.url)) {\nconst options = {\nbucketName: {\ntype: \"string\",\n},\n};\nconst { values } = parseArgs({ options });\nmain(values);\n}\n\u2022 For API details, see the following topics in AWS SDK for JavaScript API Reference.\n\u2022 DeleteObjects\n\u2022 ListObjectsV2\nScenarios API Version 2006-03-01 2336",
      "start_idx": 2551761,
      "end_idx": 2552725,
      "metadata": {
        "num_sentences": 4,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2342",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDelete incomplete multipart uploads to Amazon S3 using an AWS SDK\nThe following code example shows how to how to delete or stop incomplete Amazon S3 multipart\nuploads.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTo stop multipart uploads that are in-progress or incomplete for any reason, you can get a\nlist uploads and then delete them as shown in the following example.\n/**\n* Aborts all incomplete multipart uploads from the specified S3 bucket.\n* <p>\n* This method retrieves a list of all incomplete multipart uploads in the\nspecified S3 bucket,\n* and then aborts each of those uploads.\n*/\npublic static void abortIncompleteMultipartUploadsFromList() {\nListMultipartUploadsRequest listMultipartUploadsRequest =\nListMultipartUploadsRequest.builder()\n.bucket(bucketName)\n.build();\nListMultipartUploadsResponse response =\ns3Client.listMultipartUploads(listMultipartUploadsRequest);\nList<MultipartUpload> uploads = response.uploads();\nAbortMultipartUploadRequest abortMultipartUploadRequest;\nfor (MultipartUpload upload : uploads) {\nabortMultipartUploadRequest = AbortMultipartUploadRequest.builder()\nScenarios API Version 2006-03-01 2337",
      "start_idx": 2552727,
      "end_idx": 2554227,
      "metadata": {
        "num_sentences": 9,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2344",
      "text": "Amazon Simple Storage Service API Reference\nAbortMultipartUploadResponse abortMultipartUploadResponse =\ns3Client.abortMultipartUpload(abortMultipartUploadRequest);\nif\n(abortMultipartUploadResponse.sdkHttpResponse().isSuccessful()) {\nlogger.info(\"Upload ID [{}] to bucket [{}] successfully\naborted.\", upload.uploadId(), bucketName);\n}\n}\n}\n}\nIf you have access to the upload ID after you begin a multipart upload, you can delete the in-\nprogress upload by using the ID.\nstatic void abortMultipartUploadUsingUploadId() {\nString uploadId = startUploadReturningUploadId();\nAbortMultipartUploadResponse response = s3Client.abortMultipartUpload(b -\n> b\n.uploadId(uploadId)\n.bucket(bucketName)\n.key(key));\nif (response.sdkHttpResponse().isSuccessful()) {\nlogger.info(\"Upload ID [{}] to bucket [{}] successfully aborted.\",\nuploadId, bucketName);\n}\n}\nTo consistently delete incomplete multipart uploads older that a certain number of days,\nset up a bucket lifecycle configuration for the bucket. The following example shows how to\ncreate a rule to delete incomplete uploads older than 7 days.\nstatic void abortMultipartUploadsUsingLifecycleConfig() {\nCollection<LifecycleRule> lifeCycleRules =\nList.of(LifecycleRule.builder()\n.abortIncompleteMultipartUpload(b -> b.\ndaysAfterInitiation(7))\n.status(\"Enabled\")\n.filter(SdkBuilder::build) // Filter element is required.\n.build());\nScenarios API Version 2006-03-01 2339",
      "start_idx": 2555695,
      "end_idx": 2557100,
      "metadata": {
        "num_sentences": 7,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2345",
      "text": "Amazon Simple Storage Service API Reference\n// If the action is successful, the service sends back an HTTP 200\nresponse with an empty HTTP body.\nPutBucketLifecycleConfigurationResponse response =\ns3Client.putBucketLifecycleConfiguration(b -> b\n.bucket(bucketName)\n.lifecycleConfiguration(b1 -> b1.rules(lifeCycleRules)));\nif (response.sdkHttpResponse().isSuccessful()) {\nlogger.info(\"Rule to abort incomplete multipart uploads added to\nbucket.\");\n} else {\nlogger.error(\"Unsuccessfully applied rule. HTTP status code is [{}]\",\nresponse.sdkHttpResponse().statusCode());\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022 AbortMultipartUpload\n\u2022 ListMultipartUploads\n\u2022 PutBucketLifecycleConfiguration\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDetect PPE in images with Amazon Rekognition using an AWS SDK\nThe following code example shows how to build an app that uses Amazon Rekognition to detect\nPersonal Protective Equipment (PPE) in images.\nJava\nSDK for Java 2.x\nShows how to create an AWS Lambda function that detects images with Personal Protective\nEquipment.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nScenarios API Version 2006-03-01 2340",
      "start_idx": 2557102,
      "end_idx": 2558513,
      "metadata": {
        "num_sentences": 10,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2346",
      "text": "Amazon Simple Storage Service API Reference\nServices used in this example\n\u2022 DynamoDB\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\n\u2022 Amazon SES\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDetect entities in text extracted from an image using an AWS SDK\nThe following code example shows how to use Amazon Comprehend to detect entities in text\nextracted by Amazon Textract from an image that is stored in Amazon S3.\nPython\nSDK for Python (Boto3)\nShows how to use the AWS SDK for Python (Boto3) in a Jupyter notebook to detect entities\nin text that is extracted from an image. This example uses Amazon Textract to extract\ntext from an image stored in Amazon Simple Storage Service (Amazon S3) and Amazon\nComprehend to detect entities in the extracted text.\nThis example is a Jupyter notebook and must be run in an environment that can host\nnotebooks. For instructions on how to run the example using Amazon SageMaker, see the\ndirections in TextractAndComprehendNotebook.ipynb.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Comprehend\n\u2022 Amazon S3\n\u2022 Amazon Textract\nScenarios API Version 2006-03-01 2341",
      "start_idx": 2558515,
      "end_idx": 2559866,
      "metadata": {
        "num_sentences": 9,
        "num_words": 227,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2347",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDetect faces in an image using an AWS SDK\nThe following code example shows how to:\n\u2022 Save an image in an Amazon S3 bucket.\n\u2022 Use Amazon Rekognition to detect facial details, such as age range, gender, and emotion (such as\nsmiling).\n\u2022 Display those details.\nRust\nSDK for Rust\nSave the image in an Amazon S3 bucket with an uploads prefix, use Amazon Rekognition\nto detect facial details, such as age range, gender, and emotion (smiling, etc.), and display\nthose details.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDetect objects in images with Amazon Rekognition using an AWS SDK\nThe following code examples show how to build an app that uses Amazon Rekognition to detect\nobjects by category in images.\nScenarios API Version 2006-03-01 2342",
      "start_idx": 2559868,
      "end_idx": 2561204,
      "metadata": {
        "num_sentences": 12,
        "num_words": 226,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2348",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nShows how to use Amazon Rekognition .NET API to create an app that uses Amazon\nRekognition to identify objects by category in images located in an Amazon Simple Storage\nService (Amazon S3) bucket. The app sends the admin an email notification with the results\nusing Amazon Simple Email Service (Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\n\u2022 Amazon SES\nJava\nSDK for Java 2.x\nShows how to use Amazon Rekognition Java API to create an app that uses Amazon\nRekognition to identify objects by category in images located in an Amazon Simple Storage\nService (Amazon S3) bucket. The app sends the admin an email notification with the results\nusing Amazon Simple Email Service (Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\n\u2022 Amazon SES\nScenarios API Version 2006-03-01 2343",
      "start_idx": 2561206,
      "end_idx": 2562299,
      "metadata": {
        "num_sentences": 7,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2349",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nShows how to use Amazon Rekognition with the AWS SDK for JavaScript to create an app\nthat uses Amazon Rekognition to identify objects by category in images located in an\nAmazon Simple Storage Service (Amazon S3) bucket. The app sends the admin an email\nnotification with the results using Amazon Simple Email Service (Amazon SES).\nLearn how to:\n\u2022 Create an unauthenticated user using Amazon Cognito.\n\u2022 Analyze images for objects using Amazon Rekognition.\n\u2022 Verify an email address for Amazon SES.\n\u2022 Send an email notification using Amazon SES.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\n\u2022 Amazon SES\nKotlin\nSDK for Kotlin\nShows how to use Amazon Rekognition Kotlin API to create an app that uses Amazon\nRekognition to identify objects by category in images located in an Amazon Simple Storage\nService (Amazon S3) bucket. The app sends the admin an email notification with the results\nusing Amazon Simple Email Service (Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\nScenarios API Version 2006-03-01 2344",
      "start_idx": 2562301,
      "end_idx": 2563620,
      "metadata": {
        "num_sentences": 11,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2350",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Amazon S3\n\u2022 Amazon SES\nPython\nSDK for Python (Boto3)\nShows you how to use the AWS SDK for Python (Boto3) to create a web application that lets\nyou do the following:\n\u2022 Upload photos to an Amazon Simple Storage Service (Amazon S3) bucket.\n\u2022 Use Amazon Rekognition to analyze and label the photos.\n\u2022 Use Amazon Simple Email Service (Amazon SES) to send email reports of image analysis.\nThis example contains two main components: a webpage written in JavaScript that is built\nwith React, and a REST service written in Python that is built with Flask-RESTful.\nYou can use the React webpage to:\n\u2022 Display a list of images that are stored in your S3 bucket.\n\u2022 Upload images from your computer to your S3 bucket.\n\u2022 Display images and labels that identify items that are detected in the image.\n\u2022 Get a report of all images in your S3 bucket and send an email of the report.\nThe webpage calls the REST service. The service sends requests to AWS to perform the\nfollowing actions:\n\u2022 Get and filter the list of images in your S3 bucket.\n\u2022 Upload photos to your S3 bucket.\n\u2022 Use Amazon Rekognition to analyze individual photos and get a list of labels that identify\nitems that are detected in the photo.\n\u2022 Analyze all photos in your S3 bucket and use Amazon SES to email a report.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\nScenarios API Version 2006-03-01 2345",
      "start_idx": 2563622,
      "end_idx": 2565123,
      "metadata": {
        "num_sentences": 15,
        "num_words": 273,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2351",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Amazon S3\n\u2022 Amazon SES\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDetect people and objects in a video with Amazon Rekognition using an AWS SDK\nThe following code examples show how to detect people and objects in a video with Amazon\nRekognition.\nJava\nSDK for Java 2.x\nShows how to use Amazon Rekognition Java API to create an app to detect faces and\nobjects in videos located in an Amazon Simple Storage Service (Amazon S3) bucket. The app\nsends the admin an email notification with the results using Amazon Simple Email Service\n(Amazon SES).\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\n\u2022 Amazon SES\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nDownload all objects in an Amazon Simple Storage Service (Amazon S3) bucket to\na local directory\nThe following code example shows how to download all objects in an Amazon Simple Storage\nService (Amazon S3) bucket to a local directory.\nScenarios API Version 2006-03-01 2346",
      "start_idx": 2565125,
      "end_idx": 2566553,
      "metadata": {
        "num_sentences": 10,
        "num_words": 242,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2352",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUse an S3TransferManager to download all S3 objects in the same S3 bucket. View the\ncomplete file and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.services.s3.model.ObjectIdentifier;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedDirectoryDownload;\nimport software.amazon.awssdk.transfer.s3.model.DirectoryDownload;\nimport software.amazon.awssdk.transfer.s3.model.DownloadDirectoryRequest;\nimport java.io.IOException;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.nio.file.Files;\nimport java.nio.file.Path;\nimport java.nio.file.Paths;\nimport java.util.HashSet;\nimport java.util.Set;\nimport java.util.UUID;\nimport java.util.stream.Collectors;\npublic Integer downloadObjectsToDirectory(S3TransferManager transferManager,\nURI destinationPathURI, String bucketName) {\nDirectoryDownload directoryDownload =\ntransferManager.downloadDirectory(DownloadDirectoryRequest.builder()\n.destination(Paths.get(destinationPathURI))\n.bucket(bucketName)\n.build());\nCompletedDirectoryDownload completedDirectoryDownload =\ndirectoryDownload.completionFuture().join();\nScenarios API Version 2006-03-01 2347",
      "start_idx": 2566555,
      "end_idx": 2568024,
      "metadata": {
        "num_sentences": 5,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2353",
      "text": "Amazon Simple Storage Service API Reference\ncompletedDirectoryDownload.failedTransfers()\n.forEach(fail -> logger.warn(\"Object [{}] failed to transfer\",\nfail.toString()));\nreturn completedDirectoryDownload.failedTransfers().size();\n}\n\u2022 For API details, see DownloadDirectory in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nGet an Amazon S3 object from a Multi-Region Access Point by using an AWS SDK\nThe following code example shows how to get an object from a Multi-Region Access Point.\nKotlin\nSDK for Kotlin\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nConfigure the S3 client to use the Asymmetric Sigv4 (Sigv4a) signing algorithm.\nsuspend fun createS3Client(): S3Client {\n// Configure your S3Client to use the Asymmetric Sigv4 (Sigv4a)\nsigning algorithm.\nval sigV4AScheme = SigV4AsymmetricAuthScheme(CrtAwsSigner)\nval s3 = S3Client.fromEnvironment {\nauthSchemes = listOf(sigV4AScheme)\n}\nreturn s3\n}\nUse the Multi-Region Access Point ARN instead of a bucket name to retrieve the object.\nScenarios API Version 2006-03-01 2348",
      "start_idx": 2568026,
      "end_idx": 2569339,
      "metadata": {
        "num_sentences": 10,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2354",
      "text": "Amazon Simple Storage Service API Reference\nsuspend fun getObjectFromMrap(\ns3: S3Client,\nmrapArn: String,\nkeyName: String,\n): String? {\nval request = GetObjectRequest {\nbucket = mrapArn // Use the ARN instead of the bucket name for object\noperations.\nkey = keyName\n}\nvar stringObj: String? = null\ns3.getObject(request) { resp ->\nstringObj = resp.body?.decodeToString()\nif (stringObj != null) {\nprintln(\"Successfully read $keyName from $mrapArn\")\n}\n}\nreturn stringObj\n}\n\u2022 For more information, see AWS SDK for Kotlin developer guide.\n\u2022 For API details, see GetObject in AWS SDK for Kotlin API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nGet an object from an Amazon S3 bucket using an AWS SDK, specifying an If-\nModified-Since header\nThe following code example shows how to read data from an object in an S3 bucket, but only if\nthat bucket has not been modified since the last retrieval time.\nScenarios API Version 2006-03-01 2349",
      "start_idx": 2569341,
      "end_idx": 2570454,
      "metadata": {
        "num_sentences": 9,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2355",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nuse aws_sdk_s3::{\nerror::SdkError,\nprimitives::{ByteStream, DateTime, DateTimeFormat},\nClient,\n};\nuse s3_code_examples::error::S3ExampleError;\nuse tracing::{error, warn};\nconst KEY: &str = \"key\";\nconst BODY: &str = \"Hello, world!\";\n/// Demonstrate how `if-modified-since` reports that matching objects haven't\n/// changed.\n///\n/// # Steps\n/// - Create a bucket.\n/// - Put an object in the bucket.\n/// - Get the bucket headers.\n/// - Get the bucket headers again but only if modified.\n/// - Delete the bucket.\n#[tokio::main]\nasync fn main() -> Result<(), S3ExampleError> {\ntracing_subscriber::fmt::init();\n// Get a new UUID to use when creating a unique bucket name.\nlet uuid = uuid::Uuid::new_v4();\n// Load the AWS configuration from the environment.\nlet client = Client::new(&aws_config::load_from_env().await);\n// Generate a unique bucket name using the previously generated UUID.\n// Then create a new bucket with that name.\nScenarios API Version 2006-03-01 2350",
      "start_idx": 2570456,
      "end_idx": 2571606,
      "metadata": {
        "num_sentences": 14,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2356",
      "text": "Amazon Simple Storage Service API Reference\nlet bucket_name = format!(\"if-modified-since-{uuid}\");\nclient\n.create_bucket()\n.bucket(bucket_name.clone())\n.send()\n.await?;\n// Create a new object in the bucket whose name is `KEY` and whose\n// contents are `BODY`.\nlet put_object_output = client\n.put_object()\n.bucket(bucket_name.as_str())\n.key(KEY)\n.body(ByteStream::from_static(BODY.as_bytes()))\n.send()\n.await;\n// If the `PutObject` succeeded, get the eTag string from it. Otherwise,\n// report an error and return an empty string.\nlet e_tag_1 = match put_object_output {\nOk(put_object) => put_object.e_tag.unwrap(),\nErr(err) => {\nerror!(\"{err:?}\");\nString::new()\n}\n};\n// Request the object's headers.\nlet head_object_output = client\n.head_object()\n.bucket(bucket_name.as_str())\n.key(KEY)\n.send()\n.await;\n// If the `HeadObject` request succeeded, create a tuple containing the\n// values of the headers `last-modified` and `etag`. If the request\n// failed, return the error in a tuple instead.\nlet (last_modified, e_tag_2) = match head_object_output {\nOk(head_object) => (\nOk(head_object.last_modified().cloned().unwrap()),\nhead_object.e_tag.unwrap(),\n),\nErr(err) => (Err(err), String::new()),\nScenarios API Version 2006-03-01 2351",
      "start_idx": 2571608,
      "end_idx": 2572835,
      "metadata": {
        "num_sentences": 10,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2357",
      "text": "Amazon Simple Storage Service API Reference\n};\nwarn!(\"last modified: {last_modified:?}\");\nassert_eq!(\ne_tag_1, e_tag_2,\n\"PutObject and first GetObject had differing eTags\"\n);\nprintln!(\"First value of last_modified: {last_modified:?}\");\nprintln!(\"First tag: {}\\n\", e_tag_1);\n// Send a second `HeadObject` request. This time, the `if_modified_since`\n// option is specified, giving the `last_modified` value returned by the\n// first call to `HeadObject`.\n//\n// Since the object hasn't been changed, and there are no other objects in\n// the bucket, there should be no matching objects.\nlet head_object_output = client\n.head_object()\n.bucket(bucket_name.as_str())\n.key(KEY)\n.if_modified_since(last_modified.unwrap())\n.send()\n.await;\n// If the `HeadObject` request succeeded, the result is a typle containing\n// the `last_modified` and `e_tag_1` properties. This is _not_ the expected\n// result.\n//\n// The _expected_ result of the second call to `HeadObject` is an\n// `SdkError::ServiceError` containing the HTTP error response. If that's\n// the case and the HTTP status is 304 (not modified), the output is a\n// tuple containing the values of the HTTP `last-modified` and `etag`\n// headers.\n//\n// If any other HTTP error occurred, the error is returned as an\n// `SdkError::ServiceError`.\nlet (last_modified, e_tag_2) = match head_object_output {\nOk(head_object) => (\nOk(head_object.last_modified().cloned().unwrap()),\nhead_object.e_tag.unwrap(),\n),\nScenarios API Version 2006-03-01 2352",
      "start_idx": 2572837,
      "end_idx": 2574318,
      "metadata": {
        "num_sentences": 15,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2358",
      "text": "Amazon Simple Storage Service API Reference\nErr(err) => match err {\nSdkError::ServiceError(err) => {\n// Get the raw HTTP response. If its status is 304, the\n// object has not changed. This is the expected code path.\nlet http = err.raw();\nmatch http.status().as_u16() {\n// If the HTTP status is 304: Not Modified, return a\n// tuple containing the values of the HTTP\n// `last-modified` and `etag` headers.\n304 => (\nOk(DateTime::from_str(\nhttp.headers().get(\"last-modified\").unwrap(),\nDateTimeFormat::HttpDate,\n)\n.unwrap()),\nhttp.headers().get(\"etag\").map(|t| t.into()).unwrap(),\n),\n// Any other HTTP status code is returned as an\n// `SdkError::ServiceError`.\n_ => (Err(SdkError::ServiceError(err)), String::new()),\n}\n}\n// Any other kind of error is returned in a tuple containing the\n// error and an empty string.\n_ => (Err(err), String::new()),\n},\n};\nwarn!(\"last modified: {last_modified:?}\");\nassert_eq!(\ne_tag_1, e_tag_2,\n\"PutObject and second HeadObject had different eTags\"\n);\nprintln!(\"Second value of last modified: {last_modified:?}\");\nprintln!(\"Second tag: {}\", e_tag_2);\n// Clean up by deleting the object and the bucket.\nclient\n.delete_object()\n.bucket(bucket_name.as_str())\n.key(KEY)\n.send()\n.await?;\nScenarios API Version 2006-03-01 2353",
      "start_idx": 2574320,
      "end_idx": 2575568,
      "metadata": {
        "num_sentences": 15,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2359",
      "text": "Amazon Simple Storage Service API Reference\nclient\n.delete_bucket()\n.bucket(bucket_name.as_str())\n.send()\n.await?;\nOk(())\n}\n\u2022 For API details, see GetObject in AWS SDK for Rust API reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nGet started with encryption for Amazon S3 objects using an AWS SDK\nThe following code example shows how to get started with encryption for Amazon S3 objects.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.IO;\nusing System.Security.Cryptography;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to apply client encryption to an object in an\n/// Amazon Simple Storage Service (Amazon S3) bucket.\nScenarios API Version 2006-03-01 2354",
      "start_idx": 2575570,
      "end_idx": 2576598,
      "metadata": {
        "num_sentences": 9,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2365",
      "text": "Amazon Simple Storage Service API Reference\nCopySourceServerSideEncryptionCustomerProvidedKey = base64Key,\n// Information about the target object's encryption.\nServerSideEncryptionCustomerMethod =\nServerSideEncryptionCustomerMethod.AES256,\nServerSideEncryptionCustomerProvidedKey = copyBase64Key,\n};\nawait client.CopyObjectAsync(copyRequest);\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022 CopyObject\n\u2022 GetObject\n\u2022 GetObjectMetadata\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nGet started with tags for Amazon S3 objects using an AWS SDK\nThe following code example shows how to get started with tags for Amazon S3 objects.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nusing Amazon;\nScenarios API Version 2006-03-01 2360",
      "start_idx": 2583566,
      "end_idx": 2584675,
      "metadata": {
        "num_sentences": 8,
        "num_words": 151,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2366",
      "text": "Amazon Simple Storage Service API Reference\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to work with tags in Amazon Simple Storage\n/// Service (Amazon S3) objects.\n/// </summary>\npublic class ObjectTag\n{\npublic static async Task Main()\n{\nstring bucketName = \"amzn-s3-demo-bucket\";\nstring keyName = \"newobject.txt\";\nstring filePath = @\"*** file path ***\";\n// Specify your bucket region (an example region is shown).\nRegionEndpoint bucketRegion = RegionEndpoint.USWest2;\nvar client = new AmazonS3Client(bucketRegion);\nawait PutObjectsWithTagsAsync(client, bucketName, keyName, filePath);\n}\n/// <summary>\n/// This method uploads an object with tags. It then shows the tag\n/// values, changes the tags, and shows the new tags.\n/// </summary>\n/// <param name=\"client\">The Initialized Amazon S3 client object used\n/// to call the methods to create and change an objects tags.</param>\n/// <param name=\"bucketName\">A string representing the name of the\n/// bucket where the object will be stored.</param>\n/// <param name=\"keyName\">A string representing the key name of the\n/// object to be tagged.</param>\n/// <param name=\"filePath\">The directory location and file name of the\n/// object to be uploaded to the Amazon S3 bucket.</param>\npublic static async Task PutObjectsWithTagsAsync(IAmazonS3 client, string\nbucketName, string keyName, string filePath)\n{\ntry\n{\n// Create an object with tags.\nvar putRequest = new PutObjectRequest\n{\nBucketName = bucketName,\nKey = keyName,\nScenarios API Version 2006-03-01 2361",
      "start_idx": 2584677,
      "end_idx": 2586217,
      "metadata": {
        "num_sentences": 6,
        "num_words": 220,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2368",
      "text": "Amazon Simple Storage Service API Reference\nPutObjectTaggingResponse response2 = await\nclient.PutObjectTaggingAsync(putObjTagsRequest);\n// Retrieve the tags again and show the values.\nGetObjectTaggingRequest getTagsRequest2 = new\nGetObjectTaggingRequest()\n{\nBucketName = bucketName,\nKey = keyName,\n};\nGetObjectTaggingResponse objectTags2 = await\nclient.GetObjectTaggingAsync(getTagsRequest2);\nobjectTags2.Tagging\n.ForEach(t => Console.WriteLine($\"Key: {t.Key}, Value:\n{t.Value}\"));\n}\ncatch (AmazonS3Exception ex)\n{\nConsole.WriteLine(\n$\"Error: '{ex.Message}'\");\n}\n}\n}\n\u2022 For API details, see GetObjectTagging in AWS SDK for .NET API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nWork with Amazon S3 object lock features using an AWS SDK\nThe following code examples show how to work with S3 object lock features.\nScenarios API Version 2006-03-01 2363",
      "start_idx": 2587169,
      "end_idx": 2588198,
      "metadata": {
        "num_sentences": 6,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2369",
      "text": "Amazon Simple Storage Service API Reference\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object lock features.\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Microsoft.Extensions.Configuration;\nusing Microsoft.Extensions.DependencyInjection;\nusing Microsoft.Extensions.Hosting;\nusing Microsoft.Extensions.Logging;\nusing Microsoft.Extensions.Logging.Console;\nusing Microsoft.Extensions.Logging.Debug;\nnamespace S3ObjectLockScenario;\npublic static class S3ObjectLockWorkflow\n{\n/*\nBefore running this .NET code example, set up your development environment,\nincluding your credentials.\nThis .NET example performs the following tasks:\n1. Create test Amazon Simple Storage Service (S3) buckets with different\nlock policies.\n2. Upload sample objects to each bucket.\n3. Set some Legal Hold and Retention Periods on objects and buckets.\n4. Investigate lock policies by viewing settings or attempting to delete\nor overwrite objects.\n5. Clean up objects and buckets.\n*/\npublic static S3ActionsWrapper _s3ActionsWrapper = null!;\npublic static IConfiguration _configuration = null!;\nprivate static string _resourcePrefix = null!;\nScenarios API Version 2006-03-01 2364",
      "start_idx": 2588200,
      "end_idx": 2589506,
      "metadata": {
        "num_sentences": 18,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2380",
      "text": "Amazon Simple Storage Service API Reference\n/// </summary>\n/// <param name=\"question\">The question string to print on the console.</\nparam>\n/// <param name=\"choices\">The choices to print on the console.</param>\n/// <returns>The index of the selected choice</returns>\nprivate static int GetChoiceResponse(string? question, string[] choices)\n{\nif (question != null)\n{\nConsole.WriteLine(question);\nfor (int i = 0; i < choices.Length; i++)\n{\nConsole.WriteLine($\"\\t{i + 1}. {choices[i]}\");\n}\n}\nvar choiceNumber = 0;\nwhile (choiceNumber < 1 || choiceNumber > choices.Length)\n{\nvar choice = Console.ReadLine();\nInt32.TryParse(choice, out choiceNumber);\n}\nreturn choiceNumber - 1;\n}\n}\nA wrapper class for S3 functions.\nusing System.Net;\nusing Amazon.S3;\nusing Amazon.S3.Model;\nusing Microsoft.Extensions.Configuration;\nnamespace S3ObjectLockScenario;\n/// <summary>\n/// Encapsulate the Amazon S3 operations.\n/// </summary>\npublic class S3ActionsWrapper\nScenarios API Version 2006-03-01 2375",
      "start_idx": 2602282,
      "end_idx": 2603263,
      "metadata": {
        "num_sentences": 5,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2391",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 PutObjectRetention\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object lock features.\n// ObjectLockScenario contains the steps to run the S3 Object Lock workflow.\ntype ObjectLockScenario struct {\nquestioner demotools.IQuestioner\nresources Resources\ns3Actions *actions.S3Actions\nsdkConfig aws.Config\n}\n// NewObjectLockScenario constructs a new ObjectLockScenario instance.\nfunc NewObjectLockScenario(sdkConfig aws.Config, questioner\ndemotools.IQuestioner) ObjectLockScenario {\nscenario := ObjectLockScenario{\nquestioner: questioner,\nresources: Resources{},\ns3Actions: &actions.S3Actions{S3Client: s3.NewFromConfig(sdkConfig)},\nsdkConfig: sdkConfig,\n}\nscenario.s3Actions.S3Manager = manager.NewUploader(scenario.s3Actions.S3Client)\nscenario.resources.init(scenario.s3Actions, questioner)\nreturn scenario\n}\ntype nameLocked struct {\nname string\nlocked bool\n}\nScenarios API Version 2006-03-01 2386",
      "start_idx": 2615721,
      "end_idx": 2616807,
      "metadata": {
        "num_sentences": 6,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2392",
      "text": "Amazon Simple Storage Service API Reference\nvar createInfo = []nameLocked{\n{\"standard-bucket\", false},\n{\"lock-bucket\", true},\n{\"retention-bucket\", false},\n}\n// CreateBuckets creates the S3 buckets required for the workflow.\nfunc (scenario *ObjectLockScenario) CreateBuckets(ctx context.Context) {\nlog.Println(\"Let's create some S3 buckets to use for this workflow.\")\nsuccess := false\nfor !success {\nprefix := scenario.questioner.Ask(\n\"This example creates three buckets. Enter a prefix to name your buckets\n(remember bucket names must be globally unique):\")\nfor _, info := range createInfo {\nlog.Println(fmt.Sprintf(\"%s.%s\", prefix, info.name))\nbucketName, err := scenario.s3Actions.CreateBucketWithLock(ctx,\nfmt.Sprintf(\"%s.%s\", prefix, info.name), scenario.sdkConfig.Region, info.locked)\nif err != nil {\nswitch err.(type) {\ncase *types.BucketAlreadyExists, *types.BucketAlreadyOwnedByYou:\nlog.Printf(\"Couldn't create bucket %s.\\n\", bucketName)\ndefault:\npanic(err)\n}\nbreak\n}\nscenario.resources.demoBuckets[info.name] = &DemoBucket{\nname: bucketName,\nobjectKeys: []string{},\n}\nlog.Printf(\"Created bucket %s.\\n\", bucketName)\n}\nif len(scenario.resources.demoBuckets) < len(createInfo) {\nscenario.resources.deleteBuckets(ctx)\n} else {\nsuccess = true\n}\n}\nlog.Println(\"S3 buckets created.\")\nlog.Println(strings.Repeat(\"-\", 88))\nScenarios API Version 2006-03-01 2387",
      "start_idx": 2616809,
      "end_idx": 2618169,
      "metadata": {
        "num_sentences": 6,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2394",
      "text": "Amazon Simple Storage Service API Reference\n}\n} else {\nlog.Printf(\"Default retention policy set on bucket %s with %d day retention\nperiod.\", bucket.name, retentionPeriod)\nbucket.retentionEnabled = true\n}\nlog.Println(strings.Repeat(\"-\", 88))\n}\n// UploadTestObjects uploads test objects to the S3 buckets.\nfunc (scenario *ObjectLockScenario) UploadTestObjects(ctx context.Context) {\nlog.Println(\"Uploading test objects to S3 buckets.\")\nfor _, info := range createInfo {\nbucket := scenario.resources.demoBuckets[info.name]\nfor i := 0; i < 2; i++ {\nkey, err := scenario.s3Actions.UploadObject(ctx, bucket.name,\nfmt.Sprintf(\"example-%d\", i),\nfmt.Sprintf(\"Example object content #%d in bucket %s.\", i, bucket.name))\nif err != nil {\nswitch err.(type) {\ncase *types.NoSuchBucket:\nlog.Printf(\"Couldn't upload %s to bucket %s.\\n\", key, bucket.name)\ndefault:\npanic(err)\n}\n} else {\nlog.Printf(\"Uploaded %s to bucket %s.\\n\", key, bucket.name)\nbucket.objectKeys = append(bucket.objectKeys, key)\n}\n}\n}\nscenario.questioner.Ask(\"Test objects uploaded. Press Enter to continue.\")\nlog.Println(strings.Repeat(\"-\", 88))\n}\n// SetObjectLockConfigurations sets object lock configurations on the test\nobjects.\nfunc (scenario *ObjectLockScenario) SetObjectLockConfigurations(ctx\ncontext.Context) {\nlog.Println(\"Now let's set object lock configurations on individual objects.\")\nScenarios API Version 2006-03-01 2389",
      "start_idx": 2619701,
      "end_idx": 2621089,
      "metadata": {
        "num_sentences": 10,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2395",
      "text": "Amazon Simple Storage Service API Reference\nbuckets := []*DemoBucket{scenario.resources.demoBuckets[\"lock-bucket\"],\nscenario.resources.demoBuckets[\"retention-bucket\"]}\nfor _, bucket := range buckets {\nfor index, objKey := range bucket.objectKeys {\nswitch index {\ncase 0:\nif scenario.questioner.AskBool(fmt.Sprintf(\"\\nDo you want to add a legal hold\nto %s in %s (y/n)? \", objKey, bucket.name), \"y\") {\nerr := scenario.s3Actions.PutObjectLegalHold(ctx, bucket.name, objKey, \"\",\ntypes.ObjectLockLegalHoldStatusOn)\nif err != nil {\nswitch err.(type) {\ncase *types.NoSuchKey:\nlog.Printf(\"Couldn't set legal hold on %s.\\n\", objKey)\ndefault:\npanic(err)\n}\n} else {\nlog.Printf(\"Legal hold set on %s.\\n\", objKey)\n}\n}\ncase 1:\nq := fmt.Sprintf(\"\\nDo you want to add a 1 day Governance retention period to\n%s in %s?\\n\"+\n\"Reminder: Only a user with the s3:BypassGovernanceRetention permission is\nable to delete this object\\n\"+\n\"or its bucket until the retention period has expired. (y/n) \", objKey,\nbucket.name)\nif scenario.questioner.AskBool(q, \"y\") {\nerr := scenario.s3Actions.PutObjectRetention(ctx, bucket.name, objKey,\ntypes.ObjectLockRetentionModeGovernance, 1)\nif err != nil {\nswitch err.(type) {\ncase *types.NoSuchKey:\nlog.Printf(\"Couldn't set retention period on %s in %s.\\n\", objKey,\nbucket.name)\ndefault:\npanic(err)\n}\n} else {\nlog.Printf(\"Retention period set to 1 for %s.\", objKey)\nbucket.retentionEnabled = true\n}\n}\nScenarios API Version 2006-03-01 2390",
      "start_idx": 2621091,
      "end_idx": 2622541,
      "metadata": {
        "num_sentences": 6,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2413",
      "text": "Amazon Simple Storage Service API Reference\nlog.Println(\"Nothing to delete.\")\ndefault:\npanic(err)\n}\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for Go API Reference.\n\u2022 GetObjectLegalHold\n\u2022 GetObjectLockConfiguration\n\u2022 GetObjectRetention\n\u2022 PutObjectLegalHold\n\u2022 PutObjectLockConfiguration\n\u2022 PutObjectRetention\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object lock features.\nimport software.amazon.awssdk.services.s3.model.ObjectLockLegalHold;\nimport software.amazon.awssdk.services.s3.model.ObjectLockRetention;\nimport java.io.BufferedWriter;\nimport java.io.IOException;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Scanner;\nimport java.util.stream.Collectors;\n/*\nScenarios API Version 2006-03-01 2408",
      "start_idx": 2644043,
      "end_idx": 2644936,
      "metadata": {
        "num_sentences": 6,
        "num_words": 101,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2414",
      "text": "Amazon Simple Storage Service API Reference\nBefore running this Java V2 code example, set up your development\nenvironment, including your credentials.\nFor more information, see the following documentation topic:\nhttps://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html\nThis Java example performs the following tasks:\n1. Create test Amazon Simple Storage Service (S3) buckets with different lock\npolicies.\n2. Upload sample objects to each bucket.\n3. Set some Legal Hold and Retention Periods on objects and buckets.\n4. Investigate lock policies by viewing settings or attempting to delete or\noverwrite objects.\n5. Clean up objects and buckets.\n*/\npublic class S3ObjectLockWorkflow {\npublic static final String DASHES = new String(new char[80]).replace(\"\\0\",\n\"-\");\nstatic String bucketName;\nstatic S3LockActions s3LockActions;\nprivate static final List<String> bucketNames = new ArrayList<>();\nprivate static final List<String> fileNames = new ArrayList<>();\npublic static void main(String[] args) {\nfinal String usage = \"\"\"\nUsage:\n<bucketName> \\s\nWhere:\nbucketName - The Amazon S3 bucket name.\n\"\"\";\nif (args.length != 1) {\nSystem.out.println(usage);\nSystem.exit(1);\n}\ns3LockActions = new S3LockActions();\nbucketName = args[0];\nScanner scanner = new Scanner(System.in);\nSystem.out.println(DASHES);\nSystem.out.println(\"Welcome to the Amazon Simple Storage Service (S3)\nObject Locking Workflow Scenario.\");\nScenarios API Version 2006-03-01 2409",
      "start_idx": 2644938,
      "end_idx": 2646396,
      "metadata": {
        "num_sentences": 14,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2415",
      "text": "Amazon Simple Storage Service API Reference\nSystem.out.println(\"Press Enter to continue...\");\nscanner.nextLine();\nconfigurationSetup();\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nsetup();\nSystem.out.println(\"Setup is complete. Press Enter to continue...\");\nscanner.nextLine();\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"Lets present the user with choices.\");\nSystem.out.println(\"Press Enter to continue...\");\nscanner.nextLine();\ndemoActionChoices() ;\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"Would you like to clean up the resources? (y/n)\");\nString delAns = scanner.nextLine().trim();\nif (delAns.equalsIgnoreCase(\"y\")) {\ncleanup();\nSystem.out.println(\"Clean up is complete.\");\n}\nSystem.out.println(\"Press Enter to continue...\");\nscanner.nextLine();\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"Amazon S3 Object Locking Workflow is complete.\");\nSystem.out.println(DASHES);\n}\n// Present the user with the demo action choices.\npublic static void demoActionChoices() {\nString[] choices = {\n\"List all files in buckets.\",\n\"Attempt to delete a file.\",\n\"Attempt to delete a file with retention period bypass.\",\n\"Attempt to overwrite a file.\",\n\"View the object and bucket retention settings for a file.\",\n\"View the legal hold settings for a file.\",\nScenarios API Version 2006-03-01 2410",
      "start_idx": 2646398,
      "end_idx": 2647788,
      "metadata": {
        "num_sentences": 13,
        "num_words": 143,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2418",
      "text": "Amazon Simple Storage Service API Reference\nList<S3InfoObject> allFiles =\ns3LockActions.listBucketsAndObjects(bucketNames, true);\nList<String> fileKeys = allFiles.stream().map(f ->\nf.getKeyName()).collect(Collectors.toList());\nString[] fileKeysArray = fileKeys.toArray(new String[0]);\nint fileChoice = getChoiceResponse(null, fileKeysArray);\nString objectKey = fileKeys.get(fileChoice);\nString bucketName = allFiles.get(fileChoice).getBucketName();\ns3LockActions.getObjectLegalHold(bucketName, objectKey);\ns3LockActions.getBucketObjectLockConfiguration(bucketName);\n}\ncase 6 -> {\nSystem.out.println(\"Exiting the workflow...\");\nreturn;\n}\ndefault -> {\nSystem.out.println(\"Invalid choice. Please select again.\");\n}\n}\n}\n}\n// Clean up the resources from the scenario.\nprivate static void cleanup() {\nList<S3InfoObject> allFiles =\ns3LockActions.listBucketsAndObjects(bucketNames, false);\nfor (S3InfoObject fileInfo : allFiles) {\nString bucketName = fileInfo.getBucketName();\nString key = fileInfo.getKeyName();\nString version = fileInfo.getVersion();\nif (bucketName.contains(\"lock-enabled\") ||\n(bucketName.contains(\"retention-after-creation\"))) {\nObjectLockLegalHold legalHold =\ns3LockActions.getObjectLegalHold(bucketName, key);\nif (legalHold != null) {\nString holdStatus = legalHold.status().name();\nSystem.out.println(holdStatus);\nif (holdStatus.compareTo(\"ON\") == 0) {\ns3LockActions.modifyObjectLegalHold(bucketName, key,\nfalse);\n}\n}\nScenarios API Version 2006-03-01 2413",
      "start_idx": 2650935,
      "end_idx": 2652404,
      "metadata": {
        "num_sentences": 4,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2420",
      "text": "Amazon Simple Storage Service API Reference\nSystem.out.println(\"Bucket \"+bucketNames.get(2) +\" will be configured to\nuse object locking with a default retention period.\");\ns3LockActions.modifyBucketDefaultRetention(bucketNames.get(2));\nSystem.out.println(\"Press Enter to continue.\");\nscanner.nextLine();\nSystem.out.println(\"Object lock policies can also be added to existing\nbuckets. For this example, we will use \"+bucketNames.get(1));\ns3LockActions.enableObjectLockOnBucket(bucketNames.get(1));\nSystem.out.println(\"Press Enter to continue.\");\nscanner.nextLine();\n// Upload some files to the buckets.\nSystem.out.println(\"Now let's add some test files:\");\nString fileName = \"exampleFile.txt\";\nint fileCount = 2;\ntry (BufferedWriter writer = new BufferedWriter(new\njava.io.FileWriter(fileName))) {\nwriter.write(\"This is a sample file for uploading to a bucket.\");\n} catch (IOException e) {\ne.printStackTrace();\n}\nfor (String bucketName : bucketNames){\nfor (int i = 0; i < fileCount; i++) {\n// Get the file name without extension.\nString fileNameWithoutExtension =\njava.nio.file.Paths.get(fileName).getFileName().toString();\nint extensionIndex = fileNameWithoutExtension.lastIndexOf('.');\nif (extensionIndex > 0) {\nfileNameWithoutExtension =\nfileNameWithoutExtension.substring(0, extensionIndex);\n}\n// Create the numbered file names.\nString numberedFileName = fileNameWithoutExtension + i +\ngetFileExtension(fileName);\nfileNames.add(numberedFileName);\ns3LockActions.uploadFile(bucketName, numberedFileName, fileName);\n}\n}\nString question = null;\nScenarios API Version 2006-03-01 2415",
      "start_idx": 2653764,
      "end_idx": 2655345,
      "metadata": {
        "num_sentences": 10,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2422",
      "text": "Amazon Simple Storage Service API Reference\n}\n// Get file extension.\nprivate static String getFileExtension(String fileName) {\nint dotIndex = fileName.lastIndexOf('.');\nif (dotIndex > 0) {\nreturn fileName.substring(dotIndex);\n}\nreturn \"\";\n}\npublic static void configurationSetup() {\nString noLockBucketName = bucketName + \"-no-lock\";\nString lockEnabledBucketName = bucketName + \"-lock-enabled\";\nString retentionAfterCreationBucketName = bucketName + \"-retention-after-\ncreation\";\nbucketNames.add(noLockBucketName);\nbucketNames.add(lockEnabledBucketName);\nbucketNames.add(retentionAfterCreationBucketName);\n}\npublic static int getChoiceResponse(String question, String[] choices) {\nScanner scanner = new Scanner(System.in);\nif (question != null) {\nSystem.out.println(question);\nfor (int i = 0; i < choices.length; i++) {\nSystem.out.println(\"\\t\" + (i + 1) + \". \" + choices[i]);\n}\n}\nint choiceNumber = 0;\nwhile (choiceNumber < 1 || choiceNumber > choices.length) {\nString choice = scanner.nextLine();\ntry {\nchoiceNumber = Integer.parseInt(choice);\n} catch (NumberFormatException e) {\nSystem.out.println(\"Invalid choice. Please enter a valid\nnumber.\");\n}\n}\nreturn choiceNumber - 1;\n}\n}\nScenarios API Version 2006-03-01 2417",
      "start_idx": 2656711,
      "end_idx": 2657930,
      "metadata": {
        "num_sentences": 6,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2432",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nindex.js - Entrypoint for the workflow. This orchestrates all of the steps. Visit GitHub to see\nthe implementation details for Scenario, ScenarioInput, ScenarioOutput, and ScenarioAction.\nimport * as Scenarios from \"@aws-doc-sdk-examples/lib/scenario/index.js\";\nimport {\nexitOnFalse,\nloadState,\nsaveState,\n} from \"@aws-doc-sdk-examples/lib/scenario/steps-common.js\";\nimport { welcome, welcomeContinue } from \"./welcome.steps.js\";\nimport {\nconfirmCreateBuckets,\nconfirmPopulateBuckets,\nconfirmSetLegalHoldFileEnabled,\nconfirmSetLegalHoldFileRetention,\nconfirmSetRetentionPeriodFileEnabled,\nconfirmSetRetentionPeriodFileRetention,\nconfirmUpdateLockPolicy,\nconfirmUpdateRetention,\ncreateBuckets,\ncreateBucketsAction,\ngetBucketPrefix,\npopulateBuckets,\npopulateBucketsAction,\nsetLegalHoldFileEnabledAction,\nsetLegalHoldFileRetentionAction,\nsetRetentionPeriodFileEnabledAction,\nsetRetentionPeriodFileRetentionAction,\nupdateLockPolicy,\nupdateLockPolicyAction,\nupdateRetention,\nScenarios API Version 2006-03-01 2427",
      "start_idx": 2671117,
      "end_idx": 2672327,
      "metadata": {
        "num_sentences": 6,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2435",
      "text": "Amazon Simple Storage Service API Reference\n\"welcome\",\n\"Welcome to the Amazon Simple Storage Service (S3) Object Locking Workflow\nScenario. For this workflow, we will use the AWS SDK for JavaScript to create\nseveral S3 buckets and files to demonstrate working with S3 locking features.\",\n{ header: true },\n);\n/**\n* @param {Scenarios} scenarios\n*/\nconst welcomeContinue = (scenarios) =>\nnew scenarios.ScenarioInput(\n\"welcomeContinue\",\n\"Press Enter when you are ready to start.\",\n{ type: \"confirm\" },\n);\nexport { welcome, welcomeContinue };\nsetup.steps.js - Deploy buckets, objects, and file settings.\nimport {\nBucketVersioningStatus,\nChecksumAlgorithm,\nCreateBucketCommand,\nMFADeleteStatus,\nPutBucketVersioningCommand,\nPutObjectCommand,\nPutObjectLockConfigurationCommand,\nPutObjectLegalHoldCommand,\nPutObjectRetentionCommand,\nObjectLockLegalHoldStatus,\nObjectLockRetentionMode,\nGetBucketVersioningCommand,\nBucketAlreadyExists,\nBucketAlreadyOwnedByYou,\nS3ServiceException,\nwaitUntilBucketExists,\n} from \"@aws-sdk/client-s3\";\nimport { retry } from \"@aws-doc-sdk-examples/lib/utils/util-timers.js\";\nScenarios API Version 2006-03-01 2430",
      "start_idx": 2674945,
      "end_idx": 2676077,
      "metadata": {
        "num_sentences": 5,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2439",
      "text": "Amazon Simple Storage Service API Reference\nawait client.send(\nnew PutObjectCommand({\nBucket: state.lockEnabledBucketName,\nKey: \"file0.txt\",\nBody: \"Content\",\nChecksumAlgorithm: ChecksumAlgorithm.SHA256,\n}),\n);\nawait client.send(\nnew PutObjectCommand({\nBucket: state.lockEnabledBucketName,\nKey: \"file1.txt\",\nBody: \"Content\",\nChecksumAlgorithm: ChecksumAlgorithm.SHA256,\n}),\n);\nawait client.send(\nnew PutObjectCommand({\nBucket: state.retentionBucketName,\nKey: \"file0.txt\",\nBody: \"Content\",\nChecksumAlgorithm: ChecksumAlgorithm.SHA256,\n}),\n);\nawait client.send(\nnew PutObjectCommand({\nBucket: state.retentionBucketName,\nKey: \"file1.txt\",\nBody: \"Content\",\nChecksumAlgorithm: ChecksumAlgorithm.SHA256,\n}),\n);\n} catch (caught) {\nif (caught instanceof S3ServiceException) {\nconsole.error(\n`Error from S3 while uploading object. ${caught.name}:\n${caught.message}`,\n);\n} else {\nthrow caught;\n}\n}\n});\nScenarios API Version 2006-03-01 2434",
      "start_idx": 2679758,
      "end_idx": 2680686,
      "metadata": {
        "num_sentences": 2,
        "num_words": 94,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2455",
      "text": "Amazon Simple Storage Service API Reference\nBypassGovernanceRetention: true,\n}),\n);\n}\n} catch (err) {\nconsole.log(\n`Unable to fetch object lock retention for ${Key} in ${bucket}:\n'${err.message}'`,\n);\n}\nawait client.send(\nnew DeleteObjectCommand({\nBucket: bucket,\nKey,\nVersionId,\n}),\n);\n}\nawait client.send(new DeleteBucketCommand({ Bucket: bucket }));\nconsole.log(`Delete for ${bucket} complete.`);\n}\n});\nexport { confirmCleanup, cleanupAction };\n\u2022 For API details, see the following topics in AWS SDK for JavaScript API Reference.\n\u2022 GetObjectLegalHold\n\u2022 GetObjectLockConfiguration\n\u2022 GetObjectRetention\n\u2022 PutObjectLegalHold\n\u2022 PutObjectLockConfiguration\n\u2022 PutObjectRetention\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nScenarios API Version 2006-03-01 2450",
      "start_idx": 2697151,
      "end_idx": 2698080,
      "metadata": {
        "num_sentences": 4,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2456",
      "text": "Amazon Simple Storage Service API Reference\nManage access control lists (ACLs) for Amazon S3 buckets using an AWS SDK\nThe following code example shows how to manage access control lists (ACLs) for Amazon S3\nbuckets.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to manage Amazon Simple Storage Service\n/// (Amazon S3) access control lists (ACLs) to control Amazon S3 bucket\n/// access.\n/// </summary>\npublic class ManageACLs\n{\npublic static async Task Main()\n{\nstring bucketName = \"amzn-s3-demo-bucket1\";\nstring newBucketName = \"amzn-s3-demo-bucket2\";\nstring keyName = \"sample-object.txt\";\nstring emailAddress = \"someone@example.com\";\n// If the AWS Region where your bucket is located is different from\n// the Region defined for the default user, pass the Amazon S3\nbucket's\n// name to the client constructor. It should look like this:\n// RegionEndpoint bucketRegion = RegionEndpoint.USEast1;\nIAmazonS3 client = new AmazonS3Client();\nScenarios API Version 2006-03-01 2451",
      "start_idx": 2698082,
      "end_idx": 2699312,
      "metadata": {
        "num_sentences": 6,
        "num_words": 180,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2460",
      "text": "Amazon Simple Storage Service API Reference\n// Add a grant to reset the owner's full permission\n// (the previous clear statement removed all permissions).\nvar fullControlGrant = new S3Grant\n{\nGrantee = new S3Grantee { CanonicalUser = acl.Owner.Id },\n};\nacl.AddGrant(fullControlGrant.Grantee, S3Permission.FULL_CONTROL);\n// Specify email to identify grantee for granting permissions.\nvar grantUsingEmail = new S3Grant\n{\nGrantee = new S3Grantee { EmailAddress = emailAddress },\nPermission = S3Permission.WRITE_ACP,\n};\n// Specify log delivery group as grantee.\nvar grantLogDeliveryGroup = new S3Grant\n{\nGrantee = new S3Grantee { URI = \"http://acs.amazonaws.com/groups/\ns3/LogDelivery\" },\nPermission = S3Permission.WRITE,\n};\n// Create a new ACL.\nvar newAcl = new S3AccessControlList\n{\nGrants = new List<S3Grant> { grantUsingEmail,\ngrantLogDeliveryGroup },\nOwner = owner,\n};\n// Set the new ACL. We're throwing away the response here.\n_ = await client.PutACLAsync(new PutACLRequest\n{\nBucketName = bucketName,\nKey = keyName,\nAccessControlList = newAcl,\n});\n}\n}\nScenarios API Version 2006-03-01 2455",
      "start_idx": 2703606,
      "end_idx": 2704697,
      "metadata": {
        "num_sentences": 7,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2461",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022 GetBucketAcl\n\u2022 GetObjectAcl\n\u2022 PutBucketAcl\n\u2022 PutObjectAcl\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nManage versioned Amazon S3 objects in batches with a Lambda function using an\nAWS SDK\nThe following code example shows how to manage versioned S3 objects in batches with a Lambda\nfunction.\nPython\nSDK for Python (Boto3)\nShows how to manipulate Amazon Simple Storage Service (Amazon S3) versioned objects\nin batches by creating jobs that call AWS Lambda functions to perform processing. This\nexample creates a version-enabled bucket, uploads the stanzas from the poem You Are Old,\nFather William by Lewis Carroll, and uses Amazon S3 batch jobs to twist the poem in various\nways.\nLearn how to:\n\u2022 Create Lambda functions that operate on versioned objects.\n\u2022 Create a manifest of objects to update.\n\u2022 Create batch jobs that invoke Lambda functions to update objects.\n\u2022 Delete Lambda functions.\n\u2022 Empty and delete a versioned bucket.\nThis example is best viewed on GitHub. For complete source code and instructions on how to\nset up and run, see the full example on GitHub.\nScenarios API Version 2006-03-01 2456",
      "start_idx": 2704699,
      "end_idx": 2706103,
      "metadata": {
        "num_sentences": 14,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2462",
      "text": "Amazon Simple Storage Service API Reference\nServices used in this example\n\u2022 Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nParse Amazon S3 URIs using an AWS SDK\nThe following code example shows how to parse Amazon S3 URIs to extract important components\nlike the bucket name and object key.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nParse an Amazon S3 URI by using the S3Uri class.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.S3Uri;\nimport software.amazon.awssdk.services.s3.S3Utilities;\nimport java.net.URI;\nimport java.util.List;\nimport java.util.Map;\n/**\n*\n* @param s3Client - An S3Client through which you acquire an S3Uri\ninstance.\n* @param s3ObjectUrl - A complex URL (String) that is used to demonstrate\nS3Uri\nScenarios API Version 2006-03-01 2457",
      "start_idx": 2706105,
      "end_idx": 2707296,
      "metadata": {
        "num_sentences": 8,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2465",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nPerform a multipart copy of an Amazon S3 object using an AWS SDK\nThe following code example shows how to perform a multipart copy of an Amazon S3 object.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nusing System;\nusing System.Collections.Generic;\nusing System.Threading.Tasks;\nusing Amazon.S3;\nusing Amazon.S3.Model;\n/// <summary>\n/// This example shows how to perform a multi-part copy from one Amazon\n/// Simple Storage Service (Amazon S3) bucket to another.\n/// </summary>\npublic class MPUapiCopyObj\n{\nprivate const string SourceBucket = \"amzn-s3-demo-bucket1\";\nprivate const string TargetBucket = \"amzn-s3-demo-bucket2\";\nprivate const string SourceObjectKey = \"example.mov\";\nprivate const string TargetObjectKey = \"copied_video_file.mov\";\n/// <summary>\n/// This method starts the multi-part upload.\n/// </summary>\npublic static async Task Main()\nScenarios API Version 2006-03-01 2460",
      "start_idx": 2710303,
      "end_idx": 2711552,
      "metadata": {
        "num_sentences": 8,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2468",
      "text": "Amazon Simple Storage Service API Reference\n{\nConsole.WriteLine($\"Unknown encountered on server.\nMessage:'{e.Message}' when writing an object\");\n}\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for .NET API Reference.\n\u2022 CompleteMultipartUpload\n\u2022 CreateMultipartUpload\n\u2022 GetObjectMetadata\n\u2022 UploadPartCopy\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nPerform a multipart upload of an Amazon S3 object using an AWS SDK\nThe following code example shows how to perform a multipart upload to an Amazon S3 object.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nThe code examples use the following imports.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.core.sync.RequestBody;\nScenarios API Version 2006-03-01 2463",
      "start_idx": 2714000,
      "end_idx": 2715089,
      "metadata": {
        "num_sentences": 9,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2469",
      "text": "Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3.S3AsyncClient;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.CompletedMultipartUpload;\nimport software.amazon.awssdk.services.s3.model.CompletedPart;\nimport software.amazon.awssdk.services.s3.model.CreateMultipartUploadResponse;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport software.amazon.awssdk.services.s3.model.UploadPartRequest;\nimport software.amazon.awssdk.services.s3.model.UploadPartResponse;\nimport software.amazon.awssdk.services.s3.waiters.S3Waiter;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.FileUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadFileRequest;\nimport java.io.IOException;\nimport java.io.RandomAccessFile;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.ByteBuffer;\nimport java.nio.file.Paths;\nimport java.util.ArrayList;\nimport java.util.List;\nimport java.util.Objects;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\nUse the S3 Transfer Manager on top of the AWS CRT-based S3 client to transparently\nperform a multipart upload when the size of the content exceeds a threshold. The default\nthreshold size is 8 MB.\n/**\n* Uploads a file to an Amazon S3 bucket using the S3TransferManager.\n*\n* @param filePath the file path of the file to be uploaded\n*/\npublic void multipartUploadWithTransferManager(String filePath) {\nS3TransferManager transferManager = S3TransferManager.create();\nUploadFileRequest uploadFileRequest = UploadFileRequest.builder()\n.putObjectRequest(b -> b\n.bucket(bucketName)\n.key(key))\n.source(Paths.get(filePath))\n.build();\nScenarios API Version 2006-03-01 2464",
      "start_idx": 2715091,
      "end_idx": 2716892,
      "metadata": {
        "num_sentences": 4,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2472",
      "text": "Amazon Simple Storage Service API Reference\nCompletableFuture<PutObjectResponse> response = s3AsyncClient.putObject(b\n-> b\n.bucket(bucketName)\n.key(key),\nPaths.get(filePath));\nresponse.join();\nlogger.info(\"File uploaded in multiple 8 MiB parts using\nS3AsyncClient.\");\n}\n\u2022 For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022 CompleteMultipartUpload\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nReceive and process Amazon S3 event notifications by using an AWS SDK.\nThe following code example shows how to work with S3 event notifications in an object-oriented\nway.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nThis example show how to process S3 notification event by using Amazon SQS.\n/**\n* This method receives S3 event notifications by using an SqsAsyncClient.\nScenarios API Version 2006-03-01 2467",
      "start_idx": 2719267,
      "end_idx": 2720408,
      "metadata": {
        "num_sentences": 11,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2473",
      "text": "Amazon Simple Storage Service API Reference\n* After the client receives the messages it deserializes the JSON payload\nand logs them. It uses\n* the S3EventNotification class (part of the S3 event notification API for\nJava) to deserialize\n* the JSON payload and access the messages in an object-oriented way.\n*\n* @param queueUrl The URL of the AWS SQS queue that receives the S3 event\nnotifications.\n* @see <a href=\"https://sdk.amazonaws.com/java/api/latest/software/amazon/\nawssdk/eventnotifications/s3/model/package-summary.html\">S3EventNotification\nAPI</a>.\n* <p>\n* To use S3 event notification serialization/deserialization to objects, add\nthe following\n* dependency to your Maven pom.xml file.\n* <dependency>\n* <groupId>software.amazon.awssdk</groupId>\n* <artifactId>s3-event-notifications</artifactId>\n* <version><LATEST></version>\n* </dependency>\n* <p>\n* The S3 event notification API became available with version 2.25.11 of the\nJava SDK.\n* <p>\n* This example shows the use of the API with AWS SQS, but it can be used to\nprocess S3 event notifications\n* in AWS SNS or AWS Lambda as well.\n* <p>\n* Note: The S3EventNotification class does not work with messages routed\nthrough AWS EventBridge.\n*/\nstatic void processS3Events(String bucketName, String queueUrl, String\nqueueArn) {\ntry {\n// Configure the bucket to send Object Created and Object Tagging\nnotifications to an existing SQS queue.\ns3Client.putBucketNotificationConfiguration(b -> b\n.notificationConfiguration(ncb -> ncb\n.queueConfigurations(qcb -> qcb\n.events(Event.S3_OBJECT_CREATED,\nEvent.S3_OBJECT_TAGGING)\n.queueArn(queueArn)))\n.bucket(bucketName)\n).join();\nScenarios API Version 2006-03-01 2468",
      "start_idx": 2720410,
      "end_idx": 2722074,
      "metadata": {
        "num_sentences": 10,
        "num_words": 218,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2475",
      "text": "Amazon Simple Storage Service API Reference\nString eventName = record.getEventName();\nString key = record.getS3().getObject().getKey();\nlogger.info(record.toString());\nlogger.info(\"Event name is {} and key is {}\",\neventName, key);\n});\n}\n// Add logged messages to collection for batch deletion.\nmessagesToDelete.add(DeleteMessageBatchRequestEntry.builder()\n.id(message.messageId())\n.receiptHandle(message.receiptHandle())\n.build());\n});\n// Delete messages.\nif (!messagesToDelete.isEmpty()) {\nsqsClient.deleteMessageBatch(DeleteMessageBatchRequest.builder()\n.queueUrl(queueUrl)\n.entries(messagesToDelete)\n.build()\n).join();\n}\n} // End of while block.\n} catch (InterruptedException | ExecutionException e) {\nthrow new RuntimeException(e);\n}\n}\n\u2022 For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022 DeleteMessageBatch\n\u2022 GetQueueAttributes\n\u2022 PutBucketNotificationConfiguration\n\u2022 ReceiveMessage\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nScenarios API Version 2006-03-01 2470",
      "start_idx": 2723589,
      "end_idx": 2724762,
      "metadata": {
        "num_sentences": 7,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2476",
      "text": "Amazon Simple Storage Service API Reference\nSave EXIF and other image information using an AWS SDK\nThe following code example shows how to:\n\u2022 Get EXIF information from a a JPG, JPEG, or PNG file.\n\u2022 Upload the image file to an Amazon S3 bucket.\n\u2022 Use Amazon Rekognition to identify the three top attributes (labels) in the file.\n\u2022 Add the EXIF and label information to an Amazon DynamoDB table in the Region.\nRust\nSDK for Rust\nGet EXIF information from a JPG, JPEG, or PNG file, upload the image file to an Amazon\nS3 bucket, use Amazon Rekognition to identify the three top attributes (labels in Amazon\nRekognition) in the file, and add the EXIF and label information to a Amazon DynamoDB\ntable in the Region.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 DynamoDB\n\u2022 Amazon Rekognition\n\u2022 Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nSend S3 event notifications to Amazon EventBridge using an AWS SDK\nThe following code example shows how to enable a bucket to send S3 event notifications to\nEventBridge and route notifications to an Amazon SNS topic and Amazon SQS queue.\nScenarios API Version 2006-03-01 2471",
      "start_idx": 2724764,
      "end_idx": 2726139,
      "metadata": {
        "num_sentences": 10,
        "num_words": 240,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2477",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/** This method configures a bucket to send events to AWS EventBridge and\ncreates a rule\n* to route the S3 object created events to a topic and a queue.\n*\n* @param bucketName Name of existing bucket\n* @param topicArn ARN of existing topic to receive S3 event notifications\n* @param queueArn ARN of existing queue to receive S3 event notifications\n*\n* An AWS CloudFormation stack sets up the bucket, queue, topic before the\nmethod runs.\n*/\npublic static String setBucketNotificationToEventBridge(String bucketName,\nString topicArn, String queueArn) {\ntry {\n// Enable bucket to emit S3 Event notifications to EventBridge.\ns3Client.putBucketNotificationConfiguration(b -> b\n.bucket(bucketName)\n.notificationConfiguration(b1 -> b1\n.eventBridgeConfiguration(\nSdkBuilder::build)\n).build()).join();\n// Create an EventBridge rule to route Object Created notifications.\nPutRuleRequest putRuleRequest = PutRuleRequest.builder()\n.name(RULE_NAME)\n.eventPattern(\"\"\"\n{\n\"source\": [\"aws.s3\"],\n\"detail-type\": [\"Object Created\"],\n\"detail\": {\n\"bucket\": {\n\"name\": [\"%s\"]\nScenarios API Version 2006-03-01 2472",
      "start_idx": 2726141,
      "end_idx": 2727419,
      "metadata": {
        "num_sentences": 7,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2478",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\n}\n\"\"\".formatted(bucketName))\n.build();\n// Add the rule to the default event bus.\nPutRuleResponse putRuleResponse =\neventBridgeClient.putRule(putRuleRequest)\n.whenComplete((r, t) -> {\nif (t != null) {\nlogger.error(\"Error creating event bus rule: \" +\nt.getMessage(), t);\nthrow new RuntimeException(t.getCause().getMessage(),\nt);\n}\nlogger.info(\"Event bus rule creation request sent\nsuccessfully. ARN is: {}\", r.ruleArn());\n}).join();\n// Add the existing SNS topic and SQS queue as targets to the rule.\neventBridgeClient.putTargets(b -> b\n.eventBusName(\"default\")\n.rule(RULE_NAME)\n.targets(List.of (\nTarget.builder()\n.arn(queueArn)\n.id(\"Queue\")\n.build(),\nTarget.builder()\n.arn(topicArn)\n.id(\"Topic\")\n.build())\n)\n).join();\nreturn putRuleResponse.ruleArn();\n} catch (S3Exception e) {\nSystem.err.println(e.awsErrorDetails().errorMessage());\nSystem.exit(1);\n}\nreturn null;\n}\nScenarios API Version 2006-03-01 2473",
      "start_idx": 2727421,
      "end_idx": 2728373,
      "metadata": {
        "num_sentences": 4,
        "num_words": 108,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2479",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022 PutBucketNotificationConfiguration\n\u2022 PutRule\n\u2022 PutTargets\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nTrack an Amazon S3 object upload or download using an AWS SDK\nThe following code example shows how to track an Amazon S3 object upload or download.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nTrack the progress of a file upload.\npublic void trackUploadFile(S3TransferManager transferManager, String\nbucketName,\nString key, URI filePathURI) {\nUploadFileRequest uploadFileRequest = UploadFileRequest.builder()\n.putObjectRequest(b -> b.bucket(bucketName).key(key))\n.addTransferListener(LoggingTransferListener.create()) // Add\nlistener.\n.source(Paths.get(filePathURI))\n.build();\nFileUpload fileUpload = transferManager.uploadFile(uploadFileRequest);\nfileUpload.completionFuture().join();\n/*\nScenarios API Version 2006-03-01 2474",
      "start_idx": 2728375,
      "end_idx": 2729606,
      "metadata": {
        "num_sentences": 9,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2480",
      "text": "Amazon Simple Storage Service API Reference\nThe SDK provides a LoggingTransferListener implementation of the\nTransferListener interface.\nYou can also implement the interface to provide your own logic.\nConfigure log4J2 with settings such as the following.\n<Configuration status=\"WARN\">\n<Appenders>\n<Console name=\"AlignedConsoleAppender\"\ntarget=\"SYSTEM_OUT\">\n<PatternLayout pattern=\"%m%n\"/>\n</Console>\n</Appenders>\n<Loggers>\n<logger\nname=\"software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener\"\nlevel=\"INFO\" additivity=\"false\">\n<AppenderRef ref=\"AlignedConsoleAppender\"/>\n</logger>\n</Loggers>\n</Configuration>\nLog4J2 logs the progress. The following is example output for a 21.3\nMB file upload.\nTransfer initiated...\n| | 0.0%\n|==== | 21.1%\n|============ | 60.5%\n|====================| 100.0%\nTransfer complete!\n*/\n}\nTrack the progress of a file download.\npublic void trackDownloadFile(S3TransferManager transferManager, String\nbucketName,\nString key, String downloadedFileWithPath) {\nDownloadFileRequest downloadFileRequest = DownloadFileRequest.builder()\n.getObjectRequest(b -> b.bucket(bucketName).key(key))\n.addTransferListener(LoggingTransferListener.create()) // Add\nlistener.\nScenarios API Version 2006-03-01 2475",
      "start_idx": 2729608,
      "end_idx": 2730838,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2481",
      "text": "Amazon Simple Storage Service API Reference\n.destination(Paths.get(downloadedFileWithPath))\n.build();\nFileDownload downloadFile =\ntransferManager.downloadFile(downloadFileRequest);\nCompletedFileDownload downloadResult =\ndownloadFile.completionFuture().join();\n/*\nThe SDK provides a LoggingTransferListener implementation of the\nTransferListener interface.\nYou can also implement the interface to provide your own logic.\nConfigure log4J2 with settings such as the following.\n<Configuration status=\"WARN\">\n<Appenders>\n<Console name=\"AlignedConsoleAppender\"\ntarget=\"SYSTEM_OUT\">\n<PatternLayout pattern=\"%m%n\"/>\n</Console>\n</Appenders>\n<Loggers>\n<logger\nname=\"software.amazon.awssdk.transfer.s3.progress.LoggingTransferListener\"\nlevel=\"INFO\" additivity=\"false\">\n<AppenderRef ref=\"AlignedConsoleAppender\"/>\n</logger>\n</Loggers>\n</Configuration>\nLog4J2 logs the progress. The following is example output for a 21.3\nMB file download.\nTransfer initiated...\n|======= | 39.4%\n|=============== | 78.8%\n|====================| 100.0%\nTransfer complete!\n*/\n}\n\u2022 For API details, see the following topics in AWS SDK for Java 2.x API Reference.\nScenarios API Version 2006-03-01 2476",
      "start_idx": 2730840,
      "end_idx": 2732005,
      "metadata": {
        "num_sentences": 8,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2482",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 GetObject\n\u2022 PutObject\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nTransform data for your application with S3 Object Lambda\nThe following code example shows how to transform data for your application with S3 Object\nLambda.\n.NET\nAWS SDK for .NET\nShows how to add custom code to standard S3 GET requests to modify the requested object\nretrieved from S3 so that the object suit the needs of the requesting client or application.\nFor complete source code and instructions on how to set up and run, see the full example on\nGitHub.\nServices used in this example\n\u2022 Lambda\n\u2022 Amazon S3\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nExample approaches for unit and integration testing with an AWS SDK\nThe following code example shows how to examples for best-practice techniques when writing unit\nand integration tests using an AWS SDK.\nScenarios API Version 2006-03-01 2477",
      "start_idx": 2732007,
      "end_idx": 2733261,
      "metadata": {
        "num_sentences": 9,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2483",
      "text": "Amazon Simple Storage Service API Reference\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCargo.toml for testing examples.\n[package]\nname = \"testing-examples\"\nversion = \"0.1.0\"\nauthors = [\n\"John Disanti <jdisanti@amazon.com>\",\n\"Doug Schwartz <dougsch@amazon.com>\",\n]\nedition = \"2021\"\n[dependencies]\nasync-trait = \"0.1.51\"\naws-config = { version = \"1.0.1\", features = [\"behavior-version-latest\"] }\naws-credential-types = { version = \"1.0.1\", features = [ \"hardcoded-\ncredentials\", ] }\naws-sdk-s3 = { version = \"1.4.0\" }\naws-smithy-types = { version = \"1.0.1\" }\naws-smithy-runtime = { version = \"1.0.1\", features = [\"test-util\"] }\naws-smithy-runtime-api = { version = \"1.0.1\", features = [\"test-util\"] }\naws-types = { version = \"1.0.1\" }\nclap = { version = \"~4.4\", features = [\"derive\"] }\nhttp = \"0.2.9\"\nmockall = \"0.11.4\"\nserde_json = \"1\"\ntokio = { version = \"1.20.1\", features = [\"full\"] }\ntracing-subscriber = { version = \"0.3.15\", features = [\"env-filter\"] }\n[[bin]]\nname = \"main\"\npath = \"src/main.rs\"\nScenarios API Version 2006-03-01 2478",
      "start_idx": 2733263,
      "end_idx": 2734400,
      "metadata": {
        "num_sentences": 4,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2490",
      "text": "Amazon Simple Storage Service API Reference\n.unwrap(),\n);\nlet replay_client = StaticReplayClient::new(vec![page_1, page_2]);\nlet client: s3::Client = s3::Client::from_conf(\ns3::Config::builder()\n.behavior_version(BehaviorVersion::latest())\n.credentials_provider(make_s3_test_credentials())\n.region(s3::config::Region::new(\"us-east-1\"))\n.http_client(replay_client.clone())\n.build(),\n);\n// Run the code we want to test with it\nlet size = determine_prefix_file_size(client, \"test-bucket\", \"test-\nprefix\")\n.await\n.unwrap();\nassert_eq!(19, size);\nreplay_client.assert_requests_match(&[]);\n}\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nRecursively upload a local directory to an Amazon Simple Storage Service\n(Amazon S3) bucket\nThe following code example shows how to upload a local directory recursively to an Amazon\nSimple Storage Service (Amazon S3) bucket.\nScenarios API Version 2006-03-01 2485",
      "start_idx": 2740934,
      "end_idx": 2742001,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2491",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUse an S3TransferManager to upload a local directory. View the complete file and test.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.services.s3.model.ObjectIdentifier;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.CompletedDirectoryUpload;\nimport software.amazon.awssdk.transfer.s3.model.DirectoryUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadDirectoryRequest;\nimport java.net.URI;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.file.Paths;\nimport java.util.UUID;\npublic Integer uploadDirectory(S3TransferManager transferManager,\nURI sourceDirectory, String bucketName) {\nDirectoryUpload directoryUpload =\ntransferManager.uploadDirectory(UploadDirectoryRequest.builder()\n.source(Paths.get(sourceDirectory))\n.bucket(bucketName)\n.build());\nCompletedDirectoryUpload completedDirectoryUpload =\ndirectoryUpload.completionFuture().join();\ncompletedDirectoryUpload.failedTransfers()\n.forEach(fail -> logger.warn(\"Object [{}] failed to transfer\",\nfail.toString()));\nreturn completedDirectoryUpload.failedTransfers().size();\n}\nScenarios API Version 2006-03-01 2486",
      "start_idx": 2742003,
      "end_idx": 2743395,
      "metadata": {
        "num_sentences": 5,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2492",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 For API details, see UploadDirectory in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUpload or download large files to and from Amazon S3 using an AWS SDK\nThe following code examples show how to upload or download large files to and from Amazon S3.\nFor more information, see Uploading an object using multipart upload.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCall functions that transfer files to and from an S3 bucket using the Amazon S3\nTransferUtility.\nglobal using System.Text;\nglobal using Amazon.S3;\nglobal using Amazon.S3.Model;\nglobal using Amazon.S3.Transfer;\nglobal using TransferUtilityBasics;\n// This Amazon S3 client uses the default user credentials\n// defined for this computer.\nusing Microsoft.Extensions.Configuration;\nIAmazonS3 client = new AmazonS3Client();\nvar transferUtil = new TransferUtility(client);\nIConfiguration _configuration;\n_configuration = new ConfigurationBuilder()\nScenarios API Version 2006-03-01 2487",
      "start_idx": 2743397,
      "end_idx": 2744694,
      "metadata": {
        "num_sentences": 10,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2495",
      "text": "Amazon Simple Storage Service API Reference\nConsole.WriteLine();\nsuccess = await TransferMethods.DownloadS3DirectoryAsync(transferUtil,\nbucketName, s3Path, downloadPath);\nif (success)\n{\nConsole.WriteLine($\"Downloaded the files in {bucketName} to\n{downloadPath}.\");\nConsole.WriteLine($\"{downloadPath} now contains the following files:\");\nDisplayLocalFiles(downloadPath);\n}\nConsole.WriteLine(\"\\nThe TransferUtility Basics application has completed.\");\nPressEnter();\n// Displays the title for a section of the scenario.\nstatic void DisplayTitle(string titleText)\n{\nvar sepBar = new string('-', Console.WindowWidth);\nConsole.WriteLine(sepBar);\nConsole.WriteLine(CenterText(titleText));\nConsole.WriteLine(sepBar);\n}\n// Displays a description of the actions to be performed by the scenario.\nstatic void DisplayInstructions()\n{\nvar sepBar = new string('-', Console.WindowWidth);\nDisplayTitle(\"Amazon S3 Transfer Utility Basics\");\nConsole.WriteLine(\"This program shows how to use the Amazon S3 Transfer\nUtility.\");\nConsole.WriteLine(\"It performs the following actions:\");\nConsole.WriteLine(\"\\t1. Upload a single object to an S3 bucket.\");\nConsole.WriteLine(\"\\t2. Upload an entire directory from the local computer to\nan\\n\\t S3 bucket.\");\nConsole.WriteLine(\"\\t3. Download a single object from an S3 bucket.\");\nConsole.WriteLine(\"\\t4. Download the objects in an S3 bucket to a local\ndirectory.\");\nConsole.WriteLine($\"\\n{sepBar}\");\n}\n// Pauses the scenario.\nScenarios API Version 2006-03-01 2490",
      "start_idx": 2747593,
      "end_idx": 2749077,
      "metadata": {
        "num_sentences": 15,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2501",
      "text": "Amazon Simple Storage Service API Reference\nTransferUtility transferUtil,\nstring bucketName,\nstring s3Path,\nstring localPath)\n{\nint fileCount = 0;\n// If the directory doesn't exist, it will be created.\nif (Directory.Exists(s3Path))\n{\nvar files = Directory.GetFiles(localPath);\nfileCount = files.Length;\n}\nawait transferUtil.DownloadDirectoryAsync(new\nTransferUtilityDownloadDirectoryRequest\n{\nBucketName = bucketName,\nLocalDirectory = localPath,\nS3Directory = s3Path,\n});\nif (Directory.Exists(localPath))\n{\nvar files = Directory.GetFiles(localPath);\nif (files.Length > fileCount)\n{\nreturn true;\n}\n// No change in the number of files. Assume\n// the download failed.\nreturn false;\n}\n// The local directory doesn't exist. No files\n// were downloaded.\nreturn false;\n}\nTrack the progress of an upload using the TransferUtility.\nScenarios API Version 2006-03-01 2496",
      "start_idx": 2754856,
      "end_idx": 2755716,
      "metadata": {
        "num_sentences": 7,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2507",
      "text": "Amazon Simple Storage Service API Reference\ncatch (Exception exception)\n{\nConsole.WriteLine($\"Exception occurred: {exception.Message}\");\n// If there was an error, abort the multipart upload.\nAbortMultipartUploadRequest abortMPURequest = new\nAbortMultipartUploadRequest\n{\nBucketName = existingBucketName,\nKey = sourceKeyName,\nUploadId = initResponse.UploadId,\n};\nawait client.AbortMultipartUploadAsync(abortMPURequest);\n}\n}\n}\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUpload a large object by using an upload manager to break the data into parts and upload\nthem concurrently.\n// BucketBasics encapsulates the Amazon Simple Storage Service (Amazon S3)\nactions\n// used in the examples.\n// It contains S3Client, an Amazon S3 service client that is used to perform\nbucket\n// and object actions.\ntype BucketBasics struct {\nScenarios API Version 2006-03-01 2502",
      "start_idx": 2762411,
      "end_idx": 2763364,
      "metadata": {
        "num_sentences": 7,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2508",
      "text": "Amazon Simple Storage Service API Reference\nS3Client *s3.Client\n}\n// UploadLargeObject uses an upload manager to upload data to an object in a\nbucket.\n// The upload manager breaks large data into parts and uploads the parts\nconcurrently.\nfunc (basics BucketBasics) UploadLargeObject(ctx context.Context, bucketName\nstring, objectKey string, largeObject []byte) error {\nlargeBuffer := bytes.NewReader(largeObject)\nvar partMiBs int64 = 10\nuploader := manager.NewUploader(basics.S3Client, func(u *manager.Uploader) {\nu.PartSize = partMiBs * 1024 * 1024\n})\n_, err := uploader.Upload(ctx, &s3.PutObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\nBody: largeBuffer,\n})\nif err != nil {\nlog.Printf(\"Couldn't upload large object to %v:%v. Here's why: %v\\n\",\nbucketName, objectKey, err)\n}\nreturn err\n}\nDownload a large object by using a download manager to get the data in parts and\ndownload them concurrently.\n// DownloadLargeObject uses a download manager to download an object from a\nbucket.\n// The download manager gets the data in parts and writes them to a buffer until\nall of\n// the data has been downloaded.\nfunc (basics BucketBasics) DownloadLargeObject(ctx context.Context, bucketName\nstring, objectKey string) ([]byte, error) {\nvar partMiBs int64 = 10\nScenarios API Version 2006-03-01 2503",
      "start_idx": 2763366,
      "end_idx": 2764679,
      "metadata": {
        "num_sentences": 7,
        "num_words": 184,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2509",
      "text": "Amazon Simple Storage Service API Reference\ndownloader := manager.NewDownloader(basics.S3Client, func(d *manager.Downloader)\n{\nd.PartSize = partMiBs * 1024 * 1024\n})\nbuffer := manager.NewWriteAtBuffer([]byte{})\n_, err := downloader.Download(ctx, buffer, &s3.GetObjectInput{\nBucket: aws.String(bucketName),\nKey: aws.String(objectKey),\n})\nif err != nil {\nlog.Printf(\"Couldn't download large object from %v:%v. Here's why: %v\\n\",\nbucketName, objectKey, err)\n}\nreturn buffer.Bytes(), err\n}\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCall functions that transfer files to and from an S3 bucket using the S3TransferManager.\npublic Integer downloadObjectsToDirectory(S3TransferManager transferManager,\nURI destinationPathURI, String bucketName) {\nDirectoryDownload directoryDownload =\ntransferManager.downloadDirectory(DownloadDirectoryRequest.builder()\n.destination(Paths.get(destinationPathURI))\n.bucket(bucketName)\n.build());\nCompletedDirectoryDownload completedDirectoryDownload =\ndirectoryDownload.completionFuture().join();\ncompletedDirectoryDownload.failedTransfers()\nScenarios API Version 2006-03-01 2504",
      "start_idx": 2764681,
      "end_idx": 2765889,
      "metadata": {
        "num_sentences": 5,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2511",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUpload a large file.\nimport { S3Client } from \"@aws-sdk/client-s3\";\nimport { Upload } from \"@aws-sdk/lib-storage\";\nimport { ProgressBar } from \"@aws-doc-sdk-examples/lib/utils/util-log.js\";\nconst twentyFiveMB = 25 * 1024 * 1024;\nexport const createString = (size = twentyFiveMB) => {\nreturn \"x\".repeat(size);\n};\n/**\n* Create a 25MB file and upload it in parts to the specified\n* Amazon S3 bucket.\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\nconst str = createString();\nconst buffer = Buffer.from(str, \"utf8\");\nconst progressBar = new ProgressBar({\ndescription: `Uploading \"${key}\" to \"${bucketName}\"`,\nbarLength: 30,\n});\ntry {\nconst upload = new Upload({\nclient: new S3Client({}),\nparams: {\nBucket: bucketName,\nKey: key,\nBody: buffer,\nScenarios API Version 2006-03-01 2506",
      "start_idx": 2767185,
      "end_idx": 2768219,
      "metadata": {
        "num_sentences": 5,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2512",
      "text": "Amazon Simple Storage Service API Reference\n},\n});\nupload.on(\"httpUploadProgress\", ({ loaded, total }) => {\nprogressBar.update({ current: loaded, total });\n});\nawait upload.done();\n} catch (caught) {\nif (caught instanceof Error && caught.name === \"AbortError\") {\nconsole.error(`Multipart upload was aborted. ${caught.message}`);\n} else {\nthrow caught;\n}\n}\n};\nDownload a large file.\nimport { GetObjectCommand, NoSuchKey, S3Client } from \"@aws-sdk/client-s3\";\nimport { createWriteStream, rmSync } from \"node:fs\";\nconst s3Client = new S3Client({});\nconst oneMB = 1024 * 1024;\nexport const getObjectRange = ({ bucket, key, start, end }) => {\nconst command = new GetObjectCommand({\nBucket: bucket,\nKey: key,\nRange: `bytes=${start}-${end}`,\n});\nreturn s3Client.send(command);\n};\n/**\n* @param {string | undefined} contentRange\n*/\nexport const getRangeAndLength = (contentRange) => {\nconst [range, length] = contentRange.split(\"/\");\nconst [start, end] = range.split(\"-\");\nScenarios API Version 2006-03-01 2507",
      "start_idx": 2768221,
      "end_idx": 2769222,
      "metadata": {
        "num_sentences": 3,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2513",
      "text": "Amazon Simple Storage Service API Reference\nreturn {\nstart: Number.parseInt(start),\nend: Number.parseInt(end),\nlength: Number.parseInt(length),\n};\n};\nexport const isComplete = ({ end, length }) => end === length - 1;\nconst downloadInChunks = async ({ bucket, key }) => {\nconst writeStream = createWriteStream(\nfileURLToPath(new URL(`./${key}`, import.meta.url)),\n).on(\"error\", (err) => console.error(err));\nlet rangeAndLength = { start: -1, end: -1, length: -1 };\nwhile (!isComplete(rangeAndLength)) {\nconst { end } = rangeAndLength;\nconst nextRange = { start: end + 1, end: end + oneMB };\nconst { ContentRange, Body } = await getObjectRange({\nbucket,\nkey,\n...nextRange,\n});\nconsole.log(`Downloaded bytes ${nextRange.start} to ${nextRange.end}`);\nwriteStream.write(await Body.transformToByteArray());\nrangeAndLength = getRangeAndLength(ContentRange);\n}\n};\n/**\n* Download a large object from and Amazon S3 bucket.\n*\n* When downloading a large file, you might want to break it down into\n* smaller pieces. Amazon S3 accepts a Range header to specify the start\n* and end of the byte range to be downloaded.\n*\n* @param {{ bucketName: string, key: string }}\n*/\nexport const main = async ({ bucketName, key }) => {\ntry {\nawait downloadInChunks({\nScenarios API Version 2006-03-01 2508",
      "start_idx": 2769224,
      "end_idx": 2770500,
      "metadata": {
        "num_sentences": 4,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2514",
      "text": "Amazon Simple Storage Service API Reference\nbucket: bucketName,\nkey: key,\n});\n} catch (caught) {\nif (caught instanceof NoSuchKey) {\nconsole.error(`Failed to download object. No such key \"${key}\".`);\nrmSync(key);\n}\n}\n};\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate functions that transfer files using several of the available transfer manager settings.\nUse a callback class to write callback progress during file transfer.\nimport sys\nimport threading\nimport boto3\nfrom boto3.s3.transfer import TransferConfig\nMB = 1024 * 1024\ns3 = boto3.resource(\"s3\")\nclass TransferCallback:\n\"\"\"\nHandle callbacks from the transfer manager.\nThe transfer manager periodically calls the __call__ method throughout\nScenarios API Version 2006-03-01 2509",
      "start_idx": 2770502,
      "end_idx": 2771349,
      "metadata": {
        "num_sentences": 7,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2515",
      "text": "Amazon Simple Storage Service API Reference\nthe upload and download process so that it can take action, such as\ndisplaying progress to the user and collecting data about the transfer.\n\"\"\"\ndef __init__(self, target_size):\nself._target_size = target_size\nself._total_transferred = 0\nself._lock = threading.Lock()\nself.thread_info = {}\ndef __call__(self, bytes_transferred):\n\"\"\"\nThe callback method that is called by the transfer manager.\nDisplay progress during file transfer and collect per-thread transfer\ndata. This method can be called by multiple threads, so shared instance\ndata is protected by a thread lock.\n\"\"\"\nthread = threading.current_thread()\nwith self._lock:\nself._total_transferred += bytes_transferred\nif thread.ident not in self.thread_info.keys():\nself.thread_info[thread.ident] = bytes_transferred\nelse:\nself.thread_info[thread.ident] += bytes_transferred\ntarget = self._target_size * MB\nsys.stdout.write(\nf\"\\r{self._total_transferred} of {target} transferred \"\nf\"({(self._total_transferred / target) * 100:.2f}%).\"\n)\nsys.stdout.flush()\ndef upload_with_default_configuration(\nlocal_file_path, bucket_name, object_key, file_size_mb\n):\n\"\"\"\nUpload a file from a local folder to an Amazon S3 bucket, using the default\nconfiguration.\n\"\"\"\ntransfer_callback = TransferCallback(file_size_mb)\ns3.Bucket(bucket_name).upload_file(\nlocal_file_path, object_key, Callback=transfer_callback\nScenarios API Version 2006-03-01 2510",
      "start_idx": 2771351,
      "end_idx": 2772781,
      "metadata": {
        "num_sentences": 7,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2516",
      "text": "Amazon Simple Storage Service API Reference\n)\nreturn transfer_callback.thread_info\ndef upload_with_chunksize_and_meta(\nlocal_file_path, bucket_name, object_key, file_size_mb, metadata=None\n):\n\"\"\"\nUpload a file from a local folder to an Amazon S3 bucket, setting a\nmultipart chunk size and adding metadata to the Amazon S3 object.\nThe multipart chunk size controls the size of the chunks of data that are\nsent in the request. A smaller chunk size typically results in the transfer\nmanager using more threads for the upload.\nThe metadata is a set of key-value pairs that are stored with the object\nin Amazon S3.\n\"\"\"\ntransfer_callback = TransferCallback(file_size_mb)\nconfig = TransferConfig(multipart_chunksize=1 * MB)\nextra_args = {\"Metadata\": metadata} if metadata else None\ns3.Bucket(bucket_name).upload_file(\nlocal_file_path,\nobject_key,\nConfig=config,\nExtraArgs=extra_args,\nCallback=transfer_callback,\n)\nreturn transfer_callback.thread_info\ndef upload_with_high_threshold(local_file_path, bucket_name, object_key,\nfile_size_mb):\n\"\"\"\nUpload a file from a local folder to an Amazon S3 bucket, setting a\nmultipart threshold larger than the size of the file.\nSetting a multipart threshold larger than the size of the file results\nin the transfer manager sending the file as a standard upload instead of\na multipart upload.\n\"\"\"\ntransfer_callback = TransferCallback(file_size_mb)\nconfig = TransferConfig(multipart_threshold=file_size_mb * 2 * MB)\nScenarios API Version 2006-03-01 2511",
      "start_idx": 2772783,
      "end_idx": 2774264,
      "metadata": {
        "num_sentences": 7,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2520",
      "text": "Amazon Simple Storage Service API Reference\nclass TransferDemoManager:\n\"\"\"\nManages the demonstration. Collects user input from a command line, reports\ntransfer results, maintains a list of artifacts created during the\ndemonstration, and cleans them up after the demonstration is completed.\n\"\"\"\ndef __init__(self):\nself._s3 = boto3.resource(\"s3\")\nself._chore_list = []\nself._create_file_cmd = None\nself._size_multiplier = 0\nself.file_size_mb = 30\nself.demo_folder = None\nself.demo_bucket = None\nself._setup_platform_specific()\nself._terminal_width = shutil.get_terminal_size(fallback=(80, 80))[0]\ndef collect_user_info(self):\n\"\"\"\nCollect local folder and Amazon S3 bucket name from the user. These\nlocations are used to store files during the demonstration.\n\"\"\"\nwhile not self.demo_folder:\nself.demo_folder = input(\n\"Which file folder do you want to use to store \" \"demonstration\nfiles? \"\n)\nif not os.path.isdir(self.demo_folder):\nprint(f\"{self.demo_folder} isn't a folder!\")\nself.demo_folder = None\nwhile not self.demo_bucket:\nself.demo_bucket = input(\n\"Which Amazon S3 bucket do you want to use to store \"\n\"demonstration files? \"\n)\ntry:\nself._s3.meta.client.head_bucket(Bucket=self.demo_bucket)\nexcept ParamValidationError as err:\nprint(err)\nself.demo_bucket = None\nexcept ClientError as err:\nScenarios API Version 2006-03-01 2515",
      "start_idx": 2778303,
      "end_idx": 2779634,
      "metadata": {
        "num_sentences": 8,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2523",
      "text": "Amazon Simple Storage Service API Reference\ntry:\nself._s3.Bucket(self.demo_bucket).Object(s3_object_key).delete()\nexcept ClientError as err:\nprint(err)\ndef _setup_platform_specific(self):\n\"\"\"Set up platform-specific command used to create a large file.\"\"\"\nif platform.system() == \"Windows\":\nself._create_file_cmd = \"fsutil file createnew {} {}\"\nself._size_multiplier = MB\nelif platform.system() == \"Linux\" or platform.system() == \"Darwin\":\nself._create_file_cmd = f\"dd if=/dev/urandom of={{}} \" f\"bs={MB}\ncount={{}}\"\nself._size_multiplier = 1\nelse:\nraise EnvironmentError(\nf\"Demo of platform {platform.system()} isn't supported.\"\n)\ndef _create_demo_file(self):\n\"\"\"\nCreate a file in the demo folder specified by the user. Store the local\npath, object name, and download path for later cleanup.\nOnly the local file is created by this method. The Amazon S3 object and\ndownload file are created later during the demonstration.\nReturns:\nA tuple that contains the local file path, object name, and download\nfile path.\n\"\"\"\nfile_name_template = \"TestFile{}-{}.demo\"\nlocal_suffix = \"local\"\nobject_suffix = \"s3object\"\ndownload_suffix = \"downloaded\"\nfile_tag = len(self._chore_list) + 1\nlocal_file_path = os.path.join(\nself.demo_folder, file_name_template.format(file_tag, local_suffix)\n)\ns3_object_key = file_name_template.format(file_tag, object_suffix)\nScenarios API Version 2006-03-01 2518",
      "start_idx": 2782024,
      "end_idx": 2783406,
      "metadata": {
        "num_sentences": 8,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2525",
      "text": "Amazon Simple Storage Service API Reference\nprint(\"With configuration:\")\nfor attr in config_attrs:\nprint(f'{\"\":4}{attr:<20}: {getattr(config, attr)}')\nreturn config\nreturn wrapper\n@staticmethod\ndef _report_transfer_result(thread_info, elapsed):\n\"\"\"Report the result of a transfer, including per-thread data.\"\"\"\nprint(f\"\\nUsed {len(thread_info)} threads.\")\nfor ident, byte_count in thread_info.items():\nprint(f\"{'':4}Thread {ident} copied {byte_count} bytes.\")\nprint(f\"Your transfer took {elapsed:.2f} seconds.\")\ndef main():\n\"\"\"\nRun the demonstration script for s3_file_transfer.\n\"\"\"\ndemo_manager = TransferDemoManager()\ndemo_manager.collect_user_info()\n# Upload and download with default configuration. Because the file is 30 MB\n# and the default multipart_threshold is 8 MB, both upload and download are\n# multipart transfers.\ndemo_manager.demo(\n\"Do you want to upload and download a {} MB file \"\n\"using the default configuration?\",\nfile_transfer.upload_with_default_configuration,\nfile_transfer.download_with_default_configuration,\n)\n# Upload and download with multipart_threshold set higher than the size of\n# the file. This causes the transfer manager to use standard transfers\n# instead of multipart transfers.\ndemo_manager.demo(\n\"Do you want to upload and download a {} MB file \"\n\"as a standard (not multipart) transfer?\",\nfile_transfer.upload_with_high_threshold,\nfile_transfer.download_with_high_threshold,\n)\n# Upload with specific chunk size and additional metadata.\nScenarios API Version 2006-03-01 2520",
      "start_idx": 2784646,
      "end_idx": 2786159,
      "metadata": {
        "num_sentences": 13,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2527",
      "text": "Amazon Simple Storage Service API Reference\n\"Got expected error when trying to download an encrypted \"\n\"object without specifying encryption info:\"\n)\nprint(f\"{'':4}{err}\")\n# Remove all created and downloaded files, remove all objects from\n# S3 storage.\nif demo_manager.ask_user(\n\"Demonstration complete. Do you want to remove local files \" \"and S3\nobjects?\"\n):\ndemo_manager.cleanup()\nif __name__ == \"__main__\":\ntry:\nmain()\nexcept NoCredentialsError as error:\nprint(error)\nprint(\n\"To run this example, you must have valid credentials in \"\n\"a shared credential file or set in environment variables.\"\n)\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nuse std::fs::File;\nuse std::io::prelude::*;\nuse std::path::Path;\nuse aws_config::meta::region::RegionProviderChain;\nScenarios API Version 2006-03-01 2522",
      "start_idx": 2787537,
      "end_idx": 2788432,
      "metadata": {
        "num_sentences": 7,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2528",
      "text": "Amazon Simple Storage Service API Reference\nuse aws_sdk_s3::error::DisplayErrorContext;\nuse aws_sdk_s3::operation::{\ncreate_multipart_upload::CreateMultipartUploadOutput,\nget_object::GetObjectOutput,\n};\nuse aws_sdk_s3::types::{CompletedMultipartUpload, CompletedPart};\nuse aws_sdk_s3::{config::Region, Client as S3Client};\nuse aws_smithy_types::byte_stream::{ByteStream, Length};\nuse rand::distributions::Alphanumeric;\nuse rand::{thread_rng, Rng};\nuse s3_code_examples::error::S3ExampleError;\nuse std::process;\nuse uuid::Uuid;\n//In bytes, minimum chunk size of 5MB. Increase CHUNK_SIZE to send larger chunks.\nconst CHUNK_SIZE: u64 = 1024 * 1024 * 5;\nconst MAX_CHUNKS: u64 = 10000;\n#[tokio::main]\npub async fn main() {\nif let Err(err) = run_example().await {\neprintln!(\"Error: {}\", DisplayErrorContext(err));\nprocess::exit(1);\n}\n}\nasync fn run_example() -> Result<(), S3ExampleError> {\nlet shared_config = aws_config::load_from_env().await;\nlet client = S3Client::new(&shared_config);\nlet bucket_name = format!(\"amzn-s3-demo-bucket-{}\", Uuid::new_v4());\nlet region_provider = RegionProviderChain::first_try(Region::new(\"us-\nwest-2\"));\nlet region = region_provider.region().await.unwrap();\ns3_code_examples::create_bucket(&client, &bucket_name, &region).await?;\nlet key = \"sample.txt\".to_string();\n// Create a multipart upload. Use UploadPart and CompleteMultipartUpload to\n// upload the file.\nlet multipart_upload_res: CreateMultipartUploadOutput = client\n.create_multipart_upload()\n.bucket(&bucket_name)\n.key(&key)\n.send()\nScenarios API Version 2006-03-01 2523",
      "start_idx": 2788434,
      "end_idx": 2789994,
      "metadata": {
        "num_sentences": 8,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2531",
      "text": "Amazon Simple Storage Service API Reference\n.bucket(&bucket_name)\n.key(&key)\n.multipart_upload(completed_multipart_upload)\n.upload_id(upload_id)\n.send()\n.await?;\nlet data: GetObjectOutput =\ns3_code_examples::download_object(&client, &bucket_name, &key).await?;\nlet data_length: u64 = data\n.content_length()\n.unwrap_or_default()\n.try_into()\n.unwrap();\nif file.metadata().unwrap().len() == data_length {\nprintln!(\"Data lengths match.\");\n} else {\nprintln!(\"The data was not the same size!\");\n}\ns3_code_examples::clear_bucket(&client, &bucket_name)\n.await\n.expect(\"Error emptying bucket.\");\ns3_code_examples::delete_bucket(&client, &bucket_name)\n.await\n.expect(\"Error deleting bucket.\");\nOk(())\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUpload a stream of unknown size to an Amazon S3 object using an AWS SDK\nThe following code example shows how to upload a stream of unknown size to an Amazon S3\nobject.\nScenarios API Version 2006-03-01 2526",
      "start_idx": 2792331,
      "end_idx": 2793446,
      "metadata": {
        "num_sentences": 12,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2532",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nUse the AWS CRT-based S3 Client.\nimport com.example.s3.util.AsyncExampleUtils;\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.async.AsyncRequestBody;\nimport software.amazon.awssdk.core.async.BlockingInputStreamAsyncRequestBody;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.services.s3.S3AsyncClient;\nimport software.amazon.awssdk.services.s3.model.PutObjectResponse;\nimport java.io.ByteArrayInputStream;\nimport java.util.UUID;\nimport java.util.concurrent.CompletableFuture;\n/**\n* @param s33CrtAsyncClient - To upload content from a stream of unknown\nsize, use the AWS CRT-based S3 client. For more information, see\n* https://docs.aws.amazon.com/sdk-for-java/latest/\ndeveloper-guide/crt-based-s3-client.html.\n* @param bucketName - The name of the bucket.\n* @param key - The name of the object.\n* @return software.amazon.awssdk.services.s3.model.PutObjectResponse -\nReturns metadata pertaining to the put object operation.\n*/\npublic PutObjectResponse putObjectFromStream(S3AsyncClient s33CrtAsyncClient,\nString bucketName, String key) {\nBlockingInputStreamAsyncRequestBody body =\nAsyncRequestBody.forBlockingInputStream(null); // 'null'\nindicates a stream will be provided later.\nCompletableFuture<PutObjectResponse> responseFuture =\nScenarios API Version 2006-03-01 2527",
      "start_idx": 2793448,
      "end_idx": 2794996,
      "metadata": {
        "num_sentences": 10,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2534",
      "text": "Amazon Simple Storage Service API Reference\n* @return - software.amazon.awssdk.transfer.s3.model.CompletedUpload - The\nresult of the completed upload.\n*/\npublic CompletedUpload uploadStream(S3TransferManager transferManager, String\nbucketName, String key) {\nBlockingInputStreamAsyncRequestBody body =\nAsyncRequestBody.forBlockingInputStream(null); // 'null'\nindicates a stream will be provided later.\nUpload upload = transferManager.upload(builder -> builder\n.requestBody(body)\n.putObjectRequest(req -> req.bucket(bucketName).key(key))\n.build());\n// AsyncExampleUtils.randomString() returns a random string up to 100\ncharacters.\nString randomString = AsyncExampleUtils.randomString();\nlogger.info(\"random string to upload: {}: length={}\", randomString,\nrandomString.length());\n// Provide the stream of data to be uploaded.\nbody.writeInputStream(new ByteArrayInputStream(randomString.getBytes()));\nreturn upload.completionFuture().join();\n}\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse checksums to work with an Amazon S3 object using an AWS SDK\nThe following code example shows how to use checksums to work with an Amazon S3 object.\nScenarios API Version 2006-03-01 2529",
      "start_idx": 2796589,
      "end_idx": 2797937,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2535",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nThe code examples use a subset of the following imports.\nimport org.slf4j.Logger;\nimport org.slf4j.LoggerFactory;\nimport software.amazon.awssdk.core.exception.SdkException;\nimport software.amazon.awssdk.core.sync.RequestBody;\nimport software.amazon.awssdk.services.s3.S3Client;\nimport software.amazon.awssdk.services.s3.model.ChecksumAlgorithm;\nimport software.amazon.awssdk.services.s3.model.ChecksumMode;\nimport software.amazon.awssdk.services.s3.model.CompletedMultipartUpload;\nimport software.amazon.awssdk.services.s3.model.CompletedPart;\nimport software.amazon.awssdk.services.s3.model.CreateMultipartUploadResponse;\nimport software.amazon.awssdk.services.s3.model.GetObjectResponse;\nimport software.amazon.awssdk.services.s3.model.UploadPartRequest;\nimport software.amazon.awssdk.services.s3.model.UploadPartResponse;\nimport software.amazon.awssdk.services.s3.waiters.S3Waiter;\nimport software.amazon.awssdk.transfer.s3.S3TransferManager;\nimport software.amazon.awssdk.transfer.s3.model.FileUpload;\nimport software.amazon.awssdk.transfer.s3.model.UploadFileRequest;\nimport java.io.FileInputStream;\nimport java.io.IOException;\nimport java.io.RandomAccessFile;\nimport java.net.URISyntaxException;\nimport java.net.URL;\nimport java.nio.ByteBuffer;\nimport java.nio.file.Paths;\nimport java.security.DigestInputStream;\nimport java.security.MessageDigest;\nimport java.security.NoSuchAlgorithmException;\nimport java.util.ArrayList;\nimport java.util.Base64;\nScenarios API Version 2006-03-01 2530",
      "start_idx": 2797939,
      "end_idx": 2799621,
      "metadata": {
        "num_sentences": 4,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2537",
      "text": "Amazon Simple Storage Service API Reference\nUse the S3 Transfer Manager on top of the AWS CRT-based S3 client to transparently\nperform a multipart upload when the size of the content exceeds a threshold. The default\nthreshold size is 8 MB.\nYou can specify a checksum algorithm for the SDK to use. By default, the SDK uses the\nCRC32 algorithm.\npublic void multipartUploadWithChecksumTm(String filePath) {\nS3TransferManager transferManager = S3TransferManager.create();\nUploadFileRequest uploadFileRequest = UploadFileRequest.builder()\n.putObjectRequest(b -> b\n.bucket(bucketName)\n.key(key)\n.checksumAlgorithm(ChecksumAlgorithm.SHA1))\n.source(Paths.get(filePath))\n.build();\nFileUpload fileUpload = transferManager.uploadFile(uploadFileRequest);\nfileUpload.completionFuture().join();\ntransferManager.close();\n}\nUse the S3Client API or (S3AsyncClient API) to perform a multipart upload. If you specify\nan additional checksum, you must specify the algorithm to use on the initiation of the\nupload. You must also specify the algorithm for each part request and provide the checksum\ncalculated for each part after it is uploaded.\npublic void multipartUploadWithChecksumS3Client(String filePath) {\nChecksumAlgorithm algorithm = ChecksumAlgorithm.CRC32;\n// Initiate the multipart upload.\nCreateMultipartUploadResponse createMultipartUploadResponse =\ns3Client.createMultipartUpload(b -> b\n.bucket(bucketName)\n.key(key)\n.checksumAlgorithm(algorithm)); // Checksum specified on initiation.\nString uploadId = createMultipartUploadResponse.uploadId();\n// Upload the parts of the file.\nint partNumber = 1;\nList<CompletedPart> completedParts = new ArrayList<>();\nByteBuffer bb = ByteBuffer.allocate(1024 * 1024 * 5); // 5 MB byte buffer\nScenarios API Version 2006-03-01 2532",
      "start_idx": 2800643,
      "end_idx": 2802401,
      "metadata": {
        "num_sentences": 11,
        "num_words": 207,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2539",
      "text": "Amazon Simple Storage Service API Reference\n.multipartUpload(CompletedMultipartUpload.builder().parts(completedParts).build()));\n}\n\u2022 For API details, see the following topics in AWS SDK for Java 2.x API Reference.\n\u2022 CompleteMultipartUpload\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nWork with Amazon S3 object integrity features using an AWS SDK\nThe following code example shows how to work with S3 object integrity features.\nC++\nSDK for C++\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nRun an interactive scenario demonstrating Amazon S3 object integrity features.\n//! Routine which runs the S3 object integrity workflow.\n/*!\n\\param clientConfig: Aws client configuration.\n\\return bool: Function succeeded.\n*/\nbool AwsDoc::S3::s3ObjectIntegrityWorkflow(\nconst Aws::S3::S3ClientConfiguration &clientConfiguration) {\n/*\n* Create a large file to be used for multipart uploads.\nScenarios API Version 2006-03-01 2534",
      "start_idx": 2803535,
      "end_idx": 2804737,
      "metadata": {
        "num_sentences": 14,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2562",
      "text": "Amazon Simple Storage Service API Reference\ncompletedPart.SetChecksumCRC32C(uploadPartResult.GetChecksumCRC32C());\nbreak;\ndefault:\nstd::cerr << \"Unhandled hash method for completedPart.\" <<\nstd::endl;\nbreak;\n}\nparts.push_back(completedPart);\n} else {\nstd::cerr << \"Error uploading part. \" <<\nuploadPartOutcome.GetError().GetMessage() << std::endl;\nuploadSucceeded = false;\nbreak;\n}\nuploadedBytes += bytesToRead;\npartNumber++;\n}\nif (!uploadSucceeded) {\nabortMultipartUpload(bucket, key, uploadID, client);\nreturn false;\n} else {\nAws::S3::Model::CompleteMultipartUploadOutcome\ncompleteMultipartUploadOutcome = completeMultipartUpload(bucket,\nkey,\nuploadID,\nparts,\nclient);\nif (completeMultipartUploadOutcome.IsSuccess()) {\nstd::cout << \"Multipart upload completed.\" << std::endl;\nif (!hashDataResult.calculateObjectHash(totalHashBuffer, hashMethod))\n{\nstd::cerr << \"Error calculating hash.\" << std::endl;\nreturn false;\n}\nScenarios API Version 2006-03-01 2557",
      "start_idx": 2836052,
      "end_idx": 2837008,
      "metadata": {
        "num_sentences": 5,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2569",
      "text": "Amazon Simple Storage Service API Reference\ninput.close();\nwhile (newFile.tellp() < LARGE_FILE_SIZE && !newFile.bad()) {\nbuffer.seekg(std::stringstream::beg);\nnewFile << buffer.rdbuf();\n}\nnewFile.close();\nreturn true;\n}\n\u2022 For API details, see the following topics in AWS SDK for C++ API Reference.\n\u2022 AbortMultipartUpload\n\u2022 CompleteMultipartUpload\n\u2022 CreateMultipartUpload\n\u2022 DeleteObject\n\u2022 GetObjectAttributes\n\u2022 PutObject\n\u2022 UploadPart\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nWork with Amazon S3 versioned objects using an AWS SDK\nThe following code example shows how to:\n\u2022 Create a versioned S3 bucket.\n\u2022 Get all versions of an object.\n\u2022 Roll an object back to a previous version.\n\u2022 Delete and restore a versioned object.\n\u2022 Permanently delete all versions of an object.\nScenarios API Version 2006-03-01 2564",
      "start_idx": 2844995,
      "end_idx": 2845977,
      "metadata": {
        "num_sentences": 9,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2570",
      "text": "Amazon Simple Storage Service API Reference\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nCreate functions that wrap S3 actions.\ndef create_versioned_bucket(bucket_name, prefix):\n\"\"\"\nCreates an Amazon S3 bucket, enables it for versioning, and configures a\nlifecycle\nthat expires noncurrent object versions after 7 days.\nAdding a lifecycle configuration to a versioned bucket is a best practice.\nIt helps prevent objects in the bucket from accumulating a large number of\nnoncurrent versions, which can slow down request performance.\nUsage is shown in the usage_demo_single_object function at the end of this\nmodule.\n:param bucket_name: The name of the bucket to create.\n:param prefix: Identifies which objects are automatically expired under the\nconfigured lifecycle rules.\n:return: The newly created bucket.\n\"\"\"\ntry:\nbucket = s3.create_bucket(\nBucket=bucket_name,\nCreateBucketConfiguration={\n\"LocationConstraint\": s3.meta.client.meta.region_name\n},\n)\nlogger.info(\"Created bucket %s.\", bucket.name)\nexcept ClientError as error:\nif error.response[\"Error\"][\"Code\"] == \"BucketAlreadyOwnedByYou\":\nlogger.warning(\"Bucket %s already exists! Using it.\", bucket_name)\nbucket = s3.Bucket(bucket_name)\nelse:\nScenarios API Version 2006-03-01 2565",
      "start_idx": 2845979,
      "end_idx": 2847321,
      "metadata": {
        "num_sentences": 14,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2571",
      "text": "Amazon Simple Storage Service API Reference\nlogger.exception(\"Couldn't create bucket %s.\", bucket_name)\nraise\ntry:\nbucket.Versioning().enable()\nlogger.info(\"Enabled versioning on bucket %s.\", bucket.name)\nexcept ClientError:\nlogger.exception(\"Couldn't enable versioning on bucket %s.\", bucket.name)\nraise\ntry:\nexpiration = 7\nbucket.LifecycleConfiguration().put(\nLifecycleConfiguration={\n\"Rules\": [\n{\n\"Status\": \"Enabled\",\n\"Prefix\": prefix,\n\"NoncurrentVersionExpiration\": {\"NoncurrentDays\":\nexpiration},\n}\n]\n}\n)\nlogger.info(\n\"Configured lifecycle to expire noncurrent versions after %s days \"\n\"on bucket %s.\",\nexpiration,\nbucket.name,\n)\nexcept ClientError as error:\nlogger.warning(\n\"Couldn't configure lifecycle on bucket %s because %s. \"\n\"Continuing anyway.\",\nbucket.name,\nerror,\n)\nreturn bucket\ndef rollback_object(bucket, object_key, version_id):\n\"\"\"\nScenarios API Version 2006-03-01 2566",
      "start_idx": 2847323,
      "end_idx": 2848212,
      "metadata": {
        "num_sentences": 7,
        "num_words": 98,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2573",
      "text": "Amazon Simple Storage Service API Reference\ndef revive_object(bucket, object_key):\n\"\"\"\nRevives a versioned object that was deleted by removing the object's active\ndelete marker.\nA versioned object presents as deleted when its latest version is a delete\nmarker.\nBy removing the delete marker, we make the previous version the latest\nversion\nand the object then presents as *not* deleted.\nUsage is shown in the usage_demo_single_object function at the end of this\nmodule.\n:param bucket: The bucket that contains the object.\n:param object_key: The object to revive.\n\"\"\"\n# Get the latest version for the object.\nresponse = s3.meta.client.list_object_versions(\nBucket=bucket.name, Prefix=object_key, MaxKeys=1\n)\nif \"DeleteMarkers\" in response:\nlatest_version = response[\"DeleteMarkers\"][0]\nif latest_version[\"IsLatest\"]:\nlogger.info(\n\"Object %s was indeed deleted on %s. Let's revive it.\",\nobject_key,\nlatest_version[\"LastModified\"],\n)\nobj = bucket.Object(object_key)\nobj.Version(latest_version[\"VersionId\"]).delete()\nlogger.info(\n\"Revived %s, active version is now %s with body '%s'\",\nobject_key,\nobj.version_id,\nobj.get()[\"Body\"].read(),\n)\nelse:\nlogger.warning(\n\"Delete marker is not the latest version for %s!\", object_key\n)\nelif \"Versions\" in response:\nScenarios API Version 2006-03-01 2568",
      "start_idx": 2849475,
      "end_idx": 2850764,
      "metadata": {
        "num_sentences": 11,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2574",
      "text": "Amazon Simple Storage Service API Reference\nlogger.warning(\"Got an active version for %s, nothing to do.\",\nobject_key)\nelse:\nlogger.error(\"Couldn't get any version info for %s.\", object_key)\ndef permanently_delete_object(bucket, object_key):\n\"\"\"\nPermanently deletes a versioned object by deleting all of its versions.\nUsage is shown in the usage_demo_single_object function at the end of this\nmodule.\n:param bucket: The bucket that contains the object.\n:param object_key: The object to delete.\n\"\"\"\ntry:\nbucket.object_versions.filter(Prefix=object_key).delete()\nlogger.info(\"Permanently deleted all versions of object %s.\", object_key)\nexcept ClientError:\nlogger.exception(\"Couldn't delete all versions of %s.\", object_key)\nraise\nUpload the stanza of a poem to a versioned object and perform a series of actions on it.\ndef usage_demo_single_object(obj_prefix=\"demo-versioning/\"):\n\"\"\"\nDemonstrates usage of versioned object functions. This demo uploads a stanza\nof a poem and performs a series of revisions, deletions, and revivals on it.\n:param obj_prefix: The prefix to assign to objects created by this demo.\n\"\"\"\nwith open(\"father_william.txt\") as file:\nstanzas = file.read().split(\"\\n\\n\")\nwidth = get_terminal_size((80, 20))[0]\nprint(\"-\" * width)\nprint(\"Welcome to the usage demonstration of Amazon S3 versioning.\")\nprint(\nScenarios API Version 2006-03-01 2569",
      "start_idx": 2850766,
      "end_idx": 2852128,
      "metadata": {
        "num_sentences": 14,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2576",
      "text": "Amazon Simple Storage Service API Reference\n# Delete the stanza\nprint(\"\\nDeleting the stanza...\")\nobj_stanza_1.delete()\ntry:\nobj_stanza_1.get()\nexcept ClientError as error:\nif error.response[\"Error\"][\"Code\"] == \"NoSuchKey\":\nprint(\"The stanza is now deleted (as expected).\")\nelse:\nraise\n# Revive the stanza\nprint(\"\\nRestoring the stanza...\")\nrevive_object(bucket, obj_stanza_1.key)\nprint(\n\"The stanza is restored! The latest version is again:\",\nobj_stanza_1.get()[\"Body\"].read().decode(\"utf-8\"),\nsep=\"\\n\",\n)\n# Permanently delete all versions of the object. This cannot be undone!\nprint(\"\\nPermanently deleting all versions of the stanza...\")\npermanently_delete_object(bucket, obj_stanza_1.key)\nobj_stanza_1_versions =\nbucket.object_versions.filter(Prefix=obj_stanza_1.key)\nif len(list(obj_stanza_1_versions)) == 0:\nprint(\"The stanza has been permanently deleted and now has no versions.\")\nelse:\nprint(\"Something went wrong. The stanza still exists!\")\nprint(f\"\\nRemoving {bucket.name}...\")\nbucket.delete()\nprint(f\"{bucket.name} deleted.\")\nprint(\"Demo done!\")\n\u2022 For API details, see the following topics in AWS SDK for Python (Boto3) API Reference.\n\u2022 CreateBucket\n\u2022 DeleteObject\nScenarios API Version 2006-03-01 2571",
      "start_idx": 2853609,
      "end_idx": 2854822,
      "metadata": {
        "num_sentences": 11,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2577",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 ListObjectVersions\n\u2022 PutBucketLifecycleConfiguration\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nServerless examples for Amazon S3 using AWS SDKs\nThe following code examples show how to use Amazon S3 with AWS SDKs.\nExamples\n\u2022 Invoke a Lambda function from an Amazon S3 trigger\nInvoke a Lambda function from an Amazon S3 trigger\nThe following code examples show how to implement a Lambda function that receives an event\ntriggered by uploading an object to an S3 bucket. The function retrieves the S3 bucket name and\nobject key from the event parameter and calls the Amazon S3 API to retrieve and log the content\ntype of the object.\n.NET\nAWS SDK for .NET\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using .NET.\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nusing System.Threading.Tasks;\nusing Amazon.Lambda.Core;\nusing Amazon.S3;\nusing System;\nServerless examples API Version 2006-03-01 2572",
      "start_idx": 2854824,
      "end_idx": 2856111,
      "metadata": {
        "num_sentences": 11,
        "num_words": 202,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2579",
      "text": "Amazon Simple Storage Service API Reference\n{\ncontext.Logger.LogLine($\"Error processing request -\n{e.Message}\");\nreturn string.Empty;\n}\n}\n}\n}\nGo\nSDK for Go V2\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Go.\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage main\nimport (\n\"context\"\n\"log\"\n\"github.com/aws/aws-lambda-go/events\"\n\"github.com/aws/aws-lambda-go/lambda\"\n\"github.com/aws/aws-sdk-go-v2/config\"\n\"github.com/aws/aws-sdk-go-v2/service/s3\"\n)\nfunc handler(ctx context.Context, s3Event events.S3Event) error {\nsdkConfig, err := config.LoadDefaultConfig(ctx)\nif err != nil {\nlog.Printf(\"failed to load default config: %s\", err)\nreturn err\n}\nServerless examples API Version 2006-03-01 2574",
      "start_idx": 2857202,
      "end_idx": 2858079,
      "metadata": {
        "num_sentences": 6,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2580",
      "text": "Amazon Simple Storage Service API Reference\ns3Client := s3.NewFromConfig(sdkConfig)\nfor _, record := range s3Event.Records {\nbucket := record.S3.Bucket.Name\nkey := record.S3.Object.URLDecodedKey\nheadOutput, err := s3Client.HeadObject(ctx, &s3.HeadObjectInput{\nBucket: &bucket,\nKey: &key,\n})\nif err != nil {\nlog.Printf(\"error getting head of object %s/%s: %s\", bucket, key, err)\nreturn err\n}\nlog.Printf(\"successfully retrieved %s/%s of type %s\", bucket, key,\n*headOutput.ContentType)\n}\nreturn nil\n}\nfunc main() {\nlambda.Start(handler)\n}\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Java.\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\npackage example;\nimport software.amazon.awssdk.services.s3.model.HeadObjectRequest;\nServerless examples API Version 2006-03-01 2575",
      "start_idx": 2858081,
      "end_idx": 2859051,
      "metadata": {
        "num_sentences": 6,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2582",
      "text": "Amazon Simple Storage Service API Reference\nJavaScript\nSDK for JavaScript (v3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using JavaScript.\nimport { S3Client, HeadObjectCommand } from \"@aws-sdk/client-s3\";\nconst client = new S3Client();\nexport const handler = async (event, context) => {\n// Get the object from the event and show its content type\nconst bucket = event.Records[0].s3.bucket.name;\nconst key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g,\n' '));\ntry {\nconst { ContentType } = await client.send(new HeadObjectCommand({\nBucket: bucket,\nKey: key,\n}));\nconsole.log('CONTENT TYPE:', ContentType);\nreturn ContentType;\n} catch (err) {\nconsole.log(err);\nconst message = `Error getting object ${key} from bucket ${bucket}. Make\nsure they exist and your bucket is in the same region as this function.`;\nconsole.log(message);\nthrow new Error(message);\n}\n};\nServerless examples API Version 2006-03-01 2577",
      "start_idx": 2860561,
      "end_idx": 2861604,
      "metadata": {
        "num_sentences": 5,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2583",
      "text": "Amazon Simple Storage Service API Reference\nConsuming an S3 event with Lambda using TypeScript.\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nimport { S3Event } from 'aws-lambda';\nimport { S3Client, HeadObjectCommand } from '@aws-sdk/client-s3';\nconst s3 = new S3Client({ region: process.env.AWS_REGION });\nexport const handler = async (event: S3Event): Promise<string | undefined> => {\n// Get the object from the event and show its content type\nconst bucket = event.Records[0].s3.bucket.name;\nconst key = decodeURIComponent(event.Records[0].s3.object.key.replace(/\\+/g, '\n'));\nconst params = {\nBucket: bucket,\nKey: key,\n};\ntry {\nconst { ContentType } = await s3.send(new HeadObjectCommand(params));\nconsole.log('CONTENT TYPE:', ContentType);\nreturn ContentType;\n} catch (err) {\nconsole.log(err);\nconst message = `Error getting object ${key} from bucket ${bucket}. Make sure\nthey exist and your bucket is in the same region as this function.`;\nconsole.log(message);\nthrow new Error(message);\n}\n};\nPHP\nSDK for PHP\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nServerless examples API Version 2006-03-01 2578",
      "start_idx": 2861606,
      "end_idx": 2862855,
      "metadata": {
        "num_sentences": 7,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2584",
      "text": "Amazon Simple Storage Service API Reference\nConsuming an S3 event with Lambda using PHP.\n<?php\nuse Bref\\Context\\Context;\nuse Bref\\Event\\S3\\S3Event;\nuse Bref\\Event\\S3\\S3Handler;\nuse Bref\\Logger\\StderrLogger;\nrequire __DIR__ . '/vendor/autoload.php';\nclass Handler extends S3Handler\n{\nprivate StderrLogger $logger;\npublic function __construct(StderrLogger $logger)\n{\n$this->logger = $logger;\n}\npublic function handleS3(S3Event $event, Context $context) : void\n{\n$this->logger->info(\"Processing S3 records\");\n// Get the object from the event and show its content type\n$records = $event->getRecords();\nforeach ($records as $record)\n{\n$bucket = $record->getBucket()->getName();\n$key = urldecode($record->getObject()->getKey());\ntry {\n$fileSize = urldecode($record->getObject()->getSize());\necho \"File Size: \" . $fileSize . \"\\n\";\n// TODO: Implement your custom processing logic here\n} catch (Exception $e) {\necho $e->getMessage() . \"\\n\";\necho 'Error getting object ' . $key . ' from bucket ' .\n$bucket . '. Make sure they exist and your bucket is in the same region as this\nfunction.' . \"\\n\";\nthrow $e;\n}\n}\nServerless examples API Version 2006-03-01 2579",
      "start_idx": 2862857,
      "end_idx": 2864005,
      "metadata": {
        "num_sentences": 13,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2585",
      "text": "Amazon Simple Storage Service API Reference\n}\n}\n$logger = new StderrLogger();\nreturn new Handler($logger);\nPython\nSDK for Python (Boto3)\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Python.\n# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n# SPDX-License-Identifier: Apache-2.0\nimport json\nimport urllib.parse\nimport boto3\nprint('Loading function')\ns3 = boto3.client('s3')\ndef lambda_handler(event, context):\n#print(\"Received event: \" + json.dumps(event, indent=2))\n# Get the object from the event and show its content type\nbucket = event['Records'][0]['s3']['bucket']['name']\nkey = urllib.parse.unquote_plus(event['Records'][0]['s3']['object']['key'],\nencoding='utf-8')\ntry:\nresponse = s3.get_object(Bucket=bucket, Key=key)\nprint(\"CONTENT TYPE: \" + response['ContentType'])\nreturn response['ContentType']\nexcept Exception as e:\nServerless examples API Version 2006-03-01 2580",
      "start_idx": 2864007,
      "end_idx": 2865023,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2586",
      "text": "Amazon Simple Storage Service API Reference\nprint(e)\nprint('Error getting object {} from bucket {}. Make sure they exist and\nyour bucket is in the same region as this function.'.format(key, bucket))\nraise e\nRuby\nSDK for Ruby\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Ruby.\nrequire 'json'\nrequire 'uri'\nrequire 'aws-sdk'\nputs 'Loading function'\ndef lambda_handler(event:, context:)\ns3 = Aws::S3::Client.new(region: 'region') # Your AWS region\n# puts \"Received event: #{JSON.dump(event)}\"\n# Get the object from the event and show its content type\nbucket = event['Records'][0]['s3']['bucket']['name']\nkey = URI.decode_www_form_component(event['Records'][0]['s3']['object']['key'],\nEncoding::UTF_8)\nbegin\nresponse = s3.get_object(bucket: bucket, key: key)\nputs \"CONTENT TYPE: #{response.content_type}\"\nreturn response.content_type\nrescue StandardError => e\nputs e.message\nputs \"Error getting object #{key} from bucket #{bucket}. Make sure they exist\nand your bucket is in the same region as this function.\"\nraise e\nend\nServerless examples API Version 2006-03-01 2581",
      "start_idx": 2865025,
      "end_idx": 2866211,
      "metadata": {
        "num_sentences": 8,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2587",
      "text": "Amazon Simple Storage Service API Reference\nend\nRust\nSDK for Rust\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the Serverless examples repository.\nConsuming an S3 event with Lambda using Rust.\n// Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.\n// SPDX-License-Identifier: Apache-2.0\nuse aws_lambda_events::event::s3::S3Event;\nuse aws_sdk_s3::{Client};\nuse lambda_runtime::{run, service_fn, Error, LambdaEvent};\n/// Main function\n#[tokio::main]\nasync fn main() -> Result<(), Error> {\ntracing_subscriber::fmt()\n.with_max_level(tracing::Level::INFO)\n.with_target(false)\n.without_time()\n.init();\n// Initialize the AWS SDK for Rust\nlet config = aws_config::load_from_env().await;\nlet s3_client = Client::new(&config);\nlet res = run(service_fn(|request: LambdaEvent<S3Event>| {\nfunction_handler(&s3_client, request)\n})).await;\nres\n}\nServerless examples API Version 2006-03-01 2582",
      "start_idx": 2866213,
      "end_idx": 2867151,
      "metadata": {
        "num_sentences": 6,
        "num_words": 111,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2588",
      "text": "Amazon Simple Storage Service API Reference\nasync fn function_handler(\ns3_client: &Client,\nevt: LambdaEvent<S3Event>\n) -> Result<(), Error> {\ntracing::info!(records = ?evt.payload.records.len(), \"Received request from\nSQS\");\nif evt.payload.records.len() == 0 {\ntracing::info!(\"Empty S3 event received\");\n}\nlet bucket = evt.payload.records[0].s3.bucket.name.as_ref().expect(\"Bucket\nname to exist\");\nlet key = evt.payload.records[0].s3.object.key.as_ref().expect(\"Object key to\nexist\");\ntracing::info!(\"Request is for {} and object {}\", bucket, key);\nlet s3_get_object_result = s3_client\n.get_object()\n.bucket(bucket)\n.key(key)\n.send()\n.await;\nmatch s3_get_object_result {\nOk(_) => tracing::info!(\"S3 Get Object success, the s3GetObjectResult\ncontains a 'body' property of type ByteStream\"),\nErr(_) => tracing::info!(\"Failure with S3 Get Object request\")\n}\nOk(())\n}\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nServerless examples API Version 2006-03-01 2583",
      "start_idx": 2867153,
      "end_idx": 2868281,
      "metadata": {
        "num_sentences": 8,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2589",
      "text": "Amazon Simple Storage Service API Reference\nCode examples for Amazon S3 Control using AWS SDKs\nThe following code examples show how to use Amazon S3 Control with an AWS software\ndevelopment kit (SDK).\nBasics are code examples that show you how to perform the essential operations within a service.\nActions are code excerpts from larger programs and must be run in context. While actions show you\nhow to call individual service functions, you can see actions in context in their related scenarios.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nGet started\nHello Amazon S3 Control\nThe following code example shows how to get started using 'Amazon S3 Control'\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport\nsoftware.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\nimport software.amazon.awssdk.core.client.config.ClientOverrideConfiguration;\nimport software.amazon.awssdk.core.retry.RetryMode;\nimport software.amazon.awssdk.core.retry.RetryPolicy;\nimport software.amazon.awssdk.http.async.SdkAsyncHttpClient;\nimport software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3control.S3ControlAsyncClient;\nimport software.amazon.awssdk.services.s3control.model.JobListDescriptor;\nimport software.amazon.awssdk.services.s3control.model.JobStatus;\nimport software.amazon.awssdk.services.s3control.model.ListJobsRequest;\nAmazon S3 Control API Version 2006-03-01 2584",
      "start_idx": 2868283,
      "end_idx": 2870033,
      "metadata": {
        "num_sentences": 9,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2590",
      "text": "Amazon Simple Storage Service API Reference\nimport software.amazon.awssdk.services.s3control.paginators.ListJobsPublisher;\nimport java.time.Duration;\nimport java.util.List;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.CompletionException;\n/**\n* Before running this example:\n* <p/>\n* The SDK must be able to authenticate AWS requests on your behalf. If you have\nnot configured\n* authentication for SDKs and tools,see https://docs.aws.amazon.com/sdkref/\nlatest/guide/access.html in the AWS SDKs and Tools Reference Guide.\n* <p/>\n* You must have a runtime environment configured with the Java SDK.\n* See https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html\nin the Developer Guide if this is not set up.\n*/\npublic class HelloS3Batch {\nprivate static S3ControlAsyncClient asyncClient;\npublic static void main(String[] args) {\nS3BatchActions actions = new S3BatchActions();\nString accountId = actions.getAccountId();\ntry {\nlistBatchJobsAsync(accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"List batch jobs failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to list batch jobs: \" + ex.getMessage());\n}\n}\n/**\n* Retrieves the asynchronous S3 Control client instance.\n* <p>\n* This method creates and returns a singleton instance of the {@link\nS3ControlAsyncClient}. If the instance\nAmazon S3 Control API Version 2006-03-01 2585",
      "start_idx": 2870035,
      "end_idx": 2871476,
      "metadata": {
        "num_sentences": 7,
        "num_words": 175,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2594",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nimport\nsoftware.amazon.awssdk.auth.credentials.EnvironmentVariableCredentialsProvider;\nimport software.amazon.awssdk.core.client.config.ClientOverrideConfiguration;\nimport software.amazon.awssdk.core.retry.RetryMode;\nimport software.amazon.awssdk.core.retry.RetryPolicy;\nimport software.amazon.awssdk.http.async.SdkAsyncHttpClient;\nimport software.amazon.awssdk.http.nio.netty.NettyNioAsyncHttpClient;\nimport software.amazon.awssdk.regions.Region;\nimport software.amazon.awssdk.services.s3control.S3ControlAsyncClient;\nimport software.amazon.awssdk.services.s3control.model.JobListDescriptor;\nimport software.amazon.awssdk.services.s3control.model.JobStatus;\nimport software.amazon.awssdk.services.s3control.model.ListJobsRequest;\nimport software.amazon.awssdk.services.s3control.paginators.ListJobsPublisher;\nimport java.time.Duration;\nimport java.util.List;\nimport java.util.concurrent.CompletableFuture;\nimport java.util.concurrent.CompletionException;\n/**\n* Before running this example:\n* <p/>\n* The SDK must be able to authenticate AWS requests on your behalf. If you have\nnot configured\n* authentication for SDKs and tools,see https://docs.aws.amazon.com/sdkref/\nlatest/guide/access.html in the AWS SDKs and Tools Reference Guide.\n* <p/>\n* You must have a runtime environment configured with the Java SDK.\n* See https://docs.aws.amazon.com/sdk-for-java/latest/developer-guide/setup.html\nin the Developer Guide if this is not set up.\n*/\npublic class HelloS3Batch {\nprivate static S3ControlAsyncClient asyncClient;\nBasics API Version 2006-03-01 2589",
      "start_idx": 2875238,
      "end_idx": 2876981,
      "metadata": {
        "num_sentences": 7,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2595",
      "text": "Amazon Simple Storage Service API Reference\npublic static void main(String[] args) {\nS3BatchActions actions = new S3BatchActions();\nString accountId = actions.getAccountId();\ntry {\nlistBatchJobsAsync(accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"List batch jobs failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to list batch jobs: \" + ex.getMessage());\n}\n}\n/**\n* Retrieves the asynchronous S3 Control client instance.\n* <p>\n* This method creates and returns a singleton instance of the {@link\nS3ControlAsyncClient}. If the instance\n* has not been created yet, it will be initialized with the following\nconfiguration:\n* <ul>\n* <li>Maximum concurrency: 100</li>\n* <li>Connection timeout: 60 seconds</li>\n* <li>Read timeout: 60 seconds</li>\n* <li>Write timeout: 60 seconds</li>\n* <li>API call timeout: 2 minutes</li>\n* <li>API call attempt timeout: 90 seconds</li>\n* <li>Retry policy: 3 retries</li>\n* <li>Region: US_EAST_1</li>\n* <li>Credentials provider: {@link\nEnvironmentVariableCredentialsProvider}</li>\n* </ul>\n*\n* @return the asynchronous S3 Control client instance\n*/\nprivate static S3ControlAsyncClient getAsyncClient() {\nif (asyncClient == null) {\nSdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder()\n.maxConcurrency(100)\nBasics API Version 2006-03-01 2590",
      "start_idx": 2876983,
      "end_idx": 2878335,
      "metadata": {
        "num_sentences": 3,
        "num_words": 173,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2597",
      "text": "Amazon Simple Storage Service API Reference\nSystem.out.println(\"The job priority is \" + job.priority());\n}\n}).thenAccept(response -> {\nSystem.out.println(\"Listing batch jobs completed\");\n}).exceptionally(ex -> {\nSystem.err.println(\"Failed to list batch jobs: \" + ex.getMessage());\nthrow new RuntimeException(ex);\n});\n}\n\u2022 For API details, see ListJobsPaginator in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nLearn the basics of Amazon S3 Control with an AWS SDK\nThe following code example shows how to learn core operations for'Amazon S3 Control'.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nLearn core operations.\npackage com.example.s3.batch;\nimport software.amazon.awssdk.services.s3.model.S3Exception;\nimport java.io.IOException;\nimport java.util.Map;\nimport java.util.Scanner;\nimport java.util.UUID;\nimport java.util.concurrent.CompletionException;\nBasics API Version 2006-03-01 2592",
      "start_idx": 2879704,
      "end_idx": 2880902,
      "metadata": {
        "num_sentences": 8,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2598",
      "text": "Amazon Simple Storage Service API Reference\npublic class S3BatchScenario {\npublic static final String DASHES = new String(new char[80]).replace(\"\\0\",\n\"-\");\nprivate static final String STACK_NAME = \"MyS3Stack\";\npublic static void main(String[] args) throws IOException {\nS3BatchActions actions = new S3BatchActions();\nString accountId = actions.getAccountId();\nString uuid = java.util.UUID.randomUUID().toString();\nScanner scanner = new Scanner(System.in);\nSystem.out.println(DASHES);\nSystem.out.println(\"Welcome to the Amazon S3 Batch basics scenario.\");\nSystem.out.println(\"\"\"\nS3 Batch operations enables efficient and cost-effective processing\nof large-scale\ndata stored in Amazon S3. It automatically scales resources to handle\nvarying workloads\nwithout the need for manual intervention.\nOne of the key features of S3 Batch is its ability to perform tagging\noperations on objects stored in\nS3 buckets. Users can leverage S3 Batch to apply, update, or remove\ntags on thousands or millions of\nobjects in a single operation, streamlining the management and\norganization of their data.\nThis can be particularly useful for tasks such as cost allocation,\nlifecycle management, or\nmetadata-driven workflows, where consistent and accurate tagging is\nessential.\nS3 Batch's scalability and serverless nature make it an ideal\nsolution for organizations with\ngrowing data volumes and complex data management requirements.\nThis Java program walks you through Amazon S3 Batch operations.\nLet's get started...\n\"\"\");\nwaitForInputToContinue(scanner);\n// Use CloudFormation to stand up the resource required for this\nscenario.\nBasics API Version 2006-03-01 2593",
      "start_idx": 2880904,
      "end_idx": 2882550,
      "metadata": {
        "num_sentences": 10,
        "num_words": 219,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2599",
      "text": "Amazon Simple Storage Service API Reference\nSystem.out.println(\"Use CloudFormation to stand up the resource required\nfor this scenario.\");\nCloudFormationHelper.deployCloudFormationStack(STACK_NAME);\nMap<String, String> stackOutputs =\nCloudFormationHelper.getStackOutputs(STACK_NAME);\nString iamRoleArn = stackOutputs.get(\"S3BatchRoleArn\");\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"Setup the required bucket for this scenario.\");\nwaitForInputToContinue(scanner);\nString bucketName = \"amzn-s3-demo-bucket-\" + UUID.randomUUID(); // Change\nbucket name.\nactions.createBucket(bucketName);\nString reportBucketName = \"arn:aws:s3:::\"+bucketName;\nString manifestLocation = \"arn:aws:s3:::\"+bucketName+\"/job-manifest.csv\";\nSystem.out.println(\"Populate the bucket with the required files.\");\nString[] fileNames = {\"job-manifest.csv\", \"object-key-1.txt\", \"object-\nkey-2.txt\", \"object-key-3.txt\", \"object-key-4.txt\"};\nactions.uploadFilesToBucket(bucketName, fileNames, actions);\nwaitForInputToContinue(scanner);\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"1. Create a S3 Batch Job\");\nSystem.out.println(\"This job tags all objects listed in the manifest file\nwith tags\");\nwaitForInputToContinue(scanner);\nString jobId ;\ntry {\njobId = actions.createS3JobAsync(accountId, iamRoleArn,\nmanifestLocation, reportBucketName, uuid).join();\nSystem.out.println(\"The Job id is \" + jobId);\n} catch (S3Exception e) {\nSystem.err.println(\"SSM error: \" + e.getMessage());\nreturn;\n} catch (RuntimeException e) {\nSystem.err.println(\"Unexpected error: \" + e.getMessage());\nreturn;\n}\nwaitForInputToContinue(scanner);\nBasics API Version 2006-03-01 2594",
      "start_idx": 2882552,
      "end_idx": 2884234,
      "metadata": {
        "num_sentences": 6,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2600",
      "text": "Amazon Simple Storage Service API Reference\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"2. Update an existing S3 Batch Operations job's\npriority\");\nSystem.out.println(\"\"\"\nIn this step, we modify the job priority value. The higher the\nnumber, the higher the priority.\nSo, a job with a priority of `30` would have a higher priority than\na job with\na priority of `20`. This is a common way to represent the priority\nof a task\nor job, with higher numbers indicating a higher priority.\nEnsure that the job status allows for priority updates. Jobs in\ncertain\nstates (e.g., Cancelled, Failed, or Completed) cannot have their\npriorities\nupdated. Only jobs in the Active or Suspended state typically allow\npriority\nupdates.\n\"\"\");\ntry {\nactions.updateJobPriorityAsync(jobId, accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"Update job priority failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to update job priority: \" +\nex.getMessage());\n}\nwaitForInputToContinue(scanner);\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"3. Cancel the S3 Batch job\");\nSystem.out.print(\"Do you want to cancel the Batch job? (y/n): \");\nString cancelAns = scanner.nextLine();\nif (cancelAns != null && cancelAns.trim().equalsIgnoreCase(\"y\")) {\ntry {\nBasics API Version 2006-03-01 2595",
      "start_idx": 2884236,
      "end_idx": 2885623,
      "metadata": {
        "num_sentences": 11,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2601",
      "text": "Amazon Simple Storage Service API Reference\nactions.cancelJobAsync(jobId, accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"Cancel job failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to cancel job: \" + ex.getMessage());\n}\n} else {\nSystem.out.println(\"Job \" +jobId +\" was not canceled.\");\n}\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"4. Describe the job that was just created\");\nwaitForInputToContinue(scanner);\ntry {\nactions.describeJobAsync(jobId, accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"Describe job failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to describe job: \" + ex.getMessage());\n}\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"5. Describe the tags associated with the job\");\nwaitForInputToContinue(scanner);\ntry {\nactions.getJobTagsAsync(jobId, accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"Get job tags failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to get job tags: \" + ex.getMessage());\nBasics API Version 2006-03-01 2596",
      "start_idx": 2885625,
      "end_idx": 2886856,
      "metadata": {
        "num_sentences": 4,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2602",
      "text": "Amazon Simple Storage Service API Reference\n}\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"6. Update Batch Job Tags\");\nwaitForInputToContinue(scanner);\ntry {\nactions.putJobTaggingAsync(jobId, accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"Put job tagging failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to put job tagging: \" + ex.getMessage());\n}\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.println(\"7. Delete the Amazon S3 Batch job tagging.\");\nSystem.out.print(\"Do you want to delete Batch job tagging? (y/n)\");\nString delAns = scanner.nextLine();\nif (delAns != null && delAns.trim().equalsIgnoreCase(\"y\")) {\ntry {\nactions.deleteBatchJobTagsAsync(jobId, accountId)\n.exceptionally(ex -> {\nSystem.err.println(\"Delete batch job tags failed: \" +\nex.getMessage());\nreturn null;\n})\n.join();\n} catch (CompletionException ex) {\nSystem.err.println(\"Failed to delete batch job tags: \" +\nex.getMessage());\n}\n} else {\nSystem.out.println(\"Tagging was not deleted.\");\n}\nSystem.out.println(DASHES);\nSystem.out.println(DASHES);\nSystem.out.print(\"Do you want to delete the AWS resources used in this\nscenario? (y/n)\");\nBasics API Version 2006-03-01 2597",
      "start_idx": 2886858,
      "end_idx": 2888126,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2603",
      "text": "Amazon Simple Storage Service API Reference\nString delResAns = scanner.nextLine();\nif (delResAns != null && delResAns.trim().equalsIgnoreCase(\"y\")) {\nactions.deleteFilesFromBucket(bucketName, fileNames, actions);\nactions.deleteBucketFolderAsync(bucketName);\nactions.deleteBucket(bucketName)\n.thenRun(() -> System.out.println(\"Bucket deletion completed\"))\n.exceptionally(ex -> {\nSystem.err.println(\"Error occurred: \" + ex.getMessage());\nreturn null;\n});\nCloudFormationHelper.destroyCloudFormationStack(STACK_NAME);\n} else {\nSystem.out.println(\"The AWS resources were not deleted.\");\n}\nSystem.out.println(\"The Amazon S3 Batch scenario has successfully\ncompleted.\");\nSystem.out.println(DASHES);\n}\nprivate static void waitForInputToContinue(Scanner scanner) {\nwhile (true) {\nSystem.out.println();\nSystem.out.println(\"Enter 'c' followed by <ENTER> to continue:\");\nString input = scanner.nextLine();\nif (input.trim().equalsIgnoreCase(\"c\")) {\nSystem.out.println(\"Continuing with the program...\");\nSystem.out.println();\nbreak;\n} else {\n// Handle invalid input.\nSystem.out.println(\"Invalid input. Please try again.\");\n}\n}\n}\n}\nAn action class that wraps operations.\npublic class S3BatchActions {\nBasics API Version 2006-03-01 2598",
      "start_idx": 2888128,
      "end_idx": 2889348,
      "metadata": {
        "num_sentences": 7,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2604",
      "text": "Amazon Simple Storage Service API Reference\nprivate static S3ControlAsyncClient asyncClient;\nprivate static S3AsyncClient s3AsyncClient ;\n/**\n* Retrieves the asynchronous S3 Control client instance.\n* <p>\n* This method creates and returns a singleton instance of the {@link\nS3ControlAsyncClient}. If the instance\n* has not been created yet, it will be initialized with the following\nconfiguration:\n* <ul>\n* <li>Maximum concurrency: 100</li>\n* <li>Connection timeout: 60 seconds</li>\n* <li>Read timeout: 60 seconds</li>\n* <li>Write timeout: 60 seconds</li>\n* <li>API call timeout: 2 minutes</li>\n* <li>API call attempt timeout: 90 seconds</li>\n* <li>Retry policy: 3 retries</li>\n* <li>Region: US_EAST_1</li>\n* <li>Credentials provider: {@link\nEnvironmentVariableCredentialsProvider}</li>\n* </ul>\n*\n* @return the asynchronous S3 Control client instance\n*/\nprivate static S3ControlAsyncClient getAsyncClient() {\nif (asyncClient == null) {\nSdkAsyncHttpClient httpClient = NettyNioAsyncHttpClient.builder()\n.maxConcurrency(100)\n.connectionTimeout(Duration.ofSeconds(60))\n.readTimeout(Duration.ofSeconds(60))\n.writeTimeout(Duration.ofSeconds(60))\n.build();\nClientOverrideConfiguration overrideConfig =\nClientOverrideConfiguration.builder()\n.apiCallTimeout(Duration.ofMinutes(2))\n.apiCallAttemptTimeout(Duration.ofSeconds(90))\n.retryPolicy(RetryPolicy.builder()\n.numRetries(3)\n.build())\n.build();\nBasics API Version 2006-03-01 2599",
      "start_idx": 2889350,
      "end_idx": 2890774,
      "metadata": {
        "num_sentences": 3,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2621",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 UpdateJobPriority\n\u2022 UpdateJobStatus\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nActions for Amazon S3 Control using AWS SDKs\nThe following code examples demonstrate how to perform individual Amazon S3 Control actions\nwith AWS SDKs. Each example includes a link to GitHub, where you can find instructions for setting\nup and running the code.\nThe following examples include only the most commonly used actions. For a complete list, see the\nAmazon S3 Control API Reference.\nExamples\n\u2022 Use CreateJob with an AWS SDK or CLI\n\u2022 Use DeleteJobTagging with an AWS SDK\n\u2022 Use DescribeJob with an AWS SDK or CLI\n\u2022 Use GetJobTagging with an AWS SDK\n\u2022 Use PutJobTagging with an AWS SDK\n\u2022 Use UpdateJobPriority with an AWS SDK or CLI\n\u2022 Use UpdateJobStatus with an AWS SDK or CLI\nUse CreateJob with an AWS SDK or CLI\nThe following code examples show how to use CreateJob.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nBasics API Version 2006-03-01 2616",
      "start_idx": 2912311,
      "end_idx": 2913587,
      "metadata": {
        "num_sentences": 9,
        "num_words": 219,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2622",
      "text": "Amazon Simple Storage Service API Reference\nCLI\nAWS CLI\nTo create an Amazon S3 batch operations job\nThe following create-job example creates an Amazon S3 batch operations job to tag\nobjects as confidential` in the bucket ``employee-records.\naws s3control create-job \\\n--account-id 123456789012 \\\n--operation '{\"S3PutObjectTagging\": { \"TagSet\": [{\"Key\":\"confidential\",\n\"Value\":\"true\"}] }}' \\\n--report '{\"Bucket\":\"arn:aws:s3:::employee-records-logs\",\"Prefix\":\"batch-op-\ncreate-job\",\n\"Format\":\"Report_CSV_20180820\",\"Enabled\":true,\"ReportScope\":\"AllTasks\"}' \\\n--manifest '{\"Spec\":{\"Format\":\"S3BatchOperations_CSV_20180820\",\"Fields\":\n[\"Bucket\",\"Key\"]},\"Location\":{\"ObjectArn\":\"arn:aws:s3:::employee-records-logs/\ninv-report/7a6a9be4-072c-407e-85a2-\nec3e982f773e.csv\",\"ETag\":\"69f52a4e9f797e987155d9c8f5880897\"}}' \\\n--priority 42 \\\n--role-arn arn:aws:iam::123456789012:role/S3BatchJobRole\nOutput:\n{\n\"JobId\": \"93735294-df46-44d5-8638-6356f335324e\"\n}\n\u2022 For API details, see CreateJob in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\nBasics API Version 2006-03-01 2617",
      "start_idx": 2913589,
      "end_idx": 2914774,
      "metadata": {
        "num_sentences": 5,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2629",
      "text": "Amazon Simple Storage Service API Reference\n.report(jobReport)\n.confirmationRequired(requiresConfirmation)\n.build();\n// Create the job and get the result.\nCreateJobResponse result = s3ControlClient.createJob(request);\nreturn result.jobId();\n}\n\u2022 For API details, see CreateJob in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DeleteJobTagging with an AWS SDK\nThe following code example shows how to use DeleteJobTagging.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Asynchronously deletes the tags associated with a specific batch job.\n*\n* @param jobId The ID of the batch job whose tags should be deleted.\n* @param accountId The ID of the account associated with the batch job.\nBasics API Version 2006-03-01 2624",
      "start_idx": 2922767,
      "end_idx": 2923965,
      "metadata": {
        "num_sentences": 12,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2630",
      "text": "Amazon Simple Storage Service API Reference\n* @return A CompletableFuture that completes when the job tags have been\nsuccessfully deleted, or an exception is thrown if the deletion fails.\n*/\npublic CompletableFuture<Void> deleteBatchJobTagsAsync(String jobId, String\naccountId) {\nDeleteJobTaggingRequest jobTaggingRequest =\nDeleteJobTaggingRequest.builder()\n.accountId(accountId)\n.jobId(jobId)\n.build();\nreturn asyncClient.deleteJobTagging(jobTaggingRequest)\n.thenAccept(response -> {\nSystem.out.println(\"You have successfully deleted \" + jobId + \"\ntagging.\");\n})\n.exceptionally(ex -> {\nSystem.err.println(\"Failed to delete job tags: \" +\nex.getMessage());\nthrow new RuntimeException(ex);\n});\n}\n\u2022 For API details, see DeleteJobTagging in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse DescribeJob with an AWS SDK or CLI\nThe following code examples show how to use DescribeJob.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nBasics API Version 2006-03-01 2625",
      "start_idx": 2923967,
      "end_idx": 2925255,
      "metadata": {
        "num_sentences": 8,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2632",
      "text": "Amazon Simple Storage Service API Reference\n},\n\"RoleArn\": \"arn:aws:iam::123456789012:role/S3BatchJobRole\",\n\"ProgressSummary\": {\n\"TotalNumberOfTasks\": 8,\n\"NumberOfTasksFailed\": 0,\n\"NumberOfTasksSucceeded\": 8\n},\n\"Priority\": 42,\n\"Report\": {\n\"ReportScope\": \"AllTasks\",\n\"Format\": \"Report_CSV_20180820\",\n\"Enabled\": true,\n\"Prefix\": \"batch-op-create-job\",\n\"Bucket\": \"arn:aws:s3:::employee-records-logs\"\n},\n\"JobArn\": \"arn:aws:s3:us-west-2:123456789012:job/93735294-\ndf46-44d5-8638-6356f335324e\",\n\"CreationTime\": \"2019-10-03T21:48:48.048Z\",\n\"Status\": \"Complete\"\n}\n}\n\u2022 For API details, see DescribeJob in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Asynchronously describes the specified job.\n*\n* @param jobId the ID of the job to describe\n* @param accountId the ID of the AWS account associated with the job\n* @return a {@link CompletableFuture} that completes when the job\ndescription is available\n* @throws RuntimeException if an error occurs while describing the job\nBasics API Version 2006-03-01 2627",
      "start_idx": 2926112,
      "end_idx": 2927241,
      "metadata": {
        "num_sentences": 5,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2634",
      "text": "Amazon Simple Storage Service API Reference\nSystem.err.println(\"Failed to describe job: \" + ex.getMessage());\nthrow new RuntimeException(ex);\n});\n}\n\u2022 For API details, see DescribeJob in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse GetJobTagging with an AWS SDK\nThe following code example shows how to use GetJobTagging.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Asynchronously retrieves the tags associated with a specific job in an AWS\naccount.\n*\n* @param jobId the ID of the job for which to retrieve the tags\n* @param accountId the ID of the AWS account associated with the job\n* @return a {@link CompletableFuture} that completes when the job tags have\nbeen retrieved, or with an exception if the operation fails\n* @throws RuntimeException if an error occurs while retrieving the job tags\nBasics API Version 2006-03-01 2629",
      "start_idx": 2928910,
      "end_idx": 2930227,
      "metadata": {
        "num_sentences": 9,
        "num_words": 222,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2635",
      "text": "Amazon Simple Storage Service API Reference\n*/\npublic CompletableFuture<Void> getJobTagsAsync(String jobId, String\naccountId) {\nGetJobTaggingRequest request = GetJobTaggingRequest.builder()\n.jobId(jobId)\n.accountId(accountId)\n.build();\nreturn asyncClient.getJobTagging(request)\n.thenAccept(response -> {\nList<S3Tag> tags = response.tags();\nif (tags.isEmpty()) {\nSystem.out.println(\"No tags found for job ID: \" + jobId);\n} else {\nfor (S3Tag tag : tags) {\nSystem.out.println(\"Tag key is: \" + tag.key());\nSystem.out.println(\"Tag value is: \" + tag.value());\n}\n}\n})\n.exceptionally(ex -> {\nSystem.err.println(\"Failed to get job tags: \" + ex.getMessage());\nthrow new RuntimeException(ex); // Propagate the exception\n});\n}\n\u2022 For API details, see GetJobTagging in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse PutJobTagging with an AWS SDK\nThe following code example shows how to use PutJobTagging.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nBasics API Version 2006-03-01 2630",
      "start_idx": 2930229,
      "end_idx": 2931532,
      "metadata": {
        "num_sentences": 6,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2636",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Asynchronously adds tags to a job in the system.\n*\n* @param jobId the ID of the job to add tags to\n* @param accountId the account ID associated with the job\n* @return a CompletableFuture that completes when the tagging operation is\nfinished\n*/\npublic CompletableFuture<Void> putJobTaggingAsync(String jobId, String\naccountId) {\nS3Tag departmentTag = S3Tag.builder()\n.key(\"department\")\n.value(\"Marketing\")\n.build();\nS3Tag fiscalYearTag = S3Tag.builder()\n.key(\"FiscalYear\")\n.value(\"2020\")\n.build();\nPutJobTaggingRequest putJobTaggingRequest =\nPutJobTaggingRequest.builder()\n.jobId(jobId)\n.accountId(accountId)\n.tags(departmentTag, fiscalYearTag)\n.build();\nreturn asyncClient.putJobTagging(putJobTaggingRequest)\n.thenRun(() -> {\nSystem.out.println(\"Additional Tags were added to job \" + jobId);\n})\n.exceptionally(ex -> {\nBasics API Version 2006-03-01 2631",
      "start_idx": 2931534,
      "end_idx": 2932582,
      "metadata": {
        "num_sentences": 4,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2637",
      "text": "Amazon Simple Storage Service API Reference\nSystem.err.println(\"Failed to add tags to job: \" +\nex.getMessage());\nthrow new RuntimeException(ex); // Propagate the exception\n});\n}\n\u2022 For API details, see PutJobTagging in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse UpdateJobPriority with an AWS SDK or CLI\nThe following code examples show how to use UpdateJobPriority.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nCLI\nAWS CLI\nTo update the job priority of an Amazon S3 batch operations job\nThe following update-job-priority example updates the specified job to a new priority.\naws s3control update-job-priority \\\n--account-id 123456789012 \\\n--job-id 8d9a18fe-c303-4d39-8ccc-860d372da386 \\\n--priority 52\nOutput:\n{\n\"JobId\": \"8d9a18fe-c303-4d39-8ccc-860d372da386\",\n\"Priority\": 52\nBasics API Version 2006-03-01 2632",
      "start_idx": 2932584,
      "end_idx": 2933728,
      "metadata": {
        "num_sentences": 7,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2638",
      "text": "Amazon Simple Storage Service API Reference\n}\n\u2022 For API details, see UpdateJobPriority in AWS CLI Command Reference.\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Updates the priority of a job asynchronously.\n*\n* @param jobId the ID of the job to update\n* @param accountId the ID of the account associated with the job\n* @return a {@link CompletableFuture} that represents the asynchronous\noperation, which completes when the job priority has been updated or an error\nhas occurred\n*/\npublic CompletableFuture<Void> updateJobPriorityAsync(String jobId, String\naccountId) {\nUpdateJobPriorityRequest priorityRequest =\nUpdateJobPriorityRequest.builder()\n.accountId(accountId)\n.jobId(jobId)\n.priority(60)\n.build();\nCompletableFuture<Void> future = new CompletableFuture<>();\ngetAsyncClient().updateJobPriority(priorityRequest)\n.thenAccept(response -> {\nSystem.out.println(\"The job priority was updated\");\nfuture.complete(null); // Complete the CompletableFuture on\nsuccessful execution\n})\n.exceptionally(ex -> {\nSystem.err.println(\"Failed to update job priority: \" +\nex.getMessage());\nBasics API Version 2006-03-01 2633",
      "start_idx": 2933730,
      "end_idx": 2934950,
      "metadata": {
        "num_sentences": 5,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2639",
      "text": "Amazon Simple Storage Service API Reference\nfuture.completeExceptionally(ex); // Complete the\nCompletableFuture exceptionally on error\nreturn null; // Return null to handle the exception\n});\nreturn future;\n}\n\u2022 For API details, see UpdateJobPriority in AWS SDK for Java 2.x API Reference.\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nUse UpdateJobStatus with an AWS SDK or CLI\nThe following code examples show how to use UpdateJobStatus.\nAction examples are code excerpts from larger programs and must be run in context. You can see\nthis action in context in the following code example:\n\u2022 Learn the basics\nCLI\nAWS CLI\nTo update the status of an Amazon S3 batch operations job\nThe following update-job-status example cancels the specified job which is awaiting\napproval.\naws s3control update-job-status \\\n--account-id 123456789012 \\\n--job-id 8d9a18fe-c303-4d39-8ccc-860d372da386 \\\n--requested-job-status Cancelled\nOutput:\n{\nBasics API Version 2006-03-01 2634",
      "start_idx": 2934952,
      "end_idx": 2936080,
      "metadata": {
        "num_sentences": 7,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2641",
      "text": "Amazon Simple Storage Service API Reference\nJava\nSDK for Java 2.x\nNote\nThere's more on GitHub. Find the complete example and learn how to set up and run\nin the AWS Code Examples Repository.\n/**\n* Cancels a job asynchronously.\n*\n* @param jobId The ID of the job to be canceled.\n* @param accountId The ID of the account associated with the job.\n* @return A {@link CompletableFuture} that completes when the job status has\nbeen updated to \"CANCELLED\".\n* If an error occurs during the update, the returned future will\ncomplete exceptionally.\n*/\npublic CompletableFuture<Void> cancelJobAsync(String jobId, String accountId)\n{\nUpdateJobStatusRequest updateJobStatusRequest =\nUpdateJobStatusRequest.builder()\n.accountId(accountId)\n.jobId(jobId)\n.requestedJobStatus(String.valueOf(JobStatus.CANCELLED))\n.build();\nreturn asyncClient.updateJobStatus(updateJobStatusRequest)\n.thenAccept(updateJobStatusResponse -> {\nSystem.out.println(\"Job status updated to: \" +\nupdateJobStatusResponse.status());\n})\n.exceptionally(ex -> {\nSystem.err.println(\"Failed to cancel job: \" + ex.getMessage());\nthrow new RuntimeException(ex); // Propagate the exception\n});\n}\n\u2022 For API details, see UpdateJobStatus in AWS SDK for Java 2.x API Reference.\nBasics API Version 2006-03-01 2636",
      "start_idx": 2936936,
      "end_idx": 2938190,
      "metadata": {
        "num_sentences": 9,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2642",
      "text": "Amazon Simple Storage Service API Reference\nFor a complete list of AWS SDK developer guides and code examples, see Developing with Amazon\nS3 using the AWS SDKs. This topic also includes information about getting started and details\nabout previous SDK versions.\nBasics API Version 2006-03-01 2637",
      "start_idx": 2938192,
      "end_idx": 2938487,
      "metadata": {
        "num_sentences": 3,
        "num_words": 46,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2643",
      "text": "Amazon Simple Storage Service API Reference\nAuthenticating Requests (AWS Signature Version 4)\nTopics\n\u2022 Authentication Methods\n\u2022 Introduction to Signing Requests\n\u2022 Authenticating Requests: Using the Authorization Header (AWS Signature Version 4)\n\u2022 Authenticating Requests: Using Query Parameters (AWS Signature Version 4)\n\u2022 Examples: Signature Calculations in AWS Signature Version 4\n\u2022 Authenticating Requests: Browser-Based Uploads Using POST (AWS Signature Version 4)\n\u2022 Amazon S3 Signature Version 4 Authentication Specific Policy Keys\nEvery interaction with Amazon S3 is either authenticated or anonymous. This section explains\nrequest authentication with the AWS Signature Version 4 algorithm.\nNote\nIf you use the AWS SDKs (see Sample Code and Libraries) to send your requests, you don't\nneed to read this section because the SDK clients authenticate your requests by using\naccess keys that you provide. Unless you have a good reason not to, you should always use\nthe AWS SDKs. In Regions that support both signature versions, you can request AWS SDKs\nto use specific signature version. For more information, see Specifying Signature Version in\nRequest Authentication in the Amazon Simple Storage Service User Guide. You need to read\nthis section only if you are implementing the AWS Signature Version 4 algorithm in your\ncustom client.\nAuthentication with AWS Signature Version 4 provides some or all of the following, depending on\nhow you choose to sign your request:\n\u2022 Verification of the identity of the requester \u2013 Authenticated requests require a signature that\nyou create by using your access keys (access key ID, secret access key). For information about\ngetting access keys, see Understanding and Getting Your Security Credentials in the AWS General\nReference. If you are using temporary security credentials, the signature calculations also require\nAPI Version 2006-03-01 2638",
      "start_idx": 2938489,
      "end_idx": 2940378,
      "metadata": {
        "num_sentences": 10,
        "num_words": 286,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2644",
      "text": "Amazon Simple Storage Service API Reference\na security token. For more information, see Requesting Temporary Security Credentials in the\nIAM User Guide.\n\u2022 In-transit data protection \u2013 In order to prevent tampering with a request while it is in transit,\nyou use some of the request elements to calculate the request signature. Upon receiving the\nrequest, Amazon S3 calculates the signature by using the same request elements. If any request\ncomponent received by Amazon S3 does not match the component that was used to calculate\nthe signature, Amazon S3 will reject the request.\n\u2022 Protect against reuse of the signed portions of the request \u2013 The signed portions (using\nAWS Signatures) of requests are valid within 15 minutes of the timestamp in the request. An\nunauthorized party who has access to a signed request can modify the unsigned portions of the\nrequest without affecting the request's validity in the 15 minute window. Because of this, we\nrecommend that you maximize protection by signing request headers and body, making HTTPS\nrequests to Amazon S3, and by using the s3:x-amz-content-sha256 condition key (see\nAmazon S3 Signature Version 4 Authentication Specific Policy Keys) in AWS policies to require\nusers to sign Amazon S3 request bodies.\nNote\nAmazon S3 supports Signature Version 4, a protocol for authenticating inbound API\nrequests to AWS services, in all AWS Regions. At this time, AWS Regions created before\nJanuary 30, 2014 will continue to support the previous protocol, Signature Version 2. Any\nnew Regions after January 30, 2014 will support only Signature Version 4 and therefore all\nrequests to those Regions must be made with Signature Version 4. For more information\nabout AWS Signature Version 2, see Signing and Authenticating REST Requests in the\nAmazon Simple Storage Service User Guide.\nAuthentication Methods\nYou can express authentication information by using one of the following methods:\n\u2022 HTTP Authorization header \u2013 Using the HTTP Authorization header is the most common\nmethod of authenticating an Amazon S3 request. All of the Amazon S3 REST operations (except\nfor browser-based uploads using POST requests) require this header. For more information about\nAuthentication Methods API Version 2006-03-01 2639",
      "start_idx": 2940380,
      "end_idx": 2942628,
      "metadata": {
        "num_sentences": 15,
        "num_words": 354,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2645",
      "text": "Amazon Simple Storage Service API Reference\nthe Authorization header value, and how to calculate signature and related options, see\nAuthenticating Requests: Using the Authorization Header (AWS Signature Version 4).\n\u2022 Query string parameters \u2013 You can use a query string to express a request entirely in a URL. In\nthis case, you use query parameters to provide request information, including the authentication\ninformation. Because the request signature is part of the URL, this type of URL is often referred\nto as a presigned URL. You can use presigned URLs to embed clickable links, which can be valid\nfor up to seven days, in HTML. For more information, see Authenticating Requests: Using Query\nParameters (AWS Signature Version 4).\nAmazon S3 also supports browser-based uploads that use HTTP POST requests. With an HTTP\nPOST request, you can upload content to Amazon S3 directly from the browser. For information\nabout authenticating POST requests, see Browser-Based Uploads Using POST (AWS Signature\nVersion 4).\nIntroduction to Signing Requests\nAuthentication information that you send in a request must include a signature. To calculate a\nsignature, you first concatenate select request elements to form a string, referred to as the string\nto sign. You then use a signing key to calculate the hash-based message authentication code\n(HMAC) of the string to sign.\nIn AWS Signature Version 4, you don't use your secret access key to sign the request. Instead, you\nfirst use your secret access key to derive a signing key. The derived signing key is specific to the\ndate, service, and Region. For more information about how to derive a signing key in different\nprogramming languages, see Examples of how to derive a signing key for Signature Version 4.\nThe following diagram illustrates the general process of computing a signature.\nIntroduction to Signing Requests API Version 2006-03-01 2640",
      "start_idx": 2942630,
      "end_idx": 2944524,
      "metadata": {
        "num_sentences": 18,
        "num_words": 302,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2646",
      "text": "Amazon Simple Storage Service API Reference\nThe string to sign depends on the request type. For example, when you use the HTTP Authorization\nheader or the query parameters for authentication, you use a varying combination of request\nelements to create the string to sign. For an HTTP POST request, the POST policy in the request is\nthe string you sign. For more information about computing string to sign, follow links provided at\nthe end of this section.\nFor signing key, the diagram shows series of calculations, where result of each step you feed into\nthe next step. The final step is the signing key.\nUpon receiving an authenticated request, Amazon S3 servers re-create the signature by using the\nauthentication information that is contained in the request. If the signatures match, Amazon S3\nprocesses your request; otherwise, the request is rejected.\nFor more information about authenticating requests, see the following topics:\n\u2022 Authenticating Requests: Using the Authorization Header (AWS Signature Version 4)\n\u2022 Authenticating Requests: Using Query Parameters (AWS Signature Version 4)\n\u2022 Browser-Based Uploads Using POST (AWS Signature Version 4)\nAuthenticating Requests: Using the Authorization Header (AWS\nSignature Version 4)\nTopics\n\u2022 Overview\nUsing an Authorization Header API Version 2006-03-01 2641",
      "start_idx": 2944526,
      "end_idx": 2945839,
      "metadata": {
        "num_sentences": 9,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2647",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Signature Calculations for the Authorization Header: Transferring Payload in a Single Chunk\n(AWS Signature Version 4)\n\u2022 Signature Calculations for the Authorization Header: Transferring Payload in Multiple Chunks\n(Chunked Upload) (AWS Signature Version 4)\n\u2022 Signature Calculations for the Authorization Header: Including Trailing Headers (Chunked\nUpload) (AWS Signature Version 4)\nOverview\nUsing the HTTP Authorization header is the most common method of providing authentication\ninformation. Except for POST requests and requests that are signed by using query parameters,\nall Amazon S3 operations use the Authorization request header to provide authentication\ninformation.\nThe following is an example of the Authorization header value. Line breaks are added to this\nexample for readability:\nAuthorization: AWS4-HMAC-SHA256\nCredential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/aws4_request,\nSignedHeaders=host;range;x-amz-date,\nSignature=fe5f80f77d5fa3beca038a248ff027d0445342fe2855ddc963176630326f1024\nThe following table describes the various components of the Authorization header value in the\npreceding example:\nComponent Description\nAWS4-HMAC-SHA256\nThe algorithm that was used to calculate the signature. You\nmust provide this value when you use AWS Signature Version\n4 for authentication.\nThe string specifies AWS Signature Version 4 (AWS4) and the\nsigning algorithm (HMAC-SHA256 ).\nCredential\nOverview API Version 2006-03-01 2642",
      "start_idx": 2945841,
      "end_idx": 2947326,
      "metadata": {
        "num_sentences": 7,
        "num_words": 184,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2648",
      "text": "Amazon Simple Storage Service API Reference\nComponent Description\nYour access key ID and the scope information, which includes\nthe date, Region, and service that were used to calculate the\nsignature.\nThis string has the following form:\n<your-access-key-id> /<date>/<aws-region> /<aws-serv\nice> /aws4_request\nWhere:\n\u2022\n<date> value is specified using YYYYMMDD format.\n\u2022\n<aws-service> value is s3 when sending request to\nAmazon S3.\nSignedHeaders\nA semicolon-separated list of request headers that you\nused to compute Signature . The list includes header\nnames only, and the header names must be in lowercase. For\nexample:\nhost;range;x-amz-date\nSignature The 256-bit signature expressed as 64 lowercase hexadecimal\ncharacters. For example:\nfe5f80f77d5fa3beca038a248ff027d0445342fe2855d\ndc963176630326f1024\nNote that the signature calculations vary depending on the\noption you choose to transfer the payload.\nOverview API Version 2006-03-01 2643",
      "start_idx": 2947328,
      "end_idx": 2948268,
      "metadata": {
        "num_sentences": 8,
        "num_words": 127,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2649",
      "text": "Amazon Simple Storage Service API Reference\nThe signature calculations vary depending on the method you choose to transfer the request\npayload. S3 supports the following options:\n\u2022 Transfer payload in a single chunk \u2013 In this case, you have the following signature calculation\noptions:\n\u2022 Signed payload option \u2013 You can optionally compute the entire payload checksum and\ninclude it in signature calculation. This provides added security but you need to read your\npayload twice or buffer it in memory.\nFor example, in order to upload a file, you need to read the file first to compute a payload hash\nfor signature calculation and again for transmission when you create the request. For smaller\npayloads, this approach might be preferable. However, for large files, reading the file twice can\nbe inefficient, so you might want to upload data in chunks instead.\nWe recommend you include payload checksum for added security.\n\u2022 Unsigned payload option \u2013 Do not include payload checksum in signature calculation.\nFor step-by-step instructions to calculate signature and construct the Authorization header\nvalue, see Signature Calculations for the Authorization Header: Transferring Payload in a Single\nChunk (AWS Signature Version 4).\n\u2022 Transfer payload in multiple chunks (chunked upload) \u2013 In this case you transfer payload in\nchunks. You can transfer a payload in chunks regardless of the payload size.\nYou can break up your payload into chunks. These can be fixed or variable-size chunks. By\nuploading data in chunks, you avoid reading the entire payload to calculate the signature.\nInstead, for the first chunk, you calculate a seed signature that uses only the request headers.\nThe second chunk contains the signature for the first chunk, and each subsequent chunk contains\nthe signature for the chunk that precedes it. At the end of the upload, you send a final chunk\nwith 0 bytes of data that contains the signature of the last chunk of the payload. For more\ninformation, see Signature Calculations for the Authorization Header: Transferring Payload in\nMultiple Chunks (Chunked Upload) (AWS Signature Version 4).\nWhen signing your requests, you can use either AWS Signature Version 4 or AWS Signature Version\n4A. The key difference between the two is determined by how the signature is calculated. With\nAWS Signature Version 4A, the signature does not include Region-specific information and is\ncalculated using the AWS4-ECDSA-P256-SHA256 algorithm.\nOverview API Version 2006-03-01 2644",
      "start_idx": 2948270,
      "end_idx": 2950758,
      "metadata": {
        "num_sentences": 22,
        "num_words": 393,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2650",
      "text": "Amazon Simple Storage Service API Reference\nIn addition to these options, you have the option of including a trailer with your request. In order\nto include a trailer with your request, you need to specify that in the header by setting x-amz-\ncontent-sha256 to the appropriate value. If you are using a trailing header, you must include\nx-amz-trailer in the header and specify the trailing header names as a string in a comma-\nseparated list. All trailing headers are written after the final chunk. If you're uploading the data\nin multiple chunks, you must send a final chunk with 0 bytes of data before sending the trailing\nheader.\nWhen you send a request, you must tell Amazon S3 which of the preceding options you have\nchosen in your signature calculation, by adding the x-amz-content-sha256 header with one of\nthe following values:\nHeader value Description\nActual payload checksum This value is the actual checksum of your object and is only\nvalue possible when you are uploading the data in a single chunk.\nUNSIGNED-PAYLOAD Use this when you are uploading the object as a single\nunsigned chunk.\nSTREAMING-UNSIGNED- Use this when sending an unsigned payload over multiple\nPAYLOAD-TRAILER chunks. In this case you also have a trailing header after the\nchunk is uploaded.\nSTREAMING-AWS4-HMAC- Use this when sending a payload over multiple chunks, and\nSHA256-PAYLOAD the chunks are signed using AWS4-HMAC-SHA256 . This\nproduces a SigV4 signature.\nSTREAMING-AWS4-HMAC- Use this when sending a payload over multiple chunks, and\nSHA256-PAYLOAD-TRAILER the chunks are signed using AWS4-HMAC-SHA256 . This\nproduces a SigV4 signature. In addition, the digest for the\nchunks is included as a trailing header.\nSTREAMING-AWS4-ECDSA- Use this when sending a payload over multiple chunks, and\nP256-SHA256-PAYLOAD the chunks are signed using AWS4-ECDSA-P256-SHA256 .\nThis produces a SigV4A signature.\nOverview API Version 2006-03-01 2645",
      "start_idx": 2950760,
      "end_idx": 2952685,
      "metadata": {
        "num_sentences": 17,
        "num_words": 301,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2651",
      "text": "Amazon Simple Storage Service API Reference\nHeader value Description\nSTREAMING-AWS4-ECDSA- Use this when sending a payload over multiple chunks, and\nP256-SHA256-PAYLOAD-TRAI the chunks are signed using AWS4-ECDSA-P256-SHA256 .\nLER This produces a SigV4A signature. In addition, the digest for\nthe chunks is included as a trailing header.\nUpon receiving the request, Amazon S3 re-creates the string to sign using information in the\nAuthorization header and the date header. It then verifies with authentication service the\nsignatures match. The request date can be specified by using either the HTTP Date or the x-amz-\ndate header. If both headers are present, x-amz-date takes precedence.\nIf the signatures match, Amazon S3 processes your request; otherwise, your request will fail.\nFor more information, see the following topics:\nSignature Calculations for the Authorization Header: Transferring Payload in a Single Chunk (AWS\nSignature Version 4)\nSignature Calculations for the Authorization Header: Transferring Payload in Multiple Chunks\n(Chunked Upload) (AWS Signature Version 4)\nSignature Calculations for the Authorization Header: Including Trailing Headers (Chunked Upload)\n(AWS Signature Version 4)\nSignature Calculations for the Authorization Header: Transferring\nPayload in a Single Chunk (AWS Signature Version 4)\nWhen using the Authorization header to authenticate requests, the header value includes,\namong other things, a signature. The signature calculations vary depending on the choice you\nmake for transferring the payload (Overview). This section explains signature calculations when\nyou choose to transfer the payload in a single chunk. The example section (see Examples: Signature\nCalculations) shows signature calculations and resulting Authorization headers that you can use\nas a test suite to verify your code.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2646",
      "start_idx": 2952687,
      "end_idx": 2954608,
      "metadata": {
        "num_sentences": 13,
        "num_words": 273,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2652",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nWhen transferring payload in a single chunk, you can optionally choose to include the\npayload hash in the signature calculations, referred as signed payload (if you don't include\nit, the payload is considered unsigned). The signing procedure discussed in the following\nsection applies to both, but note the following differences:\n\u2022 Signed payload option \u2013 You include the payload hash when constructing the canonical\nrequest (that then becomes part of StringToSign, as explained in the signature\ncalculation section). You also specify the same value as the x-amz-content-sha256\nheader value when sending the request to S3.\n\u2022 Unsigned payload option \u2013 You include the literal string UNSIGNED-PAYLOAD when\nconstructing a canonical request, and set the same value as the x-amz-content-\nsha256 header value when sending the request to Amazon S3.\nWhen you send your request to Amazon S3, the x-amz-content-sha256 header value\ninforms Amazon S3 whether the payload is signed or not. Amazon S3 can then create the\nsignature accordingly for verification.\nCalculating a Signature\nTo calculate a signature, you first need a string to sign. You then calculate a HMAC-SHA256 hash of\nthe string to sign by using a signing key. The following diagram illustrates the process, including\nthe various components of the string that you create for signing\nWhen Amazon S3 receives an authenticated request, it computes the signature and then compares\nit with the signature that you provided in the request. For that reason, you must compute the\nsignature by using the same method that is used by Amazon S3. The process of putting a request in\nan agreed-upon form for signing is called canonicalization.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2647",
      "start_idx": 2954610,
      "end_idx": 2956431,
      "metadata": {
        "num_sentences": 12,
        "num_words": 286,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2653",
      "text": "Amazon Simple Storage Service API Reference\nThe following table describes the functions that are shown in the diagram. You need to implement\ncode for these functions.\nFunction Description\nLowercase() Convert the string to lowercase.\nHex() Lowercase base 16 encoding.\nSHA256Hash() Secure Hash Algorithm (SHA) cryptographic hash function.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2648",
      "start_idx": 2956433,
      "end_idx": 2956855,
      "metadata": {
        "num_sentences": 6,
        "num_words": 59,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2654",
      "text": "Amazon Simple Storage Service API Reference\nFunction Description\nHMAC-SHA256() Computes HMAC by using the SHA256 algorithm with the\nsigning key provided. This is the final signature.\nTrim() Remove any leading or trailing whitespace.\nUriEncode() URI encode every byte. UriEncode() must enforce the following\nrules:\n\u2022 URI encode every byte except the unreserved characters:\n'A'-'Z', 'a'-'z', '0'-'9', '-', '.', '_', and '~'.\n\u2022 The space character is a reserved character and must be\nencoded as \"%20\" (and not as \"+\").\n\u2022 Each URI encoded byte is formed by a '%' and the two-digit\nhexadecimal value of the byte.\n\u2022 Letters in the hexadecimal value must be uppercase, for\nexample \"%1A\".\n\u2022 Encode the forward slash character, '/', everywhere except in\nthe object key name. For example, if the object key name is\nphotos/Jan/sample.jpg , the forward slash in the key\nname is not encoded.\nImportant\nThe standard UriEncode functions provided by your\ndevelopment platform may not work because of\ndifferences in implementation and related ambiguity\nin the underlying RFCs. We recommend that you write\nyour own custom UriEncode function to ensure that\nyour encoding will work.\nTo see an example of a UriEncode function in Java, see Java\nUtilities on the GitHub website.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2649",
      "start_idx": 2956857,
      "end_idx": 2958198,
      "metadata": {
        "num_sentences": 15,
        "num_words": 214,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2655",
      "text": "Amazon Simple Storage Service API Reference\nTask 1: Create a Canonical Request\nThis section provides an overview of creating a canonical request.\nThe following is the canonical request format that Amazon S3 uses to calculate a signature. For\nsignatures to match, you must create a canonical request in this format:\n<HTTPMethod>\\n\n<CanonicalURI>\\n\n<CanonicalQueryString>\\n\n<CanonicalHeaders>\\n\n<SignedHeaders>\\n\n<HashedPayload>\nWhere:\n\u2022 HTTPMethod is one of the HTTP methods, for example GET, PUT, HEAD, and DELETE.\n\u2022 CanonicalURI is the URI-encoded version of the absolute path component of the URI\u2014\neverything starting with the \"/\" that follows the domain name and up to the end of the string or\nto the question mark character ('?') if you have query string parameters. The URI in the following\nexample, /examplebucket/myphoto.jpg, is the absolute path and you don't encode the \"/\" in\nthe absolute path:\nhttp://s3.amazonaws.com/examplebucket/myphoto.jpg\nNote\nYou do not normalize URI paths for requests to Amazon S3. For example, you may have a\nbucket with an object named \"my-object//example//photo.user\". Normalizing the path\nchanges the object name in the request to \"my-object/example/photo.user\". This is an\nincorrect path for that object.\n\u2022 CanonicalQueryString specifies the URI-encoded query string parameters. You URI-encode\nname and values individually. You must also sort the parameters in the canonical query string\nalphabetically by key name. The sorting occurs after encoding. The query string in the following\nURI example is prefix=somePrefix&marker=someMarker&max-keys=20:\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2650",
      "start_idx": 2958200,
      "end_idx": 2959875,
      "metadata": {
        "num_sentences": 14,
        "num_words": 239,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2656",
      "text": "Amazon Simple Storage Service API Reference\nhttp://s3.amazonaws.com/examplebucket?prefix=somePrefix&marker=someMarker&max-keys=20\nThe canonical query string is as follows (line breaks are added to this example for readability):\nUriEncode(\"marker\")+\"=\"+UriEncode(\"someMarker\")+\"&\"+\nUriEncode(\"max-keys\")+\"=\"+UriEncode(\"20\") + \"&\" +\nUriEncode(\"prefix\")+\"=\"+UriEncode(\"somePrefix\")\nWhen a request targets a subresource, the corresponding query parameter value will be\nan empty string (\"\"). For example, the following URI identifies the ACL subresource on the\nexamplebucket bucket:\nhttp://s3.amazonaws.com/examplebucket?acl\nThe CanonicalQueryString in this case is as follows:\nUriEncode(\"acl\") + \"=\" + \"\"\nIf the URI does not include a '?', there is no query string in the request, and you set the canonical\nquery string to an empty string (\"\"). You will still need to include the \"\\n\".\n\u2022 CanonicalHeaders is a list of request headers with their values. Individual header name and\nvalue pairs are separated by the newline character (\"\\n\"). Header names must be in lowercase.\nYou must sort the header names alphabetically to construct the string, as shown in the following\nexample:\nLowercase(<HeaderName1>)+\":\"+Trim(<value>)+\"\\n\"\nLowercase(<HeaderName2>)+\":\"+Trim(<value>)+\"\\n\"\n...\nLowercase(<HeaderNameN>)+\":\"+Trim(<value>)+\"\\n\"\nThe Lowercase() and Trim() functions used in this example are described in the preceding\nsection.\nThe CanonicalHeaders list must include the following:\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2651",
      "start_idx": 2959877,
      "end_idx": 2961438,
      "metadata": {
        "num_sentences": 9,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2657",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 HTTP host header.\n\u2022 If the Content-MD5 header is present in the request, you must add it to the\nCanonicalHeaders list.\n\u2022 Any x-amz-* headers that you plan to include in your request must also be added.\nFor example, if you are using temporary security credentials, you need to include\nx-amz-security-token in your request. You must add this header in the list of\nCanonicalHeaders.\nNote\nThe x-amz-content-sha256 header is required for all AWS Signature Version 4\nrequests. It provides a hash of the request payload. If there is no payload, you must\nprovide the hash of an empty string.\nThe following is an example CanonicalHeaders string. The header names are in lowercase and\nsorted.\nhost:s3.amazonaws.com\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130708T220855Z\nNote\nFor the purpose of calculating an authorization signature, only the host and any x-amz-\n* headers are required; however, in order to prevent data tampering, you should consider\nincluding all the headers in the signature calculation.\n\u2022 SignedHeaders is an alphabetically sorted, semicolon-separated list of lowercase request\nheader names. The request headers in the list are the same headers that you included\nin the CanonicalHeaders string. For example, for the previous example, the value of\nSignedHeaders would be as follows:\nhost;x-amz-content-sha256;x-amz-date\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2652",
      "start_idx": 2961440,
      "end_idx": 2962960,
      "metadata": {
        "num_sentences": 14,
        "num_words": 218,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2658",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 HashedPayload is the hexadecimal value of the SHA256 hash of the request payload.\nHex(SHA256Hash(<payload>)\nIf there is no payload in the request, you compute a hash of the empty string as follows:\nHex(SHA256Hash(\"\"))\nThe hash returns the following value:\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nFor example, when you upload an object by using a PUT request, you provide object data in the\nbody. When you retrieve an object by using a GET request, you compute the empty string hash.\nTask 2: Create a String to Sign\nThis section provides an overview of creating a string to sign. For step-by-step instructions, see\nTask 2: Create a String to Sign in the AWS General Reference.\nThe string to sign is a concatenation of the following strings:\n\"AWS4-HMAC-SHA256\" + \"\\n\" +\ntimeStampISO8601Format + \"\\n\" +\n<Scope> + \"\\n\" +\nHex(SHA256Hash(<CanonicalRequest>))\nThe constant string AWS4-HMAC-SHA256 specifies the hash algorithm that you are using,\nHMAC-SHA256. The timeStamp is the current UTC time in ISO 8601 format (for example,\n20130524T000000Z).\nScope binds the resulting signature to a specific date, an AWS Region, and a service. Thus, your\nresulting signature will work only in the specific Region and for a specific service. The signature is\nvalid for seven days after the specified date.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2653",
      "start_idx": 2962962,
      "end_idx": 2964407,
      "metadata": {
        "num_sentences": 11,
        "num_words": 221,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2659",
      "text": "Amazon Simple Storage Service API Reference\ndate.Format(<YYYYMMDD>) + \"/\" + <region> + \"/\" + <service> + \"/aws4_request\"\nFor Amazon S3, the service string is s3. For a list of region strings, see Regions and Endpoints in\nthe AWS General Reference. The Region column in this table provides the list of valid Region strings.\nThe following scope restricts the resulting signature to the us-east-1 Region and Amazon S3.\n20130606/us-east-1/s3/aws4_request\nNote\nScope must use the same date that you use to compute the signing key, as discussed in the\nfollowing section.\nTask 3: Calculate Signature\nIn AWS Signature Version 4, instead of using your AWS access keys to sign a request, you first\ncreate a signing key that is scoped to a specific Region and service. For more information about\nsigning keys, see Introduction to Signing Requests.\nDateKey = HMAC-SHA256(\"AWS4\"+\"<SecretAccessKey>\", \"<YYYYMMDD>\")\nDateRegionKey = HMAC-SHA256(<DateKey>, \"<aws-region>\")\nDateRegionServiceKey = HMAC-SHA256(<DateRegionKey>, \"<aws-service>\")\nSigningKey = HMAC-SHA256(<DateRegionServiceKey>, \"aws4_request\")\nNote\nSome use cases can process signature keys for up to 7 days. For more information see Share\nan Object with Others.\nFor a list of Region strings, see Regions and Endpoints in the AWS General Reference.\nUsing a signing key enables you to keep your AWS credentials in one safe place. For example, if\nyou have multiple servers that communicate with Amazon S3, you share the signing key with those\nservers; you don\u2019t have to keep a copy of your secret access key on each server. Signing key is valid\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2654",
      "start_idx": 2964409,
      "end_idx": 2966083,
      "metadata": {
        "num_sentences": 13,
        "num_words": 254,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2660",
      "text": "Amazon Simple Storage Service API Reference\nfor up to seven days. So each time you calculate signing key you will need to share the signing key\nwith your servers. For more information, see Authenticating Requests (AWS Signature Version 4).\nThe final signature is the HMAC-SHA256 hash of the string to sign, using the signing key as the key.\nHMAC-SHA256(SigningKey, StringToSign)\nFor step-by-step instructions on creating a signature, see Task 3: Create a Signature in the AWS\nGeneral Reference.\nExamples: Signature Calculations\nYou can use the examples in this section as a reference to check signature calculations in your code.\nThe calculations shown in the examples use the following data:\n\u2022 Example access keys.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAccessKey\n\u2022 Request timestamp of 20130524T000000Z (Fri, 24 May 2013 00:00:00 GMT).\n\u2022 Bucket name examplebucket.\n\u2022 The bucket is assumed to be in the US East (N. Virginia) Region. The credential Scope and the\nSigning Key calculations use us-east-1 as the Region specifier. For information about other\nRegions, see Regions and Endpoints in the AWS General Reference.\n\u2022 You can use either path-style or virtual hosted\u2013style requests. The following examples show how\nto sign a virtual hosted\u2013style request, for example:\nhttps://examplebucket.s3.amazonaws.com/photos/photo1.jpg\nFor more information, see Virtual Hosting of Buckets in the Amazon Simple Storage Service User\nGuide.\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2655",
      "start_idx": 2966085,
      "end_idx": 2967664,
      "metadata": {
        "num_sentences": 15,
        "num_words": 229,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2661",
      "text": "Amazon Simple Storage Service API Reference\nExample: GET Object\nThe following example gets the first 10 bytes of an object (test.txt) from examplebucket. For\nmore information about the API action, see GetObject.\nGET /test.txt HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nAuthorization: SignatureToBeCalculated\nRange: bytes=0-9\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date: 20130524T000000Z\nBecause this GET request does not provide any body content, the x-amz-content-sha256\nvalue is the hash of the empty request body. The following steps show signature calculations and\nconstruction of the Authorization header.\n1. StringToSign\na. CanonicalRequest\nGET\n/test.txt\nhost:examplebucket.s3.amazonaws.com\nrange:bytes=0-9\nx-amz-content-\nsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130524T000000Z\nhost;range;x-amz-content-sha256;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nIn the canonical request string, the last line is the hash of the empty request body. The\nthird line is empty because there are no query parameters in the request.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2656",
      "start_idx": 2967666,
      "end_idx": 2968992,
      "metadata": {
        "num_sentences": 8,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2662",
      "text": "Amazon Simple Storage Service API Reference\n7344ae5b7ee6c3e7e6b0fe0640412a37625d1fbfff95c48bbb2dc43964946972\n2. SigningKey\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Signature\nf0e8bdb87c964420e857bd35b5d6ed310bd44f0170aba48dd91039c6036bdb41\n4. Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/\ns3/aws4_request,SignedHeaders=host;range;x-amz-content-sha256;x-amz-\ndate,Signature=f0e8bdb87c964420e857bd35b5d6ed310bd44f0170aba48dd91039c6036bdb41\nExample: PUT Object\nThis example PUT request creates an object (test$file.text) in examplebucket . The example\nassumes the following:\n\u2022 You are requesting REDUCED_REDUNDANCY as the storage class by adding the x-amz-storage-\nclass request header. For information about storage classes, see Storage Classes in the Amazon\nSimple Storage Service User Guide.\n\u2022 The content of the uploaded file is a string, \"Welcome to Amazon S3.\" The value of x-amz-\ncontent-sha256 in the request is based on this string.\nFor information about the API action, see PutObject.\nPUT test$file.text HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2657",
      "start_idx": 2968994,
      "end_idx": 2970333,
      "metadata": {
        "num_sentences": 10,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2663",
      "text": "Amazon Simple Storage Service API Reference\nDate: Fri, 24 May 2013 00:00:00 GMT\nAuthorization: SignatureToBeCalculated\nx-amz-date: 20130524T000000Z\nx-amz-storage-class: REDUCED_REDUNDANCY\nx-amz-content-sha256: 44ce7dd67c959e0d3524ffac1771dfbba87d2b6b4b4e99e42034a8b803f8b072\n<Payload>\nThe following steps show signature calculations.\n1. StringToSign\na. CanonicalRequest\nPUT\n/test%24file.text\ndate:Fri, 24 May 2013 00:00:00 GMT\nhost:examplebucket.s3.amazonaws.com\nx-amz-content-\nsha256:44ce7dd67c959e0d3524ffac1771dfbba87d2b6b4b4e99e42034a8b803f8b072\nx-amz-date:20130524T000000Z\nx-amz-storage-class:REDUCED_REDUNDANCY\ndate;host;x-amz-content-sha256;x-amz-date;x-amz-storage-class\n44ce7dd67c959e0d3524ffac1771dfbba87d2b6b4b4e99e42034a8b803f8b072\nIn the canonical request, the third line is empty because there are no query parameters\nin the request. The last line is the hash of the body, which should be same as the x-amz-\ncontent-sha256 header value.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n9e0e90d9c76de8fa5b200d8c849cd5b8dc7a3be3951ddb7f6a76b4158342019d\n2. SigningKey\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2658",
      "start_idx": 2970335,
      "end_idx": 2971535,
      "metadata": {
        "num_sentences": 6,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2664",
      "text": "Amazon Simple Storage Service API Reference\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Signature\n98ad721746da40c64f1a55b78f14c238d841ea1380cd77a1b5971af0ece108bd\n4. Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/\naws4_request,SignedHeaders=date;host;x-amz-content-sha256;x-amz-date;x-amz-storage-\nclass,Signature=98ad721746da40c64f1a55b78f14c238d841ea1380cd77a1b5971af0ece108bd\nExample: GET Bucket Lifecycle\nThe following GET request retrieves the lifecycle configuration of examplebucket. For\ninformation about the API action, see GetBucketLifecycleConfiguration.\nGET ?lifecycle HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nAuthorization: SignatureToBeCalculated\nx-amz-date: 20130524T000000Z\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nBecause the request does not provide any body content, the x-amz-content-sha256 header\nvalue is the hash of the empty request body. The following steps show signature calculations.\n1. StringToSign\na. CanonicalRequest\nGET\n/\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2659",
      "start_idx": 2971537,
      "end_idx": 2972822,
      "metadata": {
        "num_sentences": 8,
        "num_words": 106,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2665",
      "text": "Amazon Simple Storage Service API Reference\nlifecycle=\nhost:examplebucket.s3.amazonaws.com\nx-amz-content-\nsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130524T000000Z\nhost;x-amz-content-sha256;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nIn the canonical request, the last line is the hash of the empty request body.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n9766c798316ff2757b517bc739a67f6213b4ab36dd5da2f94eaebf79c77395ca\n2. SigningKey\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Signature\nfea454ca298b7da1c68078a5d1bdbfbbe0d65c699e0f91ac7a200a0136783543\n4. Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/\ns3/aws4_request,SignedHeaders=host;x-amz-content-sha256;x-amz-\ndate,Signature=fea454ca298b7da1c68078a5d1bdbfbbe0d65c699e0f91ac7a200a0136783543\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2660",
      "start_idx": 2972824,
      "end_idx": 2973966,
      "metadata": {
        "num_sentences": 5,
        "num_words": 71,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2666",
      "text": "Amazon Simple Storage Service API Reference\nExample: Get Bucket (List Objects)\nThe following example retrieves a list of objects from examplebucket bucket. For information\nabout the API action, see ListObjects.\nGET ?max-keys=2&prefix=J HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nAuthorization: SignatureToBeCalculated\nx-amz-date: 20130524T000000Z\nx-amz-content-sha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nBecause the request does not provide a body, the value of x-amz-content-sha256 is the hash of\nthe empty request body. The following steps show signature calculations.\n1. StringToSign\na. CanonicalRequest\nGET\n/\nmax-keys=2&prefix=J\nhost:examplebucket.s3.amazonaws.com\nx-amz-content-\nsha256:e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nx-amz-date:20130524T000000Z\nhost;x-amz-content-sha256;x-amz-date\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nIn the canonical string, the last line is the hash of the empty request body.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\ndf57d21db20da04d7fa30298dd4488ba3a2b47ca3a489c74750e0f1e7df1b9b7\n2. SigningKey\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2661",
      "start_idx": 2973968,
      "end_idx": 2975213,
      "metadata": {
        "num_sentences": 8,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2667",
      "text": "Amazon Simple Storage Service API Reference\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Signature\n34b48302e7b5fa45bde8084f4b7868a86f0a534bc59db6670ed5711ef69dc6f7\n4. Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/\ns3/aws4_request,SignedHeaders=host;x-amz-content-sha256;x-amz-\ndate,Signature=34b48302e7b5fa45bde8084f4b7868a86f0a534bc59db6670ed5711ef69dc6f7\nSignature Calculation: Transfer Payload in a Single Chunk API Version 2006-03-01 2662",
      "start_idx": 2975215,
      "end_idx": 2975850,
      "metadata": {
        "num_sentences": 3,
        "num_words": 41,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2668",
      "text": "Amazon Simple Storage Service API Reference\nSignature Calculations for the Authorization Header: Transferring\nPayload in Multiple Chunks (Chunked Upload) (AWS Signature Version\n4)\nAs described in the Overview, when authenticating requests using the Authorization header,\nyou have an option of uploading the payload in chunks. You can send data in fixed size or variable\nsize chunks. This section describes the signature calculation process in chunked upload, how you\ncreate the chunk body, and how the delayed signing works where you first upload the chunk, and\nsend its signature in the subsequent chunk. The example section (see Example: PUT Object) shows\nsignature calculations and resulting Authorization headers that you can use as a test suite to\nverify your code.\nNote\nWhen transferring data in a series of chunks, you must do one of the following:\n\u2022 Explicitly specify the total content length (object length in bytes plus metadata in each\nchunk) using the Content-Length HTTP header. To do this, you must pre-compute the\ntotal length of the payload, including the metadata that you send in each chunk, before\nstarting your request.\n\u2022 Specify the Transfer-Encoding HTTP header. If you include the Transfer-Encoding\nheader and specify any value other than identity, you must omit the Content-\nLength header.\nFor all requests, you must include the x-amz-decoded-content-length header,\nspecifying the size of the object in bytes.\nEach chunk signature calculation includes the signature of the previous chunk. To begin, you create\na seed signature using only the headers. You use the seed signature in the signature calculation\nof the first chunk. For each subsequent chunk, you create a chunk signature that includes the\nsignature of the previous chunk. Thus, the chunk signatures are chained together; that is, the\nsignature of chunk n is a function F(chunk n, signature(chunk n-1)). The chaining ensures that you\nsend the chunks in the correct order.\nTo perform a chunked upload, do the following:\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2663",
      "start_idx": 2975852,
      "end_idx": 2977943,
      "metadata": {
        "num_sentences": 16,
        "num_words": 327,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2669",
      "text": "Amazon Simple Storage Service API Reference\n1. Decide the payload chunk size. You need this when you write the code.\nThe chunk size must be at least 8 KB. We recommend a chunk size of a least 64 KB for better\nperformance. This chunk size applies to all chunks except the last one. The last chunk you send\ncan be smaller than 8 KB. If your payload is small and can fit into one chunk, then it can be\nsmaller than the 8 KB.\n2. Create the seed signature for inclusion in the first chunk. For more information, see Calculating\nthe Seed Signature.\n3. Create the first chunk and stream it. For more information, see Defining the Chunk Body.\n4. For each subsequent chunk, calculate the chunk signature that includes the previous signature\nin the string you sign, construct the chunk, and send it. For more information, see Defining the\nChunk Body.\n5. Send the final additional chunk, which is the same as the other chunks in the construction, but it\nhas zero data bytes. For more information, see Defining the Chunk Body.\nCalculating the Seed Signature\nThe following diagram illustrates the process of calculating the seed signature.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2664",
      "start_idx": 2977945,
      "end_idx": 2979158,
      "metadata": {
        "num_sentences": 22,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2670",
      "text": "Amazon Simple Storage Service API Reference\nThe following table describes the functions that are shown in the diagram. You need to implement\ncode for these functions.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2665",
      "start_idx": 2979160,
      "end_idx": 2979413,
      "metadata": {
        "num_sentences": 3,
        "num_words": 37,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2671",
      "text": "Amazon Simple Storage Service API Reference\nFunction Description\nLowercase() Convert the string to lowercase.\nHex() Lowercase base 16 encoding.\nSHA256Hash() Secure Hash Algorithm (SHA) cryptographic hash function.\nHMAC-SHA256() Computes HMAC by using the SHA256 algorithm with the\nsigning key provided. This is the final signature.\nTrim() Remove any leading or trailing whitespace.\nUriEncode() URI encode every byte. UriEncode() must enforce the following\nrules:\n\u2022 URI encode every byte except the unreserved characters:\n'A'-'Z', 'a'-'z', '0'-'9', '-', '.', '_', and '~'.\n\u2022 The space character is a reserved character and must be\nencoded as \"%20\" (and not as \"+\").\n\u2022 Each URI encoded byte is formed by a '%' and the two-digit\nhexadecimal value of the byte.\n\u2022 Letters in the hexadecimal value must be uppercase, for\nexample \"%1A\".\n\u2022 Encode the forward slash character, '/', everywhere except in\nthe object key name. For example, if the object key name is\nphotos/Jan/sample.jpg , the forward slash in the key\nname is not encoded.\nImportant\nThe standard UriEncode functions provided by your\ndevelopment platform may not work because of\ndifferences in implementation and related ambiguity\nin the underlying RFCs. We recommend that you write\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2666",
      "start_idx": 2979415,
      "end_idx": 2980738,
      "metadata": {
        "num_sentences": 16,
        "num_words": 203,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2672",
      "text": "Amazon Simple Storage Service API Reference\nFunction Description\nyour own custom UriEncode function to ensure that\nyour encoding will work.\nTo see an example of a UriEncode function in Java, see Java\nUtilities on the GitHub website.\nFor information about the signing process, see Signature Calculations for the Authorization Header:\nTransferring Payload in a Single Chunk (AWS Signature Version 4). The process is the same, except\nthat the creation of CanonicalRequest differs as follows:\n\u2022 In addition to the request headers you plan to add, you must include the following headers:\nHeader Description\nx-amz-content-\nThis header is required for all AWS Signature Version 4 requests. Set\nsha256\nthe value to STREAMING-AWS4-HMAC-SHA256-PAYLOAD to\nindicate that the signature covers only headers and that there is no\npayload.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2667",
      "start_idx": 2980740,
      "end_idx": 2981649,
      "metadata": {
        "num_sentences": 6,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2673",
      "text": "Amazon Simple Storage Service API Reference\nHeader Description\nContent-E\nSet the value to aws-chunked .\nncoding\nAmazon S3 supports multiple content encodings. For example:\nContent-Encoding : aws-chunked,gzip\nThat is, you can specify your custom content-encoding when using\nSignature Version 4 streaming API.\nIf you specify Content-Encoding in your request as Content-\nEncoding : aws-chunked , S3 adds an empty value for\nContent-Encoding and stores the object metadata (Content-E\nncoding : ) to the resulting object.\nNote\nAmazon S3 stores the resulting object without the aws-\nchunked encoding. Therefore, when you retrieve the object,\nit is not a ws-chunked encoded.\nx-amz-decoded- Set the value to the length, in bytes, of the data to be chunked,\ncontent-length without counting any metadata. For example, if you are uploading\na 4 GB file, set the value to 4294967296. This is the raw size of the\nobject to be uploaded (data you want to store in Amazon S3).\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2668",
      "start_idx": 2981651,
      "end_idx": 2982696,
      "metadata": {
        "num_sentences": 10,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2674",
      "text": "Amazon Simple Storage Service API Reference\nHeader Description\nContent-Length\nSet the value to the actual size of the transmitted HTTP body,\nwhich includes the length of your data (value set for x-amz-dec\noded-content-length ), plus chunk metadata. Each chunk\nhas metadata, such as the signature of the previous chunk. Chunk\ncalculations are discussed in the following section. If you include the\nTransfer-Encoding header and specify any value other than\nidentity, you must not include the Content-Length header.\nYou send the first chunk with the seed signature. You must construct the chunk as described in the\nfollowing section.\nDefining the Chunk Body\nAll chunks include some metadata. Each chunk must conform to the following structure:\nstring(IntHexBase(chunk-size)) + \";chunk-signature=\" + signature + \\r\\n + chunk-data +\n\\r\\n\nWhere:\n\u2022 IntHexBase() is a function that you write to convert an integer chunk-size to hexadecimal. For\nexample, if chunk-size is 65536, hexadecimal string is \"10000\".\n\u2022 chunk-size is the size, in bytes, of the chunk-data, without metadata. For example, if you are\nuploading a 65 KB object and using a chunk size of 64 KB, you upload the data in three chunks:\nthe first would be 64 KB, the second 1 KB, and the final chunk with 0 bytes.\n\u2022 signature For each chunk, you calculate the signature using the following string to sign. For\nthe first chunk, you use the seed-signature as the previous signature.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2669",
      "start_idx": 2982698,
      "end_idx": 2984221,
      "metadata": {
        "num_sentences": 14,
        "num_words": 243,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2676",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 The bucket is assumed to be in the US East (N. Virginia) Region, and the credential Scope and\nthe Signing Key calculations use us-east-1 as the Region specifier. For more information,\nsee Regions and Endpoints in the Amazon Web Services General Reference.\n\u2022 You can use either path style or virtual-hosted style requests. The following examples use\nvirtual-hosted style requests, for example:\nhttps://examplebucket.s3.amazonaws.com/photos/photo1.jpg\nFor more information, see Virtual Hosting of Buckets in the Amazon Simple Storage Service User\nGuide.\nThe following example sends a PUT request to upload an object. The signature calculations assume\nthe following:\n\u2022 You are uploading a 65 KB text file, and the file content is a one-character string made up of the\nletter 'a'.\n\u2022 The chunk size is 64 KB. As a result, the payload is uploaded in three chunks, 64 KB, 1 KB, and the\nfinal chunk with 0 bytes of chunk data.\n\u2022 The resulting object has the key name chunkObject.txt.\n\u2022 You are requesting REDUCED_REDUNDANCY as the storage class by adding the x-amz-storage-\nclass request header.\nFor information about the API action, see PutObject. The general request syntax is as follows:\nPUT /examplebucket/chunkObject.txt HTTP/1.1\nHost: s3.amazonaws.com\nx-amz-date: 20130524T000000Z\nx-amz-storage-class: REDUCED_REDUNDANCY\nAuthorization: SignatureToBeCalculated\nx-amz-content-sha256: STREAMING-AWS4-HMAC-SHA256-PAYLOAD\nContent-Encoding: aws-chunked\nx-amz-decoded-content-length: 66560\nContent-Length: 66824\n<Payload>\nThe following steps show signature calculations.\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2671",
      "start_idx": 2985030,
      "end_idx": 2986724,
      "metadata": {
        "num_sentences": 13,
        "num_words": 234,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2677",
      "text": "Amazon Simple Storage Service API Reference\n1. Seed signature \u2014 Create String to Sign\na. CanonicalRequest\nPUT\n/examplebucket/chunkObject.txt\ncontent-encoding:aws-chunked\ncontent-length:66824\nhost:s3.amazonaws.com\nx-amz-content-sha256:STREAMING-AWS4-HMAC-SHA256-PAYLOAD\nx-amz-date:20130524T000000Z\nx-amz-decoded-content-length:66560\nx-amz-storage-class:REDUCED_REDUNDANCY\ncontent-encoding;content-length;host;x-amz-content-sha256;x-amz-date;x-amz-\ndecoded-content-length;x-amz-storage-class\nSTREAMING-AWS4-HMAC-SHA256-PAYLOAD\nIn the canonical request, the third line is empty because there are no query parameters\nin the request. The last line is the constant string provided as the value of the hashed\nPayload, which should be same as the value of x-amz-content-sha256 header.\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\ncee3fed04b70f867d036f722359b0b1f2f0e5dc0efadbc082b76c4c60e316455\nNote\nFor information about each of line in the string to sign, see the diagram that\nexplains seed signature calculation.\n2. SigningKey\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2672",
      "start_idx": 2986726,
      "end_idx": 2987874,
      "metadata": {
        "num_sentences": 6,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2678",
      "text": "Amazon Simple Storage Service API Reference\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Seed Signature\n4f232c4386841ef735655705268965c44a0e4690baa4adea153f7db9fa80a0a9\n4. Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/\naws4_request,SignedHeaders=content-encoding;content-length;host;x-amz-\ncontent-sha256;x-amz-date;x-amz-decoded-content-length;x-amz-storage-\nclass,Signature=4f232c4386841ef735655705268965c44a0e4690baa4adea153f7db9fa80a0a9\n5. Chunk 1: (65536 bytes, with value 97 for letter 'a')\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n4f232c4386841ef735655705268965c44a0e4690baa4adea153f7db9fa80a0a9\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nbf718b6f653bebc184e1479f1935b8da974d701b893afcf49e701f3e2f9f9c5a\nNote\nFor information about each line in the string to sign, see the preceding diagram\nthat shows various components of the string to sign (for example, the last three\nlines are, previous-signature, hash(\"\"), and hash(current-chunk-\ndata)).\nb. Chunk signature:\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2673",
      "start_idx": 2987876,
      "end_idx": 2989212,
      "metadata": {
        "num_sentences": 7,
        "num_words": 103,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2679",
      "text": "Amazon Simple Storage Service API Reference\nad80c730a21e5b8d04586a2213dd63b9a0e99e0e2307b0ade35a65485a288648\nc. Chunk data sent:\n10000;chunk-\nsignature=ad80c730a21e5b8d04586a2213dd63b9a0e99e0e2307b0ade35a65485a288648\n<65536-bytes>\n6. Chunk 2: (1024 bytes, with value 97 for letter 'a')\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\nad80c730a21e5b8d04586a2213dd63b9a0e99e0e2307b0ade35a65485a288648\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n2edc986847e209b4016e141a6dc8716d3207350f416969382d431539bf292e4a\nb. Chunk signature:\n0055627c9e194cb4542bae2aa5492e3c1575bbb81b612b7d234b86a503ef5497\nc. Chunk data sent:\n400;chunk-\nsignature=0055627c9e194cb4542bae2aa5492e3c1575bbb81b612b7d234b86a503ef5497\n<1024 bytes>\n7. Chunk 3: (0 byte data)\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n0055627c9e194cb4542bae2aa5492e3c1575bbb81b612b7d234b86a503ef5497\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nb. Chunk signature:\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2674",
      "start_idx": 2989214,
      "end_idx": 2990430,
      "metadata": {
        "num_sentences": 7,
        "num_words": 79,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2680",
      "text": "Amazon Simple Storage Service API Reference\nb6c6ea8a5354eaf15b3cb7646744f4275b71ea724fed81ceb9323e279d449df9\nc. Chunk data sent:\n0;chunk-\nsignature=b6c6ea8a5354eaf15b3cb7646744f4275b71ea724fed81ceb9323e279d449df9\nSignature Calculation: Transfer Payload in Multiple Chunks API Version 2006-03-01 2675",
      "start_idx": 2990432,
      "end_idx": 2990731,
      "metadata": {
        "num_sentences": 1,
        "num_words": 24,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2681",
      "text": "Amazon Simple Storage Service API Reference\nSignature Calculations for the Authorization Header: Including Trailing\nHeaders (Chunked Upload) (AWS Signature Version 4)\nAs described in the Overview, when authenticating requests using the Authorization header,\nyou have an option of uploading the payload in chunks. This is covered in detail in Signature\nCalculations for the Authorization Header: Transferring Payload in Multiple Chunks (Chunked\nUpload) (AWS Signature Version 4). When you send the data for the object in chunks, you also have\nthe option of including trailing headers. This section describes the steps you need to take when you\nwant to include a trailing header at the end of your multiple chunk upload.\nImportant\nWhen you are including trailing headers, you must send the following in your initial header:\n\u2022 You must set x-amz-content-sha256 to an appropriate value that indicates a trailer\nwill be included. To see the acceptable values for x-amz-content-sha256, see\nAuthenticating Requests: Using the Authorization Header (AWS Signature Version 4).\n\u2022 You must set x-amz-trailer to indicate the contents your are including in your trailing\nheader.\nTrailing headers are only sent after the chunks have been uploaded. Previous chunks are sent as\nnormal and signed as described in the previous sections, including sending the final chunk with a\npayload of 0 bytes. The trailing headers are included as their own chunk and sent after the final\nchunk with a payload of 0 bytes. For example, if your data ended with a 100 KB chunk, you would\nsend the following:\n\u2022 Previous data chunks\n\u2022 100 KB final chunk of the object\n\u2022 0 bytes chunk signifying the end of the object\n\u2022 Trailing headers chunk\nExample: PUT Object\nYou can use the examples in this section as a reference to check signature calculations in your code.\nBefore you review the examples, note the following:\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2676",
      "start_idx": 2990733,
      "end_idx": 2992689,
      "metadata": {
        "num_sentences": 12,
        "num_words": 313,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2682",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 The signature calculations in these examples use the following example security credentials.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAccessKey\n\u2022 All examples use the request timestamp 20130524T000000Z (Fri, 24 May 2013 00:00:00\nGMT).\n\u2022 All examples use examplebucket as the bucket name.\n\u2022 The bucket is assumed to be in the US East (N. Virginia) Region, and the credential Scope and\nthe Signing Key calculations use us-east-1 as the Region specifier. For more information,\nsee Regions and Endpoints in the Amazon Web Services General Reference.\n\u2022 You can use either path style or virtual-hosted style requests. The following examples use\nvirtual-hosted style requests, for example:\nhttps://examplebucket.s3.amazonaws.com/photos/photo1.jpg\nFor more information, see Virtual Hosting of Buckets in the Amazon Simple Storage Service User\nGuide.\nThe following example sends a PUT request to upload an object. The signature calculations assume\nthe following:\n\u2022 You are uploading a 65 KB text file, and the file content is a one-character string made up of the\nletter 'a'.\n\u2022 The chunk size is 64 KB. As a result, the payload is uploaded in three chunks, 64 KB, 1 KB, and the\nfinal chunk with 0 bytes of chunk data.\n\u2022 The resulting object has the key name chunkObject.txt.\n\u2022 You are requesting REDUCED_REDUNDANCY as the storage class by adding the x-amz-storage-\nclass request header.\n\u2022 The transfer is including a CRC32 checksum value as a trailing header.\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2677",
      "start_idx": 2992691,
      "end_idx": 2994327,
      "metadata": {
        "num_sentences": 15,
        "num_words": 247,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2683",
      "text": "Amazon Simple Storage Service API Reference\nFor information about the API action, see PutObject. The general request syntax is as follows:\nPUT /examplebucket/chunkObject.txt HTTP/1.1\nHost: s3.amazonaws.com\nx-amz-date: 20130524T000000Z\nx-amz-storage-class: REDUCED_REDUNDANCY\nAuthorization: SignatureToBeCalculated\nx-amz-content-sha256: STREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER\nContent-Encoding: aws-chunked\nx-amz-decoded-content-length: 66560\nx-amz-trailer: x-amz-checksum-crc32\nContent-Length: 66824\n<Payload>\nThe following steps show signature calculations.\n1. Seed signature \u2014 Create String to Sign\na. CanonicalRequest\nPUT\n/examplebucket/chunkObject.txt\ncontent-encoding:aws-chunked\nhost:s3.amazonaws.com\nx-amz-content-sha256:STREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER\nx-amz-date:20130524T000000Z\nx-amz-decoded-content-length:66560\nx-amz-storage-class:REDUCED_REDUNDANCY\nx-amz-trailer:x-amz-checksum-crc32c\ncontent-encoding;host;x-amz-content-sha256;x-amz-date;x-amz-decoded-content-\nlength;x-amz-storage-class;x-amz-trailer\nSTREAMING-AWS4-HMAC-SHA256-PAYLOAD-TRAILER\nIn the canonical request, the third line is empty because there are no query parameters\nin the request. The last line is the constant string provided as the value of the hashed\nPayload, which should be same as the value of x-amz-content-sha256 header.\nb. StringToSign\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2678",
      "start_idx": 2994329,
      "end_idx": 2995747,
      "metadata": {
        "num_sentences": 6,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2684",
      "text": "Amazon Simple Storage Service API Reference\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n44d48b8c2f70eae815a0198cc73d7a546a73a93359c070abbaa5e6c7de112559\nNote\nFor information about each of line in the string to sign, see the diagram that\nexplains seed signature calculation.\n2. SigningKey\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Seed Signature\n106e2a8a18243abcf37539882f36619c00e2dfc72633413f02d3b74544bfeb8e\n4. Authorization header\nThe resulting Authorization header is as follows:\nAWS4-HMAC-SHA256 Credential=AKIAIOSFODNN7EXAMPLE/20130524/us-east-1/s3/\naws4_request,SignedHeaders=content-encoding;content-length;host;x-amz-\ncontent-sha256;x-amz-date;x-amz-decoded-content-length;x-amz-storage-\nclass,Signature=106e2a8a18243abcf37539882f36619c00e2dfc72633413f02d3b74544bfeb8e\n5. Chunk 1: (65536 bytes, with value 97 for letter 'a')\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2679",
      "start_idx": 2995749,
      "end_idx": 2996855,
      "metadata": {
        "num_sentences": 7,
        "num_words": 84,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2685",
      "text": "Amazon Simple Storage Service API Reference\n20130524/us-east-1/s3/aws4_request\n106e2a8a18243abcf37539882f36619c00e2dfc72633413f02d3b74544bfeb8e\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nbf718b6f653bebc184e1479f1935b8da974d701b893afcf49e701f3e2f9f9c5a\nNote\nFor information about each line in the string to sign, see the preceding diagram\nthat shows various components of the string to sign (for example, the last three\nlines are, previous-signature, hash(\"\"), and hash(current-chunk-\ndata)).\nb. Chunk signature:\nb474d8862b1487a5145d686f57f013e54db672cee1c953b3010fb58501ef5aa2\nc. Chunk data sent:\n10000;chunk-\nsignature=b474d8862b1487a5145d686f57f013e54db672cee1c953b3010fb58501ef5aa2\n<65536-bytes>\n6. Chunk 2: (1024 bytes, with value 97 for letter 'a')\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\nb474d8862b1487a5145d686f57f013e54db672cee1c953b3010fb58501ef5aa2\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n41edece42d63e8d9bf515a9ba6932e1c20cbc9f5a5d134645adb5db1b9737ea3\nb. Chunk signature:\n041169d545f3f4a02fe2e3d066bfb1798dd5f3417ae8cecd0e43690aafbe79d1\nc. Chunk data sent:\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2680",
      "start_idx": 2996857,
      "end_idx": 2998112,
      "metadata": {
        "num_sentences": 6,
        "num_words": 96,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2686",
      "text": "Amazon Simple Storage Service API Reference\n400;chunk-\nsignature=041169d545f3f4a02fe2e3d066bfb1798dd5f3417ae8cecd0e43690aafbe79d1\n<1024 bytes>\n7. Chunk 3: (0 byte data)\na. Chunk string to sign:\nAWS4-HMAC-SHA256-PAYLOAD\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n041169d545f3f4a02fe2e3d066bfb1798dd5f3417ae8cecd0e43690aafbe79d1\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\ne3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\nb. Chunk signature:\ne05ab64fe1dfdbf0b5870abbaabdb063c371d4e96f2767e6934d90529c5ae850\nc. Chunk data sent:\n0;chunk-\nsignature=e05ab64fe1dfdbf0b5870abbaabdb063c371d4e96f2767e6934d90529c5ae850\n8. Chunk 4: Trailing headers\na. Trailer chunk string to sign:\nAWS4-HMAC-SHA256-TRAILER\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\ne05ab64fe1dfdbf0b5870abbaabdb063c371d4e96f2767e6934d90529c5ae850\n2e4ab969aa65b1ad6def2db10e4d3a8260683d194dbaf757f90e8a37960a4b3c\nb. Chunk signature:\n41e14ac611e27a8bb3d66c3bad6856f209297767d5dd4fc87d8fa9e422e03faf\nc. Chunk data sent:\nx-amz-checksum-crc32c:wdBDMA==\nSignature Calculation: Including Trailing Headers API Version 2006-03-01 2681",
      "start_idx": 2998114,
      "end_idx": 2999251,
      "metadata": {
        "num_sentences": 6,
        "num_words": 71,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2687",
      "text": "Amazon Simple Storage Service API Reference\nx-amz-trailer-\nsignature:41e14ac611e27a8bb3d66c3bad6856f209297767d5dd4fc87d8fa9e422e03faf\nAuthenticating Requests: Using Query Parameters (AWS\nSignature Version 4)\nAs described in the authentication overview (see Authentication Methods), you can provide\nauthentication information using query string parameters. Using query parameters to authenticate\nrequests is useful when you want to express a request entirely in a URL. This method is also\nreferred as presigning a URL.\nA use case scenario for presigned URLs is that you can grant temporary access to your Amazon S3\nresources. For example, you can embed a presigned URL on your website or alternatively use it in\ncommand line client (such as Curl) to download objects.\nNote\nYou can also use the AWS CLI to create presigned URLs. For more information, see presign\nin the AWS CLI Command Reference.\nThe following is an example presigned URL.\nhttps://examplebucket.s3.amazonaws.com/test.txt\n?X-Amz-Algorithm=AWS4-HMAC-SHA256\n&X-Amz-Credential=<your-access-key-id>/20130721/us-east-1/s3/aws4_request\n&X-Amz-Date=20130721T201207Z\n&X-Amz-Expires=86400\n&X-Amz-SignedHeaders=host\n&X-Amz-Signature=<signature-value>\nIn the example URL, note the following:\n\u2022 The line feeds are added for readability.\n\u2022 The X-Amz-Credential value in the URL shows the \"/\" character only for readability. In\npractice, it should be encoded as %2F. For example:\nUsing Query Parameters API Version 2006-03-01 2682",
      "start_idx": 2999253,
      "end_idx": 3000733,
      "metadata": {
        "num_sentences": 12,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2688",
      "text": "Amazon Simple Storage Service API Reference\n&X-Amz-Credential=<your-access-key-id>%2F20130721%2Fus-east-1%2Fs3%2Faws4_request\nThe following table describes the query parameters in the URL that provide authentication\ninformation.\nQuery String Parameter Example Value\nName\nX-Amz-Algorithm Identifies the version of AWS Signature and the algorithm that\nyou used to calculate the signature.\nFor AWS Signature Version 4, you set this parameter value to\nAWS4-HMAC-SHA256 . This string identifies AWS Signature\nVersion 4 (AWS4) and the HMAC-SHA256 algorithm (HMAC-\nSHA256).\nX-Amz-Credential In addition to your access key ID, this parameter also provides\nscope (AWS Region and service) for which the signature is\nvalid. This value must match the scope you use in signature\ncalculations, discussed in the following section. The general\nform for this parameter value is as follows:\n<your-access-key-id> /<date>/<AWS Region>/<AWS-serv\nice> /aws4_request\nFor example:\nAKIAIOSFODNN7EXAMPLE/20130721/us-east-1/s3/aw\ns4_request\nFor Amazon S3, the AWS-service string is s 3. For a list of\nS3 AWS-region strings, see R egions and Endpoints in the\nAWS General Reference.\nUsing Query Parameters API Version 2006-03-01 2683",
      "start_idx": 3000735,
      "end_idx": 3001939,
      "metadata": {
        "num_sentences": 9,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2689",
      "text": "Amazon Simple Storage Service API Reference\nQuery String Parameter Example Value\nName\nX-Amz-Date\nThe date and time format must follow the ISO 8601 standard,\nand must be formatted with the \"yyyyMMddTHHmmssZ\"\nformat. For example if the date and time was \"08/01/2016\n15:32:41.982-700\" then it must first be converted to UTC\n(Coordinated Universal Time) and then submitted as \"201608\n01T223241Z\".\nX-Amz-Expires Provides the time period, in seconds, for which the generated\npresigned URL is valid. For example, 86400 (24 hours). This\nvalue is an integer. The minimum value you can set is 1, and\nthe maximum is 604800 (seven days).\nA presigned URL can be valid for a maximum of seven days\nbecause the signing key you use in signature calculation is\nvalid for up to seven days.\nX-Amz-SignedHeaders Lists the headers that you used to calculate the signature. The\nfollowing headers are required in the signature calculations:\n\u2022\nThe HTTP host header.\n\u2022\nAny x-amz-* headers that you plan to add to the request.\nNote\nFor added security, you should sign all the request\nheaders that you plan to include in your request.\nUsing Query Parameters API Version 2006-03-01 2684",
      "start_idx": 3001941,
      "end_idx": 3003098,
      "metadata": {
        "num_sentences": 12,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2690",
      "text": "Amazon Simple Storage Service API Reference\nQuery String Parameter Example Value\nName\nX-Amz-Signature Provides the signature to authenticate your request. This\nsignature must match the signature Amazon S3 calculates;\notherwise, Amazon S3 denies the request. For example,\n733255ef022bec3f2a8701cd61d4b371f3f\n28c9f193a1f02279211d48d5193d7\nSignature calculations are described in the following section.\nX-Amz-Security-Token Optional credential parameter if using credentials sourced\nfrom the STS service.\nCalculating a Signature\nThe following diagram illustrates the signature calculation process.\nCalculating a Signature API Version 2006-03-01 2685",
      "start_idx": 3003100,
      "end_idx": 3003746,
      "metadata": {
        "num_sentences": 6,
        "num_words": 77,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2691",
      "text": "Amazon Simple Storage Service API Reference\nThe following table describes the functions that are shown in the diagram. You need to implement\ncode for these functions.\nFunction Description\nLowercase() Convert the string to lowercase.\nHex() Lowercase base 16 encoding.\nSHA256Hash() Secure Hash Algorithm (SHA) cryptographic hash function.\nCalculating a Signature API Version 2006-03-01 2686",
      "start_idx": 3003748,
      "end_idx": 3004136,
      "metadata": {
        "num_sentences": 6,
        "num_words": 54,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2692",
      "text": "Amazon Simple Storage Service API Reference\nFunction Description\nHMAC-SHA256() Computes HMAC by using the SHA256 algorithm with the\nsigning key provided. This is the final signature.\nTrim() Remove any leading or trailing whitespace.\nUriEncode() URI encode every byte. UriEncode() must enforce the following\nrules:\n\u2022 URI encode every byte except the unreserved characters:\n'A'-'Z', 'a'-'z', '0'-'9', '-', '.', '_', and '~'.\n\u2022 The space character is a reserved character and must be\nencoded as \"%20\" (and not as \"+\").\n\u2022 Each URI encoded byte is formed by a '%' and the two-digit\nhexadecimal value of the byte.\n\u2022 Letters in the hexadecimal value must be uppercase, for\nexample \"%1A\".\n\u2022 Encode the forward slash character, '/', everywhere except in\nthe object key name. For example, if the object key name is\nphotos/Jan/sample.jpg , the forward slash in the key\nname is not encoded.\nImportant\nThe standard UriEncode functions provided by your\ndevelopment platform may not work because of\ndifferences in implementation and related ambiguity\nin the underlying RFCs. We recommend that you write\nyour own custom UriEncode function to ensure that\nyour encoding will work.\nTo see an example of a UriEncode function in Java, see Java\nUtilities on the GitHub website.\nCalculating a Signature API Version 2006-03-01 2687",
      "start_idx": 3004138,
      "end_idx": 3005445,
      "metadata": {
        "num_sentences": 15,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2693",
      "text": "Amazon Simple Storage Service API Reference\nFor more information about the signing process (details of creating a canonical request, string\nto sign, and signature calculations), see Signature Calculations for the Authorization Header:\nTransferring Payload in a Single Chunk (AWS Signature Version 4). The process is generally the\nsame except that the creation of CanonicalRequest in a presigned URL differs as follows:\n\u2022 You don't include a payload hash in the Canonical Request, because when you create a\npresigned URL, you don't know the payload content because the URL is used to upload an\narbitrary payload. Instead, you use a constant string UNSIGNED-PAYLOAD.\n\u2022 The Canonical Query String must include all the query parameters from the preceding table\nexcept for X-Amz-Signature.\n\u2022 For S3, you must include the X-Amz-Security-Token query parameter in the URL if using\ncredentials sourced from the STS service.\n\u2022 Canonical Headers must include the HTTP host header. If you plan to include any of the\nx-amz-* headers, these headers must also be added for signature calculation. You can\noptionally add all other headers that you plan to include in your request. For added security, you\nshould sign as many headers as possible. If you add a signed header that is also a signed query\nparameter, and they differ in value, you will receive an InvalidRequest error as the input is\nconflicting.\nAn Example\nSuppose you have an object test.txt in your examplebucket bucket. You want to share this\nobject with others for a period of 24 hours (86400 seconds) by creating a presigned URL.\nhttps://examplebucket.s3.amazonaws.com/test.txt\n?X-Amz-Algorithm=AWS4-HMAC-SHA256\n&X-Amz-Credential=AKIAIOSFODNN7EXAMPLE%2F20130524%2Fus-east-1%2Fs3%2Faws4_request\n&X-Amz-Date=20130524T000000Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host\n&X-Amz-Signature=<signature-value>\nThe following steps illustrate first the signature calculations and then construction of the\npresigned URL. The example makes the following additional assumptions:\n\u2022 Request timestamp is Fri, 24 May 2013 00:00:00 GMT.\nAn Example API Version 2006-03-01 2688",
      "start_idx": 3005447,
      "end_idx": 3007556,
      "metadata": {
        "num_sentences": 15,
        "num_words": 300,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2694",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 The bucket is in the US East (N. Virginia) region, and the credential Scope and the Signing\nKey calculations use us-east-1 as the region specifier. For more information, see Regions and\nEndpoints in the AWS General Reference.\nYou can use this example as a test case to verify the signature that your code calculates; however,\nyou must use the same bucket name, object key, time stamp, and the following example\ncredentials:\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAccessKey\n1. StringToSign\na. CanonicalRequest\nGET\n/test.txt\nX-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIOSFODNN7EXAMPLE\n%2F20130524%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20130524T000000Z&X-Amz-\nExpires=86400&X-Amz-SignedHeaders=host\nhost:examplebucket.s3.amazonaws.com\nhost\nUNSIGNED-PAYLOAD\nb. StringToSign\nAWS4-HMAC-SHA256\n20130524T000000Z\n20130524/us-east-1/s3/aws4_request\n3bfa292879f6447bbcda7001decf97f4a54dc650c8942174ae0a9121cf58ad04\nAn Example API Version 2006-03-01 2689",
      "start_idx": 3007558,
      "end_idx": 3008626,
      "metadata": {
        "num_sentences": 4,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2695",
      "text": "Amazon Simple Storage Service API Reference\n2. SigningKey\nsigning key = HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(HMAC-SHA256(\"AWS4\" +\n\"<YourSecretAccessKey>\",\"20130524\"),\"us-east-1\"),\"s3\"),\"aws4_request\")\n3. Signature\naeeed9bbccd4d02ee5c0109b86d86835f995330da4c265957d157751f604d404\nNow you have all information to construct a presigned URL. The resulting URL for this example\nis shown as follows (you can use this to compare your presigned URL):\nhttps://examplebucket.s3.amazonaws.com/test.txt?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-\nAmz-Credential=AKIAIOSFODNN7EXAMPLE%2F20130524%2Fus-east-1%2Fs3%2Faws4_request&X-\nAmz-Date=20130524T000000Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host&X-Amz-\nSignature=aeeed9bbccd4d02ee5c0109b86d86835f995330da4c265957d157751f604d404\nExample 2\nThe following is an example (unrelated to the previous example) showing a presigned URL with the\nX-Amz-Security-Token parameter.\nhttps://examplebucket.s3.us-east-1.amazonaws.com/test.txt\n?X-Amz-Algorithm=AWS4-HMAC-SHA256\n&X-Amz-Credential=AKIAIOSFODNN7EXAMPLE%2F20130524%2Fus-east-1%2Fs3%2Faws4_request\n&X-Amz-Date=20200524T000000Z&X-Amz-Expires=86400&X-Amz-SignedHeaders=host\n&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEMv%2F%2F%2F%2F%2F%2F%2F%2F%2F\n%2FwEaCXVzLWVhc3QtMSJGMEQCIBSUbVdj9YGs2g0HkHsOHFdkwOozjARSKHL987NhhOC8AiBPepRU1obMvIbGU0T\n%2BWphFPgK%2Fqpxaf5Snvm5M57XFkCqlAgjz%2F%2F%2F%2F%2F%2F%2F%2F%2F\n%2F8BEAAaDDQ3MjM4NTU0NDY2MCIM83pULBe5%2F\n%2BNm1GZBKvkBVslSaJVgwSef7SsoZCJlfJ56weYl3QCwEGr2F4BmCZZyFpmWEYzWnhNK1AnHMj5nkfKlKBx30XAT5PZGVrmq4Vkn9ewlXQy1Iu3QJRi9Tdod8Ef9%2FyajTaUGh76%2BF5u5a4O115jwultOQiKomVwO318CO4l8lv\n%2F3HhMOkpdanMXn%2B4PY8lvM8RgnzSu90jOUpGXEOAo\n%2F6G8OqlMim3%2BZmaQmasn4VYRvESEd7O72QGZ3%2BvDnDVnss0lSYjlv8PP7IujnvhZRnj0WoeOyMe1lL0wTG\n%2Fa9usH5hE52w%2FYUJccOn0OaZuyROuVsRV4Q70sbWQhUvYUt%2B0tUMKzm8vsFOp4BaNZFqobbjtb36Y92v\n%2Bx5kY6i0s8QE886jJtUWMP5ldMziClGx3p0mN5dzsYlM3GyiJ\n%2FO1mWkPQDwg3mtSpOA9oeeuAMPTA7qMqy9RNuTKBDSx9EW27wvPzBum3SJhEfxv48euadKgrIX3Z79ruQFSQOc9LUrDjR\n%2B4SoWAJqK%2BGX8Q3vPSjsLxhqhEMWd6U4TXcM7ku3gxMbzqfT8NDg%3D\nExample 2 API Version 2006-03-01 2690",
      "start_idx": 3008628,
      "end_idx": 3010684,
      "metadata": {
        "num_sentences": 5,
        "num_words": 91,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2696",
      "text": "Amazon Simple Storage Service API Reference\n&X-Amz-Signature=<signature-value>\nExamples: Signature Calculations in AWS Signature Version 4\nTopics\n\u2022 Signature Calculation Examples Using Java (AWS Signature Version 4)\n\u2022 Examples of Signature Calculations Using C# (AWS Signature Version 4)\nFor authenticated requests, unless you are using the AWS SDKs, you have to write code to calculate\nsignatures that provide authentication information in your requests. Signature calculation in AWS\nSignature Version 4 (see Authenticating Requests (AWS Signature Version 4)) can be a complex\nundertaking, and we recommend that you use the AWS SDKs whenever possible.\nThis section provides examples of signature calculations written in Java and C#. The code samples\nsend the following requests and use the HTTP Authorization header to provide authentication\ninformation:\n\u2022 PUT object \u2013 Separate examples illustrate both uploading the full payload at once and\nuploading the payload in chunks. For information about using the Authorization header for\nauthentication, see Authenticating Requests: Using the Authorization Header (AWS Signature\nVersion 4).\n\u2022 GET object \u2013 This example generates a presigned URL to get an object. Query parameters\nprovide the signature and other authentication information. Users can paste a presigned URL\nin their browser to retrieve the object, or you can use the URL to create a clickable link. For\ninformation about using query parameters for authentication, see Authenticating Requests:\nUsing Query Parameters (AWS Signature Version 4).\nThe rest of this section describes the examples in Java and C#. The topics include instructions for\ndownloading the samples and for executing them.\nSignature Calculation Examples Using Java (AWS Signature Version 4)\nThe Java sample that shows signature calculation can be downloaded at https://\ndocs.aws.amazon.com/AmazonS3/latest/API/samples/AWSS3SigV4JavaSamples.zip. In\nRunAllSamples.java, the main() function executes sample requests to create an object,\nExamples: Signature Calculations API Version 2006-03-01 2691",
      "start_idx": 3010686,
      "end_idx": 3012759,
      "metadata": {
        "num_sentences": 13,
        "num_words": 291,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2697",
      "text": "Amazon Simple Storage Service API Reference\nretrieve an object, and create a presigned URL for the object. The sample creates an object from\nthe text string provided in the code:\nPutS3ObjectSample.putS3Object(bucketName, regionName, awsAccessKey, awsSecretKey);\nGetS3ObjectSample.getS3Object(bucketName, regionName, awsAccessKey, awsSecretKey);\nPresignedUrlSample.getPresignedUrlToS3Object(bucketName, regionName, awsAccessKey,\nawsSecretKey);\nPutS3ObjectChunkedSample.putS3ObjectChunked(bucketName, regionName, awsAccessKey,\nawsSecretKey);\nTo test the examples on a Linux-based computer\nThe following instructions are for the Linux operating system.\n1. In a terminal, navigate to the directory that contains AWSS3SigV4JavaSamples.zip.\n2. Extract the .zip file.\n3. In a text editor, open the file ./com/amazonaws/services/s3/samples/\nRunAllSamples.java. Update code with the following information:\n\u2022 The name of a bucket where the new object can be created.\nNote\nThe examples use a virtual-hosted style request to access the bucket. To avoid\npotential errors, ensure that your bucket name conforms to the bucket naming rules as\nexplained in Bucket Restrictions and Limitations in the Amazon Simple Storage Service\nUser Guide.\n\u2022 AWS Region where the bucket resides.\nIf bucket is in the US East (N. Virginia) region, use us-east-1 to specify the region. For a list of\nother AWS Regions, go to Amazon Simple Storage Service (S3) in the AWS General Reference.\n4. Compile the source code and store the compiled classes into the bin/ directory.\njavac -d bin -source 6 -verbose com\n5. Change the directory to bin/, and then run RunAllSamples.\nSignature Calculation Examples Using Java API Version 2006-03-01 2692",
      "start_idx": 3012761,
      "end_idx": 3014465,
      "metadata": {
        "num_sentences": 19,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2698",
      "text": "Amazon Simple Storage Service API Reference\njava com.amazonaws.services.s3.sample.RunAllSamples\nThe code runs all the methods in main(). For each request, the output will show the canonical\nrequest, the string to sign, and the signature.\nExamples of Signature Calculations Using C# (AWS Signature Version 4)\nThe C# sample that shows signature calculation can be downloaded at https://\ndocs.aws.amazon.com/AmazonS3/latest/API/samples/AmazonS3SigV4_Samples_CSharp.zip.\nIn Program.cs, the main() function executes sample requests to create an object, retrieve an\nobject, and create a presigned URL for the object. The code for signature calculation is in the\n\\Signers folder.\nPutS3ObjectSample.Run(awsRegion, bucketName, \"MySampleFile.txt\");\nConsole.WriteLine(\"\\n\\n************************************************\");\nPutS3ObjectChunkedSample.Run(awsRegion, bucketName, \"MySampleFileChunked.txt\");\nConsole.WriteLine(\"\\n\\n************************************************\");\nGetS3ObjectSample.Run(awsRegion, bucketName, \"MySampleFile.txt\");\nConsole.WriteLine(\"\\n\\n************************************************\");\nPresignedUrlSample.Run(awsRegion, bucketName, \"MySampleFile.txt\");\nTo test the examples with Microsoft Visual Studio 2010 or later\n1. Extract the .zip file.\n2. Start Visual Studio, and then open the .sln file.\n3. Update the App.config file with valid security credentials.\n4. Update the code as follows:\n\u2022 In Program.cs, provide the bucket name and the AWS Region where the bucket resides. The\nsample creates an object in this bucket.\n5. Run the code.\n6. To verify that the object was created, copy the presigned URL that the program creates, and\nthen paste it in a browser window.\nSignature Calculation Examples Using C# API Version 2006-03-01 2693",
      "start_idx": 3014467,
      "end_idx": 3016226,
      "metadata": {
        "num_sentences": 19,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2699",
      "text": "Amazon Simple Storage Service API Reference\nAuthenticating Requests: Browser-Based Uploads Using POST\n(AWS Signature Version 4)\nAmazon S3 supports HTTP POST requests so that users can upload content directly to Amazon\nS3. Using HTTP POST to upload content simplifies uploads and reduces upload latency where\nusers upload data to store in Amazon S3. This section describes how you authenticate HTTP POST\nrequests. For more information about HTTP POST requests, how to create a form, create a POST\npolicy, and an example, see Browser-Based Uploads Using POST (AWS Signature Version 4).\nTo authenticate an HTTP POST request you do the following:\n1. The form must include the following fields to provide signature and relevant information that\nAmazon S3 can use to re-calculate the signature upon receiving the request:\nElement Name Description\npolicy\nThe Base64-encoded security policy that describes\nwhat is permitted in the request. For signature\ncalculation this policy is the string you sign. Amazon\nS3 must get this policy so it can re-calculate the\nsignature.\nx-amz-algorithm\nThe signing algorithm used. For AWS Signature\nVersion 4, the value is AWS4-HMAC-SHA256 .\nx-amz-credential\nIn addition to your access key ID, this provides scope\ninformation you used in calculating the signing key\nfor signature calculation.\nIt is a string of the following form:\n<your-access-key-id> /<date>/<aws-regi\non> /<aws-service> /aws4_request\nFor example:\nAuthenticating HTTP POST Requests API Version 2006-03-01 2694",
      "start_idx": 3016228,
      "end_idx": 3017731,
      "metadata": {
        "num_sentences": 12,
        "num_words": 225,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2700",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description\nAKIAIOSFODNN7EXAMPLE/20130728/us-\neast-1/s3/aws4_request . .\nFor Amazon S3, the aws-service string is s3. For a list\nof Amazon S3 aws-region strings, see Regions\nand Endpoints in the AWS General Reference.\nx-amz-date\nIt is the date value in ISO8601 format. For example,\n20130728T000000Z .\nIt is the same date you used in creating the signing\nkey. This must also be the same value you provide in\nthe policy (x-amz-date ) that you signed.\nx-amz-signature\n(AWS Signature Version 4) The HMAC-SHA256 hash\nof the security policy.\nFor more information on options for the signature,\nsee Add the signature to the HTTP request in the AWS\nGeneral Reference.\n2. The POST policy must include the following elements:\nElement Name Description\nx-amz-algorithm\nThe signing algorithm that you used to calculation\nthe signature. For AWS Signature Version 4, the value\nis A WS4-HMAC-SHA256 .\nx-amz-credential\nIn addition to your access key ID, this provides scope\ninformation you used in calculating the signing key\nfor signature calculation.\nIt is a string of the following form:\nAuthenticating HTTP POST Requests API Version 2006-03-01 2695",
      "start_idx": 3017733,
      "end_idx": 3018924,
      "metadata": {
        "num_sentences": 15,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2701",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description\n<your-access-key-id> /<date>/<aws-regi\non> /<aws-service> /aws4_request\nFor example,\nAKIAIOSFODNN7EXAMPLE/20130728/us-\neast-1/s3/aws4_request . .\nx-amz-date\nThe date value specified in the ISO8601 formatted\nstring. For example, \"20130728T000000Z\". The\ndate must be the same that you used in creating the\nsigning key for signature calculation.\n3. For signature calculation the POST policy is the string to sign.\nCalculating a Signature\nThe following diagram illustrates the signature calculation process.\nCalculating a Signature API Version 2006-03-01 2696",
      "start_idx": 3018926,
      "end_idx": 3019550,
      "metadata": {
        "num_sentences": 9,
        "num_words": 80,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2702",
      "text": "Amazon Simple Storage Service API Reference\nTo Calculate a signature\n1. Create a policy using UTF-8 encoding.\n2. Convert the UTF-8-encoded policy to Base64. The result is the string to sign.\n3. Create the signature as an HMAC-SHA256 hash of the string to sign. You will provide the\nsigning key as key to the hash function.\n4. Encode the signature by using hex encoding.\nFor more information about creating HTML forms, security policies, and an example, see the\nfollowing subtopics:\n\u2022 Creating an HTML Form (Using AWS Signature Version 4)\n\u2022 POST Policy\n\u2022 Example: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4)\nAmazon S3 Signature Version 4 Authentication Specific Policy\nKeys\nThe following table shows the policy keys related Amazon S3 Signature Version 4 authentication\nthat can be in Amazon S3 policies. In a bucket policy, you can add these conditions to enforce\nspecific behavior when requests are authenticated by using Signature Version 4. For example\npolicies, see Bucket Policy Examples Using Signature Version 4 Related Condition Keys.\nApplicable Keys Description\ns3:signatureversion Identifies the version of AWS Signature\nthat you want to support for authentic\nated requests. For authenticated requests,\nAmazon S3 supports both Signature Version\n4 and Signature Version 2. You can add this\ncondition in your bucket policy to require a\nspecific signature version.\nValid values:\nAmazon S3 Signature Version 4 Authentication Specific Policy Keys API Version 2006-03-01 2697",
      "start_idx": 3019552,
      "end_idx": 3021055,
      "metadata": {
        "num_sentences": 17,
        "num_words": 234,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2703",
      "text": "Amazon Simple Storage Service API Reference\nApplicable Keys Description\n\"AWS\" identifies Signature Version 2\n\"AWS4-HMAC-SHA256\" identifies Signature\nVersion 4\ns3:authType Amazon S3 supports various methods of\nauthentication (see Authenticating Requests\n(AWS Signature Version 4). You can option\nally use this condition key to restrict incoming\nrequests to use a specific authentication\nmethod. For example, you can allow only the\nHTTP Authorization header to be used in\nrequest authentication.\nValid values:\nREST-HEADER\nREST-QUERY-STRING\nPOST\nAmazon S3 Signature Version 4 Authentication Specific Policy Keys API Version 2006-03-01 2698",
      "start_idx": 3021057,
      "end_idx": 3021693,
      "metadata": {
        "num_sentences": 4,
        "num_words": 86,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2704",
      "text": "Amazon Simple Storage Service API Reference\nApplicable Keys Description\ns3:signatureAge The length of time, in milliseconds, that a\nsignature is valid in an authenticated request.\nThis condition works for:\n\u2022 Presigned URLs \u2014 where the most restricti\nve condition wins. For more information, see\nWorking with presigned URLs.\n\u2022 Presigned POST \u2014 upload files directly to S3\nusing pre-signed POST. For more informati\non, see Amazon S3 POST Policy.\nIn Signature Version 2, this value is always set\nto 0.\nIn Signature Version 4, the signing key is valid\nfor up to seven days. Therefore, the signature\ns are also valid for up to seven days. You can\nuse this condition to further limit the signature\nage. For more information, see Introduction to\nSigning Requests.\nExample value: 100\nAmazon S3 Signature Version 4 Authentication Specific Policy Keys API Version 2006-03-01 2699",
      "start_idx": 3021695,
      "end_idx": 3022564,
      "metadata": {
        "num_sentences": 11,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2705",
      "text": "Amazon Simple Storage Service API Reference\nApplicable Keys Description\ns3:x-amz-content-sha256 You can use this condition key to disallow\nunsigned content in your bucket.\nWhen you use Signature Version 4, for requests\nthat use the Authorization header, you\nadd the x-amz-content-sha256 header\nin the signature calculation and then set its\nvalue to the hash payload.\nYou can use this condition key in your bucket\npolicy to deny any uploads where payloads are\nnot signed. For example:\n\u2022\nDeny uploads that use presigned URLs.\nFor more information, see Authenticating\nRequests: Using Query Parameters (AWS S\nignature Version 4).\n\u2022\nDeny uploads that use Authorization header\nto authenticate requests but don't sign\nthe payload. For more information, see\nSignature Calculations for the Authorization\nHeader: Transferring Payload in a Single\nChunk (AWS Signature Version 4).\nValid value: UNSIGNED-PAYLOAD\nBucket Policy Examples Using Signature Version 4 Related Condition\nKeys\nThe following bucket policy denies any Amazon S3 presigned URL request on objects in\nexamplebucket if the signature is more than ten minutes old.\nBucket Policy Examples Using Signature Version 4 Related Condition Keys API Version 2006-03-01 2700",
      "start_idx": 3022566,
      "end_idx": 3023782,
      "metadata": {
        "num_sentences": 9,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2706",
      "text": "Amazon Simple Storage Service API Reference\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"Deny a presigned URL request if the signature is more than 10 min\nold\",\n\"Effect\": \"Deny\",\n\"Principal\": \"*\",\n\"Action\": \"s3:*\",\n\"Resource\": \"arn:aws:s3:::examplebucket3/*\",\n\"Condition\": {\n\"NumericGreaterThan\": {\n\"s3:signatureAge\": 600000\n}\n}\n}\n]\n}\nThe following bucket policy allows only requests that use the Authorization header for request\nauthentication. Any POST or presigned URL requests will be denied.\n{\n\"Version\": \"2012-10-17\",\n\"Statement\": [\n{\n\"Sid\": \"Allow only requests that use Authorization header for request\nauthentication. Deny POST or presigned URL requests.\",\n\"Effect\": \"Deny\",\n\"Principal\": \"*\",\n\"Action\": \"s3:*\",\n\"Resource\": \"arn:aws:s3:::examplebucket3/*\",\n\"Condition\": {\n\"StringNotEquals\": {\n\"s3:authType\": \"REST-HEADER\"\n}\n}\n}\n]\n}\nBucket Policy Examples Using Signature Version 4 Related Condition Keys API Version 2006-03-01 2701",
      "start_idx": 3023784,
      "end_idx": 3024730,
      "metadata": {
        "num_sentences": 5,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2708",
      "text": "Amazon Simple Storage Service API Reference\nBrowser-Based Uploads Using POST (AWS Signature\nVersion 4)\nThis section discusses how to upload files directly to Amazon S3 through a browser using HTTP\nPOST requests. It also contains information about how to use the AWS Amplify JavaScript library\nfor browser-based file uploads to Amazon S3.\nTopics\n\u2022 POST Object\n\u2022 POST Object restore\n\u2022 Browser-Based Uploads Using HTTP POST\n\u2022 Calculating a Signature\n\u2022 Creating an HTML Form (Using AWS Signature Version 4)\n\u2022 POST Policy\n\u2022 Example: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4)\n\u2022 Browser-Based Uploads to Amazon S3 Using the AWS Amplify Library\nAPI Version 2006-03-01 2703",
      "start_idx": 3025265,
      "end_idx": 3025956,
      "metadata": {
        "num_sentences": 3,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2709",
      "text": "Amazon Simple Storage Service API Reference\nPOST Object\nDescription\nThe POST operation adds an object to a specified bucket by using HTML forms. POST is an\nalternate form of PUT that enables browser-based uploads as a way of putting objects in buckets.\nParameters that are passed to PUT through HTTP headers are instead passed as form fields to\nPOST in the multipart/form-data encoded message body. To add an object to a bucket, you\nmust have WRITE access on the bucket. Amazon S3 never stores partial objects. If you receive a\nsuccessful response, you can be confident that the entire object was stored.\nAmazon S3 is a distributed system. Unless you've enabled versioning for a bucket, if Amazon S3\nreceives multiple write requests for the same object simultaneously, only the last version of the\nobject written is stored.\nTo ensure that data is not corrupted while traversing the network, use the Content-MD5 form\nfield. When you use this form field, Amazon S3 checks the object against the provided MD5 value.\nIf they do not match, Amazon S3 returns an error. Additionally, you can calculate the MD5 value\nwhile posting an object to Amazon S3 and compare the returned ETag to the calculated MD5\nvalue. The ETag reflects only changes to the contents of an object, not its metadata.\nNote\nTo configure your application to send the request headers before sending the request body,\nuse the HTTP status code 100 (Continue). For POST operations, using this status code helps\nyou avoid sending the message body if the message is rejected based on the headers (for\nexample, because of an authentication failure or redirect). For more information about\nthe HTTP status code 100 (Continue), go to Section 8.2.3 of http://www.ietf.org/rfc/\nrfc2616.txt.\nAmazon S3 automatically encrypts all new objects that are uploaded to an S3 bucket. The\nencryption setting of an uploaded object depends on the default encryption configuration of the\ndestination bucket. By default, all buckets have a default encryption configuration that uses server-\nside encryption with Amazon S3 managed keys (SSE-S3).\nIf the destination bucket has an encryption configuration that uses server-side encryption with an\nAWS Key Management Service (AWS KMS) key (SSE-KMS), dual-layer server-side encryption with\nPOST Object API Version 2006-03-01 2704",
      "start_idx": 3025958,
      "end_idx": 3028271,
      "metadata": {
        "num_sentences": 20,
        "num_words": 371,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2710",
      "text": "Amazon Simple Storage Service API Reference\nan AWS KMS key (DSSE-KMS), or a customer-provided encryption key (SSE-C), Amazon S3 uses the\ncorresponding KMS key or customer-provided key to encrypt the uploaded object. When uploading\nan object, if you want to change the encryption setting of the uploaded object, you can specify the\ntype of server-side encryption. You can configure SSE-S3, SSE-KMS, DSSE-KMS, or SSE-C. For more\ninformation, see Protecting data using server-side encryption in the Amazon Simple Storage Service\nUser Guide.\nImportant\nWhen constructing your request, make sure that the file field is the last field in the form.\nVersioning\nIf you enable versioning for a bucket, POST automatically generates a unique version ID for the\nobject being added. Amazon S3 returns this ID in the response by using the x-amz-version-id\nresponse header.\nIf you suspend versioning for a bucket, Amazon S3 always uses null as the version ID of the object\nstored in a bucket.\nFor more information about returning the versioning state of a bucket, see GET Bucket (Versioning\nStatus).\nAmazon S3 is a distributed system. If you enable versioning for a bucket and Amazon S3 receives\nmultiple write requests for the same object simultaneously, all versions of the object are stored.\nTo see sample requests that use versioning, see Sample Request.\nRequests\nSyntax\nPOST / HTTP/1.1\nHost: destinationBucket.s3.amazonaws.com\nUser-Agent: browser_data\nAccept: file_types\nAccept-Language: Regions\nAccept-Encoding: encoding\nAccept-Charset: character_set\nKeep-Alive: 300\nVersioning API Version 2006-03-01 2705",
      "start_idx": 3028273,
      "end_idx": 3029867,
      "metadata": {
        "num_sentences": 12,
        "num_words": 238,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2712",
      "text": "Amazon Simple Storage Service API Reference\nfile_content\n--9431149156168\nContent-Disposition: form-data; name=\"submit\"\nUpload to Amazon S3\n--9431149156168--\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nForm Fields\nThis operation can use the following form fields.\nName Description Required\nAWSAccessKeyId The AWS access key ID of the owner of the bucket Condition\nwho grants an Anonymous user access for a al\nrequest that satisfies the set of constraints in the\npolicy.\nType: String\nDefault: None\nConstraints: Required if a policy document is\nincluded with the request.\nacl The specified Amazon S3 access control list No\n(ACL). If the specified ACL is not valid, an error is\ngenerated. For more information about ACLs, see\nAccess control list (ACL) overview in the Amazon\nSimple Storage Service User Guide.\nType: String\nDefault: private\nRequests API Version 2006-03-01 2707",
      "start_idx": 3030954,
      "end_idx": 3031871,
      "metadata": {
        "num_sentences": 8,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2713",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nValid Values: private | public-read |\npublic-read-write | aws-exec-read |\nauthenticated-read | bucket-owner-\nread | bucket-owner-full-control\nCache-Control , Content- The REST-specific headers. For more information, No\nType , Content-D see PutObject.\nisposition , Content-E\nType: String\nncoding , Expires\nDefault: None\nfile The file or text content. Yes\nThe file or text content must be the last field in the\nform.\nYou cannot upload more than one file at a time.\nType: File or text content\nDefault: None\nkey The name of the uploaded key. Yes\nTo use the file name provided by the user, use the\n${filename} variable. For example, if a user\nnamed Mary uploads the file example.jpg and\nyou specify /user/mary/${filename} , the\nkey name is /user/mary/example.jpg .\nFor more information, see Object key and\nmetadata in the Amazon Simple Storage Service\nUser Guide.\nType: String\nDefault: None\nRequests API Version 2006-03-01 2708",
      "start_idx": 3031873,
      "end_idx": 3032865,
      "metadata": {
        "num_sentences": 10,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2714",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\npolicy The security policy that describes what is Condition\npermitted in the request. Requests without a al\nsecurity policy are considered anonymous and\nwork only on publicly writable buckets. For\nmore information, see HTML forms and Upload\nexamples in the Amazon Simple Storage Service\nUser Guide.\nType: String\nDefault: None\nConstraints: A security policy is required if the\nbucket is not publicly writable.\nRequests API Version 2006-03-01 2709",
      "start_idx": 3032867,
      "end_idx": 3033382,
      "metadata": {
        "num_sentences": 5,
        "num_words": 77,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2717",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\ntagging The specified set of tags to add to the object. To No\nadd tags, use the following encoding scheme.\n<Tagging>\n<TagSet>\n<Tag>\n<Key>TagName</Key>\n<Value>TagValue</Value>\n</Tag>\n...\n</TagSet>\n</Tagging>\nFor more information, see Object tagging in the\nAmazon Simple Storage Service User Guide.\nType: String\nDefault: None\nx-amz-storage-class The storage class to use for storing the object. No\nIf you don't specify a class, Amazon S3 uses the\ndefault storage class, STANDARD. Amazon S3\nsupports other storage classes. For more informati\non, see Storage classes in the Amazon Simple\nStorage Service User Guide.\nType: String\nDefault: STANDARD\nValid values: STANDARD | REDUCED_REDUNDANCY\n| GLACIER | GLACIER_IR | STANDARD_IA\n| ONEZONE_IA | INTELLIGENT_TIERING |\nDEEP_ARCHIVE\nRequests API Version 2006-03-01 2712",
      "start_idx": 3034700,
      "end_idx": 3035580,
      "metadata": {
        "num_sentences": 8,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2718",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-meta-* Headers starting with this prefix are user-defined No\nmetadata. Each one is stored and returned as a\nset of key-value pairs. Amazon S3 doesn't validate\nor interpret user-defined metadata. For more\ninformation, see PutObject.\nType: String\nDefault: None\nx-amz-security-token The Amazon DevPay security token. No\nEach request that uses Amazon DevPay requires\ntwo x-amz-security-token form fields: one\nfor the product token and one for the user token.\nType: String\nDefault: None\nx-amz-signature (AWS Signature Version 4) The HMAC-SHA256 Condition\nhash of the security policy. al\nType: String\nDefault: None\nRequests API Version 2006-03-01 2713",
      "start_idx": 3035582,
      "end_idx": 3036303,
      "metadata": {
        "num_sentences": 8,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2719",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-website-redi If the bucket is configured as a website, this field No\nrect-location redirects requests for this object to another object\nin the same bucket or to an external URL. Amazon\nS3 stores the value of this header in the object\nmetadata. For information about object metadata,\nsee Object key and metadata in the Amazon Simple\nStorage Service User Guide.\nIn the following example, the request header sets\nthe redirect to an object (anotherPage.html ) in\nthe same bucket:\nx-amz-website-redirect-location: /\nanotherPage.html\nIn the following example, the request header sets\nthe object redirect to another website:\nx-amz-website-redirect-location:\nhttp://www.example.com/\nFor more information about website hosting in\nAmazon S3, see Hosting websites on Amazon S3\nand How to configure website page redirects in the\nAmazon Simple Storage Service User Guide.\nType: String\nDefault: None\nConstraints: The value must be prefixed by /,\nhttp://, or https://. The length of the value is\nlimited to 2 KB.\nRequests API Version 2006-03-01 2714",
      "start_idx": 3036305,
      "end_idx": 3037415,
      "metadata": {
        "num_sentences": 7,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2720",
      "text": "Amazon Simple Storage Service API Reference\nAdditional Checksum Request Form Fields\nWhen uploading an object, you can specify various checksums that you would like to use to verify\nyour data integrity. You can specify one additional checksum algorithm for Amazon S3 to use. For\nmore information about additional checksum values, see Checking object integrity in the Amazon\nSimple Storage Service User Guide.\nName Description Required\nx-amz-che Indicates the algorithm used to create the checksum for No\ncksum-alg the object. If a value is specified, you must include the\norithm matching checksum header. Otherwise, your request will\ngenerate a 400 error.\nPossible values include CRC32, CRC32C, SHA1, and SHA256.\nx-amz-che Specifies the base64-encoded, 32-bit CRC32 checksum of Condition\ncksum-crc32 the object. al\nThis parameter is required if the value of x-amz-che\ncksum-algorithm is CRC32.\nx-amz-che Specifies the base64-encoded, 32-bit CRC32C checksum of Condition\ncksum-crc32c the object. al\nThis parameter is required if the value of x-amz-che\ncksum-algorithm is CRC32C.\nx-amz-che Specifies the base64-encoded, 160-bit SHA-1 digest of the Condition\ncksum-sha1 object. al\nThis parameter is required if the value of x-amz-che\ncksum-algorithm is SHA1.\nx-amz-che Specifies the base64-encoded, 256-bit SHA-256 digest of Condition\ncksum-sha256 the object. al\nThis parameter is required if the value of x-amz-che\ncksum-algorithm is SHA256.\nRequests API Version 2006-03-01 2715",
      "start_idx": 3037417,
      "end_idx": 3038892,
      "metadata": {
        "num_sentences": 16,
        "num_words": 213,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2721",
      "text": "Amazon Simple Storage Service API Reference\nServer-Side Encryption Specific Request Form Fields\nServer-side encryption is data encryption at rest. Amazon S3 encrypts your data while writing it to\ndisks in AWS data centers and decrypts your data when you access it. When uploading an object,\nyou can specify the type of server-side encryption that you want Amazon S3 to use for encrypting\nthe object.\nThere are four types of server-side encryption:\n\u2022 Server-side encryption with Amazon S3 managed keys (SSE-S3) \u2013 Starting May 2022, all\nAmazon S3 buckets have encryption configured by default. The default option for server-\nside encryption is with SSE-S3. Each object is encrypted with a unique key. As an additional\nsafeguard, SSE-S3 encrypts the key itself with a root key that it regularly rotates. SSE-S3 uses\none of the strongest block ciphers available, 256-bit Advanced Encryption Standard (AES-256),\nto encrypt your data.\n\u2022 Server-side encryption with AWS KMS keys (SSE-KMS) \u2013 SSE-KMS is provided through an\nintegration of the AWS KMS service with Amazon S3. With AWS KMS, you have more control over\nyour keys. For example, you can view separate keys, edit control policies, and follow the keys in\nAWS CloudTrail. Additionally, you can create and manage customer managed keys or use AWS\nmanaged keys that are unique to you, your service, and your Region.\n\u2022 Dual-layer server-side encryption with AWS KMS keys (DSSE-KMS) \u2013 Dual-layer server-side\nencryption with AWS KMS keys (DSSE-KMS) is similar to SSE-KMS, but applies two individual\nlayers of object-level encryption instead of one layer.\n\u2022 Server-side encryption with customer-provided keys (SSE-C) \u2013 With SSE-C, you manage the\nencryption keys, and Amazon S3 manages the encryption as it writes to disks, and the decryption\nwhen you access your objects.\nFor more information, see Protecting data using server-side encryption in the Amazon Simple\nStorage Service User Guide.\nDepending on which type of server-side encryption you want to use, specify the following form\nfields.\n\u2022 Use SSE-S3, SSE-KMS, or DSSE-KMS \u2013 If you want to use these types of server-side encryption,\nspecify the following form fields in the request.\nRequests API Version 2006-03-01 2716",
      "start_idx": 3038894,
      "end_idx": 3041111,
      "metadata": {
        "num_sentences": 18,
        "num_words": 351,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2722",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-server- Specifies the server-side encryption algorithm to use Yes\nside-encryptio when Amazon S3 creates an object. To use SSE-S3, specify\nn AES256. To use SSE-KMS, specify aws:kms. To use DSSE-\nKMS, specify aws:kms:dsse .\nType: String\nValid Value: aws:kms, AES256, aws:kms:dsse\nx-amz-server- If the x-amz-server-side-encryption header Yes, if\nside-encryptio has a valid value of aws:kms or aws:kms:dsse , this the value\nn-aws-kms- header specifies the ID of the AWS KMS key that was used of x-\nkey-id to encrypt the object. amz-ser\nver-\nType: String\nside-\nencryptio\nn is\naws:kms\nor\naws:kms:d\nsse\nx-amz-server- If x-amz-server-side-encryption has a valid No\nside-encryptio value of aws:kms or aws:kms:dsse , this header\nn-context specifies the encryption context for the object. The value\nof this header is a base64-encoded UTF-8 string that\ncontains JSON-formatted key-value pairs for the encryptio\nn context.\nType: String\nRequests API Version 2006-03-01 2717",
      "start_idx": 3041113,
      "end_idx": 3042148,
      "metadata": {
        "num_sentences": 8,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2723",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nx-amz-server- If x-amz-server-side-encryption has a valid No\nside-encryptio value of aws:kms or aws:kms:dsse , this header\nn-bucket-key- specifies whether Amazon S3 should use an S3 Bucket Key\nenabled with SSE-KMS or DSSE-KMS. Setting this header to true\ncauses Amazon S3 to use an S3 Bucket Key for object\nencryption with SSE-KMS or DSSE-KMS.\nType: Boolean\nNote\nIf you specify x-amz-server-side-encryption:aws:kms or x-amz-server-side-\nencryption:aws:kms:dsse, but do not provide x-amz-server-side-encryption-\naws-kms-key-id, Amazon S3 uses the AWS managed key (aws/S3) to protect the data.\n\u2022 Use SSE-C \u2013 If you want to manage your own encryption keys, you must provide all the following\nform fields in the request.\nNote\nIf you use SSE-C, the ETag value that Amazon S3 returns in the response is not the MD5\nof the object.\nName Description Required\nx-amz-server- Specifies the algorithm to use to when encrypting the Yes\nside-encryptio object.\nn-customer-\nType: String\nalgorithm\nDefault: None\nValid Value: AES256\nRequests API Version 2006-03-01 2718",
      "start_idx": 3042150,
      "end_idx": 3043270,
      "metadata": {
        "num_sentences": 7,
        "num_words": 166,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2724",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nConstraints: Must be accompanied by valid x-amz-ser\nver-side-encryption-customer-key and x-\namz-server-side-encryption-customer-key-\nMD5 fields.\nx-amz-server- Specifies the customer-provided base64-encoded Yes\nside-encryptio encryption key for Amazon S3 to use in encrypting\nn-customer- data. This value is used to store the object, and then it\nkey is discarded. Amazon does not store the encryption key.\nThe key must be appropriate for use with the algorithm\nspecified in the x-amz-server-side-encryption-\ncustomer-algorithm header.\nType: String\nDefault: None\nConstraints: Must be accompanied by valid x-amz-ser\nver-side-encryption-customer-algorithm\nand x-amz-server-side-encryption-custome\nr-key-MD5 fields.\nx-amz-server- Specifies the base64-encoded 128-bit MD5 digest of the Yes\nside-encryptio encryption key according to RFC 1321. Amazon S3 uses\nn-customer- this header for a message-integrity check to ensure that\nkey-MD5 the encryption key was transmitted without error.\nType: String\nDefault: None\nConstraints: Must be accompanied by valid x-amz-ser\nver-side-encryption-customer-algorithm\nand x-amz-server-side-encryption-custome\nr-key fields.\nRequests API Version 2006-03-01 2719",
      "start_idx": 3043272,
      "end_idx": 3044530,
      "metadata": {
        "num_sentences": 10,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2725",
      "text": "Amazon Simple Storage Service API Reference\nResponses\nResponse Headers\nThis implementation of the operation can include the following response headers in addition to the\nresponse headers common to all responses. For more information, see Common Response Headers.\nName Description\nx-amz-checksum-crc32 The base64-encoded, 32-bit CRC32 checksum of the\nobject.\nType: String\nx-amz-checksum-crc32c The base64-encoded, 32-bit CRC32C checksum of\nthe object.\nType: String\nx-amz-checksum-sha1 The base64-encoded, 160-bit SHA-1 digest of the\nobject.\nType: String\nx-amz-checksum-sha256 The base64-encoded, 256-bit SHA-256 digest of the\nobject.\nType: String\nx-amz-expiration If an Expiration action is configured for the\nobject as part of the bucket's lifecycle configura\ntion, Amazon S3 returns this header. The header\nvalue includes an expiry-date component and\na URL-encoded rule-id component. For version-\nenabled buckets, this header applies only to current\nversions. Amazon S3 does not provide a header to\nindicate when a noncurrent version is eligible for\npermanent deletion. For more information, see\nPutBucketLifecycleConfiguration.\nRequests API Version 2006-03-01 2720",
      "start_idx": 3044532,
      "end_idx": 3045698,
      "metadata": {
        "num_sentences": 12,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2726",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nType: String\nsuccess_action_redirect, The URL to which the client is redirected on a\nredirect successful upload.\nType: String\nAncestor: PostResponse\nx-amz-server-side-encryptio The server-side encryption algorithm that was used\nn when storing this object in Amazon S3 (for example,\nAES256, aws:kms, aws:kms:dsse ).\nType: String\nx-amz-server-side-encryptio If the x-amz-server-side-encryption\nn-aws-kms-key-id header has a valid value of aws:kms, this header\nspecifies the ID of the KMS key that was used to\nencrypt the object.\nType: String\nx-amz-server-side-encryptio If x-amz-server-side-encryption has\nn-bucket-key-enabled a valid value of aws:kms, this header indicates\nwhether the object is encrypted with SSE-KMS by\nusing an S3 Bucket Key. If this header is set to true,\nthe object uses an S3 Bucket Key with SSE-KMS.\nType: Boolean\nx-amz-server-side-encryptio If SSE-C was requested, the response includes this\nn-customer-algorithm header, which confirms the encryption algorithm\nthat was used.\nType: String\nValid Values: AES256\nRequests API Version 2006-03-01 2721",
      "start_idx": 3045700,
      "end_idx": 3046831,
      "metadata": {
        "num_sentences": 7,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2728",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nType: String\nAncestor: PostResponse\nSpecial Errors\nThis implementation of the operation does not return special errors. For general information about\nAmazon S3 errors and a list of error codes, see Error Responses.\nExamples\nSample Request\nPOST /Neo HTTP/1.1\nContent-Length: 4\nHost: quotes.s3.amazonaws.com\nDate: Wed, 01 Mar 2006 12:00:00 GMT\nAuthorization: authorization string\nContent-Type: text/plain\nExpect: the 100-continue HTTP status code\nObjectContent\nSample Response with Versioning Suspended\nThe following is a sample response when bucket versioning is suspended:\nHTTP/1.1 100 Continue\nHTTP/1.1 200 OK\nx-amz-id-2: LriYPLdmOdAiIfgSm/F1YsViT1LW94/xUQxMsF7xiEb1a0wiIOIxl+zbwZ163pt7\nx-amz-request-id: 0A49CE4060975EAC\nx-amz-version-id: default\nDate: Wed, 12 Oct 2009 17:50:00 GMT\nETag: \"1b2cf535f27731c974343645a3985328\"\nContent-Length: 0\nConnection: close\nServer: AmazonS3\nIn this response, the version ID is null.\nExamples API Version 2006-03-01 2723",
      "start_idx": 3047698,
      "end_idx": 3048716,
      "metadata": {
        "num_sentences": 4,
        "num_words": 125,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2730",
      "text": "Amazon Simple Storage Service API Reference\nPOST Object restore\nDescription\nThis operation performs the following types of requests:\n\u2022 select \u2013 Perform a select query on an archived object\n\u2022 restore an archive \u2013 Restore an archived object\nTo use this operation, you must have permissions to perform the s3:RestoreObject and\ns3:GetObject actions. The bucket owner has this permission by default and can grant this\npermission to others. For more information about permissions, see Permissions Related to Bucket\nSubresource Operations and Managing Access Permissions to Your Amazon S3 Resources in the\nAmazon Simple Storage Service User Guide.\nQuerying Archives with Select Requests\nYou use a select type of request to perform SQL queries on archived objects. The archived objects\nthat are being queried by the select request must be formatted as uncompressed comma-\nseparated values (CSV) files. You can run queries and custom analytics on your archived data\nwithout having to restore your data to a hotter Amazon S3 tier. For an overview about select\nrequests, see Querying Archived Objects in the Amazon Simple Storage Service User Guide.\nWhen making a select request, do the following:\n\u2022 Define an output location for the select query's output. This must be an Amazon S3 bucket in\nthe same AWS Region as the bucket that contains the archive object that is being queried. The\nAWS account that initiates the job must have permissions to write to the S3 bucket. You can\nspecify the storage class and encryption for the output objects stored in the bucket. For more\ninformation about output, see Querying Archived Objects in the Amazon Simple Storage Service\nUser Guide.\nFor more information about the S3 structure in the request body, see the following:\n\u2022 PutObject\n\u2022 Managing Access with ACLs in the Amazon Simple Storage Service User Guide\n\u2022 Protecting Data Using Server-Side Encryption in the Amazon Simple Storage Service User Guide\nPOST Object restore API Version 2006-03-01 2725",
      "start_idx": 3049329,
      "end_idx": 3051311,
      "metadata": {
        "num_sentences": 13,
        "num_words": 319,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2731",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Define the SQL expression for the SELECT type of restoration for your query in the request\nbody's SelectParameters structure. You can use expressions like the following examples.\n\u2022 The following expression returns all records from the specified object.\nSELECT * FROM Object\n\u2022 Assuming that you are not using any headers for data stored in the object, you can specify\ncolumns with positional headers.\nSELECT s._1, s._2 FROM Object s WHERE s._3 > 100\n\u2022 If you have headers and you set the fileHeaderInfo in the CSV structure in the request\nbody to USE, you can specify headers in the query. (If you set the fileHeaderInfo field to\nIGNORE, the first row is skipped for the query.) You cannot mix ordinal positions with header\ncolumn names.\nSELECT s.Id, s.FirstName, s.SSN FROM S3Object s\nFor more information about using SQL with S3 Glacier Select restore, see SQL Reference for\nAmazon S3 Select and S3 Glacier Select in the Amazon Simple Storage Service User Guide.\nWhen making a select request, you can also do the following:\n\u2022 To expedite your queries, specify the Expedited tier. For more information about tiers, see\n\"Restoring Archives,\" later in this topic.\n\u2022 Specify details about the data serialization format of both the input object that is being queried\nand the serialization of the CSV-encoded query results.\nThe following are additional important facts about the select feature:\n\u2022 The output results are new Amazon S3 objects. Unlike archive retrievals, they are stored until\nexplicitly deleted\u2014manually or through a lifecycle policy.\n\u2022 You can issue more than one select request on the same Amazon S3 object. Amazon S3 doesn't\ndeduplicate requests, so avoid issuing duplicate requests.\n\u2022 Amazon S3 accepts a select request even if the object has already been restored. A select request\ndoesn\u2019t return error response 409.\nQuerying Archives with Select Requests API Version 2006-03-01 2726",
      "start_idx": 3051313,
      "end_idx": 3053258,
      "metadata": {
        "num_sentences": 18,
        "num_words": 317,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2732",
      "text": "Amazon Simple Storage Service API Reference\nRestoring Archives\nObjects in the GLACIER and DEEP_ARCHIVE storage classes are archived. To access an archived\nobject, you must first initiate a restore request. This restores a temporary copy of the archived\nobject. In a restore request, you specify the number of days that you want the restored copy to\nexist. After the specified period, Amazon S3 deletes the temporary copy but the object remains\narchived in the GLACIER or DEEP_ARCHIVE storage class that object was restored from.\nTo restore a specific object version, you can provide a version ID. If you don't provide a version ID,\nAmazon S3 restores the current version.\nThe time it takes restore jobs to finish depends on which storage class the object is being restored\nfrom and which data access tier you specify.\nWhen restoring an archived object (or using a select request), you can specify one of the following\ndata access tier options in the Tier element of the request body:\n\u2022 Expedited - Expedited retrievals allow you to quickly access your data stored in the GLACIER\nstorage class when occasional urgent requests for a subset of archives are required. For all but\nthe largest archived objects (250 MB+), data accessed using Expedited retrievals are typically\nmade available within 1\u20135 minutes. Provisioned capacity ensures that retrieval capacity for\nExpedited retrievals is available when you need it. Expedited retrievals and provisioned capacity\nare not available for the DEEP_ARCHIVE storage class.\n\u2022 Standard - Standard retrievals allow you to access any of your archived objects within several\nhours. This is the default option for the GLACIER and DEEP_ARCHIVE retrieval requests that do\nnot specify the retrieval option. Standard retrievals typically complete within 3-5 hours from the\nGLACIER storage class and typically complete within 12 hours from the DEEP_ARCHIVE storage\nclass.\n\u2022 Bulk - Bulk retrievals are Amazon S3 Glacier\u2019s lowest-cost retrieval option, enabling you to\nretrieve large amounts, even petabytes, of data inexpensively in a day. Bulk retrievals typically\ncomplete within 5-12 hours from the GLACIER storage class and typically complete within 48\nhours from the DEEP_ARCHIVE storage class.\nFor more information about archive retrieval options and provisioned capacity for Expedited data\naccess, see Restoring Archived Objects in the Amazon Simple Storage Service User Guide.\nYou can use Amazon S3 restore speed upgrade to change the restore speed to a faster speed\nwhile it is in progress. You upgrade the speed of an in-progress restoration by issuing another\nRestoring Archives API Version 2006-03-01 2727",
      "start_idx": 3053260,
      "end_idx": 3055907,
      "metadata": {
        "num_sentences": 20,
        "num_words": 415,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2733",
      "text": "Amazon Simple Storage Service API Reference\nrestore request to the same object, setting a new Tier request element. When issuing a request\nto upgrade the restore tier, you must choose a tier that is faster than the tier that the in-progress\nrestore is using. You must not change any other parameters, such as the Days request element.\nFor more information, see Upgrading the Speed of an In-Progress Restore in the Amazon Simple\nStorage Service User Guide.\nTo get the status of object restoration, you can send a HEAD request. Operations return the x-amz-\nrestore header, which provides information about the restoration status, in the response. You can\nuse Amazon S3 event notifications to notify you when a restore is initiated or completed. For more\ninformation, see Configuring Amazon S3 Event Notifications in the Amazon Simple Storage Service\nUser Guide.\nAfter restoring an archived object, you can update the restoration period by reissuing the request\nwith a new period. Amazon S3 updates the restoration period relative to the current time\nand charges only for the request\u2014there are no data transfer charges. You cannot update the\nrestoration period when Amazon S3 is actively processing your current restore request for the\nobject.\nIf your bucket has a lifecycle configuration with a rule that includes an expiration action, the\nobject expiration overrides the life span that you specify in a restore request. For example,\nif you restore an object copy for 10 days, but the object is scheduled to expire in 3 days,\nAmazon S3 deletes the object in 3 days. For more information about lifecycle configuration, see\nPutBucketLifecycleConfiguration and Object Lifecycle Management in Amazon Simple Storage\nService User Guide.\nRequests\nSyntax\nPOST /ObjectName?restore&versionId=VersionID HTTP/1.1\nHost: BucketName.s3.amazonaws.com\nDate: date\nAuthorization: authorization string (see Authenticating Requests (AWS Signature Version\n4))\nContent-MD5: MD5\nrequest body\nRequests API Version 2006-03-01 2728",
      "start_idx": 3055909,
      "end_idx": 3057911,
      "metadata": {
        "num_sentences": 15,
        "num_words": 304,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2734",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThe syntax shows some of the request headers. For a complete list, see \"Request Headers,\"\nlater in this topic.\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nRequest Headers\nName Description Required\nContent-M Yes\nThe base64-encoded 128-bit MD5 digest of the data. You must\nD5\nuse this header as a message integrity check to verify that the\nrequest body was not corrupted in transit. For more informati\non, see RFC 1864.\nType: String\nDefault: None\nRequest Elements\nThe following is an XML example of a request body for restoring an archive.\n<RestoreRequest>\n<Days>2</Days>\n<GlacierJobParameters>\n<Tier>Bulk</Tier>\n</GlacierJobParameters>\n</RestoreRequest>\nThe following table explains the XML for archive restoration in the request body.\nRequests API Version 2006-03-01 2729",
      "start_idx": 3057913,
      "end_idx": 3058778,
      "metadata": {
        "num_sentences": 9,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2735",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nRestoreRe Yes\nContainer for restore information.\nquest\nType: Container\nDays Yes, if\nLifetime of the restored (active) copy. The minimum\nrestoring an\nnumber of days that you can restore an object from S3\narchive\nGlacier is 1. After the object copy reaches the specified\nlifetime, Amazon S3 removes it from the bucket. If you are\nrestoring an archive, this element is required.\nDo not use this element with a SELECT type of request.\nType: Positive integer\nAncestors: RestoreRequest\nGlacierJo No\nContainer for Glacier job parameters.\nbParamete\nrs\nDo not use this element with a SELECT type of request.\nType: Container\nAncestors: RestoreRequest\nTier No\nThe data access tier to use when restoring the archive.\nStandard is the default.\nType: Enum\nValid values: Expedited | Standard | Bulk\nAncestors: GlacierJobParameters\nThe following XML is the request body for a select query on an archived object:\nRequests API Version 2006-03-01 2730",
      "start_idx": 3058780,
      "end_idx": 3059781,
      "metadata": {
        "num_sentences": 11,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2738",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nDescripti No\nThe optional description for the request.\non\nType: String\nAncestors: RestoreRequest\nSelectPar Yes, if request\nDescribes the parameters for the select job request.\nameters type is SELECT\nType: Container\nAncestors: RestoreRequest\nOutputLoc Yes, if request\nDescribes the location that receives the results of the select\nation type is SELECT\nrestore request.\nType: Container for Amazon S3\nAncestors: RestoreRequest\nThe SelectParameters container element contains the following elements.\nName Description Required\nExpression Yes\nThe SQL expression. For example:\n\u2022\nThe following SQL expression retrieves the first column of\nthe data from the object stored in CSV format:\nSELECT s._1 FROM Object s\n\u2022\nThe following SQL expression returns everything from\nthe object:\nSELECT * FROM Object\nRequests API Version 2006-03-01 2733",
      "start_idx": 3061877,
      "end_idx": 3062775,
      "metadata": {
        "num_sentences": 6,
        "num_words": 130,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2739",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nAncestors: SelectParameters\nExpressio Yes\nIdentifies the expression type.\nnType\nType: String\nValid values: SQL\nAncestors: SelectParameters\nInputSeri Yes\nDescribes the serialization format of the object.\nalization\nType: Container for CSV\nAncestors: SelectParameters\nOutputSer Yes\nDescribes how the results of the select job are serialized.\nializatio\nn\nType: Container for CSV\nAncestors: SelectParameters\nThe CSV container element in the InputSerialization element contains the following\nelements.\nName Description Required\nRecordDel No\nA single character used to separate individual records in\nimiter\nthe input. Instead of the default value, you can specify an\narbitrary delimiter.\nType: String\nDefault: \\n\nRequests API Version 2006-03-01 2734",
      "start_idx": 3062777,
      "end_idx": 3063602,
      "metadata": {
        "num_sentences": 7,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2740",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nAncestors: CSV\nFieldDeli No\nA single character used to separate individual fields in a\nmiter\nrecord. You can specify an arbitrary delimiter.\nType: String\nDefault: ,\nAncestors: CSV\nQuoteChar No\nA single character used for escaping when the field\nacter\ndelimiter is part of the value.\nConsider this example in a CSV file:\n\"a, b\"\nWrapping the value in quotation marks makes this value\na single field. If you don't use the quotation marks, the\ncomma is a field delimiter (which makes it two separate\nfield values, a and b).\nType: String\nDefault: \"\nAncestors: CSV\nRequests API Version 2006-03-01 2735",
      "start_idx": 3063604,
      "end_idx": 3064269,
      "metadata": {
        "num_sentences": 6,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2741",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nQuoteEsca No\nA single character used for escaping the quotation mark\npeCharact\ncharacter inside an already escaped value. For example, the\ner\nvalue \"\"\" a , b \"\"\" is parsed as \" a , b \".\nType: String\nDefault: \"\nAncestors: CSV\nFileHeade No\nDescribes the first line in the input data. It is one of the\nrInfo\nENUM values.\n\u2022\nNONE: First line is not a header.\n\u2022\nIGNORE: First line is a header, but you can't use the\nheader values to indicate the column in an expressio\nn. You can use column position (such as _1, _2, \u2026) to\nindicate the column (SELECT s._1 FROM OBJECT s).\n\u2022\nUse: First line is a header, and you can use the header\nvalue to identify a column in an expression (SELECT\n\"name\" FROM OBJECT ).\nType: Enum\nValid values: NONE | USE | IGNORE\nAncestors: CSV\nRequests API Version 2006-03-01 2736",
      "start_idx": 3064271,
      "end_idx": 3065135,
      "metadata": {
        "num_sentences": 8,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2742",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nComments No\nA single character used to indicate that a row should be\nignored when the character is present at the start of that\nrow. You can specify any character to indicate a comment\nline.\nType: String\nAncestors: CSV\nThe CSV container element (in the OutputSerialization elements) contains the following\nelements.\nName Description Required\nQuoteFiel No\nIndicates whether to use quotation marks around output\nds\nfields.\n\u2022\nALWAYS: Always use quotation marks for output fields.\n\u2022\nASNEEDED: Use quotation marks for output fields when\nneeded.\nType: Enum\nValid values: ALWAYS | ASNEEDED\nDefault: AsNeeded\nAncestors: CSV\nRecordDel No\nA single character used to separate individual records in the\nimiter\noutput. Instead of the default value, you can specify an\narbitrary delimiter.\nRequests API Version 2006-03-01 2737",
      "start_idx": 3065137,
      "end_idx": 3066019,
      "metadata": {
        "num_sentences": 9,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2743",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nDefault: \\n\nAncestors: CSV\nFieldDeli No\nA single character used to separate individual fields in a\nmiter\nrecord. You can specify an arbitrary delimiter.\nType: String\nDefault: ,\nAncestors: CSV\nQuoteChar No\nA single character used for escaping when the field\nacter\ndelimiter is part of the value. For example, if the value is a,\nb, Amazon S3 wraps this field value in quotation marks, as\nfollows: \" a , b \" .\nType: String\nDefault: \"\nAncestors: CSV\nQuoteEsca No\nA single character used for escaping the quotation mark\npeCharact\ncharacter inside an already escaped value. For example, if\ner\nthe value is \" a , b \" , Amazon S3 wraps the value in\nquotation marks, as follows: \"\"\" a , b \"\"\".\nType: String\nAncestors: CSV\nRequests API Version 2006-03-01 2738",
      "start_idx": 3066021,
      "end_idx": 3066853,
      "metadata": {
        "num_sentences": 7,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2744",
      "text": "Amazon Simple Storage Service API Reference\nThe S3 container element (in the OutputLocation element) contains the following elements.\nName Description Required\nAccessCon No\nA list of grants that control access to the staged results.\ntrolList\nType: Container for Grant\nAncestors: S3\nBucketName Yes\nThe name of the S3 bucket where the select restore results\nare stored. The bucket must be in the same AWS Region as\nthe bucket that contains the input archive object.\nType: String\nAncestors: S3\nCannedACL No\nThe canned access control list (ACL) to apply to the select\nrestore results.\nType: String\nValid values: private | public-read | public-\nread-write | aws-exec-read | authenti\ncated-read | bucket-owner-read | bucket-ow\nner-full-control\nAncestors: S3\nEncryption No\nContains encryption information for the stored results.\nType: Container for Encryption\nAncestors: S3\nPrefix Yes\nRequests API Version 2006-03-01 2739",
      "start_idx": 3066855,
      "end_idx": 3067769,
      "metadata": {
        "num_sentences": 7,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2747",
      "text": "Amazon Simple Storage Service API Reference\nThe Encryption container element (in S3) contains the following elements.\nName Description Required\nEncryptio No\nThe server-side encryption algorithm used when storing job\nnType\nresults. The default is no encryption.\nType: String\nValid Values aws:kms | AES256\nAncestors: Encryption\nKMSContext No\nOptional. If the encryption type is aws:kms, you can use\nthis value to specify the encryption context for the select\nrestore results.\nType: String\nAncestors: Encryption\nKMSKeyId No\nThe AWS Key Management Service (AWS KMS) key ID to use\nfor object encryption.\nType: String\nAncestors: Encryption\nThe TagSet container element (in the Tagging element) contains the following element.\nName Description Required\nTag No\nContains tags.\nType: Container\nAncestors: TagSet\nRequests API Version 2006-03-01 2742",
      "start_idx": 3069070,
      "end_idx": 3069908,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2749",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 If the object copy is not previously restored, then Amazon S3 returns 202 Accepted in the\nresponse.\n\u2022 If the object copy is previously restored, Amazon S3 returns 200 OK in the response.\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most\nresponses. For more information, see Common Response Headers.\nResponse Elements\nThis operation does not return response elements.\nSpecial Errors\nError Code Description HTTP SOAP Fault\nStatus Code Code Prefix\nRestoreAlreadyInPr Object restore is already in 409 Conflict Client\nogress progress. (This error does not\napply to SELECT type requests.)\nGlacierExpeditedRe Glacier expedited retrievals 503 N/A\ntrievalNotAvailabl are currently not available. Try\ne again later. (Returned if there is\ninsufficient capacity to process\nthe Expedited request. This\nerror applies only to Expedited\nretrievals and not to Standard\nor Bulk retrievals.)\nExamples\nRestore an Object for Two Days Using the Expedited Retrieval Option\nThe following restore request restores a copy of the photo1.jpg object from S3 Glacier for a\nperiod of two days using the expedited retrieval option.\nExamples API Version 2006-03-01 2744",
      "start_idx": 3070581,
      "end_idx": 3071818,
      "metadata": {
        "num_sentences": 13,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2752",
      "text": "Amazon Simple Storage Service API Reference\n</UserMetadata>\n<StorageClass>STANDARD</StorageClass>\n</S3>\n</OutputLocation>\n</RestoreRequest>\nAmazon S3 returns the following 202 Accepted response.\nHTTP/1.1 202 Accepted\nx-amz-id-2: GFihv3y6+kE7KG11GEkQhU7/2/cHR3Yb2fCb2S04nxI423Dqwg2XiQ0B/\nUZlzYQvPiBlZNRcovw=\nx-amz-request-id: 9F341CD3C4BA79E0\nx-amz-restore-output-path: js-test-s3/qE8nk5M0XIj-LuZE2HXNw6empQm3znLkHlMWInRYPS-\nOrl2W0uj6LyYm-neTvm1-btz3wbBxfMhPykd3jkl-lvZE7w42/\nDate: Sat, 20 Oct 2012 23:54:05 GMT\nContent-Length: 0\nServer: AmazonS3\nMore Info\n\u2022 GetBucketLifecycleConfiguration\n\u2022 PutBucketLifecycleConfiguration\n\u2022 SQL Reference for Amazon S3 Select and S3 Glacier Select in the Amazon Simple Storage Service\nUser Guide\nBrowser-Based Uploads Using HTTP POST\nAmazon S3 supports HTTP POST requests so that users can upload content directly to Amazon S3.\nBy using POST, end users can authenticate requests without having to pass data through a secure\nintermediary node that protects your credentials. Thus, HTTP POST has the potential to reduce\nlatency.\nThe following figure shows an Amazon S3 upload using a POST request.\nMore Info API Version 2006-03-01 2747",
      "start_idx": 3074348,
      "end_idx": 3075516,
      "metadata": {
        "num_sentences": 6,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2753",
      "text": "Amazon Simple Storage Service API Reference\n1. The user accesses your page from a web browser.\n2. Your webpage contains an HTML form that contains all the information necessary for the user to\nupload content to Amazon S3.\n3. The user uploads content to Amazon S3 through the web browser.\nThe process for sending browser-based POST requests is as follows:\n1. Create a security policy specifying conditions that restrict what you want to allow in the request,\nsuch as the bucket name where objects can be uploaded, and key name prefixes that you want\nto allow for the object that is being created.\nBrowser-Based Uploads Using HTTP POST API Version 2006-03-01 2748",
      "start_idx": 3075518,
      "end_idx": 3076179,
      "metadata": {
        "num_sentences": 9,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2754",
      "text": "Amazon Simple Storage Service API Reference\n2. Create a signature that is based on the policy. For authenticated requests, the form must include\na valid signature and the policy.\n3. Create an HTML form that your users can access in order to upload objects to your Amazon S3\nbucket.\nThe following section describes how to create a signature to authenticate a request. For\ninformation about creating forms and security policies, see Creating an HTML Form (Using AWS\nSignature Version 4).\nCalculating a Signature\nFor authenticated requests, the HTML form must include fields for a security policy and a signature.\n\u2022 A security policy (see POST Policy) controls what is allowed in the request.\n\u2022 The security policy is the StringToSign (see Introduction to Signing Requests) in your\nsignature calculation.\nCalculating a Signature API Version 2006-03-01 2749",
      "start_idx": 3076181,
      "end_idx": 3077034,
      "metadata": {
        "num_sentences": 11,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2755",
      "text": "Amazon Simple Storage Service API Reference\nTo Calculate a signature\n1. Create a policy using UTF-8 encoding.\n2. Convert the UTF-8-encoded policy bytes to base64. The result is the StringToSign.\n3. Create a signing key.\n4. Use the signing key to sign the StringToSign using HMAC-SHA256 signing algorithm.\nFor more information about creating HTML forms, security policies, and an example, see the\nfollowing:\n\u2022 Creating an HTML Form (Using AWS Signature Version 4)\n\u2022 POST Policy\n\u2022 Example: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4)\nCreating an HTML Form (Using AWS Signature Version 4)\nTopics\n\u2022 HTML Form Declaration\n\u2022 HTML Form Fields\nTo allow users to upload content to Amazon S3 by using their browsers (HTTP POST requests), you\nuse HTML forms. HTML forms consist of a form declaration and form fields. The form declaration\ncontains high-level information about the request. The form fields contain detailed request\ninformation.\nThis section describes how to create HTML forms. For a working example of browser-based upload\nusing HTTP POST and related signature calculations for request authentication, see Example:\nBrowser-Based Upload using HTTP POST (Using AWS Signature Version 4).\nThe form and policy must be UTF-8 encoded. You can apply UTF-8 encoding to the form by\nspecifying charset=UTF-8 in the content attribute. The following is an example of UTF-8\nencoding in the HTML heading.\n<html>\nCreating HTML Forms API Version 2006-03-01 2750",
      "start_idx": 3077036,
      "end_idx": 3078509,
      "metadata": {
        "num_sentences": 19,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2756",
      "text": "Amazon Simple Storage Service API Reference\n<head>\n...\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n...\n</head>\n<body>\nFollowing is an example of UTF-8 encoding in a request header.\nContent-Type: text/html; charset=UTF-8\nNote\nThe form data and boundaries (excluding the contents of the file) cannot exceed 20KB.\nHTML Form Declaration\nThe HTML form declaration has the following three attributes:\n\u2022 action \u2013 The URL that processes the request, which must be set to the URL of the\nbucket. For example, if the name of your bucket is examplebucket, the URL is http://\nexamplebucket.s3.amazonaws.com/.\nNote\nThe key name is specified in a form field.\n\u2022 method \u2013 The method must be POST.\n\u2022 enctype \u2013 The enclosure type (enctype) must be set to multipart/form-data for both file\nuploads and text area uploads. For more information about enctype, see RFC 1867.\nThis is a form declaration for the bucket examplebucket.\n<form action=\"http://examplebucket.s3.amazonaws.com/\" method=\"post\"\nenctype=\"multipart/form-data\">\nHTML Form Declaration API Version 2006-03-01 2751",
      "start_idx": 3078511,
      "end_idx": 3079593,
      "metadata": {
        "num_sentences": 10,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2757",
      "text": "Amazon Simple Storage Service API Reference\nHTML Form Fields\nThe following table describes a list of fields that you can use within a form. Among other fields,\nthere is a signature field that you can use to authenticate requests. There are fields for you to\nspecify the signature calculation algorithm (x-amz-algorithm), the credential scope (x-amz-\ncredential) that you used to generate the signing key, and the date (x-amz-date) used\nto calculate the signature. Amazon S3 uses this information to re-create the signature. If the\nsignatures match, Amazon S3 processes the request.\nNote\nThe variable ${filename} is automatically replaced with the name of the file provided\nby the user and is recognized by all form fields. If the browser or client provides a full or\npartial path to the file, only the text following the last slash (/) or backslash (\\) is used (for\nexample, C:\\Program Files\\directory1\\file.txt is interpreted as file.txt). If no\nfile or file name is provided, the variable is replaced with an empty string.\nIf you don't provide elements required for authenticated requests, such as the policy element,\nthe request is assumed to be anonymous and will succeed only if you have configured the bucket\nfor public read and write.\nElement Name Description Required\nacl\nAn Amazon S3 access control list (ACL). If an No\ninvalid ACL is specified, Amazon S3 denies\nthe request. For more information about\nACLs, see Using Amazon S3 ACLs.\nType: String\nDefault: private\nValid Values: private | public-re\nad | public-read-write | aws-\nexec-read | authenticated-read\nHTML Form Fields API Version 2006-03-01 2752",
      "start_idx": 3079595,
      "end_idx": 3081208,
      "metadata": {
        "num_sentences": 13,
        "num_words": 260,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2758",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description Required\n| bucket-owner-read | bucket-ow\nner-full-control\nCache-Control\nREST-specific headers. For more information, No\nContent-Type see PutObject.\nContent-Disposition\nContent-Encoding\nExpires\nkey\nThe key name of the uploaded object. Yes\nTo use the file name provided by the user,\nuse the ${filename} variable. For example,\nif you upload a file photo1.jpg and you\nspecify / user/user1/${filename} as\nkey name, the file is stored as /user/use\nr1/photo1.jpg .\nFor more information, see Object Key and\nMetadata in the Amazon Simple Storage\nService User Guide.\npolicy\nThe base64-encoded security policy that Required for\ndescribes what is permitted in the request. authentic\nFor authenticated requests, a policy is ated requests\nrequired.\nRequests without a security policy are\nconsidered anonymous and will succeed only\non a publicly writable bucket.\nHTML Form Fields API Version 2006-03-01 2753",
      "start_idx": 3081210,
      "end_idx": 3082171,
      "metadata": {
        "num_sentences": 10,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2760",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description Required\nsuccess_action_status\nThe status code returned to the client No\nupon successful upload if success_a\nction_redirect is not specified.\nValid values are 200, 201, or 2 04 (default).\nIf the value is set to 200 or 204, Amazon\nS3 returns an empty document with the\nspecified status code.\nIf the value is set to 201, Amazon S3 returns\nan XML document with a 201 status code.\nFor information about the content of the\nXML document, see POST Object.\nIf the value is not set or is invalid, Amazon\nS3 returns an empty document with a 204\nstatus code.\nNote\nSome versions of the Adobe Flash\nplayer do not properly handle HTTP\nresponses with an empty body. To\nsupport uploads through Adobe\nFlash, we recommend setting\nsuccess_action_status to\n201.\nHTML Form Fields API Version 2006-03-01 2755",
      "start_idx": 3082666,
      "end_idx": 3083521,
      "metadata": {
        "num_sentences": 9,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2761",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description Required\nx-amz-algorithm\nThe signing algorithm used to authenticate Required for\nthe request. For AWS Signature Version 4, authentic\nthe value is A WS4-HMAC-SHA256 . ated requests\nThis field is required if a policy document is\nincluded with the request.\nx-amz-credential In addition to your access key ID, this field\nRequired for\nalso provides scope information identifying\nauthentic\nregion and service for which the signature\nated requests\nis valid. This should be the same scope\nyou used in calculating the signing key for\nsignature calculation.\nIt is a string of the following form:\n<your-access-key-i\nd> /<date>/<aws-region> /<aws-serv\nice> /aws4_request\nFor example:\nAKIAIOSFODNN7EXAMPLE/201307\n28/us-east-1/s3/aws4_request\nFor Amazon S3, the aws-service string is\ns3. For a list of Amazon S3 aws-region\nstrings, see Regions and Endpoints in the\nAWS General Reference. This is required if a\npolicy document is included with the reques\nt.\nHTML Form Fields API Version 2006-03-01 2756",
      "start_idx": 3083523,
      "end_idx": 3084579,
      "metadata": {
        "num_sentences": 8,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2762",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description Required\nx-amz-date\nIt is the date value in ISO8601 format. For Required for\nexample, 2 0130728T000000Z . authentic\nated requests\nIt is the same date you used in creating the\nsigning key (for example, 20130728). This\nmust also be the same value you provide in\nthe policy (x-amz-date ) that you signed.\nThis is required if a policy document is\nincluded with the request.\nx-amz-security-token\nA security token used by Amazon DevPay and No\nsession credentials\nIf the request is using Amazon DevPay, it\nrequires two x -amz-security-token\nform fields: one for the product token and\none for the user token. For more informati\non, see Using DevPay in the A mazon Simple\nStorage Service User Guide.\nIf the request is using session credentials, it\nrequires one x-amz-security-token\nform. For more information, see Requestin\ng Temporary Security Credentials in the IAM\nUser Guide.\nx-amz-signature\n(AWS Signature Version 4) The HMAC-SHA2 Required for\n56 hash of the security policy. authentic\nated requests\nThis field is required if a policy document is\nincluded with the request.\nHTML Form Fields API Version 2006-03-01 2757",
      "start_idx": 3084581,
      "end_idx": 3085764,
      "metadata": {
        "num_sentences": 12,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2763",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description Required\nx-amz-meta-*\nField names starting with this prefix are user- No\ndefined metadata. Each one is stored and\nreturned as a set of key-value pairs. Amazon\nS3 doesn't validate or interpret user-defi\nned metadata. For more information, see\nPutObject.\nx-amz-*\nSee POST Object (POST Object for other x- No\namz-* headers.\nfile\nFile or text content. Yes\nThe file or content must be the last field in\nthe form.\nYou cannot upload more than one file at a\ntime.\nConditional items are required for authenticated requests and are optional for anonymous\nrequests.\nNow that you know how to create forms, next you can create a security policy that you can sign.\nFor more information, see POST Policy.\nPOST Policy\nTopics\n\u2022 Expiration\n\u2022 Condition Matching\n\u2022 Conditions\n\u2022 Character Escaping\nPOST Policy API Version 2006-03-01 2758",
      "start_idx": 3085766,
      "end_idx": 3086651,
      "metadata": {
        "num_sentences": 12,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2764",
      "text": "Amazon Simple Storage Service API Reference\nThe policy required for making authenticated requests using HTTP POST is a UTF-8 and base64-\nencoded document written in JavaScript Object Notation (JSON) that specifies conditions that\nthe request must meet. Depending on how you design your policy document, you can control the\naccess granularity per-upload, per-user, for all uploads, or according to other designs that meet\nyour needs.\nThis section describes the POST policy. For example signature calculations using POST policy, see\nExample: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4).\nNote\nAlthough the policy document is optional, we highly recommend that you use one in order\nto control what is allowed in the request. If you make the bucket publicly writable, you have\nno control at all over which users can write to your bucket.\nThe following is an example of a POST policy document.\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\",\n\"conditions\": [\n{\"acl\": \"public-read\" },\n{\"bucket\": \"johnsmith\" },\n[\"starts-with\", \"$key\", \"user/eric/\"],\n]\n}\nThe POST policy always contains the expiration and conditions elements. The example policy\nuses two condition matching types (exact matching and starts-with matching). The following\nsections describe these elements.\nExpiration\nThe expiration element specifies the expiration date and time of the POST policy in ISO8601\nGMT date format. For example, 2013-08-01T12:00:00.000Z specifies that the POST policy is\nnot valid after midnight GMT on August 1, 2013.\nCondition Matching\nFollowing is a table that describes condition matching types that you can use to specify POST\npolicy conditions (described in the next section). Although you must specify at least one condition\nExpiration API Version 2006-03-01 2759",
      "start_idx": 3086653,
      "end_idx": 3088427,
      "metadata": {
        "num_sentences": 14,
        "num_words": 265,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2765",
      "text": "Amazon Simple Storage Service API Reference\nfor each form field that you specify in the form, you can create more complex matching criteria by\nspecifying multiple conditions for a form field.\nCondition Description\nMatch Type\nExact Matches The form field value must match the value specified. This example indicates\nthat the ACL must be set to public-read:\n{\"acl\": \"public-read\" }\nThis example is an alternate way to indicate that the ACL must be set to\npublic-read:\n[ \"eq\", \"$acl\", \"public-read\" ]\nStarts With The value must start with the specified value. This example indicates that the\nobject key must start with user/user1:\n[\"starts-with\", \"$key\", \"user/user1/\"]\nMatching Content-Types values for a starts-with condition that include commas\nContent-Types are interpreted as lists. Each value in the list must meet the condition for the\nin a Comma- whole condition to pass. For example,given the following condition:\nSeparated List\n[\"starts-with\", \"$Content-Type\", \"image/\"]\nThe following value would pass the condition:\n\"image/jpg,image/png,image/gif\"\nThe following value would not pass the condition:\n[\"image/jpg,text/plain\"]\nCondition Matching API Version 2006-03-01 2760",
      "start_idx": 3088429,
      "end_idx": 3089606,
      "metadata": {
        "num_sentences": 6,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2766",
      "text": "Amazon Simple Storage Service API Reference\nCondition Description\nMatch Type\nNote\nData elements other than Content-Type are treated as strings,\nregardless of the presence of commas.\nMatching Any To configure the POST policy to allow any content within a form field, use\nContent starts-with with an empty value (\"\"). This example allows any value for\nsuccess_action_redirect :\n[\"starts-with\", \"$success_action_redirect\", \"\"]\nSpecifying For form fields that accept a range, separate the upper and lower limit with a\nRanges comma. This example allows a file size from 1 to 10 MiB:\n[\"content-length-range\", 1048576, 10485760]\nThe specific conditions supported in a POST policy are described in Conditions.\nConditions\nThe conditions in a POST policy is an array of objects, each of which is used to validate the\nrequest. You can use these conditions to restrict what is allowed in the request. For example, the\npreceding policy conditions require the following:\n\u2022 Request must specify the johnsmith bucket name.\n\u2022 Object key name must have the user/eric prefix.\n\u2022 Object ACL must be set to public-read.\nEach form field that you specify in a form (except x-amz-signature, file, policy, and field\nnames that have an x-ignore- prefix) must appear in the list of conditions.\nConditions API Version 2006-03-01 2761",
      "start_idx": 3089608,
      "end_idx": 3090912,
      "metadata": {
        "num_sentences": 11,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2767",
      "text": "Amazon Simple Storage Service API Reference\nNote\nAll variables within the form are expanded prior to validating the POST policy. Therefore,\nall condition matching should be against the expanded form fields. Suppose that you want\nto restrict your object key name to a specific prefix (user/user1). In this case, you set the\nkey form field to user/user1/${filename}. Your POST policy should be [ \"starts-\nwith\", \"$key\", \"user/user1/\" ] (do not enter [ \"starts-with\", \"$key\",\n\"user/user1/${filename}\" ]). For more information, see Condition Matching.\nPolicy document conditions are described in the following table.\nElement Name Description\nacl\nSpecifies the ACL value that must be used in the form\nsubmission.\nThis condition supports exact matching and s tarts-\nwith condition match type discussed in the following\nsection.\nbucket\nSpecifies the acceptable bucket name.\nThis condition supports exact matching condition match\ntype.\ncontent-length-range\nThe minimum and maximum allowable size for the\nuploaded content.\nThis condition supports content-length-range\ncondition match type.\nCache-Control\nREST-specific headers. For more information, see POST\nContent-Type Object.\nContent-Disposition\nConditions API Version 2006-03-01 2762",
      "start_idx": 3090914,
      "end_idx": 3092142,
      "metadata": {
        "num_sentences": 16,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2768",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description\nContent-Encoding This condition supports exact matching and s tarts-wi\nth condition match type.\nExpires\nkey\nThe acceptable key name or a prefix of the uploaded\nobject.\nThis condition supports exact matching and s tarts-wi\nth condition match type.\nsuccess_action_redirect\nThe URL to which the client is redirected upon successful\nredirect upload.\nThis condition supports exact matching and s tarts-wi\nth condition match type.\nsuccess_action_status\nThe status code returned to the client upon successful\nupload if success_action_redirect is not specified.\nThis condition supports exact matching.\nx-amz-algorithm\nThe signing algorithm that must be used during signature\ncalculation. For AWS Signature Version 4, the value is\nAWS4-HMAC-SHA256 .\nThis condition supports exact matching.\nConditions API Version 2006-03-01 2763",
      "start_idx": 3092144,
      "end_idx": 3093032,
      "metadata": {
        "num_sentences": 11,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2769",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description\nx-amz-credential\nThe credentials that you used to calculate the signature.\nIt provides access key ID and scope information identifyi\nng region and service for which the signature is valid.\nThis should be the same scope you used in calculating the\nsigning key for signature calculation.\nIt is a string of the following form:\n<your-access-key-id> /<date>/<aws-regi\non> /<aws-service> /aws4_request\nFor example:\nAKIAIOSFODNN7EXAMPLE/20130728/us-e\nast-1/s3/aws4_request\nFor Amazon S3, the aws-service string is s3. For a list of\nAmazon S3 aws-region strings, see Regions and Endp\noints in the AWS General Reference. This is required if a\nPOST policy document is included with the request.\nThis condition supports exact matching.\nx-amz-date\nThe date value specified in the ISO8601 formatted string.\nFor example, 20130728T000000Z . The date must\nbe same that you used in creating the signing key for\nsignature calculation.\nThis is required if a POST policy document is included with\nthe request.\nThis condition supports exact matching.\nConditions API Version 2006-03-01 2764",
      "start_idx": 3093034,
      "end_idx": 3094171,
      "metadata": {
        "num_sentences": 13,
        "num_words": 168,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2770",
      "text": "Amazon Simple Storage Service API Reference\nElement Name Description\nx-amz-security-token\nAmazon DevPay security token.\nEach request that uses Amazon DevPay requires two\nx-amz-security-token form fields: one for the\nproduct token and one for the user token. As a result, the\nvalues must be separated by commas. For example, if the\nuser token is eW91dHViZQ== and the product token is\nb0hnNVNKWVJIQTA= , you set the POST policy entry to:\n{ \"x-amz-security-token\": \"eW91dHViZQ\n==,b0hnNVNKWVJIQTA=\" } .\nFor more information about Amazon DevPay, see Using\nDevPay in the Amazon Simple Storage Service User Guide.\nx-amz-meta-*\nUser-specified metadata.\nThis condition supports exact matching and s tarts-wi\nth condition match type.\nx-amz-*\nSee POST Object (POST Object for other x-amz-*\nheaders.\nThis condition supports exact matching.\nNote\nIf your toolkit adds more form fields (for example, Flash adds filename), you must add\nthem to the POST policy document. If you can control this functionality, prefix x-ignore-\nto the field so Amazon S3 ignores the feature and it won't affect future versions of this\nfeature.\nConditions API Version 2006-03-01 2765",
      "start_idx": 3094173,
      "end_idx": 3095320,
      "metadata": {
        "num_sentences": 12,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2771",
      "text": "Amazon Simple Storage Service API Reference\nCharacter Escaping\nCharacters that must be escaped within a POST policy document are described in the following\ntable.\nEscape Description\nSequence\n\\\\ Backslash\n\\$ Dollar symbol\n\\b Backspace\n\\f Form feed\n\\n New line\n\\r Carriage return\n\\t Horizontal tab\n\\v Vertical tab\n\\uxxxx All Unicode characters\nNow that you are acquainted with forms and policies, and understand how signing works, you can\ntry a POST upload example. You need to write the code to calculate the signature. The example\nprovides a sample form, and a POST policy that you can use to test your signature calculations. For\nmore information, see Example: Browser-Based Upload using HTTP POST (Using AWS Signature\nVersion 4).\nCharacter Escaping API Version 2006-03-01 2766",
      "start_idx": 3095322,
      "end_idx": 3096100,
      "metadata": {
        "num_sentences": 6,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2772",
      "text": "Amazon Simple Storage Service API Reference\nExample: Browser-Based Upload using HTTP POST (Using AWS\nSignature Version 4)\nThis section shows an example of using an HTTP POST request to upload content directly to\nAmazon S3.\nFor more information on Signature Version 4, see Signature Version 4 Signing Process.\nUploading a File to Amazon S3 Using HTTP POST\nThis example provides a sample POST policy and a form that you can use to upload a file. The topic\nuses the example policy and fictitious credentials to show you the workflow and resulting signature\nand policy hash. You can use this data as test suite to verify your signature calculation code.\nThe example uses the following example credentials the signature calculations. You can use these\ncredentials to verify your signature calculation code. However, you must then replace these with\nyour own credentials when sending requests to AWS.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecret wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nAccessKey\nSample Policy and Form\nThe following POST policy supports uploads to Amazon S3 with specific conditions.\n{ \"expiration\": \"2015-12-30T12:00:00.000Z\",\n\"conditions\": [\n{\"bucket\": \"sigv4examplebucket\"},\n[\"starts-with\", \"$key\", \"user/user1/\"],\n{\"acl\": \"public-read\"},\n{\"success_action_redirect\": \"http://sigv4examplebucket.s3.amazonaws.com/\nsuccessful_upload.html\"},\n[\"starts-with\", \"$Content-Type\", \"image/\"],\n{\"x-amz-meta-uuid\": \"14365123651274\"},\nPOST Upload Example API Version 2006-03-01 2767",
      "start_idx": 3096102,
      "end_idx": 3097602,
      "metadata": {
        "num_sentences": 10,
        "num_words": 195,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2773",
      "text": "Amazon Simple Storage Service API Reference\n{\"x-amz-server-side-encryption\": \"AES256\"},\n[\"starts-with\", \"$x-amz-meta-tag\", \"\"],\n{\"x-amz-credential\": \"AKIAIOSFODNN7EXAMPLE/20151229/us-east-1/s3/aws4_request\"},\n{\"x-amz-algorithm\": \"AWS4-HMAC-SHA256\"},\n{\"x-amz-date\": \"20151229T000000Z\" }\n]\n}\nThis POST policy sets the following conditions on the request:\n\u2022 The upload must occur before noon UTC on December 30, 2015.\n\u2022 The content can be uploaded only to the sigv4examplebucket. The bucket must be in the\nregion that you specified in the credential scope (x-amz-credential form parameter), because\nthe signature you provided is valid only within this scope.\n\u2022 You can provide any key name that starts with user/user1. For example, user/user1/\nMyPhoto.jpg.\n\u2022 The ACL must be set to public-read.\n\u2022 If the upload succeeds, the user's browser is redirected to http://\nsigv4examplebucket.s3.amazonaws.com/successful_upload.html.\n\u2022 The object must be an image file.\n\u2022 The x-amz-meta-uuid tag must be set to 14365123651274.\n\u2022 The x-amz-meta-tag can contain any value.\nThe following is a Base64-encoded version of this POST policy. You use this value as your\nStringToSign in signature calculation.\neyAiZXhwaXJhdGlvbiI6ICIyMDE1LTEyLTMwVDEyOjAwOjAwLjAwMFoiLA0KICAiY29uZGl0aW9ucyI6IFsNCiAgICB7ImJ1Y2tldCI6ICJzaWd2NGV4YW1wbGVidWNrZXQifSwNCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci91c2VyMS8iXSwNCiAgICB7ImFjbCI6ICJwdWJsaWMtcmVhZCJ9LA0KICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL3NpZ3Y0ZXhhbXBsZWJ1Y2tldC5zMy5hbWF6b25hd3MuY29tL3N1Y2Nlc3NmdWxfdXBsb2FkLmh0bWwifSwNCiAgICBbInN0YXJ0cy13aXRoIiwgIiRDb250ZW50LVR5cGUiLCAiaW1hZ2UvIl0sDQogICAgeyJ4LWFtei1tZXRhLXV1aWQiOiAiMTQzNjUxMjM2NTEyNzQifSwNCiAgICB7IngtYW16LXNlcnZlci1zaWRlLWVuY3J5cHRpb24iOiAiQUVTMjU2In0sDQogICAgWyJzdGFydHMtd2l0aCIsICIkeC1hbXotbWV0YS10YWciLCAiIl0sDQoNCiAgICB7IngtYW16LWNyZWRlbnRpYWwiOiAiQUtJQUlPU0ZPRE5ON0VYQU1QTEUvMjAxNTEyMjkvdXMtZWFzdC0xL3MzL2F3czRfcmVxdWVzdCJ9LA0KICAgIHsieC1hbXotYWxnb3JpdGhtIjogIkFXUzQtSE1BQy1TSEEyNTYifSwNCiAgICB7IngtYW16LWRhdGUiOiAiMjAxNTEyMjlUMDAwMDAwWiIgfQ0KICBdDQp9\nWhen you copy/paste the preceding policy, it should have carriage returns and new lines for your\ncomputed hash to match this value (ie. ASCII text, with CRLF line terminators).\nUsing example credentials to create a signature, the signature value is as follows (in signature\ncalculation, the date is same as the x-amz-date in the policy (20151229):\n8afdbf4008c03f22c2cd3cdb72e4afbb1f6a588f3255ac628749a66d7f09699e\nUploading a File to Amazon S3 Using HTTP POST API Version 2006-03-01 2768",
      "start_idx": 3097604,
      "end_idx": 3100143,
      "metadata": {
        "num_sentences": 15,
        "num_words": 231,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2774",
      "text": "Amazon Simple Storage Service API Reference\nThe following example form specifies the preceding POST policy and supports a POST\nrequest to the sigv4examplebucket. Copy/paste the content in a text editor and save\nit as exampleform.html. You can then upload image files to the specific bucket using the\nexampleform.html. Your request will succeed if the signature you provide matches the signature\nAmazon S3 calculates.\nNote\nYou must update the bucket name, dates, credential, policy, and signature with valid values\nfor this to successfully upload to S3.\n<html>\n<head>\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n</head>\n<body>\n<form action=\"http://sigv4examplebucket.s3.amazonaws.com/\" method=\"post\"\nenctype=\"multipart/form-data\">\nKey to upload:\n<input type=\"input\" name=\"key\" value=\"user/user1/${filename}\" /><br />\n<input type=\"hidden\" name=\"acl\" value=\"public-read\" />\n<input type=\"hidden\" name=\"success_action_redirect\" value=\"http://\nsigv4examplebucket.s3.amazonaws.com/successful_upload.html\" />\nContent-Type:\n<input type=\"input\" name=\"Content-Type\" value=\"image/jpeg\" /><br />\n<input type=\"hidden\" name=\"x-amz-meta-uuid\" value=\"14365123651274\" />\n<input type=\"hidden\" name=\"x-amz-server-side-encryption\" value=\"AES256\" />\n<input type=\"text\" name=\"X-Amz-Credential\" value=\"AKIAIOSFODNN7EXAMPLE/20151229/\nus-east-1/s3/aws4_request\" />\n<input type=\"text\" name=\"X-Amz-Algorithm\" value=\"AWS4-HMAC-SHA256\" />\n<input type=\"text\" name=\"X-Amz-Date\" value=\"20151229T000000Z\" />\nTags for File:\n<input type=\"input\" name=\"x-amz-meta-tag\" value=\"\" /><br />\n<input type=\"hidden\" name=\"Policy\" value='<Base64-encoded policy string>' />\n<input type=\"hidden\" name=\"X-Amz-Signature\" value=\"<signature-value>\" />\nFile:\n<input type=\"file\" name=\"file\" /> <br />\nUploading a File to Amazon S3 Using HTTP POST API Version 2006-03-01 2769",
      "start_idx": 3100145,
      "end_idx": 3101990,
      "metadata": {
        "num_sentences": 6,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2775",
      "text": "Amazon Simple Storage Service API Reference\n<!-- The elements after this will be ignored -->\n<input type=\"submit\" name=\"submit\" value=\"Upload to Amazon S3\" />\n</form>\n</html>\nThe post parameters are case insensitive. For example, you can specify x-amz-signature or X-\nAmz-Signature.\nBrowser-Based Uploads to Amazon S3 Using the AWS Amplify\nLibrary\nThis section describes how to upload files to Amazon S3 using the AWS Amplify JavaScript library.\nFor information about setting up the AWS Amplify library, see AWS Amplify Installation and\nConfiguration.\nUsing the AWS Amplify JavaScript library to Upload Files to Amazon S3\nThe AWS Amplify library Storage module gives a simple browser-based upload mechanism for\nmanaging user content in public or private Amazon S3 storage.\nExample : AWS Amplify Manual Setup\nThe following example shows the manual setup for using the AWS Amplify Storage module. The\ndefault implementation of the Storage module uses Amazon S3.\nimport Amplify from 'aws-amplify';\nAmplify.configure(\nAuth: {\nidentityPoolId: 'XX-XXXX-X:XXXXXXXX-XXXX-1234-abcd-1234567890ab', //REQUIRED -\nAmazon Cognito Identity Pool ID\nregion: 'XX-XXXX-X', // REQUIRED - Amazon Cognito Region\nuserPoolId: 'XX-XXXX-X_abcd1234', //OPTIONAL - Amazon Cognito User Pool ID\nuserPoolWebClientId: 'XX-XXXX-X_abcd1234', //OPTIONAL - Amazon Cognito Web\nClient ID\n},\nStorage: {\nbucket: '', //REQUIRED - Amazon S3 bucket\nregion: 'XX-XXXX-X', //OPTIONAL - Amazon service region\n}\nBrowser-Based Uploads Using AWS Amplify API Version 2006-03-01 2770",
      "start_idx": 3101992,
      "end_idx": 3103523,
      "metadata": {
        "num_sentences": 8,
        "num_words": 215,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2777",
      "text": "Amazon Simple Storage Service API Reference\nCommon Request Headers\nThe following table describes headers that can be used by various types of Amazon S3 REST\nrequests.\nHeader Name Description\nAuthorization The information required for request authentication. For\nmore information, go to The Authentication Header in\nthe Amazon Simple Storage Service Developer Guide. For\nanonymous requests this header is not required.\nAccess-Control-Req A list of HTTP methods that is sent as a pre-flight CORS\nuest-Method request. If the pre-flight CORS evaluation is successful,\nthen the specified methods are allowed to be used in the\nfollowing CORS request.\nContent-Length Length of the message (without the headers) according to\nRFC 2616. This header is required for PUTs and operations\nthat load XML, such as logging and ACLs.\nContent-Type The content type of the resource in case the request has\ncontent in the body. Example: text/plain\nContent-MD5 The base64 encoded 128-bit MD5 digest of the message\n(without the headers) according to RFC 1864. This header\ncan be used as a message integrity check to verify that the\ndata is the same data that was originally sent. Although it is\noptional, we recommend using the Content-MD5 mechanism\nas an end-to-end integrity check. For more information about\nREST request authentication, go to REST Authentication in\nthe Amazon Simple Storage Service Developer Guide.\nDate The date that can be used to create the signature contained\nin the Authorization header. If the Date header is to be\nused for signing it must be specified in the ISO 8601 basic\nformat. In this case, the x-amz-date header is not needed.\nAPI Version 2006-03-01 2772",
      "start_idx": 3104171,
      "end_idx": 3105836,
      "metadata": {
        "num_sentences": 17,
        "num_words": 265,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2778",
      "text": "Amazon Simple Storage Service API Reference\nHeader Name Description\nNote that when x-amz-date is present, it always overrides\nthe value of the Date header.\nIf the Date header is not used for signing, it can be one of\nthe full date formats specified by RFC 2616, section 3.3. For\nexample, the date/time W ed, 01 Mar 2006 12:00:00\nGMT is a valid date/time header for use with Amazon S3.\nIf you are using the Date header for signing, then it must be\nin the ISO 8601 basic YYYYMMDD'T'HHMMSS'Z' format.\nIf Date is specified but is not in ISO 8601 basic format, then\nyou must also include the x-amz-date header. If Date\nis specified in ISO 8601 basic format, then this is sufficien\nt for signing requests and you do not need the x-amz-dat\ne header. For more information, see Handling Dates in\nSignature Version 4 in the Amazon Web Services Glossary.\nExpect When your application uses 100-continue, it does not send\nthe request body until it receives an acknowledgment. If the\nmessage is rejected based on the headers, the body of the\nmessage is not sent. This header can be used only if you are\nsending a body.\nValid Values: 100-continue\nHost For path-style requests, the value is s3.amazonaws.com .\nFor virtual-style requests, the value is BucketNam\ne.s3.amazonaws.com . For more information, go to\nVirtual Hosting in the Amazon Simple Storage Service User\nGuide.\nThis header is required for HTTP 1.1 (most toolkits add this\nheader automatically); optional for HTTP/1.0 requests.\nOrigin An endpoint that specifies the server name of the initial\nrequester.\nAPI Version 2006-03-01 2773",
      "start_idx": 3105838,
      "end_idx": 3107416,
      "metadata": {
        "num_sentences": 16,
        "num_words": 267,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2779",
      "text": "Amazon Simple Storage Service API Reference\nHeader Name Description\nx-amz-content-sha256 When using signature version 4 to authenticate request, this\nheader provides a hash of the request payload. For more\ninformation see Signature Calculations for the Authoriza\ntion Header: Transferring Payload in a Single Chunk (AWS\nSignature Version 4). When uploading object in chunks,\nyou set the value to STREAMING-AWS4-HMAC-SHA256-\nPAYLOAD to indicate that the signature covers only headers\nand that there is no payload. For more information, see\nSignature Calculations for the Authorization Header: Transfe\nrring Payload in Multiple Chunks (Chunked Upload) (AWS\nSignature Version 4).\nx-amz-date The date used to create the signature in the Authoriza\ntion header. The format must be ISO 8601 basic in the\nYYYYMMDD'T'HHMMSS'Z' format. For example, the date/\ntime 20170210T120000Z is a valid x -amz-date for use\nwith Amazon S3.\nx-amz-date is optional for all requests; it can be used to\noverride the date used for signing requests. If the Date h\neader is specified in the ISO 8601 basic format, then x-\namz-date is not needed. When x-amz-date is present,\nit always overrides the value of the Date header. For more\ninformation, see Handling Dates in Signature Version 4 in the\nAmazon Web Services Glossary.\nAPI Version 2006-03-01 2774",
      "start_idx": 3107418,
      "end_idx": 3108741,
      "metadata": {
        "num_sentences": 12,
        "num_words": 206,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2780",
      "text": "Amazon Simple Storage Service API Reference\nHeader Name Description\nx-amz-security-token This header can be used in the following scenarios:\n\u2022\nTo provide security tokens for Amazon DevPay operation\ns - Each request that uses Amazon DevPay requires\ntwo x-amz-security-token headers: one for\nthe product token and one for the user token. When\nAmazon S3 receives an authenticated request, it compares\nthe computed signature with the provided signature.\nImproperly formatted multi-value headers that are used to\ncalculate a signature can cause authentication issues.\n\u2022\nTo provide a security token when using temporary security\ncredentials - When making requests using temporary\nsecurity credentials that you obtained from IAM, you must\nprovide a security token by using this header. To learn\nmore about temporary security credentials, see M aking R\nequests.\nThis header is required for requests that use Amazon DevPay\nand requests that are signed by using temporary security\ncredentials.\nAPI Version 2006-03-01 2775",
      "start_idx": 3108743,
      "end_idx": 3109754,
      "metadata": {
        "num_sentences": 7,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2781",
      "text": "Amazon Simple Storage Service API Reference\nCommon Response Headers\nThe following table describes response headers that are common to most Amazon S3 responses.\nName Description\nAccess-Co A Boolean that determines if the server allows CORS requests to contain\nntrol-All credentials. If the Access-Control-Allow-Origin request header\now-Creden is set to '*' then the Access-Control-Allow-Credentials\ntials response header will be omitted, else it is set to true when CORS evaluatio\nn is successful.\nType: Boolean\nDefault: None\nAccess-Co A list of HTTP headers allowed for your CORS requests. The Access-Co\nntrol-All ntrol-Allow-Headers response header is returned for successful\now-Headers CORS evaluations and explicitly specifies all allowed Access-Control-\nRequest-Headers .\nType: String\nDefault: None\nAccess-Co A list that specifies which HTTP methods are allowed. Amazon S3 will\nntrol-All only allow CORS requests from allowed CORS methods when the CORS\now-Methods evaluation is successful.\nType: String\nDefault: None\nAccess-Co The location of the allowed origin. Amazon S3 will only send the Access-\nntrol-All Control-Allow-Origin response header when the CORS evaluation\now-Origin is successful. If the request origin matches '*' in the CORS configuration's\nallowed origins then the '*' is returned in this response header instead of\nthe original origin.\nAPI Version 2006-03-01 2776",
      "start_idx": 3109756,
      "end_idx": 3111143,
      "metadata": {
        "num_sentences": 11,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2782",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nType: String\nDefault: None\nAccess-Co A list that allows a server to identify a response header that exposes access\nntrol-Exp for applications when the CORS evaluation is successful.\nose-Headers\nType: String\nDefault: None\nAccess-Co The time in seconds that your browser can cache the response for a CORS\nntrol-Max- pre-flight request as identified by the resource, the HTTP method, and\nAge the origin. The Access-Control-Max-Age response header is only\nreturned when the CORS evaluation is successful.\nType: Integer\nDefault: None\nVary A list that indicates which request headers the CORS evaluation result\nvaries on. The Vary response header is only returned when the CORS\nevaluation is successful.\nType: String\nDefault: None\nContent-L The length in bytes of the body in the response.\nength\nType: String\nDefault: None\nContent-Type The MIME type of the content. For example, Content-Type: text/\nhtml; charset=utf-8 .\nType: String\nDefault: None\nAPI Version 2006-03-01 2777",
      "start_idx": 3111145,
      "end_idx": 3112175,
      "metadata": {
        "num_sentences": 9,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2783",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nConnection A value that specifies whether the connection to the server is open or\nclosed.\nType: Enum\nValid Values: open | close\nDefault: None\nDate The date and time that Amazon S3 responded; for example, Wed, 01 Mar\n2006 12:00:00 GMT.\nType: String\nDefault: None\nETag The entity tag (ETag) represents a specific version of the object. The ETag\nreflects changes only to the contents of an object, not its metadata. The\nETag might or might not be an MD5 digest of the object data. Whether or\nnot it is depends on how the object was created and how it is encrypted, as\nfollows:\n\u2022 Objects created through the AWS Management Console or by the PUT\nObject, POST Object, or Copy operation:\n\u2022 Objects that are plaintext or encrypted by server-side encryption with\nAmazon S3 managed keys (SSE-S3) have ETags that are an MD5 digest\nof their data.\n\u2022 Objects encrypted by server-side encryption with customer-provided\nkeys (SSE-C) or AWS Key Management Service (AWS KMS) keys (SSE-\nKMS) have ETags that are not an MD5 digest of their object data.\n\u2022 Objects created by either the Multipart Upload or Upload Part Copy\noperation have ETags that are not MD5 digests, regardless of the method\nof encryption.\nType: String\nAPI Version 2006-03-01 2778",
      "start_idx": 3112177,
      "end_idx": 3113467,
      "metadata": {
        "num_sentences": 9,
        "num_words": 220,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2784",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nServer The name of the server that created the response.\nType: String\nDefault: AmazonS3\nx-amz-del A value that specifies whether the object returned was (true) or was not\nete-marker (false) a delete marker.\nType: Boolean\nValid Values: true | false\nDefault: false\nx-amz-id-2 A special token that is used together with the x-amz-request-id\nheader to help AWS troubleshoot problems. For information about AWS\nSupport using these request IDs, see Troubleshooting Amazon S3.\nType: String\nDefault: None\nx-amz-req A value created by Amazon S3 that uniquely identifies the request.\nuest-id This value is used together with the x-amz-id-2 header to help AWS\ntroubleshoot problems. For information about AWS Support using these\nrequest IDs, see Troubleshooting Amazon S3.\nType: String\nDefault: None\nx-amz-ser The server-side encryption algorithm used when storing this object in\nver-side- Amazon S3 (for example, AES256, aws:kms).\nencryption\nValid Values: AES256 | aws:kms\nAPI Version 2006-03-01 2779",
      "start_idx": 3113469,
      "end_idx": 3114520,
      "metadata": {
        "num_sentences": 9,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2785",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nx-amz-ver The version of the object. When you enable versioning, Amazon S3\nsion-id generates a random number for objects added to a bucket. The value is\nUTF-8 encoded and URL ready. When you PUT an object in a bucket where\nversioning has been suspended, the version ID is always null.\nType: String\nValid Values: null | any URL-ready, UTF-8 encoded string\nDefault: null\nAPI Version 2006-03-01 2780",
      "start_idx": 3114522,
      "end_idx": 3114979,
      "metadata": {
        "num_sentences": 5,
        "num_words": 75,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2786",
      "text": "Amazon Simple Storage Service API Reference\nError responses\nThis section provides reference information about Amazon S3 errors.\nNote\n\u2022 In general, S3 bucket owners are billed for requests with HTTP 200 OK successful\nresponses and HTTP 4XX client error responses. Bucket owners aren't billed for HTTP\n5XX server error responses, such as HTTP 503 Slow Down errors. For more information\non S3 error codes under HTTP 3XX and 4XX status codes that aren't billed, see Billing\nfor Amazon S3 error responses in the Amazon S3 User Guide. For more information\nabout billing charges if your bucket is configured as a Requester Pays bucket, see How\nRequester Pays charges work in the Amazon S3 User Guide.\n\u2022 SOAP support over HTTP is deprecated, but SOAP is still available over HTTPS. New\nAmazon S3 features are not supported for SOAP. Instead of using SOAP, we recommend\nthat you use either the REST API or the AWS SDKs.\nTopics\n\u2022 REST error responses\n\u2022 List of error codes\n\u2022 List of SELECT Object Content Error Codes\n\u2022 List of Replication-related error codes\n\u2022 List of Tagging-related error codes\n\u2022 List of Amazon S3 on Outposts error codes\n\u2022 List of Amazon S3 Storage Lens error codes\n\u2022 List of Amazon S3 Object Lambda error codes\n\u2022 List of Amazon S3 asynchronous error codes\n\u2022 List of Amazon S3 Access Grants Error Codes\n\u2022 Amazon S3 error best practices\nAPI Version 2006-03-01 2781",
      "start_idx": 3114981,
      "end_idx": 3116354,
      "metadata": {
        "num_sentences": 9,
        "num_words": 239,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2787",
      "text": "Amazon Simple Storage Service API Reference\nREST error responses\nWhen an error occurs, the header information contains the following:\n\u2022 Content-Type: application/xml\n\u2022 An appropriate 3xx, 4xx, or 5xx HTTP status code\nThe body of the response also contains information about the error. The following sample error\nresponse shows the structure of response elements common to all REST error responses.\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<Error>\n<Code>NoSuchKey</Code>\n<Message>The resource you requested does not exist</Message>\n<Resource>/mybucket/myfoto.jpg</Resource>\n<RequestId>4442587FB7D0A2F9</RequestId>\n</Error>\nThe following table explains the REST error response elements.\nName Description\nCode The error code is a string that uniquely identifies an error condition. It is\nmeant to be read and understood by programs that detect and handle errors\nby type. For more information, see List of error codes.\nType: String\nAncestor: Error\nError Container for all error elements.\nType: Container\nAncestor: None\nMessage The error message contains a generic description of the error condition in\nEnglish. It is intended for a human audience. Simple programs display the\nmessage directly to the end user if they encounter an error condition they\nREST error responses API Version 2006-03-01 2782",
      "start_idx": 3116356,
      "end_idx": 3117649,
      "metadata": {
        "num_sentences": 10,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2788",
      "text": "Amazon Simple Storage Service API Reference\nName Description\ndon't know how or don't care to handle. Sophisticated programs with more\nexhaustive error handling and proper internationalization are more likely to\nignore the error message.\nType: String\nAncestor: Error\nRequestId ID of the request associated with the error.\nType: String\nAncestor: Error\nResource The bucket or object that is involved in the error.\nType: String\nAncestor: Error\nMany error responses contain additional structured data meant to be read and understood by a\ndeveloper diagnosing programming errors. For example, if you send a Content-MD5 header with a\nREST PUT request that doesn't match the digest calculated on the server, you receive a BadDigest\nerror. The error response also includes as detail elements the digest that the server calculated, and\nthe digest that you told the server to expect. During development, you can use this information\nto diagnose the error. In production, a well-behaved program might include this information in its\nerror log.\nFor information about general response elements, go to Error responses.\nList of error codes\nThe following table lists Amazon S3 error codes.\nList of error codes API Version 2006-03-01 2783",
      "start_idx": 3117651,
      "end_idx": 3118871,
      "metadata": {
        "num_sentences": 12,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2789",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nAccessControlListN The bucket does not allow ACLs. 400 Client\notSupported Bad\nRequest\nAccessDenied Access Denied 403 Client\nForbidden\nAccessPointAlready An access point with an identical 409 Client\nOwnedByYou name already exists in your accoun Conflict\nt.\nAccountProblem There is a problem with your 403 Client\nAWS account that prevents the Forbidden\noperation from completing\nsuccessfully. For further assistance,\nsee Contact Us.\nAllAccessDisabled All access to this Amazon S3 403 Client\nresource has been disabled. For Forbidden\nfurther assistance, see Contact Us.\nAmbiguousGrantByEm The email address that you 400 Client\nailAddress provided is associated with more Bad\nthan one account. Request\nAuthorizationHeade The authorization header that you 400 N/A\nrMalformed provided is not valid. Bad\nRequest\nAuthorizationQuery The authorization query parameter 400 N/A\nParametersError s that you provided are not valid. Bad\nRequest\nList of error codes API Version 2006-03-01 2784",
      "start_idx": 3118873,
      "end_idx": 3119956,
      "metadata": {
        "num_sentences": 9,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2790",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nBadDigest The Content-MD5 or checksum 400 Client\nvalue that you specified did not Bad\nmatch what the server received. Request\nBucketAlreadyExists The requested bucket name is not 409 Client\navailable. The bucket namespace is Conflict\nshared by all users of the system.\nSpecify a different name and try\nagain.\nBucketAlreadyOwnedByYou The bucket that you tried to create 409 Client\nalready exists, and you own it. Conflict\nAmazon S3 returns this error in all (in all\nAWS Regions except in the US East Regions\n(N. Virginia) Region (us-east-1). except\nFor legacy compatibility, if you re- us-\ncreate an existing bucket that you east-1)\nalready own in us-east-1, Amazon\nS3 returns 200 OK and resets the\nbucket access control lists (ACLs).\nFor Amazon S3 on Outposts, the\nbucket that you tried to create alr\neady exists in your Outpost and\nyou own it.\nBucketNotEmpty The bucket that you tried to delete 409 Client\nis not empty. Conflict\nClientTokenConflict Your Multi-Region Access Point 409 Client\nidempotency token was already Conflict\nused for a different request.\nList of error codes API Version 2006-03-01 2785",
      "start_idx": 3119958,
      "end_idx": 3121173,
      "metadata": {
        "num_sentences": 11,
        "num_words": 196,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2791",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nConnectionClosedBy Returned to the original caller 400 Client\nRequester when an error is encountered while Bad\nreading the WriteGetObjectResp Request\nonse body.\nConditionalRequestConflict A conflicting operation occurred. If 409 Client\nusing PutObject you can retry Conflict\nthe request. If using multipart\nupload you should initiate another\nCreateMultipartUpload\nrequest and re-upload each part.\nCredentialsNotSupported This request does not support 400 Client\ncredentials. Bad\nRequest\nCrossLocationLoggi Cross-Region logging is not 403 Client\nngProhibited allowed. Buckets in one AWS Forbidden\nRegion cannot log information to\na bucket in another Region.\nDeviceNotActiveError The device is not currently active. 400 Client\nBad\nRequest\nEndpointNotFound Direct requests to the correct 400 Client\nendpoint. Bad\nRequest\nEntityTooSmall Your proposed upload is smaller 400 Client\nthan the minimum allowed object Bad\nsize. Request\nList of error codes API Version 2006-03-01 2786",
      "start_idx": 3121175,
      "end_idx": 3122255,
      "metadata": {
        "num_sentences": 11,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2792",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nEntityTooLarge Your proposed upload exceeds the 400 Client\nmaximum allowed object size. For Bad\nmore information, see Amazon Request\nSimple Storage Service endpoints\nand quotas in the AWS General\nReference.\nExpiredToken The provided token has expired. 400 Client\nBad\nRequest\nIllegalLocationCon This error might occur for the 400 Client\nstraintException following reasons: Bad\nRequest\n\u2022\nYou are trying to access a bucket\nfrom a different Region than\nwhere the bucket exists.\n\u2022\nYou attempt to create a bucket\nwith a location constraint that\ncorresponds to a different region\nthan the regional endpoint the\nrequest was sent to.\nIllegalVersioningC The versioning configuration 400 Client\nonfigurationException specified in the request is not valid. Bad\nRequest\nIncompleteBody You did not provide the number 400 Client\nof bytes specified by the Content- Bad\nLength HTTP header. Request\nList of error codes API Version 2006-03-01 2787",
      "start_idx": 3122257,
      "end_idx": 3123292,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2793",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nIncorrectEndpoint The specified bucket exists in 400 Client\nanother Region. Direct requests to Bad\nthe correct endpoint. Request\nIncorrectNumberOfF POST requires exactly one file 400 Client\nilesInPostRequest upload per request. Bad\nRequest\nInlineDataTooLarge The inline data exceeds the 400 Client\nmaximum allowed size. Bad\nRequest\nInternalError An internal error occurred. Try 500 Server\nagain. Internal\nServer\nError\nInvalidAccessKeyId The AWS access key ID that you 403 Client\nprovided does not exist in our Forbidden\nrecords.\nInvalidAccessPoint The specified access point name or 400 Client\naccount is not valid. Bad\nRequest\nInvalidAccessPoint The specified access point alias 400 Client\nAliasError name is not valid. Bad\nRequest\nInvalidAddressingHeader You must specify the Anonymous N/A Client\nrole.\nList of error codes API Version 2006-03-01 2788",
      "start_idx": 3123294,
      "end_idx": 3124253,
      "metadata": {
        "num_sentences": 11,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2794",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nInvalidArgument This error might occur for the 400 Client\nfollowing reasons: Bad\nRequest\n\u2022\nThe specified argument was not\nvalid.\n\u2022\nThe request was missing a\nrequired header.\n\u2022\nThe specified argument was\nincomplete or in the wrong fo\nrmat.\n\u2022\nThe specified argument must\nhave a length greater than or\nequal to 3.\nInvalidBucketAclWi Bucket cannot have ACLs set with 400 Client\nthObjectOwnership ObjectOwnership's BucketOwner Bad\nEnforced setting. Request\nInvalidBucketName The specified bucket is not valid. 400 Client\nBad\nRequest\nInvalidBucketOwner The value of the expected bucket 400 Client\nAWSAccountID owner parameter must be an AWS Bad\naccount ID. Request\nInvalidBucketState The request is not valid for the 409 Client\ncurrent state of the bucket. Conflict\nList of error codes API Version 2006-03-01 2789",
      "start_idx": 3124255,
      "end_idx": 3125169,
      "metadata": {
        "num_sentences": 9,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2795",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nInvalidDigest The Content-MD5 or checksum 400 Client\nvalue that you specified is not Bad\nvalid. Request\nInvalidEncryptionA The encryption request that you 400 Client\nlgorithmError specified is not valid. The valid Bad\nvalue is A ES256. Request\nInvalidHostHeader The host headers provided in the 400 Client\nrequest used the incorrect style Bad\naddressing. Request\nInvalidHttpMethod The request is made using an 400 Client\nunexpected HTTP method. Bad\nRequest\nInvalidLocationConstraint The specified location (Region) 400 Client\nconstraint is not valid. For more Bad\ninformation about selecting Request\na Region for your buckets, see\nBuckets overview.\nInvalidObjectState The operation is not valid for the 403 Client\ncurrent state of the object. Forbidden\nInvalidPart One or more of the specified parts 400 Client\ncould not be found. The part Bad\nmight not have been uploaded, Request\nor the specified entity tag might\nnot have matched the part's entity\ntag.\nList of error codes API Version 2006-03-01 2790",
      "start_idx": 3125171,
      "end_idx": 3126281,
      "metadata": {
        "num_sentences": 11,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2796",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nInvalidPartOrder The list of parts was not in 400 Client\nascending order. The parts list Bad\nmust be specified in order by part Request\nnumber.\nInvalidPayer All access to this object has been 403 Client\ndisabled. For further assistance, Forbidden\nsee Contact Us.\nInvalidPolicyDocument The content of the form does not 400 Client\nmeet the conditions specified in Bad\nthe policy document. Request\nInvalidRange The requested range is not valid 416 Client\nfor the request. Try another range. Requested\nRange\nNot\nSatisfiab\nle\nList of error codes API Version 2006-03-01 2791",
      "start_idx": 3126283,
      "end_idx": 3126958,
      "metadata": {
        "num_sentences": 8,
        "num_words": 107,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2797",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nInvalidRequest This error might occur for the 400 Client\nfollowing reasons: Bad\nRequest\n\u2022\nThe request is using the wrong\nsignature version. Use AWS4-\nHMAC-SHA256 (Signature\nVersion 4).\n\u2022\nAn access point can be created\nonly for an existing bucket.\n\u2022\nThe access point is not in a state\nwhere it can be deleted.\n\u2022\nAn access point can be listed\nonly for an existing bucket.\n\u2022\nThe next token is not valid.\n\u2022\nAt least one action must be\nspecified in a lifecycle rule.\n\u2022\nAt least one lifecycle rule must\nbe specified.\n\u2022\nThe number of lifecycle rules\nmust not exceed the allowed\nlimit of 1000 rules.\n\u2022\nThe range for the MaxResults\nparameter is not valid.\n\u2022\nList of error codes API Version 2006-03-01 2792",
      "start_idx": 3126960,
      "end_idx": 3127763,
      "metadata": {
        "num_sentences": 11,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2798",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nSOAP requests must be made\nover an HTTPS connection.\n\u2022\nAmazon S3 Transfer Accelerat\nion is not supported for buckets\nwith non-DNS compliant names.\n\u2022\nAmazon S3 Transfer Accelerat\nion is not supported for buckets\nwith periods (.) in their names.\n\u2022\nThe Amazon S3 Transfer\nAcceleration endpoint supports\nonly virtual style requests.\n\u2022\nAmazon S3 Transfer Acceleration\nis not configured on this bucket.\n\u2022\nAmazon S3 Transfer Acceleration\nis disabled on this bucket.\n\u2022\nAmazon S3 Transfer Acceleration\nis not supported on this bucket.\nFor assistance, contact A WS\nSupport.\n\u2022\nAmazon S3 Transfer Accelerat\nion cannot be enabled on this\nbucket. For assistance, contact\nAWS Support.\n\u2022\nList of error codes API Version 2006-03-01 2793",
      "start_idx": 3127765,
      "end_idx": 3128591,
      "metadata": {
        "num_sentences": 12,
        "num_words": 133,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2799",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nConflicting values provided in\nHTTP headers and query pa\nrameters.\n\u2022\nConflicting values provided in\nHTTP headers and POST form\nfields.\n\u2022\nCopyObject request made on\nobjects larger than 5GB in size.\nInvalidSessionException Returned if the session doesn't 400 Client\nexist anymore because it timed out Bad\nor expired. Request\nInvalidSignature The request signature that the 400 Client\nserver calculated does not match Bad\nthe signature that you provided. Request\nCheck your AWS secret access key\nand signing method. For more\ninformation, see Signing and\nauthenticating REST requests.\nInvalidSecurity The provided security credentials 403 Client\nare not valid. Forbidden\nInvalidSOAPRequest The SOAP request body is not 400 Client\nvalid. Bad\nRequest\nList of error codes API Version 2006-03-01 2794",
      "start_idx": 3128593,
      "end_idx": 3129492,
      "metadata": {
        "num_sentences": 10,
        "num_words": 135,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2800",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nInvalidStorageClass The storage class that you 400 Client\nspecified is not valid. Bad\nRequest\nInvalidTargetBucke The target bucket for logging 400 Client\ntForLogging either does not exist, is not owned Bad\nby you, or does not have the Request\nappropriate grants for the log-\ndelivery group.\nInvalidToken The provided token is malformed 400 Client\nor otherwise not valid. Bad\nRequest\nInvalidURI The specified URI couldn't be 400 Client\nparsed. Bad\nRequest\nKeyTooLongError Your key is too long. 400 Client\nBad\nRequest\nKMS.DisabledException The request was rejected because 400 Client\nthe specified KMS key is not Bad\nenabled. Request\nList of error codes API Version 2006-03-01 2795",
      "start_idx": 3129494,
      "end_idx": 3130280,
      "metadata": {
        "num_sentences": 7,
        "num_words": 122,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2801",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nKMS.InvalidKeyUsag The request was rejected for one 400 Client\neException of the following reasons: Bad\nRequest\n\u2022 The KeyUsage value of the KMS\nkey is incompatible with the API\noperation.\n\u2022 The encryption algorithm or\nsigning algorithm specified for\nthe operation is incompatible\nwith the type of key material in\nthe KMS key (KeySpec).\nFor encrypting, decrypting, re-\nencrypting, and generating data\nkeys, the KeyUsage must be\nENCRYPT_DECRYPT. For signing\nand verifying messages, the\nKeyUsage must be SIGN_VERI\nFY. For generating and verifying\nmessage authentication codes\n(MACs), the KeyUsage must be\nGENERATE_VERIFY_MAC. For\nderiving key agreement secrets,\nthe KeyUsage must be KEY_AGREE\nMENT. To find the KeyUsage of\na KMS key, use the DescribeKey\noperation.\nTo find the encryption or signing\nalgorithms supported for a\nList of error codes API Version 2006-03-01 2796",
      "start_idx": 3130282,
      "end_idx": 3131259,
      "metadata": {
        "num_sentences": 8,
        "num_words": 149,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2802",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nparticular KMS key, use the\nDescribeKey operation.\nKMS.KMSInvalidStat The request was rejected because 400 Client\neException the state of the specified resource Bad\nis not valid for this request. T Request\nhis exception means one of the\nfollowing:\n\u2022 The key state of the KMS key\nis not compatible with the\noperation.\nTo find the key state, use the\nDescribeKey operation. For more\ninformation about which key\nstates are compatible with each\nKMS operation, see Key states of\nAWS KMS keys in the AWS Key\nManagement Service Developer\nGuide.\n\u2022 For cryptographic operation\ns on KMS keys in custom key\nstores, this exception represent\ns a general failure with many\npossible causes. To identify the\ncause, see the error message\nthat accompanies the exception.\nList of error codes API Version 2006-03-01 2797",
      "start_idx": 3131261,
      "end_idx": 3132167,
      "metadata": {
        "num_sentences": 8,
        "num_words": 148,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2803",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nKMS.NotFoundException The request was rejected because 400 Client\nthe specified entity or resource Bad\ncould not be found. Request\nMalformedACLError The ACL that you provided was not 400 Client\nwell formed or did not validate Bad\nagainst our published schema. Request\nMalformedPOSTRequest The body of your POST request is 400 Client\nnot well-formed multipart/form- Bad\ndata. Request\nMalformedXML The XML that you provided was 400 Client\nnot well formed or did not validate Bad\nagainst our published schema. Request\nMaxMessageLengthExceeded Your request was too large. 400 Client\nBad\nRequest\nMaxPostPreDataLeng Your POST request fields preceding 400 Client\nthExceededError the upload file were too large. Bad\nRequest\nMetadataTooLarge Your metadata headers exceed the 400 Client\nmaximum allowed metadata size. Bad\nRequest\nMethodNotAllowed The specified method is not 405 Client\nallowed against this resource. Method\nNot\nAllowed\nList of error codes API Version 2006-03-01 2798",
      "start_idx": 3132169,
      "end_idx": 3133249,
      "metadata": {
        "num_sentences": 9,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2804",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nMissingAttachment A SOAP attachment was expected, 400 Bad Client\nbut none was found. Request\nMissingAuthenticationToken The request was not signed. 403 Client\nForbidden\nMissingContentLength You must provide the Content-L 411 Client\nength HTTP header. Length\nRequired\nMissingRequestBodyError You sent an empty XML document 400 Client\nas a request. Bad\nRequest\nMissingSecurityElement The SOAP 1.1 request is missing a 400 Client\nsecurity element. Bad\nRequest\nMissingSecurityHeader Your request is missing a required 400 Client\nheader. Bad\nRequest\nNoLoggingStatusForKey There is no such thing as a logging 400 Client\nstatus subresource for a key. Bad\nRequest\nNoSuchAsyncRequest The specified request was not 404 Client\nfound. Not\nFound\nNoSuchBucket The specified bucket does not 404 Client\nexist. Not\nFound\nList of error codes API Version 2006-03-01 2799",
      "start_idx": 3133251,
      "end_idx": 3134209,
      "metadata": {
        "num_sentences": 10,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2805",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nNoSuchBucketPolicy The specified bucket does not have 404 Client\na bucket policy. Not\nFound\nNoSuchCORSConfiguration The specified bucket does not have 404 Client\na CORS configuration. Not\nFound\nNoSuchKey The specified key does not exist. 404 Client\nNot\nFound\nNoSuchLifecycleCon The specified lifecycle configura 404 Client\nfiguration tion does not exist. Not\nFound\nNoSuchMultiRegionA The specified Multi-Region Access 404 Client\nccessPoint Point does not exist. Not\nFound\nNoSuchObjectLockCo The specified object does not have 404 Client\nnfiguration an ObjectLock configuration. Not\nFound\nNoSuchWebsiteConfiguration The specified bucket does not have 404 Client\na website configuration. Not\nFound\nNoSuchTagSet The specified tag does not exist. 404 Client\nNot\nFound\nList of error codes API Version 2006-03-01 2800",
      "start_idx": 3134211,
      "end_idx": 3135129,
      "metadata": {
        "num_sentences": 9,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2806",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nNoSuchUpload The specified multipart upload 404 Client\ndoes not exist. The upload ID Not\nmight not be valid, or the multipa Found\nrt upload might have been aborted\nor completed.\nNoSuchVersion The version ID specified in the 404 Client\nrequest does not match an existing Not\nversion. Found\nNotDeviceOwnerError The device that generated 400 Client\nthe token is not owned by the Bad\nauthenticated user. Request\nNotImplemented A header that you provided implies 501 Server\nfunctionality that is not implement Not\ned. Implement\ned\nNotModified The resource was not changed. 304 Server\nNot\nModified\nNoTransformationDefined No transformation found for this 404 Client\nObject Lambda Access Point. Not\nFound\nNotSignedUp Your account is not signed up 403 Client\nfor the Amazon S3 service. You Forbidden\nmust sign up before you can use\nAmazon S3. You can sign up\nat the following URL: https://a\nws.amazon.com/s3\nList of error codes API Version 2006-03-01 2801",
      "start_idx": 3135131,
      "end_idx": 3136185,
      "metadata": {
        "num_sentences": 10,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2807",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nObjectLockConfigur The Object Lock configuration 404 Client\nationNotFoundError does not exist for this bucket. Not\nFound\nOwnershipControlsN The bucket ownership controls 404 Client\notFoundError were not found. Not\nFound\nOperationAborted A conflicting conditional operation 409 Client\nis currently in progress against this Conflict\nresource. Try again.\nPermanentRedirect The bucket that you are attemptin 301 Client\ng to access must be addressed Moved\nusing the specified endpoint. Permanent\nSend all future requests to this ly\nendpoint.\nPermanentRedirectC The API operation you are 301 Client\nontrolError attempting to access must be Moved\naddressed using the specified Permanent\nendpoint. Send all future requests ly\nto this endpoint.\nPreconditionFailed At least one of the preconditions 412 Client\nthat you specified did not hold. Precondit\nion\nFailed\nRedirect Temporary redirect. You are being 307 Client\nredirected to the bucket while Temporary\nthe Domain Name System (DNS) Redirect\nserver is being updated.\nList of error codes API Version 2006-03-01 2802",
      "start_idx": 3136187,
      "end_idx": 3137353,
      "metadata": {
        "num_sentences": 12,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2808",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nRequestHeaderSecti The request header and query 400 Client\nonTooLarge parameters used to make the Bad\nrequest exceed the maximum all Request\nowed size.\nRequestIsNotMultiP A bucket POST request must be 412 Client\nartContent of the enclosure-type multipart/ Precondit\nform-data. ion\nFailed\nRequestTimeout Your socket connection to the 400 Client\nserver was not read from or Bad\nwritten to within the timeout Request\nperiod.\nRequestTimeTooSkewed The difference between the 403 Client\nrequest time and the server's time Forbidden\nis too large.\nRequestTorrentOfBu Requesting the torrent file of a 400 Client\ncketError bucket is not permitted. Bad\nRequest\nResponseInterrupted Returned to the original caller 400 Client\nwhen an error is encountered while Bad\nreading the WriteGetObjectResp Request\nonse body.\nRestoreAlreadyInProgress The object restore is already in 409 Client\nprogress. Conflict\nList of error codes API Version 2006-03-01 2803",
      "start_idx": 3137355,
      "end_idx": 3138399,
      "metadata": {
        "num_sentences": 8,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2809",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nServerSideEncrypti The server-side encryption 400 Client\nonConfigurationNot configuration was not found. Bad\nFoundError Request\nServiceUnavailable Service is unable to handle 503 Server\nrequest. Service\nUnavailab\nle\nSignatureDoesNotMatch The request signature that the 403 Client\nserver calculated does not match Forbidden\nthe signature that you provide\nd. Check your AWS secret access\nkey and signing method. For more\ninformation, see REST Authentic\nation and SOAP Authentication.\nSlowDown Please reduce your request rate. 503 Server\nSlow\nDown\n503 SlowDown Slow Down 503 Server\nSlow\nDown\nTemporaryRedirect You are being redirected to the 307 Client\nbucket while the Domain Name Temporary\nSystem (DNS) server is being Redirect\nupdated.\nTokenCodeInvalidError The serial number and/or token 400 Client\ncode you provided is not valid. Bad\nRequest\nList of error codes API Version 2006-03-01 2804",
      "start_idx": 3138401,
      "end_idx": 3139399,
      "metadata": {
        "num_sentences": 8,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2810",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nTokenRefreshRequired The provided token must be 400 Client\nrefreshed. Bad\nRequest\nTooManyAccessPoints You have attempted to create 400 Client\nmore access points than are Bad\nallowed for an account. For Request\nmore information, see Amazon\nSimple Storage Service endpoints\nand quotas in the AWS General\nReference.\nTooManyBuckets You have attempted to create 400 Client\nmore buckets than are allowed Bad\nfor an account. For more inform Request\nation, see Amazon Simple Storage\nService endpoints and quotas in\nthe AWS General Reference.\nTooManyMultiRegion You have attempted to create a 400 Client\nAccessPointregionsError Multi-Region Access Point with Bad\nmore Regions than are allowed Request\nfor an account. For more informati\non, see Amazon Simple Storage\nService endpoints and quotas in\nthe AWS General Reference.\nList of error codes API Version 2006-03-01 2805",
      "start_idx": 3139401,
      "end_idx": 3140371,
      "metadata": {
        "num_sentences": 8,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2811",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nTooManyMultiRegion You have attempted to create 400 Client\nAccessPoints more Multi-Region Access Points Bad\nthan are allowed for an account. Request\nFor more information, see Amazon\nSimple Storage Service endpoints\nand quotas in the AWS General\nReference.\nUnauthorizedAccessError Applicable in China Regions only. 403 Client\nReturned when a request is made Forbidden\nto a bucket that doesn't have an\nICP license. For more information,\nsee ICP Recordal.\nUnexpectedContent This request contains unsupported 400 Client\ncontent. Bad\nRequest\nUnexpectedIPError Applicable in China Regions only. 403 Client\nThis request was rejected because Forbidden\nthe IP was unexpected.\nUnsupportedArgument The request contained an 400 Client\nunsupported argument. Bad\nRequest\nUnsupportedSignature The provided request is signed 400 Client\nwith an unsupported STS Token Bad\nversion or the signature version is Request\nnot supported.\nList of error codes API Version 2006-03-01 2806",
      "start_idx": 3140373,
      "end_idx": 3141440,
      "metadata": {
        "num_sentences": 11,
        "num_words": 153,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2812",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP SOAP\nstatus fault\ncode code\nprefix\nUnresolvableGrantB The email address that you 400 Client\nyEmailAddress provided does not match any Bad\naccount on record. Request\nUserKeyMustBeSpecified The bucket POST request must 400 Client\ncontain the specified field name. Bad\nIf it is specified, check the order of Request\nthe fields.\nNoSuchAccessPoint The specified access point does not 404 Client\nexist. Not\nFound\nInvalidTag Your request contains tag input 400 Client\nthat is not valid. For example, your Bad\nrequest might contain duplicate Request\nkeys, keys or values that are too\nlong, or system tags.\nMalformedPolicy Your policy contains a principal 400 Client\nthat is not valid. Bad\nRequest\nList of SELECT Object Content Error Codes\nImportant\nAmazon S3 Select is no longer available to new customers. Existing customers of Amazon\nS3 Select can continue to use the feature as usual. Learn more\nList of SELECT Object Content Error Codes API Version 2006-03-01 2807",
      "start_idx": 3141442,
      "end_idx": 3142474,
      "metadata": {
        "num_sentences": 10,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2813",
      "text": "Amazon Simple Storage Service API Reference\nThe following table contains special errors that SELECT Object Content might return. For\ngeneral information about Amazon S3 errors and a list of error codes, see Error responses.\nError code Description HTTP status SOAP fault\ncode code prefix\nAmbiguousFieldName The field name matches to 400 Client\nmultiple fields in the file. Check\nthe SQL expression and the file,\nand try again.\nBusy The service is unavailable. Try 503 Client\nagain later.\nCastFailed An attempt to convert from one 400 Client\ndata type to another using C AST\nfailed in the SQL expression.\nColumnTooLong The length of a column in the 400 Client\nresult is greater than maxCharsP\nerColumn of 1 MB.\nCSVEscapingRecordD A quoted record delimiter was 400 Client\nelimiter found in the file. To allow quoted\nrecord delimiters, set AllowQuot\nedRecordDelimiter to\n'TRUE'.\nCSVParsingError An error occurred while parsing 400 Client\nthe CSV file. Check the file and\ntry again.\nCSVUnescapedQuote An unescaped quote was found 400 Client\nwhile parsing the CSV file. To\nallow quoted record delimiter\ns, set AllowQuotedRecordD\nelimiter to ' TRUE'.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2808",
      "start_idx": 3142476,
      "end_idx": 3143689,
      "metadata": {
        "num_sentences": 15,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2814",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nEmptyRequestBody The request body cannot be 400 Client\nempty.\nEvaluatorBindingDo A column name or a path 400 Client\nesNotExist provided does not exist in the\nSQL expression.\nEvaluatorInvalidAr There is an incorrect number of 400 Client\nguments arguments in the function call in\nthe SQL expression.\nEvaluatorInvalidTi The timestamp format string in 400 Client\nmestampFormatPatte the SQL expression is not valid.\nrn\nEvaluatorInvalidTi The timestamp format pattern 400 Client\nmestampFormatPatte contains a symbol in the SQL\nrnSymbol expression that is not valid.\nEvaluatorInvalidTi The timestamp format pattern 400 Client\nmestampFormatPatte contains a valid format symbol\nrnSymbolForParsing that cannot be applied to\ntimestamp parsing in the SQL\nexpression.\nEvaluatorInvalidTi The timestamp format pattern 400 Client\nmestampFormatPatte contains a token in the SQL\nrnToken expression that is not valid.\nEvaluatorLikePatte An argument given to the LIKE 400 Client\nrnInvalidEscapeSeq expression was not valid.\nuence\nEvaluatorNegativeL LIMIT must not be negative. 400 Client\nimit\nList of SELECT Object Content Error Codes API Version 2006-03-01 2809",
      "start_idx": 3143691,
      "end_idx": 3144940,
      "metadata": {
        "num_sentences": 10,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2815",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nEvaluatorTimestamp The timestamp format pattern 400 Client\nFormatPatternDupli contains multiple format specifier\ncateFields s representing the timestamp\nfield in the SQL expression.\nEvaluatorTimestamp The timestamp format pattern 400 Client\nFormatPatternHourC contains a 12-hour hour of day\nlockAmPmMismatch format symbol but doesn't also\ncontain an AM/PM field, or it\ncontains a 24-hour hour of day\nformat specifier and contains an\nAM/PM field in the SQL express\nion.\nEvaluatorUntermina The timestamp format pattern 400 Client\ntedTimestampFormat contains an unterminated token\nPatternToken in the SQL expression.\nExpressionTooLong The SQL expression is too long. 400 Client\nThe maximum byte-length for an\nSQL expression is 256 KB.\nExternalEvalExcept The query cannot be evaluated. 400 Client\nion Check the file and try again.\nIllegalSqlFunction An illegal argument was used in 400 Client\nArgument the SQL function.\nIncorrectSqlFuncti An incorrect argument type was 400 Client\nonArgumentType specified in a function call in the\nSQL expression.\nIntegerOverflow An integer overflow or underflow 400 Client\noccurred in the SQL expression.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2810",
      "start_idx": 3144942,
      "end_idx": 3146254,
      "metadata": {
        "num_sentences": 11,
        "num_words": 188,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2816",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nInternalError An internal error occurred. 500 Client\nInvalidCast An attempt to convert from one 400 Client\ndata type to another using C AST\nfailed in the SQL expression.\nInvalidColumnIndex The column index in the SQL 400 Client\nexpression is not valid.\nInvalidCompression The file is not in a supported 400 Client\nFormat compression format. Only GZIP\nand BZIP2 are supported.\nInvalidDataSource The data source type is not valid. 400 Client\nOnly CSV, JSON, and Parquet are\nsupported.\nInvalidDataType The SQL expression contains a 400 Client\ndata type that is not valid.\nInvalidExpressionT The ExpressionType value is 400 Client\nype not valid. Only SQL expressions\nare supported.\nInvalidFileHeaderI The FileHeaderInfo value is 400 Client\nnfo not valid. Only N ONE, USE, and\nIGNORE are supported.\nInvalidJsonType The JsonType value is not valid. 400 Client\nOnly D OCUMENT and LINES are\nsupported.\nInvalidKeyPath The key path in the SQL expressio 400 Client\nn is not valid.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2811",
      "start_idx": 3146256,
      "end_idx": 3147402,
      "metadata": {
        "num_sentences": 16,
        "num_words": 181,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2817",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nInvalidQuoteFields The QuoteFields value is 400 Client\nnot valid. Only A LWAYS and\nASNEEDED are supported.\nInvalidRequestPara The value of a parameter in the 400 Client\nmeter SelectRequest element is\nnot valid. Check the service API\ndocumentation and try again.\nInvalidScanRange The provided scan range is not 400 Client\nvalid.\nInvalidTableAlias The SQL expression contains a 400 Client\ntable alias that is not valid.\nInvalidTextEncoding The encoding type is not valid. 400 Client\nOnly UTF-8 encoding is supporte\nd.\nJSONParsingError An error occurred while parsing 400 Client\nthe JSON file. Check the file and\ntry again.\nLexerInvalidChar The SQL expression contains a 400 Client\ncharacter that is not valid.\nLexerInvalidIONLit The SQL expression contains an 400 Client\neral operator that is not valid.\nLexerInvalidLiteral The SQL expression contains an 400 Client\noperator that is not valid.\nLexerInvalidOperat The SQL expression contains a 400 Client\nor literal that is not valid.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2812",
      "start_idx": 3147404,
      "end_idx": 3148562,
      "metadata": {
        "num_sentences": 14,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2818",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nLikeInvalidInputs The argument given to the LIKE 400 Client\nclause in the SQL expression is\nnot valid.\nMalformedXML The XML provided was not 400 Client\nwell formed or did not validate\nagainst our published schema.\nCheck the service documentation\nand try again.\nMaxOperatorsExceed Failed to parse SQL expressio 400 Client\ned n, try reducing complexity. For\nexample, reduce number of\noperators used.\nMethodNotAllowed The specified method is not 405 Client\nallowed against this resource. Method\nNot\nAllowed\nMissingRequiredPar The SelectRequest entity is 400 Client\nameter missing a required parameter.\nCheck the service documentation\nand try again.\nMultipleDataSource Multiple data sources are not 400 Client\nsUnsupported supported.\nNumberFormatError An error occurred while parsing a 400 Client\nnumber. This error can be caused\nby underflow or overflow of\nintegers.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2813",
      "start_idx": 3148564,
      "end_idx": 3149604,
      "metadata": {
        "num_sentences": 12,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2819",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nObjectSerializatio InputSerialization 400 Client\nnConflict specifies more than one format\n(CSV, JSON, or Parquet), or\nOutputSerialization\nspecifies more than one format\n(CSV or JSON). For InputSeri\nalization and OutputSer\nialization , you can specify\nonly one format for each.\nOverMaxColumn The number of columns in 400 Client\nthe result is greater than the\nmaximum allowable number of\ncolumns.\nOverMaxParquetBloc The Parquet file is above the max 400 Client\nkSize row group size.\nOverMaxRecordSize The length of a record in the 400 Client\ninput or result is greater than the\nmaxCharsPerRecord limit of 1\nMB.\nParquetParsingError An error occurred while parsing 400 Client\nthe Parquet file. Check the file\nand try again.\nParquetUnsupported The specified Parquet compressi 400 Client\nCompressionCodec on codec is not supported.\nParseAsteriskIsNot Other expressions are not allowed 400 Client\nAloneInSelectList in the SELECT list when * is used\nwithout dot notation in the SQL\nexpression.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2814",
      "start_idx": 3149606,
      "end_idx": 3150768,
      "metadata": {
        "num_sentences": 10,
        "num_words": 175,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2823",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nParseUnsupportedAl The SQL expression contains an 400 Client\nias unsupported use of ALIAS.\nParseUnsupportedCa Only COUNT with (*) as a 400 Client\nllWithStar parameter is supported in the\nSQL expression.\nParseUnsupportedCa The SQL expression contains an 400 Client\nse unsupported use of CASE.\nParseUnsupportedCa The SQL expression contains an 400 Client\nseClause unsupported use of CASE.\nParseUnsupportedLi The SQL expression contains an 400 Client\nteralsGroupBy unsupported use of GROUP BY .\nParseUnsupportedSe The SQL expression contains an 400 Client\nlect unsupported use of SELECT.\nParseUnsupportedSy The SQL expression contains 400 Client\nntax unsupported syntax.\nParseUnsupportedTo The SQL expression contains an 400 Client\nken unsupported token.\nTruncatedInput Object decompression failed. 400 Client\nCheck that the object is properly\ncompressed using the format\nspecified in the request.\nUnauthorizedAccess You are not authorized to 401 Client\nperform this operation.\nUnrecognizedFormat We encountered a record type 400 Client\nException that is not valid.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2818",
      "start_idx": 3154523,
      "end_idx": 3155762,
      "metadata": {
        "num_sentences": 13,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2824",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nUnsupportedFunction We encountered an unsupported 400 Client\nSQL function.\nUnsupportedParquet The specified Parquet type is not 400 Client\nType supported.\nUnsupportedRangeHe A range header is not supported 400 Client\nader for this operation.\nUnsupportedScanRan Scan range queries are not 400 Client\ngeInput supported on this type of object.\nUnsupportedSqlOper We encountered an unsupported 400 Client\nation SQL operation.\nUnsupportedSqlStru We encountered an unsupport 400 Client\ncture ed SQL structure. Check the SQL\nReference.\nUnsupportedStorage We encountered a storage class 400 Client\nClass that is not supported. Only\nSTANDARD, STANDARD_IA , and\nONEZONE_IA storage classes\nare supported.\nUnsupportedSyntax We encountered syntax that is 400 Client\nnot valid.\nUnsupportedTypeFor Your query contains an unsupport 400 Client\nQuerying ed type for comparison (e.g. verif\nying that a Parquet INT96 column\ntype is greater than 0).\nValueParseFailure A timestamp parse failure 400 Client\noccurred in the SQL expression.\nList of SELECT Object Content Error Codes API Version 2006-03-01 2819",
      "start_idx": 3155764,
      "end_idx": 3156956,
      "metadata": {
        "num_sentences": 14,
        "num_words": 171,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2825",
      "text": "Amazon Simple Storage Service API Reference\nList of Replication-related error codes\nThe following table contains special errors that the Replication operation might return. For\ngeneral information about Amazon S3 errors and a list of error codes, see Error responses.\nError code Description HTTP status SOAP fault\ncode code prefix\nInvalidArgument This error might occur for the 400 Client\nfollowing reasons:\n\u2022\nThe <Account> element is\nempty. It must contain a valid\naccount ID.\n\u2022\nThe AWS account specified in\nthe <Account> element must\nmatch the destination bucket\nowner.\n\u2022\nReplicationTime-Status\nmust contain a value.\n\u2022\nReplicationTime-Re\nplicationTimeValue\nmust contain a value.\n\u2022\nReplication-Replic\nationTimeValue-Min\nutes value must be 15.\n\u2022\nReplicationMetrics\nmust contain a S tatus.\n\u2022\nReplicationMetrics\nmust contain an E ventThre\nshold .\nList of Replication-related error codes API Version 2006-03-01 2820",
      "start_idx": 3156958,
      "end_idx": 3157870,
      "metadata": {
        "num_sentences": 11,
        "num_words": 134,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2826",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\n\u2022\nEventThreshold-Rep\nlicationTimeValue-\nMinutes value must be 15.\n\u2022\nRule ID must not contain\nnon-ASCII characters.\nInvalidRequest This error might occur for the 400 Client\nfollowing reasons:\n\u2022\nThe <Owner> in <AccessCo\nntrolTranslation> has\na value, so the <Account>\nelement must be specified.\n\u2022\nThe <Account> element is\nempty. It must contain a valid\naccount ID.\n\u2022\nThe replication destination\nmust contain both Replicati\nonTime and Metrics, or\nneither.\n\u2022\nReplicationTime and\nReplicationMetrics\nmust have the same status.\n\u2022\nS3 Replication Time Control (S3\nRTC) is not supported in this\nAWS Region.\nList of Replication-related error codes API Version 2006-03-01 2821",
      "start_idx": 3157872,
      "end_idx": 3158643,
      "metadata": {
        "num_sentences": 9,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2827",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nReplicationConfigu There is no replication configura 404 Not Client\nrationNotFoundErro tion for this bucket. Found\nr\nList of Tagging-related error codes\nThe following table contains special errors that the TagResource, UntagResource, and\nListTagsForResource operations might return for Storage Lens groups. For general information\nabout general Amazon S3 errors and a list of error codes, see Error responses.\nError Code Description HTTP SOAP Fault\nStatus Code Code Prefix\nInvalidRequest The AWS Region in the resource 400 Bad Not\nARN doesn't match the Region Request supported\nthat's specified in this request.\nThe AWS account in the resource\nARN doesn't match the account ID\nthat's specified in this request. T\nhe AWS partition in the resourceA\nrn is invalid.\nInvalidTag This request contains a tag key 400 Bad Not\nor value that isn't valid. Valid Request supported\ncharacters include the following\n: [ a-zA-Z+-=._:/] . Tag keys\ncan contain up to 128 characters.\nTag values can contain up to 256\ncharacters. There are duplicate\ntag keys in your request. User-\ndefined tag keys can't start with\naws:.\nList of Tagging-related error codes API Version 2006-03-01 2822",
      "start_idx": 3158645,
      "end_idx": 3159917,
      "metadata": {
        "num_sentences": 13,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2828",
      "text": "Amazon Simple Storage Service API Reference\nError Code Description HTTP SOAP Fault\nStatus Code Code Prefix\nNoSuchResource The specified resource doesn't 404 Not Not\nexist. Found supported\nTooManyTags The number of tags exceeds the 400 Bad Not\nlimit of 50 tags. Request supported\nList of Amazon S3 on Outposts error codes\nThe following table contains special errors that an Amazon S3 on Outposts operation might return.\nFor general information about Amazon S3 errors and a list of error codes, see Error responses.\nError code Description HTTP status SOAP fault\ncode code prefix\nBadRequest The bucket is in a transitional 400 Bad Not\nstate because of a previous Request supported\ndeletion attempt. Try again later.\nInvalidRequest This error might occur for the 400 Bad Client\nfollowing reasons: Request\n\u2022\nAmazon VPC configuration is\nrequired.\n\u2022\nPublic access is not allowed on\nS3 on Outposts access points.\nInvalidOutpostState The request is not valid for the 409 Conflict Not\ncurrent state of the Outpost. supported\nInvalidRequest The access point is not in a state 400 Bad Not\nwhere it can be deleted. Request supported\nList of Amazon S3 on Outposts error codes API Version 2006-03-01 2823",
      "start_idx": 3159919,
      "end_idx": 3161108,
      "metadata": {
        "num_sentences": 11,
        "num_words": 193,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2829",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nNoSuchOutpost The specified Outpost does not 404 Not Not\nexist. Found supported\nUnsupportedOperati The specified action was not 404 Not Not\non supported. Found supported\nInsufficientCapaci Insufficient capacity. 507 Insuffici Not\nty ent Storage supported\nList of Amazon S3 Storage Lens error codes\nThe following table contains special errors that Amazon S3 Storage Lens operations might return.\nFor general information about general Amazon S3 errors and a list of error codes, see Error\nresponses.\nError code Description HTTP status SOAP fault\ncode code prefix\nAccessDenied This Region is not supported as 403 Not\na home Region for S3 Storage Forbidden supported\nLens.\nAccountNotAuthoriz This account not authorized to 403 Not\ned use AWS Organizations. Use Forbidden supported\nyour management account or\ndelegated administrator account.\nActivityMetricsMus Activity metrics must be enabled. 400 Bad Not\ntEnabled Request supported\nAWSOrganizationsNo This account is not part of your 403 Not\ntInUseException organization. Forbidden supported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2824",
      "start_idx": 3161110,
      "end_idx": 3162326,
      "metadata": {
        "num_sentences": 11,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2830",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nDefaultConfigurati The Default configuration cannot 403 Not\nonDeleteForbidden be deleted. Forbidden supported\nDuplicateStorageLe There are two or more entries of 400 Bad Not\nnsGroupARN the same Storage Lens group Request supported\nARN in this configuration.\nEmptyExcludeContai This error occurs for the following 400 Bad Not\nner reasons: Request supported\n\u2022\nThe exclude container cannot\nbe empty.\n\u2022\nThe exclude container cannot\nhave zero buckets.\n\u2022\nThe exclude container cannot\nhave zero Regions.\nEmptyExcludeElement You must specify a Storage Lens 400 Bad Not\ngroup with your Exclude el Request supported\nement.\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2825",
      "start_idx": 3162328,
      "end_idx": 3163118,
      "metadata": {
        "num_sentences": 7,
        "num_words": 118,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2831",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nEmptyIncludeContai This error occurs for the following 400 Bad Not\nner reasons: Request supported\n\u2022\nThe include container cannot\nbe empty.\n\u2022\nThe include container cannot\nhave zero buckets.\n\u2022\nThe include container cannot\nhave zero Regions.\nInvalidAWSOrgArn There is a malformed AWS 400 Bad Not\nOrganizations ARN in the Request supported\nconfiguration.\nEmptyIncludeElement You must specify a Storage Lens 400 Bad Not\ngroup with your Include element. Request supported\nInvalidBucketFilter Organization-level configurations 400 Bad Not\ndo not support bucket filters. Request supported\nInvalidConfigId The configuration ID is not valid. 400 Bad Not\nRequest supported\nInvalidDestination The S3 bucket ARN is malformed. 400 Bad Not\nRequest supported\nInvalidEncryptionM Only one encryption method can 400 Bad Not\nethod be specified. Request supported\nInvalidFilterForDe The default configuration must 400 Bad Not\nfaultConfiguration not include any filters. Request supported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2826",
      "start_idx": 3163120,
      "end_idx": 3164264,
      "metadata": {
        "num_sentences": 11,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2832",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nInvalidIncludeExcl You can specify either an Include 400 Bad Not\nudeContainers container or an Exclude container Request supported\nin a configuration. You cannot\nspecify both in a configuration.\nInvalidIncludeExcl Only one Include or Exclude 400 Bad Not\nudeElements element is allowed. At least one Request supported\nInclude or Exclude element must\nbe present.\nInvalidKMSEncrypti The KMS key ID ARN is not valid. 400 Bad Not\nonKeyId Request supported\nInvalidMaximumPref MaxDepth must be within the 400 Bad Not\nixDepth range [1,10]. Request supported\nInvalidMinimumStor MinStorageBytesPer 400 Bad Not\nageBytesPercentage centage must be within the Request supported\nrange [1.00,100.00].\nInvalidOrganizatio The AWS Organizations ARN in 400 Bad Not\nnARN the configuration is not valid. Request supported\nInvalidOrganizatio The default configuration does 400 Bad Not\nnForDefaultConfigu not support organization-level Request supported\nration metrics.\nInvalidRegionForDe The specified Region is not 400 Bad Not\nfaultConfiguration supported for default configurati Request supported\non.\nInvalidRegionName The Region name is not valid. 400 Bad Not\nRequest supported\nInvalidStorageLens The S3 Storage Lens ARN is not 400 Bad Not\nArn required in input. Request supported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2827",
      "start_idx": 3164266,
      "end_idx": 3165704,
      "metadata": {
        "num_sentences": 13,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2833",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nInvalidStorageLens This Storage Lens group ARN isn't 400 Bad Not\nGroupARN valid or only Storage Lens group Request supported\ns in your account are allowed.\nAdditionally, you must follow the\nStorage Lens group ARN structure\n: arn::s3:::storage-\nlens-group/ and adhere to\nthe 64 character limit. Storage\nLens group names can also\ncontain only the following\ncharacters: a-z, A-Z, 0-9, hyphens\n(-), and underscores (_).\nMissingAccountLeve Activity metrics must be enabled 400 Bad Not\nlActivityMetrics at the account level when activity Request supported\nmetrics are enabled at the bucket\nlevel.\nMissingBucketLevel Activity metrics must be enabled 400 Bad Not\nActivityMetrics at the bucket level when activ Request supported\nity metrics are enabled at the\naccount level.\nMissingEncryptionM The encryption method cannot be 400 Bad Not\nethod blank. Specify either SSE-KMS or Request supported\nSSE-S3.\nMissingPrefixLevel Storage metrics at the prefix level 400 Bad Not\nStorageMetrics are mandatory when the prefix Request supported\nlevel is enabled.\nOrganizationAccess This account is not authorized to 403 Not\nDenied add AWS Organizations. Forbidden supported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2828",
      "start_idx": 3165706,
      "end_idx": 3167036,
      "metadata": {
        "num_sentences": 10,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2834",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nOrgConfigurationNo The specified Region does not 403 Not\ntSupported support AWS Organizations in Forbidden supported\nthe configuration.\nServiceNotEnabledF The S3 Storage Lens service-l 403 Not\norOrg inked role is not enabled for the Forbidden supported\norganization.\nStorageMetricsMust Prefix-level storage metrics must 400 Bad Not\nEnabled be enabled. Request supported\nTooManyBuckets The buckets container cannot 400 Bad Not\nhave more than 50 buckets. Request supported\nTooManyRegions The Regions container cannot 400 Bad Not\nhave more than 50 Regions. Request supported\nTooManyStorageLens You can't attach more than 50 400 Bad Not\nGroups Storage Lens groups to your Request supported\nStorage Lens dashboard.\nThe following table contains special errors that S3 Storage Lens groups operations might return.\nFor general information about general Amazon S3 errors and a list of error codes, see Error\nresponses.\nError code Description HTTP status SOAP fault\ncode code prefix\nAccessDenied You don't have permission to 403 Not\nperform Storage Lens group Forbidden supported\nactions. This Region is not\nsupported as home Region for S3\nStorage Lens groups.\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2829",
      "start_idx": 3167038,
      "end_idx": 3168366,
      "metadata": {
        "num_sentences": 11,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2835",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nConfigurationAlrea The specified configuration 409 Not\ndyExists already exists. Conflict supported\nDuplicateElement Tags must be unique. The 400 Bad Not\nAnd logical operator includes Request supported\nduplicate tag keys. The Or logical\noperator includes duplicate\ntags. Logical operator includes\nduplicate prefixes or suffixes.\nInvalidAge DaysLessThan and DaysGreat 400 Bad Not\nerThan must be positive Request supported\nnumbers.\nInvalidFilter A filter must include one of the 400 Bad Not\nfollowing elements: And, Or, Request supported\nMatchAnyTag , M atchAnyP\nrefix , MatchAnySuffix ,\nMatchObjectAge , M atchObje\nctSize .\nInvalidLogicalOper At least two sub elements 400 Bad Not\nator must be present in the logical Request supported\noperators And or Or.\nInvalidMatchAnyPre The MatchAnyPrefix 400 Bad Not\nfix parameter can\u2019t be empty. Request supported\nInvalidMatchAnySuf The MatchAnySuffix 400 Bad Not\nfix parameter can't be empty. Request supported\nInvalidMatchAnyTag The MatchAnyTag parameter 400 Bad Not\ncan't be empty. Request supported\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2830",
      "start_idx": 3168368,
      "end_idx": 3169586,
      "metadata": {
        "num_sentences": 12,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2836",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nInvalidMatchObject The MatchObjectAge 400 Bad Not\nAge parameter can't be empty. Request supported\nInvalidMatchObject The MatchObjectSize 400 Bad Not\nSize parameter can't be empty. Request supported\nInvalidName Storage Lens group Name 400 Bad Not\nparameter must be between 1 Request supported\nand 64 characters. The Storage\nLens group Name parameter\nmust use the ^[a-zA-Z0-9\\-\n_]+$ pattern.\nInvalidNumericComb This object age or object size 400 Bad Not\nination combination isn't valid. Request supported\nInvalidPrefix The maximum length of a prefix 400 Bad Not\nis 1,024 characters. The prefix Request supported\nstring can't be empty.\nInvalidSize BytesLessThan and 400 Bad Not\nBytesGreaterThan must be Request supported\npositive numbers. The maximum\nobject size can't exceed 5 TB.\nThe minimum object size can't be\ngreater than or equal to 5 TB.\nInvalidSuffix The maximum length of a suffix is 400 Bad Not\n1,024 characters. The suffix string Request supported\ncan't be empty.\nList of Amazon S3 Storage Lens error codes API Version 2006-03-01 2831",
      "start_idx": 3169588,
      "end_idx": 3170738,
      "metadata": {
        "num_sentences": 13,
        "num_words": 176,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2837",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status SOAP fault\ncode code prefix\nInvalidTag The object tag key can\u2019t exceed 400 Bad Not\n128 characters. The object tag Request supported\nkey string can't be null or empty.\nThe maximum length of a tag\nvalue is 256 characters. The\nobject tag key contains character\ns that aren't valid. The object tag\nkey must contain only a-z, A-Z,\n0-9, spaces, and the following\ncharacters: ^(_.:/=+\\-@]*)$ .\nMismatchedName The name specified in the request 400 Bad Not\ndoesn't match the Storage Lens Request supported\ngroup name.\nTooManyConfigurati You have attempted to create 400 Bad Not\nons more Storage Lens group Request supported\nconfigurations than the 50\nallowed.\nTooManyElements The Element exceeds the 400 Bad Not\nmaximum number of elements Request supported\nallowed within a logical operator.\nOnly 10 prefixes, suffixes, or tags\nare allowed.\nList of Amazon S3 Object Lambda error codes\nThe following table contains special errors that S3 Object Lambda might return. For information\nabout general Amazon S3 errors and a list of error codes, see Error responses.\nError responses received from the supporting access points during non-GetObject requests are\nsent to the caller unaltered.\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2832",
      "start_idx": 3170740,
      "end_idx": 3172064,
      "metadata": {
        "num_sentences": 13,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2838",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status\ncode\nLambdaInvalidResponse Returned to the original caller 400 Bad\nwhen WriteGetObjectResp Request\nonse responds with Validatio\nnError to AWS Lambda.\nSee the ValidationError\nmessage for more details. Not all\ncases of ValidationError result\nin a L ambdaInvalidResponse\nerror.\nLambdaInvocationFa Lambda function invocation failed. 400 Bad\niled Request\nCallers might receive the following\nerror when S3 Object Lambda is\nunable to successfully invoke the\nconfigured Lambda function.\nThe error message might contain\ndetails about an eventual error retu\nrned by the AWS Lambda service\nwhen invoking the function (for\nexample, status code, error code,\nerror message and request ID).\nLambdaNotFound The AWS Lambda function was not 404 Not\nfound. Found\nThe configured Lambda function,\nversion, or alias was not found\nwhen attempting to invoke it.\nEnsure that the S3 Object Lambda\nAccess Point configuration points\nto the correct Lambda function A\nRN.\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2833",
      "start_idx": 3172066,
      "end_idx": 3173158,
      "metadata": {
        "num_sentences": 10,
        "num_words": 164,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2839",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status\ncode\nThe error message might contain\ndetails about an eventual error\nreturned by the AWS Lambda\nservice when invoking the functi\non (for example, status code, error\ncode, error message and request\nID).\nLambdaPermissionError The caller is not authorized to 403\ninvoke the Lambda function. Forbidden\nThe caller must have permission\nto invoke the Lambda function.\nCheck the policies attached to the\ncaller and ensure that they've been\nallowed to use lambda:Invoke\nfor the configured function.\nThe error message might contain\ndetails about an eventual error retu\nrned by the AWS Lambda service\nwhen invoking the function (for\nexample, status code, error code,\nerror message and request ID).\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2834",
      "start_idx": 3173160,
      "end_idx": 3173997,
      "metadata": {
        "num_sentences": 6,
        "num_words": 131,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2840",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status\ncode\nLambdaResponseNotR The Lambda function exited 500\neceived without successfully calling Internal\nWriteGetObjectResponse . Service\nError\nGetObject response data is\nprovided by the Lambda function\nby calling the WriteGetO\nbjectResponse API operation\n. The Amazon CloudWatch logs\nfor the function might provide\nmore insight into why the functi\non did not successfully call this API\noperation despite exiting normally.\nLambdaRuntimeError The Lambda function failed during 500\nexecution. Internal\nService\nAn explicit error was received from\nError\nthe Lambda function. For details\nabout the failure, check the AWS\nCloudFormation logs.\nLambdaTimeout The Lambda function did not 500\nrespond in the allowed time. Internal\nService\nThe Lambda function failed to\nError\ncomplete its call to W riteGetO\nbjectResponse within 60\nseconds.\nList of Amazon S3 Object Lambda error codes API Version 2006-03-01 2835",
      "start_idx": 3173999,
      "end_idx": 3174975,
      "metadata": {
        "num_sentences": 9,
        "num_words": 142,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2841",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status\ncode\nSlowDown Reduce your request rate for 503 Slow\noperations involving AWS Lambda. Down\nThe function invocation was\nthrottled by AWS Lambda, perhaps\nbecause it has reached its configure\nd concurrency limitation. For\nmore information, see Managing\nconcurrency for a Lambda function\nin the AWS Lambda Developer\nGuide.\nThe error message might contain\ndetails about an eventual error\nreturned by the AWS Lambda\nservice when invoking the function\n(for example, status code, error\ncode, error message and request\nID).\nValidationError Validation errors might be returned 400 Bad\nfrom the W riteGetObjectResp Request\nonse API operation and can occur\nfor numerous reasons. See the error\nmessage for more details.\nList of Amazon S3 asynchronous error codes\nThe following table contains special errors that asynchronous requests might return. For general\ninformation about Amazon S3 errors and a list of error codes, see Error responses.\nThese errors are returned when you query about the state of an asynchronous request, such\nas by using DescribeMultiRegionAccessPointOperation. Because these requests are\nasynchronous, all of these errors have a status code of 200 OK.\nList of Amazon S3 asynchronous error codes API Version 2006-03-01 2836",
      "start_idx": 3174977,
      "end_idx": 3176289,
      "metadata": {
        "num_sentences": 11,
        "num_words": 199,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2842",
      "text": "Amazon Simple Storage Service API Reference\nError code Description HTTP status\ncode\nAccessDenied Access denied. 200 OK\nInternalErrors An internal server error occurred. 200 OK\nMalformedPolicy The specified policy syntax is not 200 OK\nvalid.\nMultiRegionAccessP You already have a Multi-Region 200 OK\nointAlreadyOwnedBy Access Point with the same name.\nYou\nMultiRegionAccessP The action failed because another 200 OK\nointModifiedByAnot request is modifying the specified\nherRequest resource. Try resubmitting your\nrequest after the previous request\nhas been completed.\nMultiRegionAccessP The specified Multi-Region Access 200 OK\nointNotReady Point is not ready to be updated.\nMultiRegionAccessP The buckets used to create a Multi- 200 OK\nointSameBucketRegion Region Access Point cannot be in\nthe same Region.\nMultiRegionAccessP One of the buckets supplied to 200 OK\nointUnsupportedReg create the Multi-Region Access\nion Point is in a Region that is not\nsupported.\nNoSuchBucket The specified bucket does not exist. 200 OK\nNoSuchMultiRegionA The specified Multi-Region Access 200 OK\nccessPoint Point does not exist.\nList of Amazon S3 asynchronous error codes API Version 2006-03-01 2837",
      "start_idx": 3176291,
      "end_idx": 3177473,
      "metadata": {
        "num_sentences": 12,
        "num_words": 169,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2843",
      "text": "Amazon Simple Storage Service API Reference\nList of Amazon S3 Access Grants Error Codes\nThe following table contains special errors that S3 Access Grants requests might return. For general\ninformation about Amazon S3 errors and a list of error codes, see Error responses.\nError Code Description HTTP Status\nCode\nAccessGrantAlready The specified access grant already 409\nExists exists\nAccessGrantsInstan Access Grants Instance already 409\nceAlreadyExists exists\nAccessGrantsInstan Please clean up locations before 400\nceNotEmptyError deleting the access grants instance\nAccessGrantsInstan Access Grants Instance does not 404\nceNotExistsError exist\nAccessGrantsInstan Access Grants Instance Resource 404\nceResourcePolicyNo Policy does not exist\ntExists\nAccessGrantsLocati The specified access grants location 409\nonAlreadyExistsError already exists\nAccessGrantsLocati Please clean up access grants 400\nonNotEmptyError before deleting access grants\nlocation\nAccessGrantsLocati The access grants location quota 409\nonsQuotaExceededEr has been exceeded. Access Grants\nror Locations Quota: <value>. Please\nreach out to S3 if an increase is\nrequired.\nAccessGrantsQuotaE The access grants quota has been 409\nxceededError exceeded. Access Grants Quota:\nList of Amazon S3 Access Grants Error Codes API Version 2006-03-01 2838",
      "start_idx": 3177475,
      "end_idx": 3178790,
      "metadata": {
        "num_sentences": 7,
        "num_words": 175,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2844",
      "text": "Amazon Simple Storage Service API Reference\nError Code Description HTTP Status\nCode\n<value>. Please reach out to S3 if\nan increase is required.\nInvalidTag There are duplicate tag keys in your 400\nrequest. Remove the duplicate tag\nkeys and try again.\nInvalidAccessGrant The specified Access Grant is invalid 400\nInvalidAccessGrant The specified Access Grants 400\nsLocation Location is invalid\nInvalidIamRole The specified IAM Role is invalid 400\nInvalidIdentityCen The specified identity center 400\nterInstance instance is invalid\nInvalidResourcePolicy The specified Resource Policy is 400\ninvalid\nInvalidResourcePolicy The specified Resource Policy is 400\ninvalid\nInvalidTag This request contains a tag key 400\nor value that isn't valid. Valid\ncharacters include the following: [a-\nzA-Z+-=._:/]. Tag keys can contain\nup to 128 characters. Tag values\ncan contain up to 256 characters.\nNoSuchAccessGrantE The specified access grant does not 404\nrror exist\nNoSuchAccessGrants The specified access grants location 404\nLocationError does not exist\nList of Amazon S3 Access Grants Error Codes API Version 2006-03-01 2839",
      "start_idx": 3178792,
      "end_idx": 3179906,
      "metadata": {
        "num_sentences": 9,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2845",
      "text": "Amazon Simple Storage Service API Reference\nError Code Description HTTP Status\nCode\nAccessDenied You do not have <requested 403 Client\npermission> permissions to the Forbidden\nrequested S3 Prefix: <requested\ntarget>\nStsNotAuthorizedError An error occurred (StsNotAut 403\nhorizedError ) when calling\nthe GetDataAccess operation:\nUser: access-grants.s3.a\nmazonaws.com is not authorized\nto perform: sts:AssumeRole on\nresource: <IAM Role ARN>\nStsPackedPolicyToo An error occurred (StsPacked 400\nLargeError PolicyTooLargeError ) when\ncalling the GetDataAccess operation\n: Serialized token too large for\nsession\nStsValidationError The error message varies depending 400\non the validation error.\nInvalidTags Tag keys cannot start with AWS 400\nreserved prefix for system tags.\"\nTooManyTags The number of tags exceeds the 400\nlimit of 50 tags. Remove some tags\nand try again.\nAmazon S3 error best practices\nMany error responses contain additional structured data meant to be read and understood by a\ndeveloper diagnosing programming errors. For example, if you send a Content-MD5 header with a\nREST PUT request that doesn't match the digest calculated on the server, you receive a BadDigest\nAmazon S3 error best practices API Version 2006-03-01 2840",
      "start_idx": 3179908,
      "end_idx": 3181148,
      "metadata": {
        "num_sentences": 6,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2846",
      "text": "Amazon Simple Storage Service API Reference\nerror. The error response also includes as detail elements the digest we calculated, and the digest\nyou told us to expect. During development, you can use this information to diagnose the error. In\nproduction, a well-behaved program might include this information in its error log.\nWhen designing an application for use with Amazon S3, it is important to handle Amazon S3 errors\nappropriately. This section describes issues to consider when designing your application.\nRetry InternalErrors\nInternal errors are errors that occur within the Amazon S3 environment.\nRequests that receive an InternalError response might not have processed. For example, if a PUT\nrequest returns InternalError, a subsequent GET might retrieve the old value or the updated value.\nIf Amazon S3 returns an InternalError response, retry the request.\nTune application for repeated SlowDown errors\nAs with any distributed system, S3 has protection mechanisms which detect intentional or\nunintentional resource over-consumption and react accordingly. SlowDown errors can occur when\na high request rate triggers one of these mechanisms. Reducing your request rate will decrease\nor eliminate errors of this type. Generally speaking, most users will not experience these errors\nregularly; however, if you would like more information or are experiencing high or unexpected\nSlowDown errors, please post to our Amazon S3 developer forum or sign up for AWS Support\nhttps://aws.amazon.com/premiumsupport/.\nIsolate errors\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nAmazon S3 provides a set of error codes that are used by both the SOAP and REST API. The SOAP\nAPI returns standard Amazon S3 error codes. The REST API is designed to look like a standard HTTP\nserver and interact with existing HTTP clients (e.g., browsers, HTTP client libraries, proxies, caches,\nRetry InternalErrors API Version 2006-03-01 2841",
      "start_idx": 3181150,
      "end_idx": 3183221,
      "metadata": {
        "num_sentences": 20,
        "num_words": 320,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2847",
      "text": "Amazon Simple Storage Service API Reference\nand so on). To ensure the HTTP clients handle errors properly, we map each Amazon S3 error to an\nHTTP status code.\nHTTP status codes are less expressive than Amazon S3 error codes and contain less information\nabout the error. For example, the NoSuchKey and NoSuchBucket Amazon S3 errors both map to\nthe HTTP 404 Not Found status code.\nAlthough the HTTP status codes contain less information about the error, clients that understand\nHTTP, but not the Amazon S3 API, will usually handle the error correctly.\nTherefore, when handling errors or reporting Amazon S3 errors to end users, use the Amazon S3\nerror code instead of the HTTP status code as it contains the most information about the error.\nAdditionally, when debugging your application, you should also consult the human readable\n<Details> element of the XML error response.\nIsolate errors API Version 2006-03-01 2842",
      "start_idx": 3183223,
      "end_idx": 3184140,
      "metadata": {
        "num_sentences": 8,
        "num_words": 150,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2849",
      "text": "Amazon Simple Storage Service API Reference\nAmazon S3 Resources\nFollowing is a table that lists related resources that you'll find useful as you work with this service.\nResource Description\nAmazon Simple Storage Service The getting started guide provides a quick tutorial of the\nUser Guide service based on a simple use case.\nAmazon Simple Storage Service The developer guide describes how to accomplish tasks\nUser Guide using Amazon S3 operations.\nAmazon S3 Technical FAQ The FAQ covers the top 20 questions developers have\nasked about this product.\nAmazon S3 Release Notes The Release Notes give a high-level overview of the\ncurrent release. They specifically note any new features,\ncorrections, and known issues.\nTools for Amazon Web Services A central starting point to find documentation, code\nsamples, release notes, and other information to help\nyou build innovative applications with AWS SDKs and\ntools.\nAWS Management Console The console allows you to perform most of the functions\nof Amazon S3 without programming.\nDiscussion Forums A community-based forum for developers to discuss\ntechnical questions related to Amazon Web Services.\nAWS Support Center The home page for AWS Technical Support, including\naccess to our Developer Forums, Technical FAQs, Service\nStatus page, and Premium Support.\nAWS Support The primary web page for information about AWS\nSupport, a one-on-one, fast-response support channel\nto help you build and run applications on AWS Infrastru\ncture Services.\nAPI Version 2006-03-01 2844",
      "start_idx": 3184312,
      "end_idx": 3185828,
      "metadata": {
        "num_sentences": 12,
        "num_words": 232,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2851",
      "text": "Amazon Simple Storage Service API Reference\nDocument History\nThe following table describes the important changes in each release of the Amazon Simple Storage\nService API Reference up to March 27, 2019. For changes after March 27, 2019, see the consolidated\nDocument History in the Amazon Simple Storage Service User Guide.\n\u2022 API version: 2006-03-01\n\u2022 Latest documentation update: March 27, 2019\nChange Description Release\nDate\nNew archive storage Amazon S3 now offers a new archive storage class, March 27,\nclass DEEP_ARCHIVE, for storing rarely accessed objects. Fo 2019\nr more information, see Storage Classes in the Amazon\nSimple Storage Service User Guide.\nSupport for Parquet-f Amazon S3 now supports the Apache Parquet (Parquet) December\normatted Amazon S3 format in addition to the Apache optimized row columnar 04, 2018\ninventory files (ORC) and comma-separated values (CSV) file formats\nfor inventory output files. For more information, see\nAmazon S3 Inventory in the Amazon Simple Storage\nService User Guide.\nThe following APIs were updated accordingly:\n\u2022\nGetBucketInventoryConfiguration\n\u2022\nPutBucketInventoryConfiguration\nPUT directly to the The Amazon S3 PUT and related operations now support November\nGLACIER storage class specifying GLACIER as the storage class when creating 26, 2018\nobjects. Previously, you had to transition to the GLACIER\nstorage class from another Amazon S3 storage class. For\nmore information about the GLACIER storage class, see\nAPI Version 2006-03-01 2846",
      "start_idx": 3186221,
      "end_idx": 3187715,
      "metadata": {
        "num_sentences": 9,
        "num_words": 223,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2852",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nStorage Classes in the Amazon Simple Storage Service\nUser Guide.\nThe following APIs were updated accordingly:\n\u2022\nPutObject\n\u2022\nPOST Object\n\u2022\nCopyObject\n\u2022\nCreateMultipartUpload\nObject Lock Amazon S3 now supports locking objects using a Write November\nOnce Read Many (WORM) model. You can lock objects 26, 2018\nfor a definite period of time using a retention period\nor indefinitely using a legal hold. For more information\nabout Amazon S3 Object Lock, see Locking Objects in\nthe Amazon Simple Storage Service User Guide.\nThe following APIs were updated for S3 Object Lock:\n\u2022\nPutObject\n\u2022\nGetObject\n\u2022\nHeadObject\n\u2022\nCreateBucket\n\u2022\nHeadBucket\nAPI Version 2006-03-01 2847",
      "start_idx": 3187717,
      "end_idx": 3188453,
      "metadata": {
        "num_sentences": 5,
        "num_words": 116,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2853",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nNew storage class Amazon S3 now offers a new storage class named November\nINTELLIGENT_TIERING that is for storing data that has 26, 2018\nchanging or unknown access patterns. For more informati\non, see Storage Classes in the Amazon Simple Storage\nService User Guide.\nThe following APIs were updated accordingly:\n\u2022\nPutObject\n\u2022\nPOST Object\n\u2022\nCopyObject\n\u2022\nCreateMultipartUpload\nBlock Public Access Amazon S3 now includes the ability to block public access November\nto buckets and objects on a per-bucket or account-wide 15, 2018\nbasis. For more information, see Using Amazon S3 Block\nPublic Access in the A mazon Simple Storage Service User\nGuide.\nAPI Version 2006-03-01 2848",
      "start_idx": 3188455,
      "end_idx": 3189202,
      "metadata": {
        "num_sentences": 5,
        "num_words": 117,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2854",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nFiltering enhanceme In a CRR rule configuration, you can specify an object September\nnts in cross-region filter to choose a subset of objects to apply the rule to. 19, 2018\nreplication (CRR) rules Previously, you could filter only on an object key prefix.\nIn this release, you can filter on an object key prefix,\none or more object tags, or both. For more information,\nsee R eplication Configuration Overview in the Amazon\nSimple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\nPutBucketReplication\n\u2022\nGetBucketReplication\n\u2022\nDeleteBucketReplication\nNew storage class Amazon S3 now offers a new storage class, ONEZONE_I April 4,\nA (IA, for infrequent access) for storing objects. For more 2018\ninformation, see Storage Classes in the Amazon Simple\nStorage Service User Guide.\nAmazon S3 Select Amazon S3 Select is now generally available. This feature April 4,\nretrieves object content based on an SQL expression. For 2018\nmore information, see Selecting Content from Objects in\nthe Amazon Simple Storage Service User Guide.\nThe following API has been updated:\n\u2022\nSelectObjectContent\nAPI Version 2006-03-01 2849",
      "start_idx": 3189204,
      "end_idx": 3190413,
      "metadata": {
        "num_sentences": 10,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2855",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nAsia Pacific (Osaka-Lo Amazon S3 is now available in the Asia Pacific (Osaka- February\ncal) Region Local) Region. For more information about Amazon S3 12, 2018\nRegions and endpoints, see Regions and Endpoints in the\nAWS General Reference.\nImportant\nYou can use the Asia Pacific (Osaka-Local) Region\nonly in conjunction with the Asia Pacific (Tokyo)\nRegion. To request access to Asia Pacific (Osaka-\nLocal) Region, contact your sales representative.\nEurope (Paris) Region Amazon S3 is now available in the Europe (Paris) Region. December\nFor more information about Amazon S3 regions and 18, 2017\nendpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nChina (Ningxia) Amazon S3 is now available in the China (Ningxia) December\nRegion Region. For more information about Amazon S3 regions 11, 2017\nand endpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nQuerying archives Amazon S3 now supports querying S3 Glacier data November\nwith SQL archives with SQL. For more information, see Querying 29, 2017\nArchived Objects in the Amazon Simple Storage Service\nUser Guide.\nThe following API changed:\n\u2022\nRestoreObject\nAPI Version 2006-03-01 2850",
      "start_idx": 3190415,
      "end_idx": 3191651,
      "metadata": {
        "num_sentences": 11,
        "num_words": 190,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2856",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nSELECT Object Amazon S3 now supports the SELECT Object Content November\nContent (Preview) functionality as part of a Preview program. This feature 29, 2017\nretrieves object content based on an SQL expression.\nThe following API has been added:\n\u2022\nSelectObjectContent\nSupport for ORC- Amazon S3 now supports the Apache optimized row November\nformatted Amazon S3 columnar (ORC) format in addition to comma-separated 17, 2017\ninventory files values (CSV) file format for inventory output files. For\nmore information, see Amazon S3 Inventory in the\nAmazon Simple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\nGetBucketInventoryConfiguration\n\u2022\nPutBucketInventoryConfiguration\nAPI Version 2006-03-01 2851",
      "start_idx": 3191653,
      "end_idx": 3192453,
      "metadata": {
        "num_sentences": 5,
        "num_words": 113,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2857",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nDefault encryption Amazon S3 default encryption provides a way to set the November\nfor S3 buckets default encryption behavior for an S3 bucket. You can 06, 2017\nset default encryption on a bucket so that all objects\nare encrypted when they are stored in the bucket. The\nobjects are encrypted using server-side encryption with\neither Amazon S3-managed keys (SSE-S3) or AWS KMS-\nmanaged keys (SSE-KMS). For more information, see\nAmazon S3 Default Encryption for S3 Buckets in the\nAmazon Simple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\nDeleteBucketEncryption\n\u2022\nGetBucketEncryption\n\u2022\nPutBucketEncryption\nEncryption status in Amazon S3 now supports including encryption status in November\nAmazon S3 inventory Amazon S3 inventory so you can see how your objects 06, 2017\nare encrypted at rest for compliance auditing or other\npurposes. You can also configure to encrypt Amazon\nS3 inventory with server-side encryption (SSE) or SSE-\nKMS so that all inventory files are encrypted accordingl\ny. For more information, see Amazon S3 Inventory in the\nAmazon Simple Storage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\nGetBucketInventoryConfiguration\n\u2022\nPutBucketInventoryConfiguration\nAPI Version 2006-03-01 2852",
      "start_idx": 3192455,
      "end_idx": 3193784,
      "metadata": {
        "num_sentences": 8,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2858",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nCross-region replicati Cross-region replication (CRR) now supports the November\non (CRR) enhanceme following: 06, 2017\nnts\n\u2022\nIn a cross-account scenario, you can add a CRR\nconfiguration to change replica ownership to the AWS\naccount that owns the destination bucket. For more\ninformation, see CRR: Change Replica Owner in the\nAmazon Simple Storage Service User Guide.\n\u2022\nBy default, Amazon S3 does not replicate objects in\nyour source bucket that are created using server-si\nde encryption using AWS KMS-managed keys. In your\nCRR configuration, you can now direct Amazon S3\nto replicate these objects. For more information, see\nCRR: Replicating Objects Created with SEE Using AWS\nKMS-Managed Encryption Keys in the Amazon Simple\nStorage Service User Guide.\nThe following APIs are updated accordingly:\n\u2022\nGetBucketReplication\n\u2022\nPutBucketReplication\nEurope (London) Amazon S3 is now available in the Europe (London) December\nRegion Region. For more information about Amazon S3 regions 13, 2016\nand endpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nCanada (Central) Amazon S3 is now available in the Canada (Central) December\nRegion Region. For more information about Amazon S3 regions 8, 2016\nand endpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nAPI Version 2006-03-01 2853",
      "start_idx": 3193786,
      "end_idx": 3195165,
      "metadata": {
        "num_sentences": 10,
        "num_words": 209,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2859",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nObject tagging Amazon S3 now supports object tagging. The following November\nsupport new API operations support object tagging: 29, 2016\n\u2022 PutObjectTagging\n\u2022 GetObjectTagging\n\u2022 DeleteObjectTagging\nIn addition, other API operations are updated to support\nobject tagging. For more information, see Object\nTagging in the Amazon Simple Storage Service User Guide.\nS3 lifecycle now Amazon S3 now supports tag-based filtering in lifecycle November\nsupports object tag configuration. You can now specify a lifecycle rule, in 29, 2016\nbased filter which you can specify a key prefix, one or more object\ntags, or a combination of both, to select a subset of\nobjects to which the lifecycle rule applies. For more\ninformation, see Object Lifecycle Managementin the\nAmazon Simple Storage Service User Guide.\nAmazon S3 now supports Expedited and Bulk data\nretrievals in addition to Standard retrievals when\nrestoring objects archived to S3 Glacier.\nAPI Version 2006-03-01 2854",
      "start_idx": 3195167,
      "end_idx": 3196206,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2860",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nCloudWatch request Amazon S3 now supports CloudWatch metrics for November\nmetrics for buckets requests made on buckets. The following new API 29, 2016\noperations support configuring request metrics:\n\u2022 DeleteBucketMetricsConfiguration\n\u2022 GetBucketMetricsConfiguration\n\u2022 PutBucketMetricsConfiguration\n\u2022 ListBucketMetricsConfigurations\nFor more information, see Monitoring Metrics with\nAmazon CloudWatch in the Amazon Simple Storage\nService User Guide.\nAmazon S3 Inventory Amazon S3 now supports storage inventory. Amazon S3 November\ninventory provides a flat-file output of your objects and 29, 2016\ntheir corresponding metadata on a daily or weekly basis\nfor an S3 bucket or a shared prefix (that is, objects that\nhave names that begin with a common string).\nThe following new API operations are for storage\ninventory:\n\u2022 DeleteBucketInventoryConfiguration\n\u2022 GetBucketInventoryConfiguration\n\u2022 PutBucketInventoryConfiguration\n\u2022 ListBucketInventoryConfigurations\nFor more information, see Amazon S3 Storage Inventory\nin the Amazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 2855",
      "start_idx": 3196208,
      "end_idx": 3197372,
      "metadata": {
        "num_sentences": 6,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2861",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nAmazon S3 Analytics The new Amazon S3 analytics \u2013 storage class analysis November\n\u2013 Storage Class feature observes data access patterns to help you 29, 2016\nAnalysis determine when to transition less frequently accessed\nSTANDARD storage to the STANDARD_IA (IA, for\ninfrequent access) storage class. After storage class\nanalysis observes the infrequent access patterns of a\nfiltered set of data over a period of time, you can use\nthe analysis results to help you improve your lifecycle\nconfigurations. This feature also includes a detailed dai\nly analysis of your storage usage at the specified bucket,\nprefix, or tag level that you can export to a S3 bucket.\nThe following new API operations are for storage class\nanalysis:\n\u2022\nDeleteBucketAnalyticsConfiguration\n\u2022\nGetBucketAnalyticsConfiguration\n\u2022\nPutBucketAnalyticsConfiguration\n\u2022\nListBucketAnalyticsConfigurations\nFor more information, see Amazon S3 Analytics \u2013\nStorage Class Analysis in the A mazon Simple Storage\nService User Guide.\nAdded S3 Glacier Amazon S3 now supports Expedited and Bulk data November\nretrieval options to retrievals in addition to Standard retrievals when 21, 2016\nRestoreObject restoring objects archived to S3 Glacier. For more\ninformation, see R estoring Archived Objects in the\nAmazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 2856",
      "start_idx": 3197374,
      "end_idx": 3198776,
      "metadata": {
        "num_sentences": 7,
        "num_words": 206,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2862",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nUS East (Ohio) Region Amazon S3 is now available in the US East (Ohio) Region. October\nFor more information about Amazon S3 regions and 17, 2016\nendpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nAsia Pacific (Mumbai) Amazon S3 is now available in the Asia Pacific (Mumbai) June 27,\nregion region. For more information about Amazon S3 regions 2016\nand endpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nGET Bucket (List The GET Bucket (List Objects) API has been revised. We May 4,\nObjects) API revised recommend that you use the new version, GET Bucket 2016\n(List Objects) version 2. For more information, see\nListObjectsV2.\nAmazon S3 Transfer Amazon S3 Transfer Acceleration enables fast, easy, and April 19,\nAcceleration secure transfers of files over long distances between 2016\nyour client and an S3 bucket. Transfer Acceleration takes\nadvantage of Amazon CloudFront\u2019s globally distributed\nedge locations.\nFor more information, see Transfer Acceleration in the\nAmazon Simple Storage Service User Guide.\nThe following new API operations support Transfer\nAcceleration: GetBucketAccelerateConfiguration and\nPutBucketAccelerateConfiguration.\nLifecycle support to Lifecycle configuration expiration action now allows you March 16,\nremove expired object to direct Amazon S3 to remove expired object delete 2016\ndelete marker markers in versioned bucket. For more information, see\nElements to Describe Lifecycle Actions in the Amazon\nSimple Storage Service User Guide.\nAPI Version 2006-03-01 2857",
      "start_idx": 3198778,
      "end_idx": 3200380,
      "metadata": {
        "num_sentences": 14,
        "num_words": 236,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2863",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nBucket lifecycle Bucket lifecycle configuration now supports the March 16,\nconfiguration now AbortIncompleteMultipartUpload action that 2016\nsupports the action you can use to direct Amazon S3 to cancel multipart\nto cancel incomplete uploads that don't complete within a specified number\nmultipart uploads of days after being initiated. When a multipart upload\nbecomes eligible for an abort operation, Amazon S3\ndeletes any uploaded parts and cancels the multipart\nupload.\nThe following API operations have been updated to\nsupport the new action:\n\u2022\nPutBucketLifecycleConfiguration \u2013 The XML conf\niguration now allows you to specify the AbortInco\nmpleteMultipartUpload action in a lifecycle\nconfiguration rule.\n\u2022\nListParts and CreateMultipartUpload \u2013 Both of these\nAPI operations now return two additional response\nheaders (x-amz-abort-date , and x -amz-abo\nrt-rule-id ) if the bucket has a lifecycle rule that\nspecifies the A bortIncompleteMultipartUpl\noad action. These headers in the response indicate\nwhen the initiated multipart upload will become\neligible for an abort operation and which lifecycle rule\nis applicable.\nFor conceptual information, see the following topics in\nthe Amazon Simple Storage Service User Guide:\n\u2022\nAPI Version 2006-03-01 2858",
      "start_idx": 3200382,
      "end_idx": 3201713,
      "metadata": {
        "num_sentences": 6,
        "num_words": 192,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2864",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nAborting Incomplete Multipart Uploads Using a Bucket\nLifecycle configuration\n\u2022\nElements to Describe Lifecycle Actions\nAmazon S3 Signature Amazon S3 Signature Version 4 now supports unsigned January\nVersion 4 now payloads when authenticating requests using the 15, 2016\nsupports unsigned Authorization header. Because you don't sign the\npayloads payload, it does not provide the same security that comes\nwith payload signing, but it provides similar performance\ncharacteristics as signature version 2. For more informati\non, see Signature Calculations for the Authorization\nHeader: Transferring Payload in a Single Chunk (AWS\nSignature Version 4).\nAsia Pacific (Seoul) Amazon S3 is now available in the Asia Pacific (Seoul) January 6,\nregion region. For more information about Amazon S3 regions 2016\nand endpoints, see Regions and Endpoints in the AWS\nGeneral Reference.\nRenamed the US Changed the region name string from US Standard to US December\nStandard region East (N. Virginia). This is only a region name update, there 11, 2015\nis no change in the functionality.\nAPI Version 2006-03-01 2859",
      "start_idx": 3201715,
      "end_idx": 3202887,
      "metadata": {
        "num_sentences": 8,
        "num_words": 177,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2865",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nNew storage class Amazon S3 now offers a new storage class, STANDARD_ September\nIA (IA, for infrequent access) for storing objects. This 16, 2015\nstorage class is optimized for long-lived and less freque\nntly accessed data. For more information, see Storage\nClasses in the Amazon Simple Storage Service User Guide.\nLifecycle configuration feature updates now allow you to\ntransition objects to the STANDARD_IA storage class. For\nmore information, see Object Lifecycle Management in\nthe Amazon Simple Storage Service User Guide.\nPreviously, the cross-region replication feature used the\nstorage class of the source object for object replicas.\nNow, when you configure cross-region replication you can\nspecify a storage class for the object replica created in\nthe destination bucket. For more information, see Cross-\nRegion Replication in the Amazon Simple Storage Service\nUser Guide.\nEvent notifications Amazon S3 event notifications have been updated to July 28,\nadd notifications when objects are deleted and to add 2015\nfiltering on object names with prefix and suffix matching.\nFor the relevant API operations, see PutBucketNotificat\nionConfiguration, and G etBucketNotificationConfig\nuration. For more information, see Configuring Amazon\nS3 Event Notifications in the Amazon Simple Storage\nService User Guide.\nAPI Version 2006-03-01 2860",
      "start_idx": 3202889,
      "end_idx": 3204305,
      "metadata": {
        "num_sentences": 12,
        "num_words": 206,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2866",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nCross-region replicati Amazon S3 now supports cross-region replication. Cross- March 24,\non region replication is the automatic, asynchronous copying 2015\nof objects across buckets in different AWS Regions. Fo\nr the relevant API operations, see PutBucketReplication,\nGetBucketReplication and DeleteBucketReplication. For\nmore information, see Enabling Cross-Region Replication\nin the Amazon Simple Storage Service User Guide.\nEvent notifications Amazon S3 now supports new event types and destinati November\nons in a bucket notification configuration. Prior to this 13, 2014\nrelease, Amazon S3 supported only the s3:Reduce\ndRedundancyLostObject event type and an\nAmazon SNS topic as the destination. For more inform\nation about the new event types, go to Setting Up\nNotification of Bucket Events in the Amazon Simple\nStorage Service User Guide. For the relevant API operation\ns, see PutBucketNotificationConfiguration and GetBucket\nNotificationConfiguration.\nAPI Version 2006-03-01 2861",
      "start_idx": 3204307,
      "end_idx": 3205369,
      "metadata": {
        "num_sentences": 9,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2867",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nServer-side encryptio Amazon S3 now supports server-side encryption using November\nn with AWS Key AWS Key Management Service (KMS). With server-side 12, 2014\nManagement Service encryption with KMS, you manage the envelope key\n(KMS) through KMS, and Amazon S3 calls KMS to access the\nenvelope key within the permissions you set.\nFor more information about server-side encryption with\nKMS, see Protecting Data Using Server-Side Encryption\nwith AWS Key Management Service in the Amazon Simple\nStorage Service User Guide.\nThe following Amazon S3 REST API operations support\nheaders related to KMS.\n\u2022 PutObject\n\u2022 CopyObject\n\u2022 POST Object\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\nEurope (Frankfurt) Amazon S3 is now available in the Europe (Frankfurt) October\nRegion Region region. 23, 2014\nAPI Version 2006-03-01 2862",
      "start_idx": 3205371,
      "end_idx": 3206255,
      "metadata": {
        "num_sentences": 6,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2868",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nServer-side encryptio Amazon S3 now supports server-side encryption using June 12,\nn with customer- customer-provided encryption keys (SSE-C). Server- 2014\nprovided encryption side encryption enables you to request Amazon S3 to\nkeys encrypt your data at rest. When using SSE-C, Amazon\nS3 encrypts your objects with the custom encryptio\nn keys that you provide. Since Amazon S3 performs\nthe encryption for you, you get the benefits of using\nyour own encryption keys without the cost of writing or\nexecuting your own encryption code.\nFor more information about SSE-C, go to Server-Side\nEncryption (Using Customer-Provided Encryption Keys) in\nthe Amazon Simple Storage Service User Guide.\nThe following Amazon S3 REST API operations support\nheaders related to SSE-C.\n\u2022 GetObject\n\u2022 HeadObject\n\u2022 PutObject\n\u2022 CopyObject\n\u2022 POST Object\n\u2022 CreateMultipartUpload\n\u2022 UploadPart\n\u2022 UploadPartCopy\nAPI Version 2006-03-01 2863",
      "start_idx": 3206257,
      "end_idx": 3207242,
      "metadata": {
        "num_sentences": 6,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2869",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nLifecycle support for Prior to this release lifecycle configuration was supported May 20,\nversioning only on nonversioned buckets. Now you can configure 2014\nlifecycle on both the nonversioned and versioning-enabl\ned buckets.\nFor more information, go to Object Lifecycle Managemen\nt in the Amazon Simple Storage Service User Guide.\nThe related API operations, see PutBucketLifecycle\nConfiguration, GetBucketLifecycleConfiguration, and\nDeleteBucketLifecycle.\nAmazon S3 now Amazon S3 now supports Signature Version 4 (SigV4) in January\nsupports Signature all regions, the latest specification for how to sign and 30, 2014\nVersion 4 authenticate AWS requests.\nFor more information, see Authenticating Requests (AWS\nSignature Version 4).\nAmazon S3 list The following Amazon S3 list actions now support November\nactions now support encoding-type optional request parameter. 1, 2013\nencoding-type\nListObjects\nrequest parameter\nListObjectVersions\nListMultipartUploads\nListParts\nAn object key can contain any Unicode character;\nhowever, the XML 1.0 parser cannot parse some charac\nters, such as characters with an ASCII value from 0 to\n10. For characters that are not supported in XML 1.0,\nyou can add this parameter to request that Amazon S3\nencode the keys in the response.\nAPI Version 2006-03-01 2864",
      "start_idx": 3207244,
      "end_idx": 3208615,
      "metadata": {
        "num_sentences": 10,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2870",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nSOAP Support Over SOAP support over HTTP is deprecated, but it is still September\nHTTP Deprecated available over HTTPS. New Amazon S3 features will not 19, 2013\nbe supported for SOAP. We recommend that you use ei\nther the REST API or the AWS SDKs.\nRoot domain support Amazon S3 now supports hosting static websites at the December\nfor website hosting root domain. Visitors to your website can access your site 27, 2012\nfrom their browser without specifying \"www\" in the web\naddress (e.g., \"example.com\"). Many customers already\nhost static websites on Amazon S3 that are accessible\nfrom a \"www\" subdomain (e.g., \"www.example.com\").\nPreviously, to support root domain access, you needed to\nrun your own web server to proxy root domain requests\nfrom browsers to your website on Amazon S3. Running\na web server to proxy requests introduces additional\ncosts, operational burden, and another potential point of\nfailure. Now, you can take advantage of the high availabil\nity and durability of Amazon S3 for both \"www\" and root\ndomain addresses.\nFor an example walkthrough, go to Example: Setting\nUp a Static Website Using a Custom Domain in the\nAmazon Simple Storage Service User Guide. For conceptua\nl information, go to Hosting Static Websites on Amazon\nS3 in the Amazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 2865",
      "start_idx": 3208617,
      "end_idx": 3210022,
      "metadata": {
        "num_sentences": 12,
        "num_words": 228,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2871",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nSupport for Archiving Amazon S3 now supports a storage option that enables November\nData to Amazon you to utilize Amazon Glacier's low-cost storage service 13, 2012\nGlacier for data archival. To archive objects, you define archival\nrules identifying objects and a timeline when you want\nAmazon S3 to archive these objects to S3 Glacier. You\ncan easily set the rules on a bucket using the Amazon S3\nconsole or programmatically using the Amazon S3 API or\nAWS SDKs.\nTo support data archival rules, Amazon S3 lifecycle\nmanagement API has been updated. For more informati\non, see PutBucketLifecycleConfiguration.\nAfter you archive objects, you must first restore a copy\nbefore you can access the data. Amazon S3 offers a new\nAPI for you to initiate a restore. For more information,\nsee RestoreObject.\nFor conceptual information, go to Object Lifecycle\nManagement in the Amazon Simple Storage Service User\nGuide.\nAPI Version 2006-03-01 2866",
      "start_idx": 3210024,
      "end_idx": 3211034,
      "metadata": {
        "num_sentences": 10,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2872",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nSupport for Website For a bucket that is configured as a website, Amazon October\nPage Redirects S3 now supports redirecting a request for an object to 4, 2012\nanother object in the same bucket or to an external URL.\nYou can configure redirect by adding the x-amz-web\nsite-redirect-location metadata to the object.\nThe object upload API operations PutObject, CreateMul\ntipartUpload, and POST Object allow you to configure\nthe x-amz-website-redirect-location object\nmetadata.\nFor conceptual information, go to How to Configure\nWebsite Page Redirects in the Amazon Simple Storage\nService User Guide.\nCross-Origin Resource Amazon S3 now supports Cross-Origin Resource Sharing August\nSharing (CORS) (CORS). CORS defines a way in which client web applicati 31, 2012\nsupport ons that are loaded in one domain can interact with\nor access resources in a different domain. With CORS\nsupport in Amazon S3, you can build rich client-side web\napplications on top of Amazon S3 and selectively allow\ncross-domain access to your Amazon S3 resources. For\nmore information, see Enabling Cross-Origin Resource\nSharing in the Amazon Simple Storage Service User Guide.\nCost Allocation Amazon S3 now supports cost allocation tagging, which August\nTagging support allows you to label S3 buckets so you can more easily 21, 2012\ntrack their cost against projects or other criteria. For\nmore information, see Cost Allocation Tagging in the\nAmazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 2867",
      "start_idx": 3211036,
      "end_idx": 3212595,
      "metadata": {
        "num_sentences": 11,
        "num_words": 239,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2873",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nObject Expiration You can use Object Expiration to schedule automatic December\nsupport removal of data after a configured time period. You set 27, 2011\nobject expiration by adding lifecycle configuration to a\nbucket. For more information, see Transitioning Objects:\nGeneral Considerations in the Amazon Simple Storage\nService User Guide.\nNew Region Amazon S3 now supports the South America (S\u00e3o Paulo) December\nsupported region. For more information, see Buckets and Regions in 14, 2011\nthe Amazon Simple Storage Service User Guide.\nMulti-Object Delete Amazon S3 now supports Multi-Object Delete API December\nthat enables you to delete multiple objects in a single 7, 2011\nrequest. With this feature, you can remove large numbers\nof objects from Amazon S3 more quickly than using\nmultiple individual DELETE requests.\nFor more information about the API see, see DeleteObj\nects.\nFor conceptual information about the delete operation\n, see Deleting Objects in the Amazon Simple Storage\nService User Guide.\nNew region Amazon S3 now supports the US West (Oregon) region. November\nsupported For more information, see Buckets and Regions in the 8, 2011\nAmazon Simple Storage Service User Guide.\nAPI Version 2006-03-01 2868",
      "start_idx": 3212597,
      "end_idx": 3213888,
      "metadata": {
        "num_sentences": 12,
        "num_words": 197,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2874",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nServer-side encryptio Amazon S3 now supports server-side encryption. It October\nn support enables you to request Amazon S3 to encrypt your data 17, 2011\nat rest, that is, encrypt your object data when Amazon\nS3 writes your data to disks in its data centers. To request\nserver-side encryption, you must add the x-amz-ser\nver-side-encryption header to your request.\nTo learn more about data encryption, go to U sing Data\nEncryption in the Amazon Simple Storage Service User\nGuide.\nMultipart Upload API Prior to this release, Amazon S3 API supported copying June 21,\nextended to enable objects (see CopyObject) of up to 5 GB in size. To 2011\ncopying objects up to enable copying objects larger than 5 GB, Amazon S3\n5 TB extends the multipart upload API with a new operation\n, Upload Part (Copy) . You can use this multipart\nupload operation to copy objects up to 5 TB in size. For\nconceptual information about multipart upload, go to\nUploading Objects Using Multipart Upload in the Amazon\nSimple Storage Service User Guide. To learn more about\nthe new API, see UploadPartCopy.\nSOAP API calls over To increase security, SOAP API calls over HTTP are June 6,\nHTTP disabled disabled. Authenticated and anonymous SOAP requests 2011\nmust be sent to Amazon S3 using SSL.\nAPI Version 2006-03-01 2869",
      "start_idx": 3213890,
      "end_idx": 3215254,
      "metadata": {
        "num_sentences": 12,
        "num_words": 228,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2875",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nSupport for hosting Amazon S3 introduces enhanced support for hosting February\nstatic websites in static websites. This includes support for index 17, 2011\nAmazon S3 documents and custom error documents. When using\nthese features, requests to the root of your bucket or a\nsubfolder (e.g., h ttp://mywebsite.com/subfol\nder ) returns your index document instead of the list\nof objects in your bucket. If an error is encountered,\nAmazon S3 returns your custom error message instead\nof an Amazon S3 error message. For API information to\nconfigure your bucket as a website, see the following\nsections:\n\u2022 PutBucketWebsite\n\u2022 GetBucketWebsite\n\u2022 DeleteBucketWebsite\nFor conceptual overview, go to Hosting Websites on\nAmazon S3 in the Amazon Simple Storage Service User\nGuide.\nResponse Header API The GET Object REST API now allows you to change the January\nSupport response headers of the REST GET Object request for 14, 2011\neach request. That is, you can alter object metadata in\nthe response, without altering the object itself. For more\ninformation, see GetObject.\nAPI Version 2006-03-01 2870",
      "start_idx": 3215256,
      "end_idx": 3216419,
      "metadata": {
        "num_sentences": 9,
        "num_words": 182,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2876",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nLarge Object Support Amazon S3 has increased the maximum size of an object December\nyou can store in an S3 bucket from 5 GB to 5 TB. If 9, 2010\nyou are using the REST API you can upload objects of\nup to 5 GB size in a single PUT operation. For larger\nobjects, you must use the Multipart Upload REST API to\nupload objects in parts. For conceptual information, go to\nUploading Objects Using Multipart Upload in the Amazon\nSimple Storage Service User Guide. For multipart upload\nAPI information, see CreateMultipartUpload, UploadPar\nt, C ompleteMultipartUpload, L istParts, and ListMulti\npartUploads\nMultipart upload Multipart upload enables faster, more flexible uploads November\ninto Amazon S3. It allows you to upload a single object 10, 2010\nas a set of parts. For conceptual information, go to\nUploading Objects Using Multipart Upload in the Amazon\nSimple Storage Service User Guide. For multipart upload\nAPI information, see CreateMultipartUpload, UploadPar\nt, C ompleteMultipartUpload, L istParts, and ListMulti\npartUploads\nNotifications The Amazon S3 notifications feature enables you to July 14,\nconfigure a bucket so that Amazon S3 publishes a 2010\nmessage to an Amazon Simple Notification Service (SNS\n) topic when Amazon S3 detects a key event on a bucket.\nFor more information, see GET Bucket notification and\nPUT Bucket notification.\nBucket policies Bucket policies is an access management system you use July 6,\nto set access permissions on buckets, objects, and sets 2010\nof objects. This functionality supplements and in many\ncases replaces access control lists.\nAPI Version 2006-03-01 2871",
      "start_idx": 3216421,
      "end_idx": 3218101,
      "metadata": {
        "num_sentences": 12,
        "num_words": 265,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2877",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nReduced Redundancy Amazon S3 now enables you to reduce your storage costs May 12,\nby storing objects in Amazon S3 with reduced redundanc 2010\ny. For more information, see PUT Object.\nNew region Amazon S3 now supports the Asia Pacific (Singapore) April 28,\nsupported region and therefore new location constraints. For more 2010\ninformation, see GET Bucket location and PUT Bucket.\nObject Versioning This release introduces object Versioning. All objects now February\nhave a key and a version. If you enable versioning for a 8, 2010\nbucket, Amazon S3 gives all objects added to a bucket\na unique version ID. This feature enables you to recover\nfrom unintended overwrites and deletions. For more\ninformation, see G ET Object, DELETE Object, PUT Object,\nPUT Object Copy, or POST Object. The SOAP API does\nnot support versioned objects.\nNew region Amazon S3 now supports the US-West (Northern December\nsupported California) region. The new endpoint is s3-us-wes 2, 2009\nt-1.amazonaws.com . For more information, see\nHow to Select a Region for Your Buckets in the Amazon\nSimple Storage Service User Guide.\nC# Library Support AWS now provides Amazon S3 C# libraries, sample code, November\ntutorials, and other resources for software developers 11, 2009\nwho prefer to build applications using language-specific\nAPI operations instead of REST or SOAP. These libraries pr\novide basic functions (not included in the REST or SOAP\nAPIs), such as request authentication, request retries, and\nerror handling so that it's easier to get started.\nAPI Version 2006-03-01 2872",
      "start_idx": 3218103,
      "end_idx": 3219735,
      "metadata": {
        "num_sentences": 16,
        "num_words": 258,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2878",
      "text": "Amazon Simple Storage Service API Reference\nChange Description Release\nDate\nTechnical documents The API reference has been split out of the Amazon S3 September\nreorganized Developer Guide. Now, on the documentation landing pa 16, 2009\nge, Amazon Simple Storage Service Documentation, you\ncan select the document you want to view. When viewing\nthe documents online, the links in one document will take\nyou, when appropriate, to one of the other guides.\nAPI Version 2006-03-01 2873",
      "start_idx": 3219737,
      "end_idx": 3220216,
      "metadata": {
        "num_sentences": 4,
        "num_words": 75,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2880",
      "text": "Amazon Simple Storage Service API Reference\nAppendix: SelectObjectContent Response\nDescription\nThe Amazon S3 Select operation filters the contents of an Amazon S3 object based on a simple\nstructured query language (SQL) statement. Given the response size of this operation is unknown,\nAmazon S3 Select streams the response as a series of messages and includes a Transfer-\nEncoding header with chunked as its value in the response.\nFor more information about Amazon S3 Select, see Selecting Content from Objects in the Amazon\nSimple Storage Service User Guide.\nFor more information about using SQL with Amazon S3 Select, see SQL Reference for Amazon S3\nSelect and S3 Glacier Select in the Amazon Simple Storage Service User Guide.\nResponses\nA successful Amazon S3 Select Operation returns 200 OK status code.\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most\nresponses. For more information, see Common Response Headers.\nResponse Body\nSince the Amazon S3 Select response size is unknown, Amazon S3 streams the response as a\nseries of messages and includes a Transfer-Encoding header with chunked as its value in the\nresponse. The following example shows the response format at the top level:\n<Message 1>\n<Message 2>\n<Message 3>\n......\n<Message n>\nEach message consists of two sections: the prelude and the data. The prelude section consists of 1)\nthe total byte-length of the message, and 2) the combined byte-length of all the headers. The data\nsection consists of 1) the headers, and 2) a payload.\nAppendix: SelectObjectContent Response API Version 2006-03-01 2875",
      "start_idx": 3220512,
      "end_idx": 3222132,
      "metadata": {
        "num_sentences": 12,
        "num_words": 256,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2881",
      "text": "Amazon Simple Storage Service API Reference\nEach section ends with a 4-byte big-endian integer checksum (CRC). Amazon S3 Select uses CRC32\n(often referred to as GZIP CRC32) to calculate both CRCs. For more information about CRC32, see\nGZIP file format specification version 4.3.\nTotal message overhead including the prelude and both checksums is 16 bytes.\nNote\nAll integer values within messages are in network byte order, or big-endian order.\nThe following diagram shows the components that make up a message and a header. Note that\nthere are multiple headers per message.\nNote\nFor Amazon S3 Select, the header value type is always 7 (type=String). For this type, the\nheader value consists of two components, a 2-byte big-endian integer length, and a UTF-8\nstring that is of that byte-length. The following diagram shows the components that make\nup Amazon S3 Select headers.\nResponses API Version 2006-03-01 2876",
      "start_idx": 3222134,
      "end_idx": 3223047,
      "metadata": {
        "num_sentences": 11,
        "num_words": 146,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2882",
      "text": "Amazon Simple Storage Service API Reference\nPayload byte-length calculations (these two calculations are equivalent):\n\u2022 payload_length = total_length - header_length - sizeOf(total_length) - sizeOf(header_length) -\nsizeOf(prelude_crc) - sizeOf(message_crc)\n\u2022 payload_length = total_length - header_length - 16\nEach message contains the following components:\n\u2022 Prelude: Always fixed size of 8 bytes (two fields of 4 bytes each):\n\u2022 First four bytes: Total byte-length: Big-endian integer byte-length of the entire message\n(including the 4-byte total length field itself).\n\u2022 Second four bytes: Headers byte-length: Big-endian integer byte-length of the headers portion\nof the message (excluding the headers length field itself).\n\u2022 Prelude CRC: 4-byte big-endian integer checksum (CRC) for the prelude portion of the message\n(excluding the CRC itself). The prelude has a separate CRC from the message CRC (see below),\nto ensure that corrupted byte-length information can be detected immediately, without causing\npathological buffering behavior.\n\u2022 Headers: A set of metadata annotating the message, such as the message type, payload format,\nand so on. Messages can have multiple headers, so this portion of the message can have\ndifferent byte-lengths depending on the message type. Headers are key-value pairs, where both\nthe key and value are UTF-8 strings. Headers can appear in any order within the headers portion\nof the message, and any given header type can only appear once.\nFor Amazon S3 Select, following is a list of header names and the set of valid values depending\non the message type.\n\u2022 MessageType Header:\nResponses API Version 2006-03-01 2877",
      "start_idx": 3223049,
      "end_idx": 3224702,
      "metadata": {
        "num_sentences": 10,
        "num_words": 248,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2883",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 HeaderName => \":message-type\"\n\u2022 Valid HeaderValues => \"error\", \"event\"\n\u2022 EventType Header:\n\u2022 HeaderName => \":event-type\"\n\u2022 Valid HeaderValues => \"Records\", \"Cont\", \"Progress\", \"Stats\", \"End\"\n\u2022 ErrorCode Header:\n\u2022 HeaderName => \":error-code\"\n\u2022 Valid HeaderValues => Error Code from the table in the List of SELECT Object Content Error\nCodes section.\n\u2022 ErrorMessage Header:\n\u2022 HeaderName => \":error-message\"\n\u2022 Valid HeaderValues => Error message returned by the service, to help diagnose request-level\nerrors.\n\u2022 Payload: Can be anything.\n\u2022 Message CRC: 4-byte big-endian integer checksum (CRC) from the start of the message to the\nstart of the checksum (that is, everything in the message excluding the message CRC itself).\nEach header contains the following components. There can be multiple headers per message.\n\u2022 Header Name Byte-Length: Byte-length of the header name.\n\u2022 Header Name: Name of the header, indicating the header type. Valid values: \":message-type\"\n\":event-type\" \":error-code\" \":error-message\"\n\u2022 Header Value Type: Enum indicating the header value type. For Amazon S3 Select, this is always\n7.\n\u2022 Value String Byte-Length: (For Amazon S3 Select) Byte-length of the header value string.\n\u2022 Header Value String: (For Amazon S3 Select) Value of the header string. Valid values for this\nfield vary based on the type of the header. See the sections below for valid values for each\nheader type and message type.\nFor Amazon S3 Select, responses can be messages of the following types:\n\u2022 Records message: Can contain a single record, partial records, or multiple records. Depending on\nthe size of the result, a response can contain one or more of these messages.\nResponses API Version 2006-03-01 2878",
      "start_idx": 3224704,
      "end_idx": 3226454,
      "metadata": {
        "num_sentences": 17,
        "num_words": 274,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2884",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 Continuation message: Amazon S3 periodically sends this message to keep the TCP connection\nopen. These messages appear in responses at random. The client must detect the message type\nand process accordingly.\n\u2022 Progress message: Amazon S3 periodically sends this message, if requested. It contains\ninformation about the progress of a query that has started but has not yet completed.\n\u2022 Stats message: Amazon S3 sends this message at the end of the request. It contains statistics\nabout the query.\n\u2022 End message: Indicates that the request is complete, and no more messages will be sent. You\nshould not assume that the request is complete until the client receives an End message.\n\u2022 RequestLevelError message: Amazon S3 sends this message if the request failed for any\nreason. It contains the error code and error message for the failure. If Amazon S3 sends a\nRequestLevelError message, it doesn't send an End message.\nThe following sections explain the structure of each message type in more detail.\nFor sample code and unit tests that use this protocol, see AWS C Event Stream on the GitHub\nwebsite.\nRecords Message\nHeader specification\nRecords messages contain three headers, as follows:\nResponses API Version 2006-03-01 2879",
      "start_idx": 3226456,
      "end_idx": 3227728,
      "metadata": {
        "num_sentences": 15,
        "num_words": 205,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2892",
      "text": "Amazon Simple Storage Service API Reference\nAppendix: OPTIONS object\nDescription\nA browser can send this preflight request to Amazon S3 to determine if it can send an actual\nrequest with the specific origin, HTTP method, and headers.\nAmazon S3 supports cross-origin resource sharing (CORS) by enabling you to add a cors\nsubresource on a bucket. When a browser sends this preflight request, Amazon S3 responds by\nevaluating the rules that are defined in the cors configuration.\nIf cors is not enabled on the bucket, then Amazon S3 returns a 403 Forbidden response.\nFor more information about CORS, go to Enabling Cross-Origin Resource Sharing in the Amazon\nSimple Storage Service User Guide.\nRequests\nSyntax\nOPTIONS /ObjectName HTTP/1.1\nHost: BucketName.s3.amazonaws.com\nOrigin: Origin\nAccess-Control-Request-Method: HTTPMethod\nAccess-Control-Request-Headers: RequestHeader\nRequest Parameters\nThis operation does not introduce any specific request parameters, but it may contain any request\nparameters that are required by the actual request.\nRequest Headers\nName Description Required\nOrigin Yes\nIdentifies the origin of the cross-origin request to Amazon\nS3. For example, http://www.example.com.\nType: String\nAppendix: OPTIONS object API Version 2006-03-01 2887",
      "start_idx": 3230778,
      "end_idx": 3232039,
      "metadata": {
        "num_sentences": 9,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2893",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nDefault: None\nAccess-Co Yes\nIdentifies what HTTP method will be used in the actual\nntrol-Req\nrequest.\nuest-Method\nType: String\nDefault: None\nAccess-Co No\nA comma-delimited list of HTTP headers that will be sent\nntrol-Req\nin the actual request.\nuest-Headers\nFor example, to put an object with server-side encryption,\nthis preflight request will determine if it can include the\nx-amz-server-side-encryption header with the\nrequest.\nType: String\nDefault: None\nRequest Elements\nThis implementation of the operation does not use request elements.\nResponses\nResponse Headers\nHeader Description\nAccess-Control-All\nThe origin you sent in your request. If the origin in your request\now-Origin\nis not allowed, Amazon S3 will not include this header in the\nresponse.\nResponses API Version 2006-03-01 2888",
      "start_idx": 3232041,
      "end_idx": 3232904,
      "metadata": {
        "num_sentences": 7,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2894",
      "text": "Amazon Simple Storage Service API Reference\nHeader Description\nType: String\nAccess-Control-Max-\nHow long, in seconds, the results of the preflight request can be\nAge\ncached.\nType: String\nAccess-Control-All\nThe HTTP method that was sent in the original request. If the\now-Methods\nmethod in the request is not allowed, Amazon S3 will not\ninclude this header in the response.\nType: String\nAccess-Control-All\nA comma-delimited list of HTTP headers that the browser can\now-Headers\nsend in the actual request. If any of the requested headers is\nnot allowed, Amazon S3 will not include that header in the\nresponse, nor will the response contain any of the headers with\nthe Access-Control prefix.\nType: String\nAccess-Control-Exp\nA comma-delimited list of HTTP headers. This header provides\nose-Headers\nthe JavaScript client with access to these headers in the\nresponse to the actual request.\nType: String\nResponse Elements\nThis implementation of the operation does not return response elements.\nResponses API Version 2006-03-01 2889",
      "start_idx": 3232906,
      "end_idx": 3233930,
      "metadata": {
        "num_sentences": 9,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2896",
      "text": "Amazon Simple Storage Service API Reference\nAppendix: SOAP API\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThis section describes the SOAP API with respect to service, bucket, and object operations. Note\nthat SOAP requests, both authenticated and anonymous, must be sent to Amazon S3 using SSL.\nAmazon S3 returns an error when you send a SOAP request over HTTP.\nThe latest Amazon S3 WSDL is available at docs.aws.amazon.com/2006-03-01/AmazonS3.wsdl.\nTopics\n\u2022 Operations on the Service (SOAP API)\n\u2022 Operations on Buckets (SOAP API)\n\u2022 Operations on Objects (SOAP API)\n\u2022 Authenticating SOAP requests\n\u2022 Setting access policy with SOAP\n\u2022 Common elements\n\u2022 SOAP Error Responses\nOperations on the Service (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThis section describes operations you can perform on the Amazon S3 service.\nTopics\nAppendix: SOAP API API Version 2006-03-01 2891",
      "start_idx": 3234886,
      "end_idx": 3236078,
      "metadata": {
        "num_sentences": 12,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2897",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 ListAllMyBuckets (SOAP API)\nListAllMyBuckets (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe ListAllMyBuckets operation returns a list of all buckets owned by the sender of the\nrequest.\nExample\nSample Request\n<ListAllMyBuckets xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</ListAllMyBuckets>\nSample Response\n<ListAllMyBucketsResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<Owner>\n<ID>bcaf1ffd86f41161ca5fb16fd081034f</ID>\n<DisplayName>webfile</DisplayName>\n</Owner>\n<Buckets>\n<Bucket>\n<Name>quotes;/Name>\n<CreationDate>2006-02-03T16:45:09.000Z</CreationDate>\n</Bucket>\n<Bucket>\n<Name>samples</Name>\n<CreationDate>2006-02-03T16:41:58.000Z</CreationDate>\n</Bucket>\nOperations on the Service (SOAP API) API Version 2006-03-01 2892",
      "start_idx": 3236080,
      "end_idx": 3237184,
      "metadata": {
        "num_sentences": 5,
        "num_words": 102,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2898",
      "text": "Amazon Simple Storage Service API Reference\n</Buckets>\n</ListAllMyBucketsResult>\nResponse Body\n\u2022 Owner:\nThis provides information that Amazon S3 uses to represent your identity for purposes of\nauthentication and access control. ID is a unique and permanent identifier for the developer\nwho made the request. DisplayName is a human-readable name representing the developer who\nmade the request. It is not unique, and might change over time.We recommend that you match\nyour DisplayName to your Forum name.\n\u2022 Name:\nThe name of a bucket. Note that if one of your buckets was recently deleted, the name of the\ndeleted bucket might still be present in this list for a period of time.\n\u2022 CreationDate:\nThe time that the bucket was created.\nAccess Control\nYou must authenticate with a valid AWS Access Key ID. Anonymous requests are never allowed to\nlist buckets, and you can only list buckets for which you are the owner.\nOperations on Buckets (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThis section describes operations you can perform on Amazon S3 buckets.\nTopics\n\u2022 CreateBucket (SOAP API)\nOperations on Buckets (SOAP API) API Version 2006-03-01 2893",
      "start_idx": 3237186,
      "end_idx": 3238497,
      "metadata": {
        "num_sentences": 14,
        "num_words": 218,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2899",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 DeleteBucket (SOAP API)\n\u2022 ListBucket (SOAP API)\n\u2022 GetBucketAccessControlPolicy (SOAP API)\n\u2022 SetBucketAccessControlPolicy (SOAP API)\n\u2022 GetBucketLoggingStatus (SOAP API)\n\u2022 SetBucketLoggingStatus (SOAP API)\nCreateBucket (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe CreateBucket operation creates a bucket. Not every string is an acceptable bucket name. For\ninformation on bucket naming restrictions, see Working with Amazon S3 Buckets .\nNote\nTo determine whether a bucket name exists, use ListBucket and set MaxKeys to 0. A\nNoSuchBucket response indicates that the bucket is available, an AccessDenied response\nindicates that someone else owns the bucket, and a Success response indicates that you\nown the bucket or have permission to access it.\nExample Create a bucket named \"quotes\"\nSample Request\n<CreateBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\nOperations on Buckets (SOAP API) API Version 2006-03-01 2894",
      "start_idx": 3238499,
      "end_idx": 3239811,
      "metadata": {
        "num_sentences": 9,
        "num_words": 170,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2900",
      "text": "Amazon Simple Storage Service API Reference\n</CreateBucket>\nSample Response\n<CreateBucketResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<CreateBucketResponse>\n<Bucket>quotes</Bucket>\n</CreateBucketResponse>\n</CreateBucketResponse>\nElements\n\u2022 Bucket: The name of the bucket you are trying to create.\n\u2022 AccessControlList: The access control list for the new bucket. This element is optional. If\nnot provided, the bucket is created with an access policy that give the requester FULL_CONTROL\naccess.\nAccess Control\nYou must authenticate with a valid AWS Access Key ID. Anonymous requests are never allowed to\ncreate buckets.\nRelated Resources\n\u2022 ListBucket (SOAP API)\nDeleteBucket (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe DeleteBucket operation deletes a bucket. All objects in the bucket must be deleted before\nthe bucket itself can be deleted.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2895",
      "start_idx": 3239813,
      "end_idx": 3240897,
      "metadata": {
        "num_sentences": 12,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2901",
      "text": "Amazon Simple Storage Service API Reference\nExample\nThis example deletes the \"quotes\" bucket.\nSample Request\n<DeleteBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<AWSAccessKeyId> AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</DeleteBucket>\nSample Response\n<DeleteBucketResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<DeleteBucketResponse>\n<Code>204</Code>\n<Description>No Content</Description>\n</DeleteBucketResponse>\n</DeleteBucketResponse>\nElements\n\u2022 Bucket: The name of the bucket you want to delete.\nAccess Control\nOnly the owner of a bucket is allowed to delete it, regardless the access control policy on the\nbucket.\nListBucket (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe ListBucket operation returns information about some of the items in the bucket.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2896",
      "start_idx": 3240899,
      "end_idx": 3242023,
      "metadata": {
        "num_sentences": 8,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2902",
      "text": "Amazon Simple Storage Service API Reference\nFor a general introduction to the list operation, see the Listing Object Keys.\nRequests\nThis example lists up to 1000 keys in the \"quotes\" bucket that have the prefix \"notes.\"\nSyntax\n<ListBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Prefix>notes/</Prefix>\n<Delimiter>/</Delimiter>\n<MaxKeys>1000</MaxKeys>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</ListBucket>\nParameters\nName Description Required\nprefix Limits the response to keys which begin with the indicated No\nprefix. You can use prefixes to separate a bucket into different\nsets of keys in a way similar to how a file system uses folders.\nImportant\nReplacement must be made for object keys containing\nspecial characters (such as carriage returns) when using\nXML requests. For more information, see XML related\nobject key constraints.\nType: String\nDefault: None\nmarker Indicates where in the bucket to begin listing. The list will only No\ninclude keys that occur lexicographically after marker. This is\nOperations on Buckets (SOAP API) API Version 2006-03-01 2897",
      "start_idx": 3242025,
      "end_idx": 3243236,
      "metadata": {
        "num_sentences": 9,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2903",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nconvenient for pagination: To get the next page of results use\nthe last key of the current page as the marker.\nType: String\nDefault: None\nmax-keys The maximum number of keys you'd like to see in the response No\nbody. The server might return fewer than this many keys, but\nwill not return more.\nType: String\nDefault: None\ndelimiter Causes keys that contain the same string between the prefix No\nand the first occurrence of the delimiter to be rolled up into a\nsingle result element in the CommonPrefixes collection. These\nrolled-up keys are not returned elsewhere in the response.\nType: String\nDefault: None\nSuccess Response\nThis response assumes the bucket contains the following keys:\nnotes/todos.txt\nnotes/2005-05-23/customer_mtg_notes.txt\nnotes/2005-05-23/phone_notes.txt\nnotes/2005-05-28/sales_notes.txt\nSyntax\n<?xml version=\"1.0\" encoding=\"UTF-8\"?>\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01/\">\n<Name>backups</Name>\n<Prefix>notes/</Prefix>\nOperations on Buckets (SOAP API) API Version 2006-03-01 2898",
      "start_idx": 3243238,
      "end_idx": 3244334,
      "metadata": {
        "num_sentences": 6,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2904",
      "text": "Amazon Simple Storage Service API Reference\n<MaxKeys>1000</MaxKeys>\n<Delimiter>/</Delimiter>\n<IsTruncated>false</IsTruncated>\n<Contents>\n<Key>notes/todos.txt</Key>\n<LastModified>2006-01-01T12:00:00.000Z</LastModified>\n<ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag>\n<Size>5126</Size>\n<StorageClass>STANDARD</StorageClass>\n<Owner>\n<ID>75aa57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>\n<DisplayName>webfile</DisplayName>\n</Owner>\n<StorageClass>STANDARD</StorageClass>\n</Contents>\n<CommonPrefixes>\n<Prefix>notes/2005-05-23/</Prefix>\n</CommonPrefixes>\n<CommonPrefixes>\n<Prefix>notes/2005-05-28/</Prefix>\n</CommonPrefixes>\n</ListBucketResult>\nAs you can see, many of the fields in the response echo the request parameters. IsTruncated,\nContents, and CommonPrefixes are the only response elements that can contain new\ninformation.\nResponse Elements\nName Description\nContents Metadata about each object returned.\nType: XML metadata\nAncestor: ListBucketResult\nCommonPre A response can contain CommonPrefixes only if you specify a delimiter\nfixes . When you do, CommonPrefixes contains all (if there are any) keys\nbetween Prefix and the next occurrence of the string specified by\ndelimiter . In effect, CommonPrefixes lists keys that act like subdirect\nories in the directory specified by Prefix. For example, if prefix is\nOperations on Buckets (SOAP API) API Version 2006-03-01 2899",
      "start_idx": 3244336,
      "end_idx": 3245740,
      "metadata": {
        "num_sentences": 7,
        "num_words": 140,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2905",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nnotes/ and delimiter is a slash (/), in notes/summer/july , the\ncommon prefix is notes/summer/ .\nType: String\nAncestor: ListBucketResult\nDelimiter Causes keys that contain the same string between the prefix and the first\noccurrence of the delimiter to be rolled up into a single result element in the\nCommonPrefixes collection. These rolled-up keys are not returned elsewhere\nin the response.\nType: String\nAncestor: ListBucketResult\nIsTruncated Specifies whether (true) or not (false) all of the results were returned. All\nof the results may not be returned if the number of results exceeds that\nspecified by MaxKeys.\nType: String\nAncestor: boolean\nMarker Indicates where in the bucket to begin listing.\nType: String\nAncestor: ListBucketResult\nMaxKeys The maximum number of keys returned in the response body.\nType: String\nAncestor: ListBucketResult\nOperations on Buckets (SOAP API) API Version 2006-03-01 2900",
      "start_idx": 3245742,
      "end_idx": 3246713,
      "metadata": {
        "num_sentences": 8,
        "num_words": 145,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2906",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nName Name of the bucket.\nType: String\nAncestor: ListBucketResult\nPrefix Keys that begin with the indicated prefix.\nType: String\nAncestor: ListBucketResult\nResponse Body\nFor information about the list response, see Listing Keys Response.\nAccess Control\nTo list the keys of a bucket you need to have been granted READ access on the bucket.\nGetBucketAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe GetBucketAccessControlPolicy operation fetches the access control policy for a bucket.\nExample\nThis example retrieves the access control policy for the \"quotes\" bucket.\nSample Request\n<GetBucketAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\nOperations on Buckets (SOAP API) API Version 2006-03-01 2901",
      "start_idx": 3246715,
      "end_idx": 3247679,
      "metadata": {
        "num_sentences": 10,
        "num_words": 137,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2907",
      "text": "Amazon Simple Storage Service API Reference\n<Bucket>quotes</Bucket>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetBucketAccessControlPolicy>\nSample Response\n<AccessControlPolicy>\n<Owner>\n<ID>a9a7b886d6fd2441bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Owner>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>a9a7b886d6f41bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n<Grant>\n<Grantee xsi:type=\"Group\">\n<URI>http://acs.amazonaws.com/groups/global/AllUsers<URI>\n</Grantee>\n<Permission>READ</Permission>\n</Grant>\n</AccessControlList>\n<AccessControlPolicy>\nResponse Body\nThe response contains the access control policy for the bucket. For an explanation of this response,\nsee SOAP Access Policy .\nAccess Control\nYou must have READ_ACP rights to the bucket in order to retrieve the access control policy for a\nbucket.\nOperations on Buckets (SOAP API) API Version 2006-03-01 2902",
      "start_idx": 3247681,
      "end_idx": 3248778,
      "metadata": {
        "num_sentences": 4,
        "num_words": 89,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2908",
      "text": "Amazon Simple Storage Service API Reference\nSetBucketAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe SetBucketAccessControlPolicy operation sets the Access Control Policy for an existing\nbucket. If successful, the previous Access Control Policy for the bucket is entirely replaced with the\nspecified Access Control Policy.\nExample\nGive the specified user (usually the owner) FULL_CONTROL access to the \"quotes\" bucket.\nSample Request\n<SetBucketAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>a9a7b8863000e241bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n</AccessControlList>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</SetBucketAccessControlPolicy >\nSample Response\n<GetBucketAccessControlPolicyResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<GetBucketAccessControlPolicyResponse>\n<Code>200</Code>\nOperations on Buckets (SOAP API) API Version 2006-03-01 2903",
      "start_idx": 3248780,
      "end_idx": 3250131,
      "metadata": {
        "num_sentences": 7,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2909",
      "text": "Amazon Simple Storage Service API Reference\n<Description>OK</Description>\n</GetBucketAccessControlPolicyResponse>\n</GetBucketAccessControlPolicyResponse>\nAccess Control\nYou must have WRITE_ACP rights to the bucket in order to set the access control policy for a\nbucket.\nGetBucketLoggingStatus (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe GetBucketLoggingStatus retrieves the logging status for an existing bucket.\nFor a general introduction to this feature, see Server Logs.\nExample\nSample Request\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<soap:Envelope xmlns:soap=\"http://schemas.xmlsoap.org/soap/envelope/\"\nxmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xmlns:xsd=\"http://\nwww.w3.org/2001/XMLSchema\">\n<soap:Body>\n<GetBucketLoggingStatus xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>mybucket</Bucket>\n<AWSAccessKeyId>YOUR_AWS_ACCESS_KEY_ID</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>YOUR_SIGNATURE_HERE</Signature>\n</GetBucketLoggingStatus>\n</soap:Body>\n</soap:Envelope>\nOperations on Buckets (SOAP API) API Version 2006-03-01 2904",
      "start_idx": 3250133,
      "end_idx": 3251383,
      "metadata": {
        "num_sentences": 7,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2910",
      "text": "Amazon Simple Storage Service API Reference\nSample Response\n<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<soapenv:Envelope xmlns:soapenv=\"http://schemas.xmlsoap.org/soap/envelope/\"\nxmlns:xsd=\"http://www.w3.org/2001/XMLSchema\" xmlns:xsi=\"http://www.w3.org/2001/\nXMLSchema-instance\" >\n<soapenv:Header>\n</soapenv:Header>\n<soapenv:Body>\n<GetBucketLoggingStatusResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<GetBucketLoggingStatusResponse>\n<LoggingEnabled>\n<TargetBucket>mylogs</TargetBucket>\n<TargetPrefix>mybucket-access_log-</TargetPrefix>\n</LoggingEnabled>\n</GetBucketLoggingStatusResponse>\n</GetBucketLoggingStatusResponse>\n</soapenv:Body>\n</soapenv:Envelope>\nAccess Control\nOnly the owner of a bucket is permitted to invoke this operation.\nSetBucketLoggingStatus (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe SetBucketLoggingStatus operation updates the logging status for an existing bucket.\nFor a general introduction to this feature, see Server Logs.\nExample\nThis sample request enables server access logging for the 'mybucket' bucket, and configures the\nlogs to be delivered to 'mylogs' under prefix 'access_log-'\nOperations on Buckets (SOAP API) API Version 2006-03-01 2905",
      "start_idx": 3251385,
      "end_idx": 3252737,
      "metadata": {
        "num_sentences": 7,
        "num_words": 139,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2912",
      "text": "Amazon Simple Storage Service API Reference\nOperations on Objects (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThis section describes operations you can perform on Amazon S3 objects.\nTopics\n\u2022 PutObjectInline (SOAP API)\n\u2022 PutObject (SOAP API)\n\u2022 CopyObject (SOAP API)\n\u2022 GetObject (SOAP API)\n\u2022 GetObjectExtended (SOAP API)\n\u2022 DeleteObject (SOAP API)\n\u2022 GetObjectAccessControlPolicy (SOAP API)\n\u2022 SetObjectAccessControlPolicy (SOAP API)\nPutObjectInline (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe PutObjectInline operation adds an object to a bucket. The data for the object is provided\nin the body of the SOAP message.\nIf an object already exists in a bucket, the new object will overwrite it because Amazon S3 stores\nthe last write request. However, Amazon S3 is a distributed system. If Amazon S3 receives multiple\nOperations on Objects (SOAP API) API Version 2006-03-01 2907",
      "start_idx": 3254032,
      "end_idx": 3255238,
      "metadata": {
        "num_sentences": 12,
        "num_words": 198,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2913",
      "text": "Amazon Simple Storage Service API Reference\nwrite requests for the same object nearly simultaneously, all of the objects might be stored, even\nthough only one wins in the end. Amazon S3 does not provide object locking; if you need this,\nmake sure to build it into your application layer.\nTo ensure an object is not corrupted over the network, you can calculate the MD5 of an object, PUT\nit to Amazon S3, and compare the returned Etag to the calculated MD5 value.\nPutObjectInline is not suitable for use with large objects. The system limits this\noperation to working with objects 1MB or smaller. PutObjectInline will fail with the\nInlineDataTooLargeError status code if the Data parameter encodes an object larger than\n1MB. To upload large objects, consider using the non-inline PutObject API, or the REST API instead.\nExample\nThis example writes some text and metadata into the \"Nelson\" object in the \"quotes\" bucket, give\na user (usually the owner) FULL_CONTROL access to the object, and make the object readable by\nanonymous parties.\nSample Request\n<PutObjectInline xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<Metadata>\n<Name>Content-Type</Name>\n<Value>text/plain</Value>\n</Metadata>\n<Metadata>\n<Name>family</Name>\n<Value>Muntz</Value>\n</Metadata>\n<Data>aGEtaGE=</Data>\n<ContentLength>5</ContentLength>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>a9a7b886d6fde241bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n<Grant>\nOperations on Objects (SOAP API) API Version 2006-03-01 2908",
      "start_idx": 3255240,
      "end_idx": 3256864,
      "metadata": {
        "num_sentences": 9,
        "num_words": 206,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2914",
      "text": "Amazon Simple Storage Service API Reference\n<Grantee xsi:type=\"Group\">\n<URI>http://acs.amazonaws.com/groups/global/AllUsers</URI>\n</Grantee>\n<Permission>READ</Permission>\n</Grant>\n</AccessControlList>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</PutObjectInline>\nSample Response\n<PutObjectInlineResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<PutObjectInlineResponse>\n<ETag>&quot828ef3fdfa96f00ad9f27c383fc9ac7f&quot</ETag>\n<LastModified>2006-01-01T12:00:00.000Z</lastModified>\n</PutObjectInlineResponse>\n</PutObjectInlineResponse>\nElements\n\u2022 Bucket: The bucket in which to add the object.\n\u2022 Key: The key to assign to the object.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related object\nkey constraints.\n\u2022 Metadata: You can provide name-value metadata pairs in the metadata element. These will be\nstored with the object.\n\u2022 Data: The base 64 encoded form of the data.\n\u2022 ContentLength: The length of the data in bytes.\nOperations on Objects (SOAP API) API Version 2006-03-01 2909",
      "start_idx": 3256866,
      "end_idx": 3258085,
      "metadata": {
        "num_sentences": 9,
        "num_words": 121,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2915",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 AccessControlList: An Access Control List for the resource. This element is optional. If\nomitted, the requester is given FULL_CONTROL access to the object. If the object already exists,\nthe preexisting access control policy is replaced.\nResponses\n\u2022 ETag: The entity tag is an MD5 hash of the object that you can use to do conditional fetches\nof the object using GetObjectExtended. The ETag only reflects changes to the contents of an\nobject, not its metadata.\n\u2022 LastModified: The Amazon S3 timestamp for the saved object.\nAccess Control\nYou must have WRITE access to the bucket in order to put objects into the bucket.\nRelated Resources\n\u2022 PutObject (SOAP API)\n\u2022 CopyObject (SOAP API)\nPutObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe PutObject operation adds an object to a bucket. The data for the object is attached as a DIME\nattachment.\nTo ensure an object is not corrupted over the network, you can calculate the MD5 of an object, PUT\nit to Amazon S3, and compare the returned Etag to the calculated MD5 value.\nIf an object already exists in a bucket, the new object will overwrite it because Amazon S3 stores\nthe last write request. However, Amazon S3 is a distributed system. If Amazon S3 receives multiple\nOperations on Objects (SOAP API) API Version 2006-03-01 2910",
      "start_idx": 3258087,
      "end_idx": 3259580,
      "metadata": {
        "num_sentences": 17,
        "num_words": 256,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2916",
      "text": "Amazon Simple Storage Service API Reference\nwrite requests for the same object nearly simultaneously, all of the objects might be stored, even\nthough only one wins in the end. Amazon S3 does not provide object locking; if you need this,\nmake sure to build it into your application layer.\nExample\nThis example puts some data and metadata in the \"Nelson\" object of the \"quotes\" bucket, give a\nuser (usually the owner) FULL_CONTROL access to the object, and make the object readable by\nanonymous parties. In this sample, the actual attachment is not shown.\nSample Request\n<PutObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<Metadata>\n<Name>Content-Type</Name>\n<Value>text/plain</Value>\n</Metadata>\n<Metadata>\n<Name>family</Name>\n<Value>Muntz</Value>\n</Metadata>\n<ContentLength>5</ContentLength>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>a9a7b886d6241bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n<Grant>\n<Grantee xsi:type=\"Group\">\n<URI>http://acs.amazonaws.com/groups/global/AllUsers<URI>\n</Grantee>\n<Permission>READ</Permission>\n</Grant>\n</AccessControlList>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2007-05-11T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</PutObject>\nOperations on Objects (SOAP API) API Version 2006-03-01 2911",
      "start_idx": 3259582,
      "end_idx": 3261015,
      "metadata": {
        "num_sentences": 5,
        "num_words": 138,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2917",
      "text": "Amazon Simple Storage Service API Reference\nSample Response\n<PutObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<PutObjectResponse>\n<ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag>\n<LastModified>2006-03-01T12:00:00.183Z</LastModified>\n</PutObjectResponse>\n</PutObjectResponse>\nElements\n\u2022 Bucket: The bucket in which to add the object.\n\u2022 Key: The key to assign to the object.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related object\nkey constraints.\n\u2022 Metadata: You can provide name-value metadata pairs in the metadata element. These will be\nstored with the object.\n\u2022 ContentLength: The length of the data in bytes.\n\u2022 AccessControlList: An Access Control List for the resource. This element is optional. If\nomitted, the requester is given FULL_CONTROL access to the object. If the object already exists,\nthe preexisting Access Control Policy is replaced.\nResponses\n\u2022 ETag: The entity tag is an MD5 hash of the object that you can use to do conditional fetches\nof the object using GetObjectExtended. The ETag only reflects changes to the contents of an\nobject, not its metadata.\n\u2022 LastModified: The Amazon S3 timestamp for the saved object.\nAccess Control\nTo put objects into a bucket, you must have WRITE access to the bucket.\nOperations on Objects (SOAP API) API Version 2006-03-01 2912",
      "start_idx": 3261017,
      "end_idx": 3262449,
      "metadata": {
        "num_sentences": 16,
        "num_words": 202,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2918",
      "text": "Amazon Simple Storage Service API Reference\nRelated Resources\n\u2022 CopyObject (SOAP API)\nCopyObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nDescription\nThe CopyObject operation creates a copy of an object when you specify the key and bucket of a\nsource object and the key and bucket of a target destination.\nWhen copying an object, you can preserve all metadata (default) or specify new metadata.\nHowever, the ACL is not preserved and is set to private for the user making the request. To\noverride the default ACL setting, specify a new ACL when generating a copy request. For more\ninformation, see Using ACLs.\nAll copy requests must be authenticated. Additionally, you must have read access to the source\nobject and write access to the destination bucket. For more information, see Using Auth Access.\nTo only copy an object under certain conditions, such as whether the Etag matches or\nwhether the object was modified before or after a specified date, use the request parameters\nCopySourceIfUnmodifiedSince, CopyIfUnmodifiedSince, CopySourceIfMatch, or\nCopySourceIfNoneMatch.\nNote\nYou might need to configure the SOAP stack socket timeout for copying large objects.\nRequest Syntax\n<CopyObject xmlns=\"http://bucket_name.s3.amazonaws.com/2006-03-01\">\nOperations on Objects (SOAP API) API Version 2006-03-01 2913",
      "start_idx": 3262451,
      "end_idx": 3263928,
      "metadata": {
        "num_sentences": 14,
        "num_words": 227,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2919",
      "text": "Amazon Simple Storage Service API Reference\n<SourceBucket>source_bucket</SourceBucket>\n<SourceObject>source_object</SourceObject>\n<DestinationBucket>destination_bucket</DestinationBucket>\n<DestinationObject>destination_object</DestinationObject>\n<MetadataDirective>{REPLACE | COPY}</MetadataDirective>\n<Metadata>\n<Name>metadata_name</Name>\n<Value>metadata_value</Value>\n</Metadata>\n...\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"user_type\">\n<ID>user_id</ID>\n<DisplayName>display_name</DisplayName>\n</Grantee>\n<Permission>permission</Permission>\n</Grant>\n...\n</AccessControlList>\n<CopySourceIfMatch>etag</CopySourceIfMatch>\n<CopySourceIfNoneMatch>etag</CopySourceIfNoneMatch>\n<CopySourceIfModifiedSince>date_time</CopySourceIfModifiedSince>\n<CopySourceIfUnmodifiedSince>date_time</CopySourceIfUnmodifiedSince>\n<AWSAccessKeyId>AWSAccessKeyId</AWSAccessKeyId>\n<Timestamp>TimeStamp</Timestamp>\n<Signature>Signature</Signature>\n</CopyObject>\nRequest Parameters\nName Description Required\nSourceBucket The name of the source bucket. Yes\nType: String\nDefault: None\nConstraints: A valid source bucket.\nSourceKey The key name of the source object. Yes\nOperations on Objects (SOAP API) API Version 2006-03-01 2914",
      "start_idx": 3263930,
      "end_idx": 3265136,
      "metadata": {
        "num_sentences": 4,
        "num_words": 77,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2920",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nType: String\nDefault: None\nConstraints: The key for a valid source\nobject to which you have READ access.\nImportant\nReplacement must be made\nfor object keys containing\nspecial characters (such as\ncarriage returns) when using XML\nrequests. For more informati\non, see XML related object key\nconstraints.\nDestinationBucket The name of the destination bucket. Yes\nType: String\nDefault: None\nConstraints: You must have WRITE access\nto the destination bucket.\nDestinationKey The key of the destination object. Yes\nType: String\nDefault: None\nConstraints: You must have WRITE access\nto the destination bucket.\nOperations on Objects (SOAP API) API Version 2006-03-01 2915",
      "start_idx": 3265138,
      "end_idx": 3265869,
      "metadata": {
        "num_sentences": 8,
        "num_words": 109,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2921",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nMetadataDirective Specifies whether the metadata is copied No\nfrom the source object or replaced with\nmetadata provided in the request.\nType: String\nDefault: COPY\nValid values: COPY | REPLACE\nConstraints: Values other than COPY or\nREPLACE will result in an immediate\nerror. You cannot copy an object to itself\nunless the MetadataDirective header is\nspecified and its value set to REPLACE.\nMetadata Specifies metadata name-value pairs to No\nset for the object.If MetadataDirective is\nset to COPY, all metadata is ignored.\nType: String\nDefault: None\nConstraints: None.\nAccessControlList Grants access to users by e-mail No\naddresses or canonical user ID.\nType: String\nDefault: None\nConstraints: None\nOperations on Objects (SOAP API) API Version 2006-03-01 2916",
      "start_idx": 3265871,
      "end_idx": 3266699,
      "metadata": {
        "num_sentences": 7,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2922",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nCopySourceIfMatch Copies the object if its entity tag (ETag) No\nmatches the specified tag; otherwise\nreturn a PreconditionFailed.\nType: String\nDefault: None\nConstraints: None. If the Etag does not\nmatch, the object is not copied.\nCopySourceIfNoneMatch Copies the object if its entity tag (ETag) No\nis different than the specified Etag;\notherwise returns an error.\nType: String\nDefault: None\nConstraints: None.\nCopySourceIfUnmodi Copies the object if it hasn't been No\nfiedSince modified since the specified time;\notherwise returns a PreconditionFailed.\nType: dateTime\nDefault: None\nCopySourceIfModifiedSince Copies the object if it has been modified No\nsince the specified time; otherwise\nreturns an error.\nType: dateTime\nDefault: None\nOperations on Objects (SOAP API) API Version 2006-03-01 2917",
      "start_idx": 3266701,
      "end_idx": 3267567,
      "metadata": {
        "num_sentences": 8,
        "num_words": 124,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2923",
      "text": "Amazon Simple Storage Service API Reference\nResponse Syntax\n<CopyObjectResponse xmlns=\"http://bucket_name.s3.amazonaws.com/2006-03-01\">\n<CopyObjectResponse>\n<ETag>\"etag\"</ETag>\n<LastModified>timestamp</LastModified>\n</CopyObjectResponse>\n</CopyObjectResponse>\nResponse Elements\nFollowing is a list of response elements.\nNote\nThe SOAP API does not return extra whitespace. Extra whitespace is only returned by the\nREST API.\nName Description\nEtag Returns the etag of the new object. The ETag only\nreflects changes to the contents of an object, not\nits metadata.\nType: String\nAncestor: CopyObjectResult\nLastModified Returns the date the object was last modified.\nType: String\nAncestor: CopyObjectResult\nFor information about general response elements, see Using REST Error Response Headers.\nOperations on Objects (SOAP API) API Version 2006-03-01 2918",
      "start_idx": 3267569,
      "end_idx": 3268417,
      "metadata": {
        "num_sentences": 8,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2924",
      "text": "Amazon Simple Storage Service API Reference\nSpecial Errors\nThere are no special errors for this operation. For information about general Amazon S3 errors, see\nList of error codes.\nExamples\nThis example copies the flotsam object from the pacific bucket to the jetsam object of the\natlantic bucket, preserving its metadata.\nSample Request\n<CopyObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<SourceBucket>pacific</SourceBucket>\n<SourceObject>flotsam</SourceObject>\n<DestinationBucket>atlantic</DestinationBucket>\n<DestinationObject>jetsam</DestinationObject>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2008-02-18T13:54:10.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbq7RrtSFmw=</Signature>\n</CopyObject>\nSample Response\n<CopyObjectResponse xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<CopyObjectResponse>\n<ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag>\n<LastModified>2008-02-18T13:54:10.183Z</LastModified>\n</CopyObjectResponse>\n</CopyObjectResponse>\nThis example copies the \"tweedledee\" object from the wonderland bucket to the \"tweedledum\"\nobject of the wonderland bucket, replacing its metadata.\nSample Request\n<CopyObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<SourceBucket>wonderland</SourceBucket>\n<SourceObject>tweedledee</SourceObject>\n<DestinationBucket>wonderland</DestinationBucket>\n<DestinationObject>tweedledum</DestinationObject>\n<MetadataDirective >REPLACE</MetadataDirective >\nOperations on Objects (SOAP API) API Version 2006-03-01 2919",
      "start_idx": 3268419,
      "end_idx": 3269915,
      "metadata": {
        "num_sentences": 5,
        "num_words": 112,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2925",
      "text": "Amazon Simple Storage Service API Reference\n<Metadata>\n<Name>Content-Type</Name>\n<Value>text/plain</Value>\n</Metadata>\n<Metadata>\n<Name>relationship</Name>\n<Value>twins</Value>\n</Metadata>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2008-02-18T13:54:10.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbq7RrtSFmw=</Signature>\n</CopyObject>\nSample Response\n<CopyObjectResponse xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<CopyObjectResponse>\n<ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag>\n<LastModified>2008-02-18T13:54:10.183Z</LastModified>\n</CopyObjectResponse>\n</CopyObjectResponse>\nRelated Resources\n\u2022 PutObject (SOAP API)\n\u2022 PutObjectInline (SOAP API)\nGetObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe GetObject operation returns the current version of an object. If you try to GetObject\nan object that has a delete marker as its current version, S3 returns a 404 error. You cannot use\nthe SOAP API to retrieve a specified version of an object. To do that, use the REST API. For more\ninformation, see Versioning. For more options, use the GetObjectExtended (SOAP API) operation.\nOperations on Objects (SOAP API) API Version 2006-03-01 2920",
      "start_idx": 3269917,
      "end_idx": 3271256,
      "metadata": {
        "num_sentences": 10,
        "num_words": 152,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2927",
      "text": "Amazon Simple Storage Service API Reference\n</GetObjectResponse>\n</GetObjectResponse>\nElements\n\u2022 Bucket: The bucket from which to retrieve the object.\n\u2022 Key: The key that identifies the object.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related object\nkey constraints.\n\u2022 GetMetadata: The metadata is returned with the object if this is true.\n\u2022 GetData: The object data is returned if this is true.\n\u2022 InlineData: If this is true, then the data is returned, base 64-encoded, as part of the SOAP\nbody of the response. If false, then the data is returned as a SOAP attachment. The InlineData\noption is not suitable for use with large objects. The system limits this operation to working\nwith 1MB of data or less. A GetObject request with the InlineData flag set will fail with the\nInlineDataTooLargeError status code if the resulting Data parameter would have encoded\nmore than 1MB. To download large objects, consider calling GetObject without setting the\nInlineData flag, or use the REST API instead.\nReturned Elements\n\u2022 Metadata: The name-value paired metadata stored with the object.\n\u2022 Data: If InlineData was true in the request, this contains the base 64 encoded object data.\n\u2022 LastModified: The time that the object was stored in Amazon S3.\n\u2022 ETag: The object's entity tag. This is a hash of the object that can be used to do conditional\ngets. The ETag only reflects changes to the contents of an object, not its metadata.\nAccess Control\nYou can read an object only if you have been granted READ access to the object.\nOperations on Objects (SOAP API) API Version 2006-03-01 2922",
      "start_idx": 3272431,
      "end_idx": 3274132,
      "metadata": {
        "num_sentences": 20,
        "num_words": 283,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2928",
      "text": "Amazon Simple Storage Service API Reference\nSOAP Chunked and Resumable Downloads\nTo provide GET flexibility, Amazon S3 supports chunked and resumable downloads.\nSelect from the following:\n\u2022 For large object downloads, you might want to break them into smaller chunks. For more\ninformation, see Range GETs\n\u2022 For GET operations that fail, you can design your application to download the remainder instead\nof the entire file. For more information, see REST GET Error Recovery\nRange GETs\nFor some clients, you might want to break large downloads into smaller downloads. To break a GET\ninto smaller units, use Range.\nBefore you can break a GET into smaller units, you must determine its size. For example, the\nfollowing request gets the size of the bigfile object.\n<ListBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>bigbucket</Bucket>\n<Prefix>bigfile</Prefix>\n<MaxKeys>1</MaxKeys>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</ListBucket>\nAmazon S3 returns the following response.\n<ListBucketResult xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<Name>quotes</Name>\n<Prefix>N</Prefix>\n<MaxKeys>1</MaxKeys>\n<IsTruncated>false</IsTruncated>\n<Contents>\n<Key>bigfile</Key>\n<LastModified>2006-01-01T12:00:00.000Z</LastModified>\n<ETag>&quot;828ef3fdfa96f00ad9f27c383fc9ac7f&quot;</ETag>\n<Size>2023276</Size>\nOperations on Objects (SOAP API) API Version 2006-03-01 2923",
      "start_idx": 3274134,
      "end_idx": 3275619,
      "metadata": {
        "num_sentences": 9,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2930",
      "text": "Amazon Simple Storage Service API Reference\n</GetObjectResponse>\nTo ensure the file did not change since the previous portion was downloaded, specify the IfMatch\nelement. Although the IfMatch element is not required, it is recommended for content that is likely\nto change.\nThe following is a request that gets the remainder of the file, using the IfMatch request header.\n<GetObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>bigbucket</Bucket>\n<Key>bigfile</Key>\n<GetMetadata>true</GetMetadata>\n<GetData>true</GetData>\n<InlineData>true</InlineData>\n<ByteRangeStart>10485761</ByteRangeStart>\n<ByteRangeEnd>2023276</ByteRangeEnd>\n<IfMatch>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</IfMatch>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObject>\nAmazon S3 returns the following response and the remainder of the file.\n<GetObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<GetObjectResponse>\n<Status>\n<Code>200</Code>\n<Description>OK</Description>\n</Status>\n<Metadata>\n<Name>Content-Type</Name>\n<Value>text/plain</Value>\n</Metadata>\n<Metadata>\n<Name>family</Name>\n<Value>>Muntz</Value>\n</Metadata>\n<Data>--remainder of bigfile--</Data>\n<LastModified>2006-01-01T12:00:00.000Z</LastModified>\n<ETag>\"828ef3fdfa96f00ad9f27c383fc9ac7f\"</ETag>\n</GetObjectResponse>\nOperations on Objects (SOAP API) API Version 2006-03-01 2925",
      "start_idx": 3276936,
      "end_idx": 3278384,
      "metadata": {
        "num_sentences": 5,
        "num_words": 114,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2932",
      "text": "Amazon Simple Storage Service API Reference\nREST GET Error Recovery\nIf an object GET fails, you can get the rest of the file by specifying the range to download. To do so,\nyou must get the size of the object using ListBucket and perform a range GET on the remainder\nof the file. For more information, see GetObjectExtended (SOAP API).\nRelated Resources\nOperations on Objects (SOAP API)\nGetObjectExtended (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nGetObjectExtended is exactly like GetObject (SOAP API), except that it supports the following\nadditional elements that can be used to accomplish much of the same functionality provided by\nHTTP GET headers (go to http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html).\nGetObjectExtended supports the following elements in addition to those supported by GetObject:\n\u2022 ByteRangeStart, ByteRangeEnd: These elements specify that only a portion of the object\ndata should be retrieved. They follow the behavior of the HTTP byte ranges (go to http://\nwww.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.35).\n\u2022 IfModifiedSince: Return the object only if the object's timestamp is later than the specified\ntimestamp. (http://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.25)\n\u2022 IfUnmodifiedSince: Return the object only if the object's timestamp is earlier than or\nequal to the specified timestamp. (go to http://www.w3.org/Protocols/rfc2616/rfc2616-\nsec14.html#sec14.28)\n\u2022 IfMatch: Return the object only if its ETag matches the supplied tag(s). (go to http://\nwww.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.24)\n\u2022 IfNoneMatch: Return the object only if its ETag does not match the supplied tag(s). (go to\nhttp://www.w3.org/Protocols/rfc2616/rfc2616-sec14.html#sec14.26)\nOperations on Objects (SOAP API) API Version 2006-03-01 2927",
      "start_idx": 3279452,
      "end_idx": 3281403,
      "metadata": {
        "num_sentences": 14,
        "num_words": 267,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2933",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 ReturnCompleteObjectOnConditionFailure:ReturnCompleteObjectOnConditionFailure:\nIf true, then if the request includes a range element and one or both of IfUnmodifiedSince/\nIfMatch elements, and the condition fails, return the entire object rather than a fault. This\nenables the If-Range functionality (go to http://www.w3.org/Protocols/rfc2616/rfc2616-\nsec14.html#sec14.27).\nDeleteObject (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe DeleteObject operation removes the specified object from Amazon S3. Once deleted, there\nis no method to restore or undelete an object.\nNote\nIf you delete an object that does not exist, Amazon S3 will return a success (not an error\nmessage).\nExample\nThis example deletes the \"Nelson\" object from the \"quotes\" bucket.\nSample Request\n<DeleteObject xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<AWSAccessKeyId> AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</DeleteObject>\nSample Response\nOperations on Objects (SOAP API) API Version 2006-03-01 2928",
      "start_idx": 3281405,
      "end_idx": 3282734,
      "metadata": {
        "num_sentences": 10,
        "num_words": 162,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2934",
      "text": "Amazon Simple Storage Service API Reference\n<DeleteObjectResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<DeleteObjectResponse>\n<Code>200</Code>\n<Description>OK</Description>\n</DeleteObjectResponse>\n</DeleteObjectResponse>\nElements\n\u2022 Bucket: The bucket that holds the object.\n\u2022 Key: The key that identifies the object.\nImportant\nReplacement must be made for object keys containing special characters (such as\ncarriage returns) when using XML requests. For more information, see XML related object\nkey constraints.\nAccess Control\nYou can delete an object only if you have WRITE access to the bucket, regardless of who owns the\nobject or what rights are granted to it.\nGetObjectAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe GetObjectAccessControlPolicy operation fetches the access control policy for an object.\nOperations on Objects (SOAP API) API Version 2006-03-01 2929",
      "start_idx": 3282736,
      "end_idx": 3283803,
      "metadata": {
        "num_sentences": 10,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2935",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nReplacement must be made for object keys containing special characters (such as carriage\nreturns) when using XML requests. For more information, see XML related object key\nconstraints.\nExample\nThis example retrieves the access control policy for the \"Nelson\" object from the \"quotes\" bucket.\nSample Request\n<GetObjectAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</GetObjectAccessControlPolicy>\nSample Response\n<AccessControlPolicy>\n<Owner>\n<ID>a9a7b886d6fd24a541bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Owner>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>a9a7b841bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n<Grant>\n<Grantee xsi:type=\"Group\">\n<URI>http://acs.amazonaws.com/groups/global/AllUsers<URI>\n</Grantee>\n<Permission>READ</Permission>\n</Grant>\nOperations on Objects (SOAP API) API Version 2006-03-01 2930",
      "start_idx": 3283805,
      "end_idx": 3285009,
      "metadata": {
        "num_sentences": 4,
        "num_words": 92,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2936",
      "text": "Amazon Simple Storage Service API Reference\n</AccessControlList>\n</AccessControlPolicy>\nResponse Body\nThe response contains the access control policy for the bucket. For an explanation of this response,\nSOAP Access Policy .\nAccess Control\nYou must have READ_ACP rights to the object in order to retrieve the access control policy for an\nobject.\nSetObjectAccessControlPolicy (SOAP API)\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nThe SetObjectAccessControlPolicy operation sets the access control policy for an existing\nobject. If successful, the previous access control policy for the object is entirely replaced with the\nspecified access control policy.\nExample\nThis example gives the specified user (usually the owner) FULL_CONTROL access to the \"Nelson\"\nobject from the \"quotes\" bucket.\nSample Request\n<SetObjectAccessControlPolicy xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>a9a7b886d6fd24a52fe8ca5bef65f89a64e0193f23000e241bf9b1c61be666e9</ID>\n<DisplayName>chriscustomer</DisplayName>\nOperations on Objects (SOAP API) API Version 2006-03-01 2931",
      "start_idx": 3285011,
      "end_idx": 3286329,
      "metadata": {
        "num_sentences": 10,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2937",
      "text": "Amazon Simple Storage Service API Reference\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n</AccessControlList>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2006-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</SetObjectAccessControlPolicy>\nSample Response\n<SetObjectAccessControlPolicyResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<SetObjectAccessControlPolicyResponse>\n<Code>200</Code>\n<Description>OK</Description>\n</SetObjectAccessControlPolicyResponse>\n</SetObjectAccessControlPolicyResponse>\nKey\nImportant\nReplacement must be made for object keys containing special characters (such as carriage\nreturns) when using XML requests. For more information, see XML related object key\nconstraints.\nAccess Control\nYou must have WRITE_ACP rights to the object in order to set the access control policy for a\nbucket.\nAuthenticating SOAP requests\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nAuthenticating SOAP requests API Version 2006-03-01 2932",
      "start_idx": 3286331,
      "end_idx": 3287507,
      "metadata": {
        "num_sentences": 7,
        "num_words": 120,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2938",
      "text": "Amazon Simple Storage Service API Reference\nEvery non-anonymous request must contain authentication information to establish the identity of\nthe principal making the request. In SOAP, the authentication information is put into the following\nelements of the SOAP request:\n\u2022 Your AWS Access Key ID\nNote\nWhen making authenticated SOAP requests, temporary security credentials are not\nsupported. For more information about types of credentials, see Making requests.\n\u2022 Timestamp: This must be a dateTime (go to http://www.w3.org/TR/xmlschema-2/\n#dateTime) in the Coordinated Universal Time (Greenwich Mean Time) time zone, such as\n2009-01-01T12:00:00.000Z. Authorization will fail if this timestamp is more than 15 minutes\naway from the clock on Amazon S3 servers.\n\u2022 Signature: The RFC 2104 HMAC-SHA1 digest (go to http://www.ietf.org/rfc/\nrfc2104.txt) of the concatenation of \"AmazonS3\" + OPERATION + Timestamp, using\nyour AWS Secret Access Key as the key. For example, in the following CreateBucket\nsample request, the signature element would contain the HMAC-SHA1 digest of the value\n\"AmazonS3CreateBucket2009-01-01T12:00:00.000Z\":\nFor example, in the following CreateBucket sample request, the signature element would contain\nthe HMAC-SHA1 digest of the value \"AmazonS3CreateBucket2009-01-01T12:00:00.000Z\":\nExample\n<CreateBucket xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Acl>private</Acl>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2009-01-01T12:00:00.000Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</CreateBucket>\nNote\nSOAP requests, both authenticated and anonymous, must be sent to Amazon S3 using SSL.\nAmazon S3 returns an error when you send a SOAP request over HTTP.\nAuthenticating SOAP requests API Version 2006-03-01 2933",
      "start_idx": 3287509,
      "end_idx": 3289313,
      "metadata": {
        "num_sentences": 9,
        "num_words": 222,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2939",
      "text": "Amazon Simple Storage Service API Reference\nImportant\nDue to different interpretations regarding how extra time precision should be\ndropped, .NET users should take care not to send Amazon S3 overly specific time\nstamps. This can be accomplished by manually constructing DateTime objects with only\nmillisecond precision.\nSetting access policy with SOAP\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nAccess control can be set at the time a bucket or object is written by including the\n\"AccessControlList\" element with the request to CreateBucket, PutObjectInline, or\nPutObject. The AccessControlList element is described in Identity and Access Management for\nAmazon S3 . If no access control list is specified with these operations, the resource is created with\na default access policy that gives the requester FULL_CONTROL access (this is the case even if the\nrequest is a PutObjectInline or PutObject request for an object that already exists).\nFollowing is a request that writes data to an object, makes the object readable by anonymous\nprincipals, and gives the specified user FULL_CONTROL rights to the bucket (Most developers will\nwant to give themselves FULL_CONTROL access to their own bucket).\nExample\nFollowing is a request that writes data to an object and makes the object readable by anonymous\nprincipals.\nSample Request\n<PutObjectInline xmlns=\"http://doc.s3.amazonaws.com/2006-03-01\">\n<Bucket>quotes</Bucket>\n<Key>Nelson</Key>\n<Metadata>\nSetting access policy with SOAP API Version 2006-03-01 2934",
      "start_idx": 3289315,
      "end_idx": 3290977,
      "metadata": {
        "num_sentences": 11,
        "num_words": 249,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2940",
      "text": "Amazon Simple Storage Service API Reference\n<Name>Content-Type</Name>\n<Value>text/plain</Value>\n</Metadata>\n<Data>aGEtaGE=</Data>\n<ContentLength>5</ContentLength>\n<AccessControlList>\n<Grant>\n<Grantee xsi:type=\"CanonicalUser\">\n<ID>75cc57f09aa0c8caeab4f8c24e99d10f8e7faeebf76c078efc7c6caea54ba06a</ID>\n<DisplayName>chriscustomer</DisplayName>\n</Grantee>\n<Permission>FULL_CONTROL</Permission>\n</Grant>\n<Grant>\n<Grantee xsi:type=\"Group\">\n<URI>http://acs.amazonaws.com/groups/global/AllUsers<URI>\n</Grantee>\n<Permission>READ</Permission>\n</Grant>\n</AccessControlList>\n<AWSAccessKeyId>AKIAIOSFODNN7EXAMPLE</AWSAccessKeyId>\n<Timestamp>2009-03-01T12:00:00.183Z</Timestamp>\n<Signature>Iuyz3d3P0aTou39dzbqaEXAMPLE=</Signature>\n</PutObjectInline>\nSample Response\n<PutObjectInlineResponse xmlns=\"http://s3.amazonaws.com/doc/2006-03-01\">\n<PutObjectInlineResponse>\n<ETag>&quot828ef3fdfa96f00ad9f27c383fc9ac7f&quot</ETag>\n<LastModified>2009-01-01T12:00:00.000Z</LastModified>\n</PutObjectInlineResponse>\n</PutObjectInlineResponse>\nThe access control policy can be read or set for an existing bucket or object using\nthe GetBucketAccessControlPolicy, GetObjectAccessControlPolicy,\nSetBucketAccessControlPolicy, and SetObjectAccessControlPolicy methods. For more\ninformation, see the detailed explanation of these methods.\nCommon elements\nYou can include the following authorization-related elements with any SOAP request:\nCommon elements API Version 2006-03-01 2935",
      "start_idx": 3290979,
      "end_idx": 3292426,
      "metadata": {
        "num_sentences": 3,
        "num_words": 93,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2941",
      "text": "Amazon Simple Storage Service API Reference\n\u2022 AWSAccessKeyId: The AWS Access Key ID of the requester\n\u2022 Timestamp: The current time on your system\n\u2022 Signature: The signature for the request\nSOAP Error Responses\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nIn SOAP, an error result is returned to the client as a SOAP fault, with the HTTP response code 500.\nIf you do not receive a SOAP fault, then your request was successful. The Amazon S3 SOAP fault\ncode is comprised of a standard SOAP 1.1 fault code (either \"Server\" or \"Client\") concatenated with\nthe Amazon S3-specific error code. For example: \"Server.InternalError\" or \"Client.NoSuchBucket\".\nThe SOAP fault string element contains a generic, human readable error message in English.\nFinally, the SOAP fault detail element contains miscellaneous information relevant to the error.\nFor example, if you attempt to delete the object \"Fred\", which does not exist, the body of the SOAP\nresponse contains a \"NoSuchKey\" SOAP fault.\nThe following example shows a sample SOAP error response.\n<soapenv:Body>\n<soapenv:Fault>\n<Faultcode>soapenv:Client.NoSuchKey</Faultcode>\n<Faultstring>The specified key does not exist.</Faultstring>\n<Detail>\n<Key>Fred</Key>\n</Detail>\n</soapenv:Fault>\n</soapenv:Body>\nThe following table explains the SOAP error response elements\nSOAP Error Responses API Version 2006-03-01 2936",
      "start_idx": 3292428,
      "end_idx": 3293938,
      "metadata": {
        "num_sentences": 12,
        "num_words": 226,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2942",
      "text": "Amazon Simple Storage Service API Reference\nName Description\nDetail Container for the key involved in the error\nType: Container\nAncestor: Body.Fault\nFault Container for error information.\nType: Container\nAncestor: Body\nFaultcode The fault code is a string that uniquely identifies an error condition. It is meant\nto be read and understood by programs that detect and handle errors by type.\nFor more information, see List of Error Codes.\nType: String\nAncestor: Body.Fault\nFaultstri The fault string contains a generic description of the error condition in English.\nng It is intended for a human audience. Simple programs display the message\ndirectly to the end user if they encounter an error condition they don't know\nhow or don't care to handle. Sophisticated programs with more exhaustive\nerror handling and proper internationalization are more likely to ignore the\nfault string.\nType: String\nAncestor: Body.Fault\nKey Identifies the key involved in the error\nType: String\nAncestor: Body.Fault\nSOAP Error Responses API Version 2006-03-01 2937",
      "start_idx": 3293940,
      "end_idx": 3294983,
      "metadata": {
        "num_sentences": 9,
        "num_words": 160,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2943",
      "text": "Amazon Simple Storage Service API Reference\nAppendix: Authenticating requests (AWS signature version 2)\nImportant\nThis section describes how to authenticate requests using AWS Signature Version 2.\nSignature Version 2 is being turned off (deprecated), Amazon S3 will only accept API\nrequests that are signed using Signature Version 4. For more information, see AWS\nSignature Version 2 Turned Off (Deprecated) for Amazon S3\nSignature Version 4 is supported in all AWS Regions, and it is the only version that is\nsupported for new Regions. For more information, see Authenticating Requests (AWS\nSignature Version 4) in the Amazon Simple Storage Service API Reference.\nAmazon S3 offers you the ability to identify what API signature version was used to sign a\nrequest. It is important to identify if any of your workflows are utilizing Signature Version 2\nsigning and upgrading them to use Signature Version 4 to prevent impact to your business.\n\u2022 If you are using CloudTrail event logs(recommended option), please see Identifying\nAmazon S3 Signature Version 2 requests by using CloudTrail on how to query and\nidentify such requests.\n\u2022 If you are using the Amazon S3 Server Access logs, see Using Amazon S3 server access\nlogs to identify requests\nTopics\n\u2022 Authenticating requests using the REST API (AWS signature version 2)\n\u2022 Signing and authenticating REST requests (AWS signature version 2)\n\u2022 Browser-based uploads using POST (AWS signature version 2)\nAppendix: Authenticating requests (AWS signature version 2) API Version 2006-03-01 2938",
      "start_idx": 3294985,
      "end_idx": 3296523,
      "metadata": {
        "num_sentences": 8,
        "num_words": 241,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2944",
      "text": "Amazon Simple Storage Service API Reference\nAuthenticating requests using the REST API (AWS signature version 2)\nWhen accessing Amazon S3 using REST, you must provide the following items in your request so\nthe request can be authenticated:\nRequest elements\n\u2022 AWS access key Id \u2013 Each request must contain the access key ID of the identity you are using to\nsend your request.\n\u2022 Signature \u2013 Each request must contain a valid request signature, or the request is rejected.\nA request signature is calculated using your secret access key, which is a shared secret known\nonly to you and AWS.\n\u2022 Time stamp \u2013 Each request must contain the date and time the request was created, represented\nas a string in UTC.\n\u2022 Date \u2013 Each request must contain the time stamp of the request.\nDepending on the API action you're using, you can provide an expiration date and time for\nthe request instead of or in addition to the time stamp. See the authentication topic for the\nparticular action to determine what it requires.\nFollowing are the general steps for authenticating requests to Amazon S3. It is assumed you have\nthe necessary security credentials, access key ID and secret access key.\nAuthenticating requests using the REST API (AWS signature version 2) API Version 2006-03-01 2939",
      "start_idx": 3296525,
      "end_idx": 3297792,
      "metadata": {
        "num_sentences": 10,
        "num_words": 216,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2945",
      "text": "Amazon Simple Storage Service API Reference\n1 Construct a request to AWS.\n2 Calculate the signature using your secret access key.\n3 Send the request to Amazon S3. Include your access key ID and the signature in your\nrequest. Amazon S3 performs the next three steps.\nAuthenticating requests using the REST API (AWS signature version 2) API Version 2006-03-01 2940",
      "start_idx": 3297794,
      "end_idx": 3298156,
      "metadata": {
        "num_sentences": 6,
        "num_words": 60,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2946",
      "text": "Amazon Simple Storage Service API Reference\n4 Amazon S3 uses the access key ID to look up your secret access key.\n5 Amazon S3 calculates a signature from the request data and the secret access key\nusing the same algorithm that you used to calculate the signature you sent in the\nrequest.\n6 If the signature generated by Amazon S3 matches the one you sent in the request,\nthe request is considered authentic. If the comparison fails, the request is discarded,\nand Amazon S3 returns an error response.\nAuthenticating requests using the REST API (AWS signature version 2) API Version 2006-03-01 2941",
      "start_idx": 3298158,
      "end_idx": 3298754,
      "metadata": {
        "num_sentences": 5,
        "num_words": 102,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2947",
      "text": "Amazon Simple Storage Service API Reference\nDetailed authentication information\nFor detailed information about REST authentication, see Signing and authenticating REST requests\n(AWS signature version 2).\nSigning and authenticating REST requests (AWS signature version 2)\nTopics\n\u2022 Using temporary security credentials\n\u2022 The authentication header\n\u2022 Request canonicalization for signing\n\u2022 Constructing the CanonicalizedResource element\n\u2022 Constructing the CanonicalizedAmzHeaders element\n\u2022 Positional versus named HTTP header StringToSign elements\n\u2022 Time stamp requirement\n\u2022 Authentication examples\n\u2022 REST request signing problems\n\u2022 Query string request authentication alternative\nNote\nThis topic explains authenticating requests using Signature Version 2. Amazon S3 now\nsupports the latest Signature Version 4. This latest signature version is supported in all\nregions and any new regions after January 30, 2014 will support only Signature Version\n4. For more information, go to Authenticating Requests (AWS Signature Version 4) in the\nAmazon Simple Storage Service API Reference.\nAuthentication is the process of proving your identity to the system. Identity is an important factor\nin Amazon S3 access control decisions. Requests are allowed or denied in part based on the identity\nof the requester. For example, the right to create buckets is reserved for registered developers\nand (by default) the right to create objects in a bucket is reserved for the owner of the bucket in\nquestion. As a developer, you'll be making requests that invoke these privileges, so you'll need to\nprove your identity to the system by authenticating your requests. This section shows you how.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2942",
      "start_idx": 3298756,
      "end_idx": 3300522,
      "metadata": {
        "num_sentences": 12,
        "num_words": 258,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2948",
      "text": "Amazon Simple Storage Service API Reference\nNote\nThe content in this section does not apply to HTTP POST. For more information, see\nBrowser-based uploads using POST (AWS signature version 2).\nThe Amazon S3 REST API uses a custom HTTP scheme based on a keyed-HMAC (Hash Message\nAuthentication Code) for authentication. To authenticate a request, you first concatenate selected\nelements of the request to form a string. You then use your AWS secret access key to calculate the\nHMAC of that string. Informally, we call this process \"signing the request,\" and we call the output of\nthe HMAC algorithm the signature, because it simulates the security properties of a real signature.\nFinally, you add this signature as a parameter of the request by using the syntax described in this\nsection.\nWhen the system receives an authenticated request, it fetches the AWS secret access key that you\nclaim to have and uses it in the same way to compute a signature for the message it received. It\nthen compares the signature it calculated against the signature presented by the requester. If the\ntwo signatures match, the system concludes that the requester must have access to the AWS secret\naccess key and therefore acts with the authority of the principal to whom the key was issued. If\nthe two signatures do not match, the request is dropped and the system responds with an error\nmessage.\nExample Authenticated Amazon S3 REST request\nGET /photos/puppy.jpg HTTP/1.1\nHost: awsexamplebucket1.us-west-1.s3.amazonaws.com\nDate: Tue, 27 Mar 2007 19:36:42 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:\nqgk2+6Sv9/oM7G3qLEjTH1a1l1g=\nUsing temporary security credentials\nIf you are signing your request using temporary security credentials (see Making requests), you\nmust include the corresponding security token in your request by adding the x-amz-security-\ntoken header.\nWhen you obtain temporary security credentials using the AWS Security Token Service API, the\nresponse includes temporary security credentials and a session token. You provide the session\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2943",
      "start_idx": 3300524,
      "end_idx": 3302656,
      "metadata": {
        "num_sentences": 14,
        "num_words": 327,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2949",
      "text": "Amazon Simple Storage Service API Reference\ntoken value in the x-amz-security-token header when you send requests to Amazon S3. For\ninformation about the AWS Security Token Service API provided by IAM, go to Action in the AWS\nSecurity Token Service API Reference Guide .\nThe authentication header\nThe Amazon S3 REST API uses the standard HTTP Authorization header to pass authentication\ninformation. (The name of the standard header is unfortunate because it carries authentication\ninformation, not authorization.) Under the Amazon S3 authentication scheme, the Authorization\nheader has the following form:\nAuthorization: AWS AWSAccessKeyId:Signature\nDevelopers are issued an AWS access key ID and AWS secret access key when they register. For\nrequest authentication, the AWSAccessKeyId element identifies the access key ID that was used\nto compute the signature and, indirectly, the developer making the request.\nThe Signature element is the RFC 2104 HMAC-SHA1 of selected elements from the request,\nand so the Signature part of the Authorization header will vary from request to request. If the\nrequest signature calculated by the system matches the Signature included with the request, the\nrequester will have demonstrated possession of the AWS secret access key. The request will then be\nprocessed under the identity, and with the authority, of the developer to whom the key was issued.\nFollowing is pseudogrammar that illustrates the construction of the Authorization request\nheader. (In the example, \\n means the Unicode code point U+000A, commonly called newline).\nAuthorization = \"AWS\" + \" \" + AWSAccessKeyId + \":\" + Signature;\nSignature = Base64( HMAC-SHA1( UTF-8-Encoding-Of(YourSecretAccessKey), UTF-8-Encoding-\nOf( StringToSign ) ) );\nStringToSign = HTTP-Verb + \"\\n\" +\nContent-MD5 + \"\\n\" +\nContent-Type + \"\\n\" +\nDate + \"\\n\" +\nCanonicalizedAmzHeaders +\nCanonicalizedResource;\nCanonicalizedResource = [ \"/\" + Bucket ] +\n<HTTP-Request-URI, from the protocol name up to the query string> +\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2944",
      "start_idx": 3302658,
      "end_idx": 3304750,
      "metadata": {
        "num_sentences": 12,
        "num_words": 313,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2950",
      "text": "Amazon Simple Storage Service API Reference\n[ subresource, if present. For example \"?acl\", \"?location\", or \"?logging\"];\nCanonicalizedAmzHeaders = <described below>\nHMAC-SHA1 is an algorithm defined by RFC 2104 - Keyed-Hashing for Message Authentication\n. The algorithm takes as input two byte-strings, a key and a message. For Amazon S3 request\nauthentication, use your AWS secret access key (YourSecretAccessKey) as the key, and the\nUTF-8 encoding of the StringToSign as the message. The output of HMAC-SHA1 is also a byte\nstring, called the digest. The Signature request parameter is constructed by Base64 encoding this\ndigest.\nRequest canonicalization for signing\nRecall that when the system receives an authenticated request, it compares the computed request\nsignature with the signature provided in the request in StringToSign. For that reason, you must\ncompute the signature by using the same method used by Amazon S3. We call the process of\nputting a request in an agreed-upon form for signing canonicalization.\nConstructing the CanonicalizedResource element\nCanonicalizedResource represents the Amazon S3 resource targeted by the request. Construct\nit for a REST request as follows:\nLaunch process\n1 Start with an empty string (\"\").\n2 If the request specifies a bucket using the HTTP Host header (virtual hosted-style), append\nthe bucket name preceded by a \"/\" (e.g., \"/bucketname\"). For path-style requests and\nrequests that don't address a bucket, do nothing. For more information about virtual\nhosted-style requests, see Virtual hosting of buckets .\nFor a virtual hosted-style request \"https://awsexamplebucket1.s3.us-west-1.amazo\nnaws.com/photos/puppy.jpg\", the CanonicalizedResource is \"/awsexamplebucket1\".\nFor the path-style request, \"https://s3.us-west-1.amazonaws.com/awsexamplebucket1/\nphotos/puppy.jpg\", the CanonicalizedResource is \"\".\n3 Append the path part of the un-decoded HTTP Request-URI, up-to but not including the\nquery string.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2945",
      "start_idx": 3304752,
      "end_idx": 3306803,
      "metadata": {
        "num_sentences": 18,
        "num_words": 285,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2951",
      "text": "Amazon Simple Storage Service API Reference\nFor a virtual hosted-style request \"https://awsexamplebucket1.s3.us-west-1.amazo\nnaws.com/photos/puppy.jpg\", the CanonicalizedResource is \"/awsexamplebucket1/\nphotos/puppy.jpg\".\nFor a path-style request, \"https://s3.us-west-1.amazonaws.com/awsexamplebucket1/\nphotos/puppy.jpg\", the CanonicalizedResource is \"/awsexamplebucket1/photos/\npuppy.jpg\". At this point, the CanonicalizedResource is the same for both the virtual\nhosted-style and path-style request.\nFor a request that does not address a bucket, such as GET Service, append \"/\".\n4 If the request addresses a subresource, such as ?versioning , ?location , ?acl, ?\nlifecycle , or ?versionid , append the subresource, its value if it has one, and the\nquestion mark. Note that in case of multiple subresources, subresources must be lexicogra\nphically sorted by subresource name and separated by '&', e.g., ?acl&versionId=value.\nThe subresources that must be included when constructing the CanonicalizedResource\nElement are acl, lifecycle, location, logging, notification, partNumber, policy, requestPa\nyment, uploadId, uploads, versionId, versioning, versions, and website.\nIf the request specifies query string parameters overriding the response header values\n(see Get Object), append the query string parameters and their values. When signing,\nyou do not encode these values; however, when making the request, you must encode\nthese parameter values. The query string parameters in a GET request include response-\ncontent-type , response-content-language , response-expires ,\nresponse-cache-control , response-content-disposition , and response-\ncontent-encoding .\nThe delete query string parameter must be included when you create the Canonical\nizedResource for a multi-object Delete request.\nElements of the CanonicalizedResource that come from the HTTP Request-URI should be signed\nliterally as they appear in the HTTP request, including URL-Encoding meta characters.\nThe CanonicalizedResource might be different than the HTTP Request-URI. In particular,\nif your request uses the HTTP Host header to specify a bucket, the bucket does not appear\nin the HTTP Request-URI. However, the CanonicalizedResource continues to include the\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2946",
      "start_idx": 3306805,
      "end_idx": 3309131,
      "metadata": {
        "num_sentences": 16,
        "num_words": 305,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2952",
      "text": "Amazon Simple Storage Service API Reference\nbucket. Query string parameters might also appear in the Request-URI but are not included in\nCanonicalizedResource. For more information, see Virtual hosting of buckets .\nConstructing the CanonicalizedAmzHeaders element\nTo construct the CanonicalizedAmzHeaders part of StringToSign, select all HTTP request\nheaders that start with 'x-amz-' (using a case-insensitive comparison), and use the following\nprocess.\nCanonicalizedAmzHeaders process\n1 Convert each HTTP header name to lowercase. For example, 'X-Amz-Date ' becomes 'x-\namz-date '.\n2 Sort the collection of headers lexicographically by header name.\n3 Combine header fields with the same name into one \"header-name:comma-separate\nd-value-list\" pair as prescribed by RFC 2616, section 4.2, without any spaces between\nvalues. For example, the two metadata headers 'x-amz-meta-username: fred ' and\n'x-amz-meta-username: barney ' would be combined into the single header 'x-\namz-meta-username: fred,barney '.\n4 \"Unfold\" long headers that span multiple lines (as allowed by RFC 2616, section 4.2) by\nreplacing the folding spaces (including new-line) by a single space.\n5 Trim any spaces around the colon in the header. For example, the header 'x-amz-meta-\nusername: fred,barney ' would become 'x-amz-meta-username:fred,ba\nrney '\n6 Finally, append a newline character (U+000A) to each canonicalized header in the\nresulting list. Construct the CanonicalizedResource element by concatenating all headers\nin this list into a single string.\nPositional versus named HTTP header StringToSign elements\nThe first few header elements of StringToSign (Content-Type, Date, and Content-MD5) are\npositional in nature. StringToSign does not include the names of these headers, only their\nvalues from the request. In contrast, the 'x-amz-' elements are named. Both the header names and\nthe header values appear in StringToSign.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2947",
      "start_idx": 3309133,
      "end_idx": 3311134,
      "metadata": {
        "num_sentences": 18,
        "num_words": 284,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2953",
      "text": "Amazon Simple Storage Service API Reference\nIf a positional header called for in the definition of StringToSign is not present in your request\n(for example, Content-Type or Content-MD5 are optional for PUT requests and meaningless for\nGET requests), substitute the empty string (\"\") for that position.\nTime stamp requirement\nA valid time stamp (using either the HTTP Date header or an x-amz-date alternative) is\nmandatory for authenticated requests. Furthermore, the client timestamp included with an\nauthenticated request must be within 15 minutes of the Amazon S3 system time when the\nrequest is received. If not, the request will fail with the RequestTimeTooSkewed error code. The\nintention of these restrictions is to limit the possibility that intercepted requests could be replayed\nby an adversary. For stronger protection against eavesdropping, use the HTTPS transport for\nauthenticated requests.\nNote\nThe validation constraint on request date applies only to authenticated requests that\ndo not use query string authentication. For more information, see Query string request\nauthentication alternative.\nSome HTTP client libraries do not expose the ability to set the Date header for a request. If you\nhave trouble including the value of the 'Date' header in the canonicalized headers, you can set the\ntimestamp for the request by using an 'x-amz-date' header instead. The value of the x-amz-\ndate header must be in one of the RFC 2616 formats (http://www.ietf.org/rfc/rfc2616.txt). When\nan x-amz-date header is present in a request, the system will ignore any Date header when\ncomputing the request signature. Therefore, if you include the x-amz-date header, use the empty\nstring for the Date when constructing the StringToSign. See the next section for an example.\nAuthentication examples\nThe examples in this section use the (non-working) credentials in the following table.\nParameter Value\nAWSAccessKeyId AKIAIOSFODNN7EXAMPLE\nAWSSecretAccessKey wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2948",
      "start_idx": 3311136,
      "end_idx": 3313226,
      "metadata": {
        "num_sentences": 16,
        "num_words": 306,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2954",
      "text": "Amazon Simple Storage Service API Reference\nIn the example StringToSigns, formatting is not significant, and \\n means the Unicode code\npoint U+000A, commonly called newline. Also, the examples use \"+0000\" to designate the time\nzone. You can use \"GMT\" to designate timezone instead, but the signatures shown in the examples\nwill be different.\nObject GET\nThis example gets an object from the awsexamplebucket1 bucket.\nRequest StringToSign\nGET /photos/puppy.jpg HTTP/1.1 GET\\n\nHost: awsexamplebucket1.us- \\n\nwest-1.s3.amazonaws.com \\n\nDate: Tue, 27 Mar 2007 19:36:42 Tue, 27 Mar 2007 19:36:42 +0000\\n\n+0000 /awsexamplebucket1/photos/puppy.jpg\nAuthorization: AWS AKIAIOSFO\nDNN7EXAMPLE:\nqgk2+6Sv9/oM7G3qLEjTH1a1l1g=\nNote that the CanonicalizedResource includes the bucket name, but the HTTP Request-URI does\nnot. (The bucket is specified by the Host header.)\nNote\nThe following Python script calculates the preceding signature, using the provided\nparameters. You can use this script to construct your own signatures, replacing the keys and\nStringToSign as appropriate.\nimport base64\nimport hmac\nfrom hashlib import sha1\naccess_key = 'AKIAIOSFODNN7EXAMPLE'.encode(\"UTF-8\")\nsecret_key = 'wJalrXUtnFEMI/K7MDENG/bPxRfiCYEXAMPLEKEY'.encode(\"UTF-8\")\nstring_to_sign = 'GET\\n\\n\\nTue, 27 Mar 2007 19:36:42 +0000\\n/awsexamplebucket1/\nphotos/puppy.jpg'.encode(\"UTF-8\")\nsignature = base64.b64encode(\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2949",
      "start_idx": 3313228,
      "end_idx": 3314705,
      "metadata": {
        "num_sentences": 9,
        "num_words": 185,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2955",
      "text": "Amazon Simple Storage Service API Reference\nhmac.new(\nsecret_key, string_to_sign, sha1\n).digest()\n).strip()\nprint(f\"AWS {access_key.decode()}:{signature.decode()}\")\nObject PUT\nThis example puts an object into the awsexamplebucket1 bucket.\nRequest StringToSign\nPUT /photos/puppy.jpg HTTP/1.1 PUT\\n\nContent-Type: image/jpeg \\n\nContent-Length: 94328 image/jpeg\\n\nHost: awsexamplebucket1.s3.us-wes Tue, 27 Mar 2007 21:15:45 +0000\\n\nt-1.amazonaws.com /awsexamplebucket1/photos/puppy.jpg\nDate: Tue, 27 Mar 2007 21:15:45 +0000\nAuthorization: AWS AKIAIOSFODNN7EXAMP\nLE:\niqRzw+ileNPu1fhspnRs8nOjjIA=\nNote the Content-Type header in the request and in the StringToSign. Also note that the Content-\nMD5 is left blank in the StringToSign, because it is not present in the request.\nList\nThis example lists the content of the awsexamplebucket1 bucket.\nRequest StringToSign\nGET /?prefix=photos&max-keys=50&marker=puppy GET\\n\nHTTP/1.1 \\n\nUser-Agent: Mozilla/5.0 \\n\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2950",
      "start_idx": 3314707,
      "end_idx": 3315750,
      "metadata": {
        "num_sentences": 5,
        "num_words": 123,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2957",
      "text": "Amazon Simple Storage Service API Reference\nRequest StringToSign\n/awsexamplebucket1/photos/puppy.jpg\nx-amz-date: Tue, 27 Mar 2007 21:20:26\n+0000\nAuthorization: AWS AKIAIOSFODNN7EXAMP\nLE:XbyTlbQdu9Xw5o8P4iMwPktxQd8=\nNote how we used the alternate 'x-amz-date' method of specifying the date (because our client\nlibrary prevented us from setting the date, say). In this case, the x-amz-date takes precedence\nover the Date header. Therefore, date entry in the signature must contain the value of the x-amz-\ndate header.\nUpload\nThis example uploads an object to a CNAME style virtual hosted bucket with metadata.\nRequest StringToSign\nPUT /db-backup.dat.gz HTTP/1.1 PUT\\n\nUser-Agent: curl/7.15.5 4gJE4saaMU4BqNR0kLY+lw==\\n\nHost: static.example.com:8080 application/x-download\\n\nDate: Tue, 27 Mar 2007 21:06:08 +0000 Tue, 27 Mar 2007 21:06:08 +0000\\n\nx-amz-acl: public-read x-amz-acl:public-read\\n\ncontent-type: application/x-download x-amz-meta-checksumalgorithm:c\nContent-MD5: 4gJE4saaMU4BqNR0kLY+lw== rc32\\n\nX-Amz-Meta-ReviewedBy: joe@example.com x-amz-meta-filechecksum:0x026\nX-Amz-Meta-ReviewedBy: jane@exam 61779\\n\nple.com x-amz-meta-reviewedby:\nX-Amz-Meta-FileChecksum: 0x02661779 joe@example.com,jane@example.com\nX-Amz-Meta-ChecksumAlgorithm: crc32 \\n\nContent-Disposition: attachment; /static.example.com/db-backup.dat\nfilename=database.dat .gz\nContent-Encoding: gzip\nContent-Length: 5913339\nAuthorization: AWS AKIAIOSFODNN7EXAMP\nLE:\njtBQa0Aq+DkULFI8qrpwIjGEx0E=\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2952",
      "start_idx": 3317017,
      "end_idx": 3318575,
      "metadata": {
        "num_sentences": 5,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2958",
      "text": "Amazon Simple Storage Service API Reference\nNotice how the 'x-amz-' headers are sorted, trimmed of extra spaces, and converted to lowercase.\nNote also that multiple headers with the same name have been joined using commas to separate\nvalues.\nNote how only the Content-Type and Content-MD5 HTTP entity headers appear in the\nStringToSign. The other Content-* entity headers do not.\nAgain, note that the CanonicalizedResource includes the bucket name, but the HTTP Request-\nURI does not. (The bucket is specified by the Host header.)\nList all my buckets\nRequest StringToSign\nGET / HTTP/1.1 GET\\n\nHost: s3.us-west-1.amazonaws.com \\n\nDate: Wed, 28 Mar 2007 01:29:59 +0000 \\n\nWed, 28 Mar 2007 01:29:59\nAuthorization: AWS AKIAIOSFODNN7EXAMPLE:qGdzdE +0000\\n\nRIC03wnaRNKh6OqZehG9s= /\nUnicode keys\nRequest StringToSign\nGET /dictionary/fran%C3%A7ais/pr GET\\n\n%c3%a9f%c3%a8re HTTP/1.1 \\n\nHost: s3.us-west-1.amazonaws.com \\n\nDate: Wed, 28 Mar 2007 01:49:49 +0000 Wed, 28 Mar 2007 01:49:49 +0000\\n\nAuthorization: AWS AKIAIOSFODNN7EXAMP /dictionary/fran%C3%A7ais/pr\nLE:DNEZGsoieTZ92F3bUfSPQcbGmlM= %c3%a9f%c3%a8re\nNote\nThe elements in StringToSign that were derived from the Request-URI are taken literally,\nincluding URL-Encoding and capitalization.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2953",
      "start_idx": 3318577,
      "end_idx": 3319908,
      "metadata": {
        "num_sentences": 8,
        "num_words": 178,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2959",
      "text": "Amazon Simple Storage Service API Reference\nREST request signing problems\nWhen REST request authentication fails, the system responds to the request with an XML error\ndocument. The information contained in this error document is meant to help developers diagnose\nthe problem. In particular, the StringToSign element of the SignatureDoesNotMatch error\ndocument tells you exactly what request canonicalization the system is using.\nSome toolkits silently insert headers that you do not know about beforehand, such as adding the\nheader Content-Type during a PUT. In most of these cases, the value of the inserted header\nremains constant, allowing you to discover the missing headers by using tools such as Ethereal or\ntcpmon.\nQuery string request authentication alternative\nYou can authenticate certain types of requests by passing the required information as query-string\nparameters instead of using the Authorization HTTP header. This is useful for enabling direct\nthird-party browser access to your private Amazon S3 data without proxying the request. The idea\nis to construct a \"presigned\" request and encode it as a URL that an end-user's browser can retrieve.\nAdditionally, you can limit a presigned request by specifying an expiration time.\nFor more information on using query parameters to authenticate requests , see Authenticating\nRequests: Using Query Parameters (AWS Signature Version 4) in the Amazon Simple Storage Service\nAPI Reference. For examples of using the AWS SDKs to generating presigned URLs, see Sharing\nobjects with presigned URLs .\nCreating a signature\nFollowing is an example query string authenticated Amazon S3 REST request.\nGET /photos/puppy.jpg\n?AWSAccessKeyId=AKIAIOSFODNN7EXAMPLE&Expires=1141889120&Signature=vjbyPxybdZaNmGa\n%2ByT272YEAiv4%3D HTTP/1.1\nHost: awsexamplebucket1.s3.us-west-1.amazonaws.com\nDate: Mon, 26 Mar 2007 19:37:58 +0000\nThe query string request authentication method doesn't require any special HTTP headers. Instead,\nthe required authentication elements are specified as query string parameters:\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2954",
      "start_idx": 3319910,
      "end_idx": 3322052,
      "metadata": {
        "num_sentences": 14,
        "num_words": 299,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2960",
      "text": "Amazon Simple Storage Service API Reference\nQuery string Example value Description\nparameter\nname\nAWSAccess AKIAIOSFODNN7EXAMPLE Your AWS access key ID. Specifies\nKeyId the AWS secret access key used to\nsign the request and, indirectly, the\nidentity of the developer making the\nrequest.\nExpires 1141889120 The time when the signature expires,\nspecified as the number of seconds\nsince the epoch (00:00:00 UTC on\nJanuary 1, 1970). A request received\nafter this time (according to the\nserver) will be rejected.\nSignature vjbyPxybdZaNmGa%2B The URL encoding of the Base64\nyT272YEAiv4%3D encoding of the HMAC-SHA1 of\nStringToSign.\nThe query string request authentication method differs slightly from the ordinary method but only\nin the format of the Signature request parameter and the StringToSign element. Following is\npseudo-grammar that illustrates the query string request authentication method.\nSignature = URL-Encode( Base64( HMAC-SHA1( YourSecretAccessKey, UTF-8-Encoding-\nOf( StringToSign ) ) ) );\nStringToSign = HTTP-VERB + \"\\n\" +\nContent-MD5 + \"\\n\" +\nContent-Type + \"\\n\" +\nExpires + \"\\n\" +\nCanonicalizedAmzHeaders +\nCanonicalizedResource;\nYourSecretAccessKey is the AWS secret access key ID that Amazon assigns to you when you\nsign up to be an Amazon Web Service developer. Notice how the Signature is URL-Encoded to\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2955",
      "start_idx": 3322054,
      "end_idx": 3323471,
      "metadata": {
        "num_sentences": 9,
        "num_words": 208,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2961",
      "text": "Amazon Simple Storage Service API Reference\nmake it suitable for placement in the query string. Note also that in StringToSign, the HTTP\nDate positional element has been replaced with Expires. The CanonicalizedAmzHeaders and\nCanonicalizedResource are the same.\nNote\nIn the query string authentication method, you do not use the Date or the x-amz-date\nrequest header when calculating the string to sign.\nQuery string request authentication\nRequest StringToSign\nGET /photos/puppy.jpg?AWSAccess GET\\n\nKeyId=AKIAIOSFODNN7EXAMPLE& \\n\nSignature=NpgCjnDzrM%2BWFzo \\n\nENXmpNDUsSn8%3D& 1175139620\\n\nExpires=1175139620 HTTP/1.1\n/awsexamplebucket1/photos/puppy.jpg\nHost: awsexamplebucket1.s3.us-wes\nt-1.amazonaws.com\nWe assume that when a browser makes the GET request, it won't provide a Content-MD5 or a\nContent-Type header, nor will it set any x-amz- headers, so those parts of the StringToSign are\nleft blank.\nUsing Base64 encoding\nHMAC request signatures must be Base64 encoded. Base64 encoding converts the signature into\na simple ASCII string that can be attached to the request. Characters that could appear in the\nsignature string like plus (+), forward slash (/), and equals (=) must be encoded if used in a URI.\nFor example, if the authentication code includes a plus (+) sign, encode it as %2B in the request.\nEncode a forward slash as %2F and equals as %3D.\nFor examples of Base64 encoding, refer to the Amazon S3 Authentication examples.\nSigning and authenticating REST requests (AWS signature version 2) API Version 2006-03-01 2956",
      "start_idx": 3323473,
      "end_idx": 3325008,
      "metadata": {
        "num_sentences": 12,
        "num_words": 222,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2962",
      "text": "Amazon Simple Storage Service API Reference\nBrowser-based uploads using POST (AWS signature version 2)\nAmazon S3 supports POST, which allows your users to upload content directly to Amazon S3. POST\nis designed to simplify uploads, reduce upload latency, and save you money on applications where\nusers upload data to store in Amazon S3.\nNote\nThe request authentication discussed in this section is based on AWS Signature Version 2, a\nprotocol for authenticating inbound API requests to AWS services.\nAmazon S3 now supports Signature Version 4, a protocol for authenticating inbound API\nrequests to AWS services, in all AWS Regions. At this time, AWS Regions created before\nJanuary 30, 2014 will continue to support the previous protocol, Signature Version 2. Any\nnew regions after January 30, 2014 will support only Signature Version 4 and therefore all\nrequests to those regions must be made with Signature Version 4. For more information,\nsee Authenticating Requests in Browser-Based Uploads Using POST (AWS Signature Version\n4) in the Amazon Simple Storage Service API Reference.\nThe following figure shows an upload using Amazon S3 POST.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2957",
      "start_idx": 3325010,
      "end_idx": 3326237,
      "metadata": {
        "num_sentences": 9,
        "num_words": 191,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2964",
      "text": "Amazon Simple Storage Service API Reference\nHTML forms (AWS signature version 2)\nTopics\n\u2022 HTML form encoding\n\u2022 HTML form declaration\n\u2022 HTML form fields\n\u2022 Policy construction\n\u2022 Constructing a signature\n\u2022 Redirection\nWhen you communicate with Amazon S3, you normally use the REST or SOAP API to perform put,\nget, delete, and other operations. With POST, users upload data directly to Amazon S3 through\ntheir browsers, which cannot process the SOAP API or create a REST PUT request.\nNote\nSOAP support over HTTP is deprecated, but it is still available over HTTPS. New Amazon S3\nfeatures will not be supported for SOAP. We recommend that you use either the REST API\nor the AWS SDKs.\nTo allow users to upload content to Amazon S3 by using their browsers, you use HTML forms.\nHTML forms consist of a form declaration and form fields. The form declaration contains high-level\ninformation about the request. The form fields contain detailed information about the request, as\nwell as the policy that is used to authenticate it and ensure that it meets the conditions that you\nspecify.\nNote\nThe form data and boundaries (excluding the contents of the file) cannot exceed 20 KB.\nThis section explains how to use HTML forms.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2959",
      "start_idx": 3326688,
      "end_idx": 3327987,
      "metadata": {
        "num_sentences": 12,
        "num_words": 219,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2965",
      "text": "Amazon Simple Storage Service API Reference\nHTML form encoding\nThe form and policy must be UTF-8 encoded. You can apply UTF-8 encoding to the form by\nspecifying it in the HTML heading or as a request header.\nNote\nThe HTML form declaration does not accept query string authentication parameters.\nThe following is an example of UTF-8 encoding in the HTML heading:\n<html>\n<head>\n...\n<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\n...\n</head>\n<body>\nThe following is an example of UTF-8 encoding in a request header:\nContent-Type: text/html; charset=UTF-8\nHTML form declaration\nThe form declaration has three components: the action, the method, and the enclosure type. If any\nof these values is improperly set, the request fails.\nThe action specifies the URL that processes the request, which must be set to the URL\nof the bucket. For example, if the name of your bucket is awsexamplebucket1 and the\nRegion is US West (N. California), the URL is https://awsexamplebucket1.s3.us-\nwest-1.amazonaws.com/.\nNote\nThe key name is specified in a form field.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2960",
      "start_idx": 3327989,
      "end_idx": 3329144,
      "metadata": {
        "num_sentences": 9,
        "num_words": 179,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2966",
      "text": "Amazon Simple Storage Service API Reference\nThe method must be POST.\nThe enclosure type (enctype) must be specified and must be set to multipart/form-data for both\nfile uploads and text area uploads. For more information, go to RFC 1867.\nExample\nThe following example is a form declaration for the bucket \"awsexamplebucket1\".\n<form action=\"https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\" method=\"post\"\nenctype=\"multipart/form-data\">\nHTML form fields\nThe following table describes fields that can be used within an HTML form.\nNote\nThe variable ${filename} is automatically replaced with the name of the file provided\nby the user and is recognized by all form fields. If the browser or client provides a full or\npartial path to the file, only the text following the last slash (/) or backslash (\\) will be used.\nFor example, \"C:\\Program Files\\directory1\\file.txt\" will be interpreted as \"file.txt\". If no file\nor file name is provided, the variable is replaced with an empty string.\nField name Description Required\nAWSAccessKeyId\nThe AWS Access Key ID of the owner of the Conditional\nbucket who grants an anonymous user\naccess for a request that satisfies the set of\nconstraints in the policy. This field is required\nif the request includes a policy document.\nacl\nAn Amazon S3 access control list (ACL). If No\nan invalid access control list is specified, an\nerror is generated.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2961",
      "start_idx": 3329146,
      "end_idx": 3330615,
      "metadata": {
        "num_sentences": 14,
        "num_words": 227,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2967",
      "text": "Amazon Simple Storage Service API Reference\nField name Description Required\nType: String\nDefault: private\nValid Values: private | public-re\nad | public-read-write | aws-\nexec-read | authenticated-read\n| bucket-owner-read | bucket-ow\nner-full-control\nCache-Control,\nREST-specific headers. For more information, No\nContent-Type, Content-\nsee PUT Object.\nDisposition, Conten\nt-Encoding, Expires\nkey\nThe name of the uploaded key. Yes\nTo use the filename provided by the user, use\nthe ${filename} variable. For example, if user\nBetty uploads the file lolcatz.jpg and you\nspecify /user/betty/${filename}, the file is\nstored as /user/betty/lolcatz.jpg.\nFor more information, see Working with\nobject metadata .\npolicy\nSecurity policy describing what is permitted No\nin the request. Requests without a securit\ny policy are considered anonymous and will\nsucceed only on publicly writable buckets.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2962",
      "start_idx": 3330617,
      "end_idx": 3331590,
      "metadata": {
        "num_sentences": 9,
        "num_words": 136,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2968",
      "text": "Amazon Simple Storage Service API Reference\nField name Description Required\nsuccess_action_red\nThe URL to which the client is redirected No\nirect, redirect\nupon successful upload. Amazon S3 appends\nthe bucket, key, and etag values as query\nstring parameters to the URL.\nIf success_action_redirect is not specified\n, Amazon S3 returns the empty document\ntype specified in the success_action_status\nfield.\nIf Amazon S3 cannot interpret the URL, it\nignores the field.\nIf the upload fails, Amazon S3 displays an\nerror and does not redirect the user to a URL.\nFor more information, see Redirection.\nNote\nThe redirect field name is deprecate\nd and support for the redirect field\nname will be removed in the future.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2963",
      "start_idx": 3331592,
      "end_idx": 3332387,
      "metadata": {
        "num_sentences": 8,
        "num_words": 126,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2969",
      "text": "Amazon Simple Storage Service API Reference\nField name Description Required\nsuccess_action_status\nThe status code returned to the client upon No\nsuccessful upload if success_action_redirect\nis not specified.\nValid values are 200, 201, or 204 (default).\nIf the value is set to 200 or 204, Amazon S3\nreturns an empty document with a 200 or\n204 status code.\nIf the value is set to 201, Amazon S3 returns\nan XML document with a 201 status code.\nFor information about the content of the\nXML document, see POST Object.\nIf the value is not set or if it is set to an\ninvalid value, Amazon S3 returns an empty\ndocument with a 204 status code.\nNote\nSome versions of the Adobe Flash\nplayer do not properly handle\nHTTP responses with an empty\nbody. To support uploads through\nAdobe Flash, we recommend setting\nsuccess_action_status to\n201.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2964",
      "start_idx": 3332389,
      "end_idx": 3333303,
      "metadata": {
        "num_sentences": 9,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2970",
      "text": "Amazon Simple Storage Service API Reference\nField name Description Required\nsignature\nThe HMAC signature constructed by using Conditional\nthe secret access key that corresponds to\nthe provided AWSAccessKeyId. This field is\nrequired if a policy document is included\nwith the request.\nFor more information, see Identity and Access\nManagement for Amazon S3.\nOther field names prefixed\nUser-specified metadata. No\nwith x-amz-meta-\nAmazon S3 does not validate or use this data.\nFor more information, see PUT Object.\nfile\nFile or text content. Yes\nThe file or content must be the last field in\nthe form. Any fields below it are ignored.\nYou cannot upload more than one file at a\ntime.\nPolicy construction\nTopics\n\u2022 Expiration\n\u2022 Conditions\n\u2022 Condition matching\n\u2022 Character escaping\nThe policy is a UTF-8 and Base64-encoded JSON document that specifies conditions that the\nrequest must meet and is used to authenticate the content. Depending on how you design your\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2965",
      "start_idx": 3333305,
      "end_idx": 3334347,
      "metadata": {
        "num_sentences": 12,
        "num_words": 165,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2971",
      "text": "Amazon Simple Storage Service API Reference\npolicy documents, you can use them per upload, per user, for all uploads, or according to other\ndesigns that meet your needs.\nNote\nAlthough the policy document is optional, we highly recommend it over making a bucket\npublicly writable.\nThe following is an example of a policy document:\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\",\n\"conditions\": [\n{\"acl\": \"public-read\" },\n{\"bucket\": \"awsexamplebucket1\" },\n[\"starts-with\", \"$key\", \"user/eric/\"],\n]\n}\nThe policy document contains the expiration and conditions.\nExpiration\nThe expiration element specifies the expiration date of the policy in ISO 8601 UTC date format. For\nexample, \"2007-12-01T12:00:00.000Z\" specifies that the policy is not valid after midnight UTC on\n2007-12-01. Expiration is required in a policy.\nConditions\nThe conditions in the policy document validate the contents of the uploaded object. Each form\nfield that you specify in the form (except AWSAccessKeyId, signature, file, policy, and field names\nthat have an x-ignore- prefix) must be included in the list of conditions.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2966",
      "start_idx": 3334349,
      "end_idx": 3335523,
      "metadata": {
        "num_sentences": 9,
        "num_words": 172,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2972",
      "text": "Amazon Simple Storage Service API Reference\nNote\nIf you have multiple fields with the same name, the values must be separated by commas.\nFor example, if you have two fields named \"x-amz-meta-tag\" and the first one has a value\nof \"Ninja\" and second has a value of \"Stallman\", you would set the policy document to\nNinja,Stallman.\nAll variables within the form are expanded before the policy is validated. Therefore, all\ncondition matching should be performed against the expanded fields. For example, if\nyou set the key field to user/betty/${filename}, your policy might be [ \"starts-\nwith\", \"$key\", \"user/betty/\" ]. Do not enter [ \"starts-with\", \"$key\",\n\"user/betty/${filename}\" ]. For more information, see Condition matching.\nThe following table describes policy document conditions.\nElement name Description\nacl\nSpecifies conditions that the ACL must meet.\nSupports exact matching and starts-with .\ncontent-length-range\nSpecifies the minimum and maximum allowable size for the\nuploaded content.\nSupports range matching.\nCache-Control, Content-Type,\nREST-specific headers.\nContent-Disposition, Content-\nEncoding, Expires\nSupports exact matching and starts-with .\nkey\nThe name of the uploaded key.\nSupports exact matching and starts-with .\nsuccess_action_redirect, redirect\nThe URL to which the client is redirected upon successful\nupload.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2967",
      "start_idx": 3335525,
      "end_idx": 3336951,
      "metadata": {
        "num_sentences": 18,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2973",
      "text": "Amazon Simple Storage Service API Reference\nElement name Description\nSupports exact matching and starts-with .\nsuccess_action_status\nThe status code returned to the client upon successful\nupload if success_action_redirect is not specified.\nSupports exact matching.\nOther field names prefixed with\nUser-specified metadata.\nx-amz-meta-\nSupports exact matching and starts-with .\nNote\nIf your toolkit adds additional fields (e.g., Flash adds filename), you must add them to the\npolicy document. If you can control this functionality, prefix x-ignore- to the field so\nAmazon S3 ignores the feature and it won't affect future versions of this feature.\nCondition matching\nThe following table describes condition matching types. Although you must specify one condition\nfor each form field that you specify in the form, you can create more complex matching criteria by\nspecifying multiple conditions for a form field.\nCondition Description\nExact Matches Exact matches verify that fields match specific values. This example indicates\nthat the ACL must be set to public-read:\n{\"acl\": \"public-read\" }\nThis example is an alternate way to indicate that the ACL must be set to\npublic-read:\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2968",
      "start_idx": 3336953,
      "end_idx": 3338214,
      "metadata": {
        "num_sentences": 11,
        "num_words": 187,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2974",
      "text": "Amazon Simple Storage Service API Reference\nCondition Description\n[ \"eq\", \"$acl\", \"public-read\" ]\nStarts With If the value must start with a certain value, use starts-with. This example\nindicates that the key must start with user/betty:\n[\"starts-with\", \"$key\", \"user/betty/\"]\nMatching Any To configure the policy to allow any content within a field, use starts-with\nContent with an empty value. This example allows any success_action_redirect:\n[\"starts-with\", \"$success_action_redirect\", \"\"]\nSpecifying For fields that accept ranges, separate the upper and lower ranges with a\nRanges comma. This example allows a file size from 1 to 10 megabytes:\n[\"content-length-range\", 1048579, 10485760]\nCharacter escaping\nThe following table describes characters that must be escaped within a policy document.\nEscape Description\nsequence\n\\\\ Backslash\n\\$ Dollar sign\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2969",
      "start_idx": 3338216,
      "end_idx": 3339156,
      "metadata": {
        "num_sentences": 5,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2976",
      "text": "Amazon Simple Storage Service API Reference\nRedirection\nThis section describes how to handle redirects.\nGeneral redirection\nOn completion of the POST request, the user is redirected to the location that you specified in\nthe success_action_redirect field. If Amazon S3 cannot interpret the URL, it ignores the\nsuccess_action_redirect field.\nIf success_action_redirect is not specified, Amazon S3 returns the empty document type\nspecified in the success_action_status field.\nIf the POST request fails, Amazon S3 displays an error and does not provide a redirect.\nPre-upload redirection\nIf your bucket was created using <CreateBucketConfiguration>, your end users might require a\nredirect. If this occurs, some browsers might handle the redirect incorrectly. This is relatively rare\nbut is most likely to occur right after a bucket is created.\nUpload examples (AWS signature version 2)\nTopics\n\u2022 File upload\n\u2022 Text area upload\nNote\nThe request authentication discussed in this section is based on AWS Signature Version 2, a\nprotocol for authenticating inbound API requests to AWS services.\nAmazon S3 now supports Signature Version 4, a protocol for authenticating inbound API\nrequests to AWS services, in all AWS Regions. At this time, AWS Regions created before\nJanuary 30, 2014 will continue to support the previous protocol, Signature Version 2. Any\nnew regions after January 30, 2014 will support only Signature Version 4 and therefore all\nrequests to those regions must be made with Signature Version 4. For more information,\nsee Examples: Browser-Based Upload using HTTP POST (Using AWS Signature Version 4) in\nthe Amazon Simple Storage Service API Reference.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2971",
      "start_idx": 3339770,
      "end_idx": 3341518,
      "metadata": {
        "num_sentences": 14,
        "num_words": 265,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2980",
      "text": "Amazon Simple Storage Service API Reference\n--9431149156168\nContent-Disposition: form-data; name=\"file\"; filename=\"MyFilename.jpg\"\nContent-Type: image/jpeg\n...file content...\n--9431149156168\nContent-Disposition: form-data; name=\"submit\"\nUpload to Amazon S3\n--9431149156168--\nSample response\nHTTP/1.1 303 Redirect\nx-amz-request-id: 1AEE782442F35865\nx-amz-id-2: cxzFLJRatFHy+NGtaDFRR8YvI9BHmgLxjvJzNiGGICARZ/mVXHj7T+qQKhdpzHFh\nContent-Type: application/xml\nDate: Wed, 14 Nov 2007 21:21:33 GMT\nConnection: close\nLocation: https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nsuccessful_upload.html?bucket=awsexamplebucket1&key=user/eric/\nMyPicture.jpg&etag=&quot;39d459dfbc0faabbb5e179358dfb94c3&quot;\nServer: AmazonS3\nText area upload\nTopics\n\u2022 Policy and form construction\n\u2022 Sample request\n\u2022 Sample response\nThe following example shows the complete process for constructing a policy and form to upload\na text area. Uploading a text area is useful for submitting user-created content, such as blog\npostings.\nPolicy and form construction\nThe following policy supports text area uploads to Amazon S3 for the awsexamplebucket1 bucket.\n{ \"expiration\": \"2007-12-01T12:00:00.000Z\",\n\"conditions\": [\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2975",
      "start_idx": 3346915,
      "end_idx": 3348191,
      "metadata": {
        "num_sentences": 4,
        "num_words": 132,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2981",
      "text": "Amazon Simple Storage Service API Reference\n{\"bucket\": \"awsexamplebucket1\"},\n[\"starts-with\", \"$key\", \"user/eric/\"],\n{\"acl\": \"public-read\"},\n{\"success_action_redirect\": \"https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nnew_post.html\"},\n[\"eq\", \"$Content-Type\", \"text/html\"],\n{\"x-amz-meta-uuid\": \"14365123651274\"},\n[\"starts-with\", \"$x-amz-meta-tag\", \"\"]\n]\n}\nThis policy requires the following:\n\u2022 The upload must occur before 12:00 GMT on 2007-12-01.\n\u2022 The content must be uploaded to the awsexamplebucket1 bucket.\n\u2022 The key must start with \"user/eric/\".\n\u2022 The ACL is set to public-read.\n\u2022 The success_action_redirect is set to https://awsexamplebucket1.s3.us-west-1.amazonaws.com/\nnew_post.html.\n\u2022 The object is HTML text.\n\u2022 The x-amz-meta-uuid tag must be set to 14365123651274.\n\u2022 The x-amz-meta-tag can contain any value.\nFollowing is a Base64-encoded version of this policy.\neyAiZXhwaXJhdGlvbiI6ICIyMDA3LTEyLTAxVDEyOjAwOjAwLjAwMFoiLAogICJjb25kaXR\npb25zIjogWwogICAgeyJidWNrZXQiOiAiam9obnNtaXRoIn0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiRrZXkiLCAidXNlci9lcmljLyJd\nLAogICAgeyJhY2wiOiAicHVibGljLXJlYWQifSwKICAgIHsic3VjY2Vzc19hY3Rpb25fcmVkaXJlY3QiOiAiaHR0cDovL2pvaG5zbWl0a\nC5zMy5hbWF6b25hd3MuY29tL25ld19wb3N0Lmh0bWwifSwKICAgIFsiZXEiLCAiJENvbnRlbnQtVHlwZSIsICJ0ZXh0L2h0bWwiXSwKI\nCAgIHsieC1hbXotbWV0YS11dWlkIjogIjE0MzY1MTIzNjUxMjc0In0sCiAgICBbInN0YXJ0cy13aXRoIiwgIiR4LWFtei1tZXRhLXRhZy\nIsICIiXQogIF0KfQo=\nUsing your credentials, create a signature. For example, qA7FWXKq6VvU68lI9KdveT1cWgF= is the\nsignature for the preceding policy document.\nThe following form supports a POST request to the amzn-s3-demo-bucket bucket that uses this\npolicy.\n<html>\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2976",
      "start_idx": 3348193,
      "end_idx": 3349918,
      "metadata": {
        "num_sentences": 13,
        "num_words": 154,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2984",
      "text": "Amazon Simple Storage Service API Reference\n--178521717625888\nContent-Disposition: form-data; name=\"submit\"\nUpload to Amazon S3\n--178521717625888--\nSample response\nHTTP/1.1 303 Redirect\nx-amz-request-id: 1AEE782442F35865\nx-amz-id-2: cxzFLJRatFHy+NGtaDFRR8YvI9BHmgLxjvJzNiGGICARZ/mVXHj7T+qQKhdpzHFh\nContent-Type: application/xml\nDate: Wed, 14 Nov 2007 21:21:33 GMT\nConnection: close\nLocation: https://awsexamplebucket1.s3.us-west-1.amazonaws.com/new_post.html?\nbucket=awsexamplebucket1&key=user/eric/\nNewEntry.html&etag=40c3271af26b7f1672e41b8a274d28d4\nServer: AmazonS3\nPOST with adobe flash (AWS signature version 2)\nThis section describes how to use POST with Adobe Flash.\nAdobe flash player security\nBy default, the Adobe Flash Player security model prohibits Adobe Flash Players from making\nnetwork connections to servers outside the domain that serves the SWF file.\nTo override the default, you must upload a publicly readable crossdomain.xml file to the bucket\nthat will accept POST uploads. The following is a sample crossdomain.xml file.\n<?xml version=\"1.0\"?>\n<!DOCTYPE cross-domain-policy SYSTEM\n\"http://www.macromedia.com/xml/dtds/cross-domain-policy.dtd\">\n<cross-domain-policy>\n<allow-access-from domain=\"*\" secure=\"false\" />\n</cross-domain-policy>\nNote\nFor more information about the Adobe Flash security model, go to the Adobe website.\nBrowser-based uploads using POST (AWS signature version 2) API Version 2006-03-01 2979",
      "start_idx": 3353318,
      "end_idx": 3354752,
      "metadata": {
        "num_sentences": 7,
        "num_words": 155,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2985",
      "text": "Amazon Simple Storage Service API Reference\nAdding the crossdomain.xml file to your bucket allows any Adobe Flash Player to connect\nto the crossdomain.xml file within your bucket; however, it does not grant access to the\nactual Amazon S3 bucket.\nAdobe flash considerations\nThe FileReference API in Adobe Flash adds the Filename form field to the POST request. When\nyou build Adobe Flash applications that upload to Amazon S3 by using the FileReference API\naction, include the following condition in your policy:\n['starts-with', '$Filename', '']\nSome versions of the Adobe Flash Player do not properly handle HTTP responses that have an\nempty body. To configure POST to return a response that does not have an empty body, set\nsuccess_action_status to 201. Amazon S3 will then return an XML document with a 201\nstatus code. For information about the content of the XML document, see POST Object. For\ninformation about form fields, see HTML form fields.\nAppendix: Lifecycle Configuration APIs (Deprecated)\nBucket lifecycle configuration is updated to support filters based on object tags. That is, you can\nnow specify a rule that specifies key name prefix, one or more object tags, or both to select a\nsubset of objects to which the rule applies. The APIs have been updated accordingly. The following\ntopics describes the prior version of the PUT and GET bucket lifecycle operations for backward\ncompatibility.\nTopics\n\u2022 PUT Bucket lifecycle (Deprecated)\n\u2022 GET Bucket lifecycle (Deprecated)\nAppendix: Lifecycle Configuration APIs (Deprecated) API Version 2006-03-01 2980",
      "start_idx": 3354754,
      "end_idx": 3356320,
      "metadata": {
        "num_sentences": 12,
        "num_words": 246,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2986",
      "text": "Amazon Simple Storage Service API Reference\nPUT Bucket lifecycle (Deprecated)\nDescription\nImportant\nFor an updated version of this API, see PutBucketLifecycleConfiguration. This version\nhas been deprecated. Existing lifecycle configurations will work. For new lifecycle\nconfigurations, use the updated API.\nCreates a new lifecycle configuration for the bucket or replaces an existing lifecycle configuration.\nFor information about lifecycle configuration, see Object Lifecycle Management in the Amazon\nSimple Storage Service User Guide.\nPermissions\nBy default, all Amazon S3 resources, including buckets, objects, and related subresources (for\nexample, lifecycle configuration and website configuration) are private. Only the resource owner,\nthe AWS account that created the resource, can access it. The resource owner can optionally grant\naccess permissions to others by writing an access policy. For this operation, users must get the\ns3:PutLifecycleConfiguration permission.\nYou can also explicitly deny permissions. Explicit denial also supersedes any other permissions. If\nyou want to prevent users or accounts from removing or deleting objects from your bucket, you\nmust deny them permissions for the following actions:\n\u2022 s3:DeleteObject\n\u2022 s3:DeleteObjectVersion\n\u2022 s3:PutLifecycleConfiguration\nFor more information about permissions, see Managing Access Permissions to Your Amazon S3\nResources in the Amazon Simple Storage Service User Guide.\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2981",
      "start_idx": 3356322,
      "end_idx": 3357832,
      "metadata": {
        "num_sentences": 14,
        "num_words": 204,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2987",
      "text": "Amazon Simple Storage Service API Reference\nRequests\nSyntax\nPUT /?lifecycle HTTP/1.1\nHost: bucketname.s3.amazonaws.com\nContent-Length: length\nDate: date\nAuthorization: authorization string\nContent-MD5: MD5\nLifecycle configuration in the request body\nFor details about authorization strings, see Authenticating Requests (AWS Signature Version 4).\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nRequest Headers\nName Description Required\nContent-MD5 Yes\nThe base64-encoded 128-bit MD5 digest\nof the data. You must use this header as a\nmessage integrity check to verify that the\nrequest body was not corrupted in transit. For\nmore information, see RFC 1864.\nType: String\nDefault: None\nRequest Body\nIn the request, you specify the lifecycle configuration in the request body. The lifecycle\nconfiguration is specified as XML. The following is an example of a basic lifecycle configuration.\nIt specifies one rule. The Prefix in the rule identifies objects to which the rule applies. The rule\nalso specifies two actions (Transitionand Expiration). Each action specifies a timeline when\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2982",
      "start_idx": 3357834,
      "end_idx": 3359015,
      "metadata": {
        "num_sentences": 12,
        "num_words": 167,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2988",
      "text": "Amazon Simple Storage Service API Reference\nAmazon S3 should perform the action. The Status indicates whether the rule is enabled or\ndisabled.\n<LifecycleConfiguration>\n<Rule>\n<ID>sample-rule</ID>\n<Prefix>key-prefix</Prefix>\n<Status>rule-status</Status>\n<Transition>\n<Date>value</Date>\n<StorageClass>storage class</StorageClass>\n</Transition>\n<Expiration>\n<Days>value</Days>\n</Expiration>\n</Rule>\n</LifecycleConfiguration>\nIf the state of your bucket is versioning-enabled or versioning-suspended, you can have many\nversions of the same object: one current version and zero or more noncurrent versions. The\nfollowing lifecycle configuration specifies the actions (NoncurrentVersionTransition,\nNoncurrentVersionExpiration) that are specific to noncurrent object versions.\n<LifecycleConfiguration>\n<Rule>\n<ID>sample-rule</ID>\n<Prefix>key-prefix</Prefix>\n<Status>rule-status</Status>\n<NoncurrentVersionTransition>\n<NoncurrentDays>value</NoncurrentDays>\n<StorageClass>storage class</StorageClass>\n</NoncurrentVersionTransition>\n<NoncurrentVersionExpiration>\n<NoncurrentDays>value</NoncurrentDays>\n</NoncurrentVersionExpiration>\n</Rule>\n</LifecycleConfiguration>\nYou can use the multipart upload API to upload large objects in parts. For more information\nabout multipart uploads, see Multipart Upload Overview in the Amazon Simple Storage Service\nUser Guide. With lifecycle configuration, you can tell Amazon S3 to cancel incomplete multipart\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2983",
      "start_idx": 3359017,
      "end_idx": 3360515,
      "metadata": {
        "num_sentences": 7,
        "num_words": 147,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2989",
      "text": "Amazon Simple Storage Service API Reference\nuploads, which are identified by the key name prefix specified in the rule, if they don't complete\nwithin a specified number of days. When Amazon S3 cancels a multipart upload, it deletes\nall parts associated with the upload. This ensures that you don't have incomplete multipart\nuploads that have left parts stored in Amazon S3, so you don't have to pay storage costs\nfor them. The following is an example lifecycle configuration that specifies a rule with the\nAbortIncompleteMultipartUpload action. This action tells Amazon S3 to cancel incomplete\nmultipart uploads seven days after initiation.\n<LifecycleConfiguration>\n<Rule>\n<ID>sample-rule</ID>\n<Prefix>SomeKeyPrefix/</Prefix>\n<Status>rule-status</Status>\n<AbortIncompleteMultipartUpload>\n<DaysAfterInitiation>7</DaysAfterInitiation>\n</AbortIncompleteMultipartUpload>\n</Rule>\n</LifecycleConfiguration>\nThe following table describes the XML elements in the lifecycle configuration.\nName Description Required\nAbortIncompleteMul Yes, if\nContainer for specifying when an incomplet\ntipartUpload no other\ne multipart upload becomes eligible for an\naction is\nabort operation.\nspecified\nfor the rule\nChild: DaysAfterInitiation\nType: Container\nAncestor: Rule\nDate Yes, if\nDate when you want Amazon S3 to take the\nDays and\naction. For more information, see Lifecycle\nExpiredOb\nRules: Based on a Specific Date in the\njectDelet\nAmazon Simple Storage Service User Guide.\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2984",
      "start_idx": 3360517,
      "end_idx": 3362035,
      "metadata": {
        "num_sentences": 10,
        "num_words": 201,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2990",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nThe date value must conform to ISO 8601 eMarker\nformat. The time is always midnight UTC. are absent\nType: String\nAncestor: Expiration or Transition\nDays Yes, if\nSpecifies the number of days after object\nDate and\ncreation when the specific rule action takes\nExpiredOb\neffect.\njectDelet\neMarker\nType: Nonnegative Integer when used with\nare absent\nTransition , Positive Integer when used\nwith Expiration\nAncestor: Expiration , Transition\nDaysAfterInitiation Yes, if a\nSpecifies the number of days after initiating a\nparent tag\nmultipart upload when the multipart upload\nis specified\nmust be completed. If it does not complete\nby the specified number of days, it becomes\neligible for an abort operation and Amazon\nS3 cancels the incomplete multipart upload.\nType: Positive Integer\nAncestor: AbortIncompleteMul\ntipartUpload\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2985",
      "start_idx": 3362037,
      "end_idx": 3362987,
      "metadata": {
        "num_sentences": 6,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2991",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nExpiration Yes, if\nThis action specifies a period in an object's\nno other\nlifetime when Amazon S3 should take the\naction is\nappropriate expiration action. The action\npresent in\nAmazon S3 takes depends on whether the\nthe Rule.\nbucket is versioning-enabled.\n\u2022\nIf versioning has never been enabled on\nthe bucket, Amazon S3 deletes the only\ncopy of the object permanently.\n\u2022\nIf the bucket is versioning-enabled (or\nversioning is suspended), the action applies\nonly to the current version of the object. A\nversioning-enabled bucket can have many\nversions of the same object: one current\nversion and zero or more noncurrent\nversions.\nInstead of deleting the current version,\nAmazon S3 makes it a noncurrent version\nby adding a delete marker as the new\ncurrent version.\nImportant\nIf a bucket's state is versioning-\nsuspended, Amazon S3 creates\na delete marker with version\nID null. If you have a version\nwith version ID null, Amazon S3\noverwrites that version.\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2986",
      "start_idx": 3362989,
      "end_idx": 3364074,
      "metadata": {
        "num_sentences": 10,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2992",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nNote\nTo set the expiration for noncurren\nt objects, use the Noncurren\ntVersionExpiration action.\nType: Container\nChildren: Days or Date\nAncestor: Rule\nID No\nUnique identifier for the rule. The value\ncannot be longer than 255 characters.\nType: String\nAncestor: Rule\nLifecycleConfiguration Yes\nContainer for lifecycle rules. You can add as\nmany as 1000 rules.\nType: Container\nChildren: Rule\nAncestor: None\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2987",
      "start_idx": 3364076,
      "end_idx": 3364611,
      "metadata": {
        "num_sentences": 6,
        "num_words": 78,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2993",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nExpiredObjectDelet Yes, if\nOn a versioned bucket (a versioning-enabled\neMarker Date and\nor versioning-suspended bucket), you can\nDays are\nadd this element in the lifecycle configuration\nabsent\nto tell Amazon S3 to delete expired object\ndelete markers. For an example, see Example\n8: Removing Expired Object Delete Markers\nin the Amazon Simple Storage Service User\nGuide. Don't add it to a non-versioned bucket,\nbecause that type of bucket cannot include d\nelete markers.\nType: String\nValid values: true | false (the value false is\nallowed, but it is no-op, which means that\nAmazon S3 will not take action)\nAncestor: Expiration\nNoncurrentDays Yes\nSpecifies the number of days an object is\nnoncurrent before Amazon S3 can perform\nthe associated action. For information about\nthe noncurrent days calculations, see How\nAmazon S3 Calculates When an Object\nBecame Noncurrent in the Amazon Simple\nStorage Service User Guide.\nType: Nonnegative Integer when used with\nNoncurrentVersionTransition ,\nPositive Integer when used with N oncurren\ntVersionExpiration\nAncestor: NoncurrentVersionE\nxpiration or NoncurrentVersionT\nransition\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2988",
      "start_idx": 3364613,
      "end_idx": 3365866,
      "metadata": {
        "num_sentences": 6,
        "num_words": 183,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2994",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nNoncurrentVersionE Yes, if\nSpecifies when noncurrent object versions\nxpiration no other\nexpire. Upon expiration, Amazon S3 perman\naction is\nently deletes the noncurrent object versions.\npresent in\nthe Rule\nSet this lifecycle configuration action on a\nbucket that has versioning enabled (or suspe\nnded) to tell Amazon S3 to delete noncurren\nt object versions at a specific period in the\nobject's lifetime.\nType: Container\nChildren: NoncurrentDays\nAncestor: Rule\nNoncurrentVersionT Yes, if\nContainer for the transition rule that\nransition no other\ndescribes when noncurrent objects transitio\naction is\nn to the STANDARD_IA , ONEZONE_IA , or\npresent in\nGLACIER storage class.\nthe Rule\nIf your bucket is versioning-enabled (or if\nversioning is suspended), you can set this acti\non to tell Amazon S3 to transition noncurren\nt object versions at a specific period in the\nobject's lifetime.\nType: Container\nChildren: NoncurrentDays and StorageClass\nAncestor: Rule\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2989",
      "start_idx": 3365868,
      "end_idx": 3366956,
      "metadata": {
        "num_sentences": 6,
        "num_words": 161,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2995",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nPrefix Yes\nObject key prefix that identifies one or more\nobjects to which the rule applies.\nType: String\nAncestor: Rule\nRule Yes\nContainer for a lifecycle rule. A lifecycle\nconfiguration can contain as many as 1000\nrules.\nType: Container\nAncestor:LifecycleConfiguration\nStatus Yes\nIf enabled, Amazon S3 executes the rule as\nscheduled. If it is disabled, Amazon S3 ignores\nthe rule.\nType: String\nAncestor: Rule\nValid values: Enabled, Disabled\nStorageClass\nSpecifies the Amazon S3 storage class to Yes\nwhich you want the object to transition.\nThis\nType: String element is\nrequired\nAncestor: Transition and NoncurrentVersionT\nonly if you\nransition\nspecify one\nor both its\nValid values: STANDARD_IA | ONEZONE_IA |\nancestors.\nGLACIER\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2990",
      "start_idx": 3366958,
      "end_idx": 3367818,
      "metadata": {
        "num_sentences": 8,
        "num_words": 128,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2996",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nTransition Yes, if\nThis action specifies a period in the objects'\nno other\nlifetime when Amazon S3 should transition\naction is\nthem to the STANDARD_IA , ONEZONE_IA ,\npresent in\nor GLACIER storage class. When this action\nthe Rule\nis in effect, what Amazon S3 does depends on\nwhether the bucket is versioning-enabled.\n\u2022\nIf versioning has never been enabled on\nthe bucket, Amazon S3 transitions the only\ncopy of the object to the specified storage\nclass.\n\u2022\nIf your bucket is versioning-enabled (or\nversioning is suspended), Amazon S3\ntransitions only the current versions of\nobjects identified in the rule.\nNote\nA versioning-enabled bucket\ncan have many versions of an\nobject. This action has no effect\non noncurrent object versions.\nTo transition noncurrent objects,\nyou must use the N oncurren\ntVersionTransition action.\nType: Container\nChildren: Days or Date, and StorageClass\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2991",
      "start_idx": 3367820,
      "end_idx": 3368828,
      "metadata": {
        "num_sentences": 8,
        "num_words": 157,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2997",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nAncestor: Rule\nResponses\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most\nresponses. For more information, see Common Response Headers.\nResponse Elements\nThis implementation of the operation does not return response elements.\nSpecial Errors\nThis implementation of the operation does not return special errors. For general information about\nAmazon S3 errors and a list of error codes, see Error Responses.\nExamples\nExample 1: Add Lifecycle Configuration to a Bucket That Is Not Versioning-enabled\nThe following lifecycle configuration specifies two rules, each with one action.\n\u2022 The Transition action tells Amazon S3 to transition objects with the \"documents/\" prefix to the\nGLACIER storage class 30 days after creation.\n\u2022 The Expiration action tells Amazon S3 to delete objects with the \"logs/\" prefix 365 days after\ncreation.\n<LifecycleConfiguration>\n<Rule>\n<ID>id1</ID>\n<Prefix>documents/</Prefix>\n<Status>Enabled</Status>\n<Transition>\n<Days>30</Days>\n<StorageClass>GLACIER</StorageClass>\n</Transition>\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2992",
      "start_idx": 3368830,
      "end_idx": 3370023,
      "metadata": {
        "num_sentences": 9,
        "num_words": 158,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_2999",
      "text": "Amazon Simple Storage Service API Reference\nHTTP/1.1 200 OK\nx-amz-id-2: r+qR7+nhXtJDDIJ0JJYcd+1j5nM/rUFiiiZ/fNbDOsd3JUE8NWMLNHXmvPfwMpdc\nx-amz-request-id: 9E26D08072A8EF9E\nDate: Wed, 14 May 2014 02:11:22 GMT\nContent-Length: 0\nServer: AmazonS3\nExample 2: Add Lifecycle Configuration to a Versioning-enabled Bucket\nThe following lifecycle configuration specifies two rules, each with one action for Amazon S3\nto perform. You specify these actions when your bucket is versioning-enabled or versioning is\nsuspended:\n\u2022 The NoncurrentVersionExpiration action tells Amazon S3 to expire noncurrent versions of\nobjects with the \"logs/\" prefix 100 days after the objects become noncurrent.\n\u2022 The NoncurrentVersionTransition action tells Amazon S3 to transition noncurrent versions\nof objects with the \"documents/\" prefix to the GLACIER storage class 30 days after they become\nnoncurrent.\n<LifeCycleConfiguration>\n<Rule>\n<ID>DeleteAfterBecomingNonCurrent</ID>\n<Prefix>logs/</Prefix>\n<Status>Enabled</Status>\n<NoncurrentVersionExpiration>\n<NoncurrentDays>100</NoncurrentDays>\n</NoncurrentVersionExpiration>\n</Rule>\n<Rule>\n<ID>TransitionAfterBecomingNonCurrent</ID>\n<Prefix>documents/</Prefix>\n<Status>Enabled</Status>\n<NoncurrentVersionTransition>\n<NoncurrentDays>30</NoncurrentDays>\n<StorageClass>GLACIER</StorageClass>\n</NoncurrentVersionTransition>\n</Rule>\n</LifeCycleConfiguration>\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2994",
      "start_idx": 3370979,
      "end_idx": 3372414,
      "metadata": {
        "num_sentences": 4,
        "num_words": 141,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3001",
      "text": "Amazon Simple Storage Service API Reference\nAdditional Examples\nFor more examples of transitioning objects to storage classes such as STANDARD_IA or\nONEZONE_IA, see Examples of Lifecycle Configuration.\nRelated Resources\n\u2022 GetBucketLifecycleConfiguration\n\u2022 POST Object restore\n\u2022 By default, a resource owner\u2014in this case, a bucket owner, which is the AWS account that\ncreated the bucket\u2014can perform any of the operations. A resource owner can also grant others\npermission to perform the operation. For more information, see the following topics in the\nAmazon Simple Storage Service User Guide:\n\u2022 Specifying Permissions in a Policy\n\u2022 Managing Access Permissions to Your Amazon S3 Resources\nPUT Bucket lifecycle (Deprecated) API Version 2006-03-01 2996",
      "start_idx": 3373592,
      "end_idx": 3374341,
      "metadata": {
        "num_sentences": 4,
        "num_words": 110,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3002",
      "text": "Amazon Simple Storage Service API Reference\nGET Bucket lifecycle (Deprecated)\nDescription\nImportant\nFor an updated version of this API, see GetBucketLifecycleConfiguration. If you configured a\nbucket lifecycle using the <filter> element, you should see an updated version of this topic.\nThis topic is provided for backward compatibility.\nReturns the lifecycle configuration information set on the bucket. For information about\nlifecycle configuration, go to Object Lifecycle Management in the Amazon Simple Storage Service\nUser Guide.\nTo use this operation, you must have permission to perform the\ns3:GetLifecycleConfiguration action. The bucket owner has this permission by default. The\nbucket owner can grant this permission to others. For more information about permissions, see\nManaging Access Permissions to Your Amazon S3 Resources in the Amazon Simple Storage Service\nUser Guide.\nRequests\nSyntax\nGET /?lifecycle HTTP/1.1\nHost: bucketname.s3.amazonaws.com\nDate: date\nAuthorization: authorization string (see Authenticating Requests (AWS Signature Version\n4))\nRequest Parameters\nThis implementation of the operation does not use request parameters.\nRequest Headers\nThis implementation of the operation uses only request headers that are common to all operations.\nFor more information, see Common Request Headers.\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 2997",
      "start_idx": 3374343,
      "end_idx": 3375722,
      "metadata": {
        "num_sentences": 13,
        "num_words": 189,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3003",
      "text": "Amazon Simple Storage Service API Reference\nRequest Elements\nThis implementation of the operation does not use request elements.\nResponses\nResponse Headers\nThis implementation of the operation uses only response headers that are common to most\nresponses. For more information, see Common Response Headers.\nResponse Elements\nThis implementation of GET returns the following response elements.\nName Description Required\nAbortIncompleteMul Container for specifying when an incomplet Yes, if\ntipartUpload e multipart upload becomes eligible for an no other\nabort operation. action is\nspecified\nChild: DaysAfterInitiation\nfor the rule\nType: Container\nAncestor: Rule\nDate Yes, if\nDate when you want Amazon S3 to take the\nDays and\naction. For more information, see Lifecycle\nExpiredOb\nRules: Based on a Specific Date in the\njectDelet\nAmazon Simple Storage Service User Guide.\neMarker\nare absent\nThe date value must conform to the ISO 8601\nformat. The time is always midnight UTC.\nType: String\nAncestor: Expiration or Transition\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 2998",
      "start_idx": 3375724,
      "end_idx": 3376806,
      "metadata": {
        "num_sentences": 10,
        "num_words": 159,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3004",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nDays Yes, if\nSpecifies the number of days after object\nDate and\ncreation when the specific rule action takes\nExpiredOb\neffect. The object's eligibility time is calculate\njectDelet\nd as creation time + the number of days with\neMarker\nthe resulting time rounded to midnight UTC\nare absent\nof the next day.\nType: Non-negative Integer when used with\nTransition , Positive Integer when used\nwith Expiration .\nAncestor: Transition or Expiration\nDaysAfterInitiation Yes, if\nSpecifies the number of days after initiating a\nDate is\nmultipart upload when the multipart upload\nabsent\nmust be completed. If it does not complete\nby the specified number of days, it becomes e\nligible for an abort operation and Amazon S3\ncancels the incomplete multipart upload.\nType: Positive Integer\nAncestor: AbortIncompleteMul\ntipartUpload\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 2999",
      "start_idx": 3376808,
      "end_idx": 3377752,
      "metadata": {
        "num_sentences": 6,
        "num_words": 144,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3005",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nExpiration Yes, if the\nThis action specifies a period in the object's\nparent tag\nlifetime when Amazon S3 should take the\nis specified\nappropriate expiration action. The expiration\naction occurs only on objects that are eligible\naccording to the period specified in the child\nDate or Days element. The action Amazon\nS3 takes depends on whether the bucket is\nversioning enabled.\n\u2022\nIf versioning has never been enabled on\nthe bucket, Amazon S3 deletes the only\ncopy of the object permanently.\n\u2022\nOtherwise, if your bucket is versioning-\nenabled (or versioning is suspended), the\naction applies only to the current version\nof the object. Buckets that are versionin\ng-enabled or versioning-suspended can\nhave many versions of the same object:\none current version, and zero or more\nnoncurrent versions.\nInstead of deleting the current version,\nAmazon S3 makes it a noncurrent version\nby adding a delete marker as the new\ncurrent version.\nImportant\nIf the state of a bucket is versionin\ng-suspended, Amazon S3 creates\na delete marker with version ID\nnull. If you have a version with\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3000",
      "start_idx": 3377754,
      "end_idx": 3378960,
      "metadata": {
        "num_sentences": 9,
        "num_words": 194,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3006",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nversion ID null, then Amazon S3\noverwrites that version.\nNote\nTo set the expiration for noncurren\nt objects, you must use the\nNoncurrentVersionE\nxpiration action.\nType: Container\nChildren: Days or Date\nAncestor: Rule\nID No\nUnique identifier for the rule. The value\ncannot be longer than 255 characters.\nType: String\nAncestor: Rule\nLifecycleConfiguration Yes\nContainer for lifecycle rules. You can add as\nmany as 1000 rules.\nType: Container\nChildren: Rule\nAncestor: None\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3001",
      "start_idx": 3378962,
      "end_idx": 3379563,
      "metadata": {
        "num_sentences": 7,
        "num_words": 89,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3007",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nExpiredObjectDelet Yes, if\nOn a versioned bucket (versioning-enabled or\neMarker Date and\nversioning-suspended bucket), this element\nDays are\nindicates whether Amazon S3 will delete any\nabsent\nexpired object delete markers in the bucket.\nFor an example, go to E xample 8: Specify\nExpiration Action to Remove Expired Object\nDelete Markers in the Amazon Simple Storage\nService User Guide.\nType: String\nValid values: true | false (the value false is\nallowed but it is no-op, Amazon S3 doesn't\ntake action if the value is false)\nAncestor: Expiration\nNoncurrentDays Yes, only\nSpecifies the number of days that an object\nif the\nis noncurrent before Amazon S3 can perform\nancestor is\nthe associated action. For information about\npresent\ncalculating noncurrent days, see Lifecycle\nRules Based on the Number of Days in the\nAmazon Simple Storage Service User Guide.\nType: Nonnegative Integer when used with\nNoncurrentVersionTransition ,\nPositive Integer when used with N oncurren\ntVersionExpiration\nAncestor: NoncurrentVersionE\nxpiration or NoncurrentVersionT\nransition\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3002",
      "start_idx": 3379565,
      "end_idx": 3380755,
      "metadata": {
        "num_sentences": 5,
        "num_words": 174,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3008",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nNoncurrentVersionE Yes, if\nSpecifies when noncurrent object versions\nxpiration no other\nexpire. Upon expiration, Amazon S3 perman\naction is\nently deletes the noncurrent object versions.\npresent in\nthe Rule\nSet this lifecycle configuration action on a\nbucket that has versioning enabled (or suspe\nnded) to request that Amazon S3 delete\nnoncurrent object versions at a specific\nperiod in the object's lifetime.\nType: Container\nChildren: NoncurrentDays\nAncestor: Rule\nNoncurrentVersionT Yes, if\nContainer for the transition rule that\nransition no other\ndescribes when noncurrent objects transitio\naction is\nn to the STANDARD_IA , ONEZONE_IA , or\npresent in\nthe GLACIER storage class.\nthe Rule\nIf your bucket is versioning-enabled (or\nversioning is suspended), you can set this\naction to request Amazon S3 to transition\nnoncurrent object versions to the GLACIER\nstorage class at a specific period in the\nobject's lifetime.\nType: Container\nChildren: NoncurrentDays and StorageClass\nAncestor: Rule\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3003",
      "start_idx": 3380757,
      "end_idx": 3381880,
      "metadata": {
        "num_sentences": 6,
        "num_words": 163,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3009",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nPrefix Yes\nObject key prefix identifying one or more\nobjects to which the rule applies.\nType: String\nAncestor: Rule\nRule Yes\nContainer for a lifecycle rule.\nType: Container\nAncestor: LifecycleConfiguration\nStatus Yes\nIf Enabled, Amazon S3 executes the rule as\nscheduled. If Disabled, Amazon S3 ignores the\nrule.\nType: String\nAncestor: Rule\nValid values: Enabled or Disabled\nStorageClass Yes\nSpecifies the Amazon S3 storage class to\nwhich you want to transition the object.\nType: String\nAncestor: Transition and NoncurrentVers\nionTransition\nValid values: STANDARD_IA | ONEZONE_IA\n| GLACIER\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3004",
      "start_idx": 3381882,
      "end_idx": 3382602,
      "metadata": {
        "num_sentences": 6,
        "num_words": 104,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3010",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nTransition Yes, if\nThis action specifies a period in the objects'\nno other\nlifetime when Amazon S3 should transition\naction is\nthem to the STANDARD_IA , ONEZONE_IA ,\npresent in\nor GLACIER storage class. When this action\nthe Rule\nis in effect, what Amazon S3 does depends on\nwhether the bucket is versioning-enabled.\n\u2022\nIf versioning has never been enabled on\nthe bucket, Amazon S3 transitions the only\ncopy of the object to the specified storage\nclass.\n\u2022\nWhen your bucket is versioning-enabled\n(or versioning is suspended), Amazon S3\ntransitions only the current versions of the\nobjects identified in the rule.\nNote\nA versioning-enabled or versioning-\nsuspended bucket can contain many\nversions of an object. This action\nhas no effect on the noncurrent\nobject versions. To transition\nnoncurrent objects, you must\nuse the N oncurrentVersionT\nransition action.\nType: Container\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3005",
      "start_idx": 3382604,
      "end_idx": 3383609,
      "metadata": {
        "num_sentences": 8,
        "num_words": 156,
        "source": "paragraph"
      }
    },
    {
      "chunk_id": "4f161031-4dab-487a-8b04-cff65ef06c6a_chunk_3011",
      "text": "Amazon Simple Storage Service API Reference\nName Description Required\nChildren: Days or Date, and StorageClass\nAncestor: Rule\nSpecial Errors\nError Code Description HTTP SOAP Fault\nStatus Code Code Prefix\nNoSuchLifecycleCon The lifecycle configuration does 404 Not Client\nfiguration not exist. Found\nFor general information about Amazon S3 errors and a list of error codes, see Error responses.\nExamples\nExample 1: Retrieve a Lifecycle Subresource\nThis example is a GET request to retrieve the lifecycle subresource from the specified bucket,\nand an example response with the returned lifecycle configuration.\nSample Request\nGET /?lifecycle HTTP/1.1\nHost: examplebucket.s3.amazonaws.com\nx-amz-date: Thu, 15 Nov 2012 00:17:21 GMT\nAuthorization: signatureValue\nSample Response\nHTTP/1.1 200 OK\nx-amz-id-2: ITnGT1y4RyTmXa3rPi4hklTXouTf0hccUjo0iCPjz6FnfIutBj3M7fPGlWO2SEWp\nx-amz-request-id: 51991C342C575321\nDate: Thu, 15 Nov 2012 00:17:23 GMT\nServer: AmazonS3\nContent-Length: 358\nGET Bucket lifecycle (Deprecated) API Version 2006-03-01 3006",
      "start_idx": 3383611,
      "end_idx": 3384647,
      "metadata": {
        "num_sentences": 4,
        "num_words": 132,
        "source": "paragraph"
      }
    }
  ],
  "metadata": {
    "total_chunks": 1967,
    "avg_chunk_size": 171.87086934417894,
    "chunking_method": "NaiveChunker",
    "processed_at": "2025-05-04T18:45:20.779682",
    "total_paragraphs": 3014,
    "total_sentences": 19822,
    "total_words": 449908,
    "chunking_strategy": "naive_paragraph"
  }
}